{
  "id": "ca82140c-48d0-40ce-9b1f-ef23baf6d128",
  "name": "Criador e Editor de Componentes Langflow",
  "description": "Auxilia na criação ou edição de componentes Langflow 1.0.18\n (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "Amaralkarl",
    "first_name": "Claudinei",
    "last_name": "de Carvalho",
    "id": "66be7526-cacc-46ac-a9f3-bcd93344190c",
    "full_name": "Claudinei de Carvalho"
  },
  "store_url": "https://www.langflow.store/store/component/ca82140c-48d0-40ce-9b1f-ef23baf6d128",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-20T23:43:12.009Z",
    "updated": "2024-09-20T23:43:12.070Z",
    "downloaded": "2025-08-19T17:50:07.215Z"
  },
  "tags": [
    {
      "tags_id": {
        "name": "Memory",
        "id": "e660a9ea-35fb-4587-bfbd-13dba4c556d1"
      }
    }
  ],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-KlWrc",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "As the Langflow Component Helper, my role is to assist users with queries and guidance on Langflow Components. I provide examples, reference documentation, and support to help users navigate and utilize CustomComponents effectively. My conversational style is casual and friendly, aiming to create a comfortable and engaging experience. I rely on concrete examples and documents to inform my responses, ensuring accuracy and relevance. When users have questions about Langflow Components, I guide them through the process, from placing a Custom Component on the canvas to writing and saving the code in the Langflow UI. I am here to clarify any confusion and provide support for users to succeed with CustomComponents.\n\n\n# Custom Components\n\n\nBuild custom components in Langflow for various data processing and transformation tasks.\n\nThis guide provides a comprehensive overview of how to create custom components using Langflow.\n\n## Basic Structure of a Custom Component\n\nA custom component in Langflow typically includes the following parts:\n\n1. **Class Definition**: Inherits from the `Component` class.\n2. **Component Metadata**: Defines display name, description, and icon.\n3. **Inputs and Outputs**: Specifies the inputs and outputs for the component.\n4. **Processing Logic**: Implements the logic for processing data within the component.\n\nA custom component in Python looks like this:\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, IntInput, BoolInput, DropdownInput, HandleInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema import Data, Message\nfrom typing import List, Optional\n\nclass ExampleComponent(Component):\n    display_name = \"Example Component\"\n    description = \"A template for creating custom components.\"\n    icon = \"icon-name\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"Text input for the component.\",\n        ),\n        IntInput(\n            name=\"input_number\",\n            display_name=\"Input Number\",\n            info=\"Numeric input for the component.\",\n        ),\n        BoolInput(\n            name=\"input_boolean\",\n            display_name=\"Input Boolean\",\n            info=\"Boolean input for the component.\",\n        ),\n        DropdownInput(\n            name=\"input_choice\",\n            display_name=\"Input Choice\",\n            options=[\"Option1\", \"Option2\", \"Option3\"],\n            info=\"Dropdown input for the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n    ]\n\n    def process_data(self) -> Data:\n        input_text = self.input_text\n        input_number = self.input_number\n        input_boolean = self.input_boolean\n        input_choice = self.input_choice\n\n        # Implement your processing logic here\n        result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n        self.status = result\n        return Data(data=(\"result\": result))\n\n```\n\n## Create a Custom Component Step-by-Step\n\n1. Create a class that inherits from the `Component` class.\n\n```python\nclass ExampleComponent(Component):\n    # Class content\n```\n\n2. Define metadata such as `display_name`, `description`, and `icon`.\n\n```python\ndisplay_name = \"Example Component\"\ndescription = \"A template for creating custom components.\"\nicon = \"icon-name\"\n```\n\n3. Define the inputs and outputs for the component using the `inputs` and `outputs` lists.\n\n**Inputs** can be of various types such as `TextInput`, `IntInput`, `BoolInput`, `DropdownInput`, etc.\n\n```python\ninputs = [\n    MessageTextInput(\n        name=\"input_text\",\n        display_name=\"Input Text\",\n        info=\"Text input for the component.\",\n    ),\n    IntInput(\n        name=\"input_number\",\n        display_name=\"Input Number\",\n        info=\"Numeric input for the component.\",\n    ),\n    BoolInput(\n        name=\"input_boolean\",\n        display_name=\"Input Boolean\",\n        info=\"Boolean input for the component.\",\n    ),\n    DropdownInput(\n        name=\"input_choice\",\n        display_name=\"Input Choice\",\n        options=[\"Option1\", \"Option2\", \"Option3\"],\n        info=\"Dropdown input for the component.\",\n    ),\n]\n\n```\n\n**Outputs** define the output methods for the component.\n\n```python\noutputs = [\n    Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n]\n```\n\n4. Implement the logic for processing data within the component. Define methods for processing data and returning results.\n\n```python\ndef process_data(self) -> Data:\n    input_text = self.input_text\n    input_number = self.input_number\n    input_boolean = self.input_boolean\n    input_choice = self.input_choice\n\n    # Implement your processing logic here\n    result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n    self.status = result\n    return Data(data=(\"result\": result))\n\n```\n\n## Advanced Example: Create a Conditional Router Component\n\nThis example demonstrates a more complex component that routes data based on a condition.\n\nNotice that this component has two outputs associated with the methods `true_response` and `false_response`.\n\nThese methods trigger `self.stop` to block the transmission for the selected output, allowing for logic operations to be implemented visually.\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.field_typing import Text\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes input based on a specified condition.\"\n    icon = \"router\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"Value to be evaluated.\",\n        ),\n        MessageTextInput(\n            name=\"comparison_value\",\n            display_name=\"Comparison Value\",\n            info=\"Value to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\"],\n            info=\"Comparison operator.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"true_response\"),\n        Output(display_name=\"False Output\", name=\"false_response\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_value: str, comparison_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return input_value == comparison_value\n        elif operator == \"not equals\":\n            return input_value != comparison_value\n        elif operator == \"contains\":\n            return comparison_value in input_value\n        return False\n\n    def true_response(self) -> Text:\n        if self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"false_response\")\n            return self.input_value\n        else:\n            self.stop(\"true_response\")\n            return \"\"\n\n    def false_response(self) -> Text:\n        if not self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"true_response\")\n            return self.input_value\n        else:\n            self.stop(\"false_response\")\n            return \"\"\n\n```\n\nBy following these steps and examples, you can create custom components in Langflow tailored to your specific needs. The modular structure of Custom Components allows for flexible and reusable components that can be easily integrated into your workflows.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 328,
        "id": "Prompt-KlWrc",
        "position": {
          "x": 1288.410977120352,
          "y": 337.48865283611076
        },
        "positionAbsolute": {
          "x": 1288.410977120352,
          "y": 337.48865283611076
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "Memory-8Wvwd",
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "BaseChatMemory"
                ],
                "selected": "BaseChatMemory",
                "name": "lc_memory",
                "display_name": "Memory",
                "method": "build_lc_memory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false
          },
          "type": "Memory",
          "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
          "display_name": "Chat Memory"
        },
        "dragging": false,
        "height": 378,
        "id": "Memory-8Wvwd",
        "position": {
          "x": 1879.9416882974574,
          "y": 144.5166067576386
        },
        "positionAbsolute": {
          "x": 1879.9416882974574,
          "y": 144.5166067576386
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "ChatInput-WJaHo",
        "type": "genericNode",
        "position": {
          "x": 1291.876360699971,
          "y": 720.3773024740386
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "preciso que contenha uma seleção de Timezone",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatInput-WJaHo",
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input"
        },
        "selected": false,
        "width": 384,
        "height": 300,
        "positionAbsolute": {
          "x": 1291.876360699971,
          "y": 720.3773024740386
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-HBbk4",
        "type": "genericNode",
        "position": {
          "x": 3068.6654175280623,
          "y": 424.5073126422287
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatOutput-HBbk4",
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output"
        },
        "selected": false,
        "width": 384,
        "height": 300,
        "positionAbsolute": {
          "x": 3068.6654175280623,
          "y": 424.5073126422287
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-WJMCb",
        "type": "genericNode",
        "position": {
          "x": 1881.9922468253626,
          "y": 553.7552105326374
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": "0.4",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "OpenAIModel-WJMCb"
        },
        "selected": false,
        "width": 384,
        "height": 601,
        "dragging": false,
        "positionAbsolute": {
          "x": 1881.9922468253626,
          "y": 553.7552105326374
        }
      },
      {
        "id": "ToolCallingAgent-JKL6M",
        "type": "genericNode",
        "position": {
          "x": 2517.5081812228436,
          "y": 437.6513379023284
        },
        "data": {
          "type": "ToolCallingAgent",
          "node": {
            "template": {
              "_type": "Component",
              "chat_history": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_history",
                "value": "",
                "display_name": "Chat History",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "system_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "user_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_prompt",
                "value": "{input}",
                "display_name": "Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "This prompt must contain 'input' key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
            "icon": "LangChain",
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "AgentExecutor"
                ],
                "selected": "AgentExecutor",
                "name": "agent",
                "display_name": "Agent",
                "method": "build_agent",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "tools",
              "llm",
              "system_prompt",
              "user_prompt",
              "chat_history"
            ],
            "beta": true,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "ToolCallingAgent-JKL6M"
        },
        "selected": false,
        "width": 384,
        "height": 687,
        "dragging": false,
        "positionAbsolute": {
          "x": 2517.5081812228436,
          "y": 437.6513379023284
        }
      },
      {
        "id": "CalculatorTool-rva0y",
        "type": "genericNode",
        "position": {
          "x": 1280.4389483623318,
          "y": 1049.2030489652316
        },
        "data": {
          "type": "CalculatorTool",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport operator\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\nfrom langchain.tools import StructuredTool\n\n\nclass CalculatorToolComponent(LCToolComponent):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n    name = \"CalculatorTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n        ),\n    ]\n\n    class CalculatorToolSchema(BaseModel):\n        expression: str = Field(..., description=\"The arithmetic expression to evaluate.\")\n\n    def run_model(self) -> List[Data]:\n        return self._evaluate_expression(self.expression)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"calculator\",\n            description=\"Evaluate basic arithmetic expressions. Input should be a string containing the expression.\",\n            func=self._evaluate_expression,\n            args_schema=self.CalculatorToolSchema,\n        )\n\n    def _evaluate_expression(self, expression: str) -> List[Data]:\n        try:\n            # Define the allowed operators\n            operators = {\n                ast.Add: operator.add,\n                ast.Sub: operator.sub,\n                ast.Mult: operator.mul,\n                ast.Div: operator.truediv,\n                ast.Pow: operator.pow,\n            }\n\n            def eval_expr(node):\n                if isinstance(node, ast.Num):\n                    return node.n\n                elif isinstance(node, ast.BinOp):\n                    return operators[type(node.op)](eval_expr(node.left), eval_expr(node.right))\n                elif isinstance(node, ast.UnaryOp):\n                    return operators[type(node.op)](eval_expr(node.operand))\n                else:\n                    raise TypeError(node)\n\n            # Parse the expression and evaluate it\n            tree = ast.parse(expression, mode=\"eval\")\n            result = eval_expr(tree.body)\n\n            # Format the result to a reasonable number of decimal places\n            formatted_result = f\"{result:.6f}\".rstrip(\"0\").rstrip(\".\")\n\n            self.status = formatted_result\n            return [Data(data={\"result\": formatted_result})]\n\n        except (SyntaxError, TypeError, KeyError) as e:\n            error_message = f\"Invalid expression: {str(e)}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n        except Exception as e:\n            error_message = f\"Error: {str(e)}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "expression": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "expression",
                "value": "",
                "display_name": "Expression",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Perform basic arithmetic operations on a given expression.",
            "icon": "calculator",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "Calculator",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "expression"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "CalculatorTool-rva0y"
        },
        "selected": false,
        "width": 384,
        "height": 372,
        "dragging": false,
        "positionAbsolute": {
          "x": 1280.4389483623318,
          "y": 1049.2030489652316
        }
      },
      {
        "id": "WhatsAppSender-LAgtq",
        "type": "genericNode",
        "position": {
          "x": 307.5327815989244,
          "y": 562.695025323701
        },
        "data": {
          "type": "WhatsAppSender",
          "node": {
            "template": {
              "_type": "Component",
              "access_token": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "access_token",
                "value": "",
                "display_name": "Access Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Facebook Graph API Access Token.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, StrInput, SecretStrInput\r\nfrom axiestudio.template import Output\r\nfrom axiestudio.schema import Data\r\nimport requests\r\n\r\nclass WhatsAppSender(Component):\r\n    display_name  = \"WhatsApp Message Sender\"\r\n    description   = \"Send a WhatsApp message using WhatsApp Business API.\"\r\n    documentation = \"https://developers.facebook.com/docs/whatsapp\"\r\n    icon          = \"message-square\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"whatsapp_business_account_id\",\r\n            display_name=\"WhatsApp Business Account ID\",\r\n            info=\"Your WhatsApp Business Account ID.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"access_token\",\r\n            display_name=\"Access Token\",\r\n            info=\"Your Facebook Graph API Access Token.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"to_number\",\r\n            display_name=\"To Number\",\r\n            info=\"Recipient's phone number including the country code (e.g., '+19999999999').\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"message_body\",\r\n            display_name=\"Message Body\",\r\n            info=\"The content of the message to be sent.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Message ID\", name=\"message_id\", method=\"send_message\"),\r\n    ]\r\n\r\n    def send_message(self) -> Data:\r\n        whatsapp_business_account_id = self.whatsapp_business_account_id\r\n        access_token = self.access_token\r\n        to_number = self.to_number\r\n        message_body = self.message_body\r\n\r\n        url = f\"https://graph.facebook.com/v14.0/{whatsapp_business_account_id}/messages\"\r\n        headers = {\r\n            \"Authorization\": f\"Bearer {access_token}\",\r\n            \"Content-Type\": \"application/json\",\r\n        }\r\n        payload = {\r\n            \"messaging_product\": \"whatsapp\",\r\n            \"to\": to_number,\r\n            \"type\": \"text\",\r\n            \"text\": {\r\n                \"body\": message_body\r\n            }\r\n        }\r\n\r\n        response = requests.post(url, json=payload, headers=headers)\r\n        response_data = response.json()\r\n\r\n        if response.status_code == 200:\r\n            message_id = response_data['messages'][0]['id']\r\n            self.status = f'WhatsApp Message sent to {to_number}'\r\n            return Data(data={\"message_id\": message_id})\r\n        else:\r\n            self.status = f\"Failed to send message: {response_data.get('error', {}).get('message')}\"\r\n            return Data(data={\"message_id\": None})\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message_body": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message_body",
                "value": "",
                "display_name": "Message Body",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The content of the message to be sent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "to_number": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "to_number",
                "value": "",
                "display_name": "To Number",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Recipient's phone number including the country code (e.g., '+19999999999').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "whatsapp_business_account_id": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "whatsapp_business_account_id",
                "value": "",
                "display_name": "WhatsApp Business Account ID",
                "advanced": false,
                "dynamic": false,
                "info": "Your WhatsApp Business Account ID.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Send a WhatsApp message using WhatsApp Business API.",
            "icon": "message-square",
            "base_classes": [
              "Data"
            ],
            "display_name": "Send To WhatsApp",
            "documentation": "https://developers.facebook.com/docs/whatsapp",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "message_id",
                "display_name": "Message ID",
                "method": "send_message",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "whatsapp_business_account_id",
              "access_token",
              "to_number",
              "message_body"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.16",
            "official": false
          },
          "id": "WhatsAppSender-LAgtq"
        },
        "selected": true,
        "width": 384,
        "height": 585,
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatInput-WJaHo",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-WJaHoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-WJMCb",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WJMCbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-WJMCb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-WJaHo",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-WJaHo{œdataTypeœ:œChatInputœ,œidœ:œChatInput-WJaHoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-WJMCb{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WJMCbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-KlWrc",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KlWrcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ToolCallingAgent-JKL6M",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "ToolCallingAgent-JKL6M",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-KlWrc",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-KlWrc{œdataTypeœ:œPromptœ,œidœ:œPrompt-KlWrcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Memory-8Wvwd",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-8Wvwdœ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}",
        "target": "ToolCallingAgent-JKL6M",
        "targetHandle": "{œfieldNameœ:œchat_historyœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "chat_history",
            "id": "ToolCallingAgent-JKL6M",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-8Wvwd",
            "name": "messages",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Memory-8Wvwd{œdataTypeœ:œMemoryœ,œidœ:œMemory-8Wvwdœ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œchat_historyœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-WJMCb",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WJMCbœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ToolCallingAgent-JKL6M",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-JKL6M",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-WJMCb",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-WJMCb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WJMCbœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ToolCallingAgent-JKL6M",
        "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-JKL6Mœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-HBbk4",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-HBbk4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-HBbk4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-JKL6M",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ToolCallingAgent-JKL6M{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-JKL6Mœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-HBbk4{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-HBbk4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CalculatorTool-rva0y",
        "sourceHandle": "{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-rva0yœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "ToolCallingAgent-JKL6M",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œToolœ,œBaseToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-JKL6M",
            "inputTypes": [
              "Tool",
              "BaseTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CalculatorTool",
            "id": "CalculatorTool-rva0y",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CalculatorTool-rva0y{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-rva0yœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œToolœ,œBaseToolœ],œtypeœ:œotherœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 323.7008750353525,
      "y": -7.11897111415675,
      "zoom": 0.42078084351059986
    }
  },
  "metadata": {
    "Prompt": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "ToolCallingAgent": {
      "count": 1
    },
    "CalculatorTool": {
      "count": 1
    },
    "WhatsAppSender": {
      "count": 1
    },
    "total": 8
  },
  "original": {
    "id": "ca82140c-48d0-40ce-9b1f-ef23baf6d128",
    "name": "Criador e Editor de Componentes Langflow",
    "description": "Auxilia na criação ou edição de componentes Langflow 1.0.18\n",
    "is_component": false,
    "liked_by_count": "4",
    "downloads_count": "13",
    "metadata": {
      "Prompt": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "ToolCallingAgent": {
        "count": 1
      },
      "CalculatorTool": {
        "count": 1
      },
      "WhatsAppSender": {
        "count": 1
      },
      "total": 8
    },
    "last_tested_version": "1.0.18",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-KlWrc",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "As the Langflow Component Helper, my role is to assist users with queries and guidance on Langflow Components. I provide examples, reference documentation, and support to help users navigate and utilize CustomComponents effectively. My conversational style is casual and friendly, aiming to create a comfortable and engaging experience. I rely on concrete examples and documents to inform my responses, ensuring accuracy and relevance. When users have questions about Langflow Components, I guide them through the process, from placing a Custom Component on the canvas to writing and saving the code in the Langflow UI. I am here to clarify any confusion and provide support for users to succeed with CustomComponents.\n\n\n# Custom Components\n\n\nBuild custom components in Langflow for various data processing and transformation tasks.\n\nThis guide provides a comprehensive overview of how to create custom components using Langflow.\n\n## Basic Structure of a Custom Component\n\nA custom component in Langflow typically includes the following parts:\n\n1. **Class Definition**: Inherits from the `Component` class.\n2. **Component Metadata**: Defines display name, description, and icon.\n3. **Inputs and Outputs**: Specifies the inputs and outputs for the component.\n4. **Processing Logic**: Implements the logic for processing data within the component.\n\nA custom component in Python looks like this:\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, IntInput, BoolInput, DropdownInput, HandleInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema import Data, Message\nfrom typing import List, Optional\n\nclass ExampleComponent(Component):\n    display_name = \"Example Component\"\n    description = \"A template for creating custom components.\"\n    icon = \"icon-name\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"Text input for the component.\",\n        ),\n        IntInput(\n            name=\"input_number\",\n            display_name=\"Input Number\",\n            info=\"Numeric input for the component.\",\n        ),\n        BoolInput(\n            name=\"input_boolean\",\n            display_name=\"Input Boolean\",\n            info=\"Boolean input for the component.\",\n        ),\n        DropdownInput(\n            name=\"input_choice\",\n            display_name=\"Input Choice\",\n            options=[\"Option1\", \"Option2\", \"Option3\"],\n            info=\"Dropdown input for the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n    ]\n\n    def process_data(self) -> Data:\n        input_text = self.input_text\n        input_number = self.input_number\n        input_boolean = self.input_boolean\n        input_choice = self.input_choice\n\n        # Implement your processing logic here\n        result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n        self.status = result\n        return Data(data=(\"result\": result))\n\n```\n\n## Create a Custom Component Step-by-Step\n\n1. Create a class that inherits from the `Component` class.\n\n```python\nclass ExampleComponent(Component):\n    # Class content\n```\n\n2. Define metadata such as `display_name`, `description`, and `icon`.\n\n```python\ndisplay_name = \"Example Component\"\ndescription = \"A template for creating custom components.\"\nicon = \"icon-name\"\n```\n\n3. Define the inputs and outputs for the component using the `inputs` and `outputs` lists.\n\n**Inputs** can be of various types such as `TextInput`, `IntInput`, `BoolInput`, `DropdownInput`, etc.\n\n```python\ninputs = [\n    MessageTextInput(\n        name=\"input_text\",\n        display_name=\"Input Text\",\n        info=\"Text input for the component.\",\n    ),\n    IntInput(\n        name=\"input_number\",\n        display_name=\"Input Number\",\n        info=\"Numeric input for the component.\",\n    ),\n    BoolInput(\n        name=\"input_boolean\",\n        display_name=\"Input Boolean\",\n        info=\"Boolean input for the component.\",\n    ),\n    DropdownInput(\n        name=\"input_choice\",\n        display_name=\"Input Choice\",\n        options=[\"Option1\", \"Option2\", \"Option3\"],\n        info=\"Dropdown input for the component.\",\n    ),\n]\n\n```\n\n**Outputs** define the output methods for the component.\n\n```python\noutputs = [\n    Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n]\n```\n\n4. Implement the logic for processing data within the component. Define methods for processing data and returning results.\n\n```python\ndef process_data(self) -> Data:\n    input_text = self.input_text\n    input_number = self.input_number\n    input_boolean = self.input_boolean\n    input_choice = self.input_choice\n\n    # Implement your processing logic here\n    result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n    self.status = result\n    return Data(data=(\"result\": result))\n\n```\n\n## Advanced Example: Create a Conditional Router Component\n\nThis example demonstrates a more complex component that routes data based on a condition.\n\nNotice that this component has two outputs associated with the methods `true_response` and `false_response`.\n\nThese methods trigger `self.stop` to block the transmission for the selected output, allowing for logic operations to be implemented visually.\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.field_typing import Text\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes input based on a specified condition.\"\n    icon = \"router\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"Value to be evaluated.\",\n        ),\n        MessageTextInput(\n            name=\"comparison_value\",\n            display_name=\"Comparison Value\",\n            info=\"Value to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\"],\n            info=\"Comparison operator.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"true_response\"),\n        Output(display_name=\"False Output\", name=\"false_response\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_value: str, comparison_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return input_value == comparison_value\n        elif operator == \"not equals\":\n            return input_value != comparison_value\n        elif operator == \"contains\":\n            return comparison_value in input_value\n        return False\n\n    def true_response(self) -> Text:\n        if self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"false_response\")\n            return self.input_value\n        else:\n            self.stop(\"true_response\")\n            return \"\"\n\n    def false_response(self) -> Text:\n        if not self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"true_response\")\n            return self.input_value\n        else:\n            self.stop(\"false_response\")\n            return \"\"\n\n```\n\nBy following these steps and examples, you can create custom components in Langflow tailored to your specific needs. The modular structure of Custom Components allows for flexible and reusable components that can be easily integrated into your workflows.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput",
                  "load_from_db": false
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "base_classes": [
                "Message"
              ],
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": []
              },
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 328,
          "id": "Prompt-KlWrc",
          "position": {
            "x": 1288.410977120352,
            "y": 337.48865283611076
          },
          "positionAbsolute": {
            "x": 1288.410977120352,
            "y": 337.48865283611076
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "Memory-8Wvwd",
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "icon": "message-square-more",
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "BaseChatMemory"
                  ],
                  "selected": "BaseChatMemory",
                  "name": "lc_memory",
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false
            },
            "type": "Memory",
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "display_name": "Chat Memory"
          },
          "dragging": false,
          "height": 378,
          "id": "Memory-8Wvwd",
          "position": {
            "x": 1879.9416882974574,
            "y": 144.5166067576386
          },
          "positionAbsolute": {
            "x": 1879.9416882974574,
            "y": 144.5166067576386
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "ChatInput-WJaHo",
          "type": "genericNode",
          "position": {
            "x": 1291.876360699971,
            "y": 720.3773024740386
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "preciso que contenha uma seleção de Timezone",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatInput-WJaHo",
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input"
          },
          "selected": false,
          "width": 384,
          "height": 300,
          "positionAbsolute": {
            "x": 1291.876360699971,
            "y": 720.3773024740386
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-HBbk4",
          "type": "genericNode",
          "position": {
            "x": 3068.6654175280623,
            "y": 424.5073126422287
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatOutput-HBbk4",
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output"
          },
          "selected": false,
          "width": 384,
          "height": 300,
          "positionAbsolute": {
            "x": 3068.6654175280623,
            "y": 424.5073126422287
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-WJMCb",
          "type": "genericNode",
          "position": {
            "x": 1881.9922468253626,
            "y": 553.7552105326374
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": "0.4",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "OpenAIModel-WJMCb"
          },
          "selected": false,
          "width": 384,
          "height": 601,
          "dragging": false,
          "positionAbsolute": {
            "x": 1881.9922468253626,
            "y": 553.7552105326374
          }
        },
        {
          "id": "ToolCallingAgent-JKL6M",
          "type": "genericNode",
          "position": {
            "x": 2517.5081812228436,
            "y": 437.6513379023284
          },
          "data": {
            "type": "ToolCallingAgent",
            "node": {
              "template": {
                "_type": "Component",
                "chat_history": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_history",
                  "value": "",
                  "display_name": "Chat History",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool",
                    "BaseTool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, List\n\nfrom langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.inputs import MultilineInput\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\nfrom axiestudio.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = LCToolsAgentComponent._base_inputs + [\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> Optional[List[Data]]:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "handle_parsing_errors",
                  "value": true,
                  "display_name": "Handle Parse Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "max_iterations": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_iterations",
                  "value": 15,
                  "display_name": "Max Iterations",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_prompt",
                  "value": "",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "user_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_prompt",
                  "value": "{input}",
                  "display_name": "Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "This prompt must contain 'input' key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": true,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
              "icon": "LangChain",
              "base_classes": [
                "AgentExecutor",
                "Message"
              ],
              "display_name": "Tool Calling Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "AgentExecutor"
                  ],
                  "selected": "AgentExecutor",
                  "name": "agent",
                  "display_name": "Agent",
                  "method": "build_agent",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "response",
                  "display_name": "Response",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "handle_parsing_errors",
                "verbose",
                "max_iterations",
                "tools",
                "llm",
                "system_prompt",
                "user_prompt",
                "chat_history"
              ],
              "beta": true,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "ToolCallingAgent-JKL6M"
          },
          "selected": false,
          "width": 384,
          "height": 687,
          "dragging": false,
          "positionAbsolute": {
            "x": 2517.5081812228436,
            "y": 437.6513379023284
          }
        },
        {
          "id": "CalculatorTool-rva0y",
          "type": "genericNode",
          "position": {
            "x": 1280.4389483623318,
            "y": 1049.2030489652316
          },
          "data": {
            "type": "CalculatorTool",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport operator\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\nfrom langchain.tools import StructuredTool\n\n\nclass CalculatorToolComponent(LCToolComponent):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n    name = \"CalculatorTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n        ),\n    ]\n\n    class CalculatorToolSchema(BaseModel):\n        expression: str = Field(..., description=\"The arithmetic expression to evaluate.\")\n\n    def run_model(self) -> List[Data]:\n        return self._evaluate_expression(self.expression)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"calculator\",\n            description=\"Evaluate basic arithmetic expressions. Input should be a string containing the expression.\",\n            func=self._evaluate_expression,\n            args_schema=self.CalculatorToolSchema,\n        )\n\n    def _evaluate_expression(self, expression: str) -> List[Data]:\n        try:\n            # Define the allowed operators\n            operators = {\n                ast.Add: operator.add,\n                ast.Sub: operator.sub,\n                ast.Mult: operator.mul,\n                ast.Div: operator.truediv,\n                ast.Pow: operator.pow,\n            }\n\n            def eval_expr(node):\n                if isinstance(node, ast.Num):\n                    return node.n\n                elif isinstance(node, ast.BinOp):\n                    return operators[type(node.op)](eval_expr(node.left), eval_expr(node.right))\n                elif isinstance(node, ast.UnaryOp):\n                    return operators[type(node.op)](eval_expr(node.operand))\n                else:\n                    raise TypeError(node)\n\n            # Parse the expression and evaluate it\n            tree = ast.parse(expression, mode=\"eval\")\n            result = eval_expr(tree.body)\n\n            # Format the result to a reasonable number of decimal places\n            formatted_result = f\"{result:.6f}\".rstrip(\"0\").rstrip(\".\")\n\n            self.status = formatted_result\n            return [Data(data={\"result\": formatted_result})]\n\n        except (SyntaxError, TypeError, KeyError) as e:\n            error_message = f\"Invalid expression: {str(e)}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n        except Exception as e:\n            error_message = f\"Error: {str(e)}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "expression": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "expression",
                  "value": "",
                  "display_name": "Expression",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Perform basic arithmetic operations on a given expression.",
              "icon": "calculator",
              "base_classes": [
                "Data",
                "Tool"
              ],
              "display_name": "Calculator",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "expression"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "CalculatorTool-rva0y"
          },
          "selected": false,
          "width": 384,
          "height": 372,
          "dragging": false,
          "positionAbsolute": {
            "x": 1280.4389483623318,
            "y": 1049.2030489652316
          }
        },
        {
          "id": "WhatsAppSender-LAgtq",
          "type": "genericNode",
          "position": {
            "x": 307.5327815989244,
            "y": 562.695025323701
          },
          "data": {
            "type": "WhatsAppSender",
            "node": {
              "template": {
                "_type": "Component",
                "access_token": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "access_token",
                  "value": "",
                  "display_name": "Access Token",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Facebook Graph API Access Token.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, StrInput, SecretStrInput\r\nfrom axiestudio.template import Output\r\nfrom axiestudio.schema import Data\r\nimport requests\r\n\r\nclass WhatsAppSender(Component):\r\n    display_name  = \"WhatsApp Message Sender\"\r\n    description   = \"Send a WhatsApp message using WhatsApp Business API.\"\r\n    documentation = \"https://developers.facebook.com/docs/whatsapp\"\r\n    icon          = \"message-square\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"whatsapp_business_account_id\",\r\n            display_name=\"WhatsApp Business Account ID\",\r\n            info=\"Your WhatsApp Business Account ID.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"access_token\",\r\n            display_name=\"Access Token\",\r\n            info=\"Your Facebook Graph API Access Token.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"to_number\",\r\n            display_name=\"To Number\",\r\n            info=\"Recipient's phone number including the country code (e.g., '+19999999999').\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"message_body\",\r\n            display_name=\"Message Body\",\r\n            info=\"The content of the message to be sent.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Message ID\", name=\"message_id\", method=\"send_message\"),\r\n    ]\r\n\r\n    def send_message(self) -> Data:\r\n        whatsapp_business_account_id = self.whatsapp_business_account_id\r\n        access_token = self.access_token\r\n        to_number = self.to_number\r\n        message_body = self.message_body\r\n\r\n        url = f\"https://graph.facebook.com/v14.0/{whatsapp_business_account_id}/messages\"\r\n        headers = {\r\n            \"Authorization\": f\"Bearer {access_token}\",\r\n            \"Content-Type\": \"application/json\",\r\n        }\r\n        payload = {\r\n            \"messaging_product\": \"whatsapp\",\r\n            \"to\": to_number,\r\n            \"type\": \"text\",\r\n            \"text\": {\r\n                \"body\": message_body\r\n            }\r\n        }\r\n\r\n        response = requests.post(url, json=payload, headers=headers)\r\n        response_data = response.json()\r\n\r\n        if response.status_code == 200:\r\n            message_id = response_data['messages'][0]['id']\r\n            self.status = f'WhatsApp Message sent to {to_number}'\r\n            return Data(data={\"message_id\": message_id})\r\n        else:\r\n            self.status = f\"Failed to send message: {response_data.get('error', {}).get('message')}\"\r\n            return Data(data={\"message_id\": None})\r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "message_body": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "message_body",
                  "value": "",
                  "display_name": "Message Body",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The content of the message to be sent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "to_number": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "to_number",
                  "value": "",
                  "display_name": "To Number",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Recipient's phone number including the country code (e.g., '+19999999999').",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "whatsapp_business_account_id": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "whatsapp_business_account_id",
                  "value": "",
                  "display_name": "WhatsApp Business Account ID",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Your WhatsApp Business Account ID.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Send a WhatsApp message using WhatsApp Business API.",
              "icon": "message-square",
              "base_classes": [
                "Data"
              ],
              "display_name": "Send To WhatsApp",
              "documentation": "https://developers.facebook.com/docs/whatsapp",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "message_id",
                  "display_name": "Message ID",
                  "method": "send_message",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "whatsapp_business_account_id",
                "access_token",
                "to_number",
                "message_body"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.16",
              "official": false
            },
            "id": "WhatsAppSender-LAgtq"
          },
          "selected": true,
          "width": 384,
          "height": 585,
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ChatInput-WJaHo",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-WJaHoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-WJMCb",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WJMCbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-WJMCb",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-WJaHo",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-WJaHo{œdataTypeœ:œChatInputœ,œidœ:œChatInput-WJaHoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-WJMCb{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WJMCbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-KlWrc",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KlWrcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ToolCallingAgent-JKL6M",
          "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "system_prompt",
              "id": "ToolCallingAgent-JKL6M",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-KlWrc",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-KlWrc{œdataTypeœ:œPromptœ,œidœ:œPrompt-KlWrcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Memory-8Wvwd",
          "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-8Wvwdœ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}",
          "target": "ToolCallingAgent-JKL6M",
          "targetHandle": "{œfieldNameœ:œchat_historyœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "chat_history",
              "id": "ToolCallingAgent-JKL6M",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-8Wvwd",
              "name": "messages",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-Memory-8Wvwd{œdataTypeœ:œMemoryœ,œidœ:œMemory-8Wvwdœ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œchat_historyœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-WJMCb",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WJMCbœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ToolCallingAgent-JKL6M",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ToolCallingAgent-JKL6M",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-WJMCb",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-WJMCb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WJMCbœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ToolCallingAgent-JKL6M",
          "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-JKL6Mœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-HBbk4",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-HBbk4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-HBbk4",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ToolCallingAgent",
              "id": "ToolCallingAgent-JKL6M",
              "name": "response",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ToolCallingAgent-JKL6M{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-JKL6Mœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-HBbk4{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-HBbk4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CalculatorTool-rva0y",
          "sourceHandle": "{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-rva0yœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "ToolCallingAgent-JKL6M",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œToolœ,œBaseToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "ToolCallingAgent-JKL6M",
              "inputTypes": [
                "Tool",
                "BaseTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CalculatorTool",
              "id": "CalculatorTool-rva0y",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CalculatorTool-rva0y{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-rva0yœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-JKL6M{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-JKL6Mœ,œinputTypesœ:[œToolœ,œBaseToolœ],œtypeœ:œotherœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 323.7008750353525,
        "y": -7.11897111415675,
        "zoom": 0.42078084351059986
      }
    },
    "date_created": "2024-09-20T23:43:12.009Z",
    "date_updated": "2024-09-20T23:43:12.070Z",
    "status": "Public",
    "sort": null,
    "user_updated": "66be7526-cacc-46ac-a9f3-bcd93344190c",
    "user_created": {
      "username": "Amaralkarl",
      "first_name": "Claudinei",
      "last_name": "de Carvalho",
      "id": "66be7526-cacc-46ac-a9f3-bcd93344190c"
    },
    "tags": [
      {
        "tags_id": {
          "name": "Memory",
          "id": "e660a9ea-35fb-4587-bfbd-13dba4c556d1"
        }
      }
    ]
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:05.495Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 106,
    "converter_version": "1.0.0"
  }
}