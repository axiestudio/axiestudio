{
  "id": "d9c23aec-e04b-43b0-b12f-54a9d5740d3a",
  "name": "Untitled document",
  "description": "Empowering Language Engineering. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "Tonic",
    "first_name": "Joseph",
    "last_name": "Pollack",
    "id": "fe937923-6052-46fb-9bf7-ed6531f3a396",
    "full_name": "Joseph Pollack"
  },
  "store_url": "https://www.langflow.store/store/component/d9c23aec-e04b-43b0-b12f-54a9d5740d3a",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-07-14T13:32:04.976Z",
    "updated": "2024-07-14T13:32:05.043Z",
    "downloaded": "2025-08-19T17:50:04.992Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.9",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-z2Wlh",
        "type": "genericNode",
        "position": {
          "x": 873.5757828887203,
          "y": 405.2161825488851
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              },
              "store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "store_message",
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatInput-z2Wlh"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "positionAbsolute": {
          "x": 873.5757828887203,
          "y": 405.2161825488851
        },
        "dragging": false
      },
      {
        "id": "AzureOpenAIModel-gKaGl",
        "type": "genericNode",
        "position": {
          "x": 944.0567616069204,
          "y": -503.9393433608303
        },
        "data": {
          "type": "AzureOpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "api_version": {
                "trace_as_metadata": true,
                "options": [
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview",
                  "2023-09-01-preview",
                  "2023-12-01-preview",
                  "2024-04-09",
                  "2024-05-13"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "2024-05-13",
                "name": "api_version",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_deployment",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_endpoint": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_endpoint",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.7,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generate text using Azure OpenAI LLMs.",
            "icon": "Azure",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens",
              "input_value",
              "stream",
              "system_message"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AzureOpenAIModel-gKaGl"
        },
        "selected": false,
        "width": 384,
        "height": 814,
        "positionAbsolute": {
          "x": 944.0567616069204,
          "y": -503.9393433608303
        },
        "dragging": false
      },
      {
        "id": "ConversationChain-LIs7J",
        "type": "genericNode",
        "position": {
          "x": 1461.3911286985663,
          "y": 554.0327406914548
        },
        "data": {
          "type": "ConversationChain",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMemory"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input value to pass to the chain.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Chain to have a conversation and load context from memory.",
            "base_classes": [
              "Message"
            ],
            "display_name": "ConversationChain",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "invoke_chain",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "llm",
              "memory"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ConversationChain-LIs7J"
        },
        "selected": false,
        "width": 384,
        "height": 433,
        "positionAbsolute": {
          "x": 1461.3911286985663,
          "y": 554.0327406914548
        },
        "dragging": false
      },
      {
        "id": "AzureOpenAIModel-s7Qkp",
        "type": "genericNode",
        "position": {
          "x": 1832.8637977699173,
          "y": -413.77152604889613
        },
        "data": {
          "type": "AzureOpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "api_version": {
                "trace_as_metadata": true,
                "options": [
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview",
                  "2023-09-01-preview",
                  "2023-12-01-preview",
                  "2024-04-09",
                  "2024-05-13"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "2024-05-13",
                "name": "api_version",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_deployment",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_endpoint": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_endpoint",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.7,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generate text using Azure OpenAI LLMs.",
            "icon": "Azure",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens",
              "input_value",
              "stream",
              "system_message"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AzureOpenAIModel-s7Qkp"
        },
        "selected": false,
        "width": 384,
        "height": 814,
        "positionAbsolute": {
          "x": 1832.8637977699173,
          "y": -413.77152604889613
        },
        "dragging": false
      },
      {
        "id": "ConversationChain-tE8x7",
        "type": "genericNode",
        "position": {
          "x": 2233.997556792527,
          "y": 553.0636880055982
        },
        "data": {
          "type": "ConversationChain",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMemory"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input value to pass to the chain.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Chain to have a conversation and load context from memory.",
            "base_classes": [
              "Message"
            ],
            "display_name": "ConversationChain",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "invoke_chain",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "llm",
              "memory"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ConversationChain-tE8x7"
        },
        "selected": false,
        "width": 384,
        "height": 433,
        "positionAbsolute": {
          "x": 2233.997556792527,
          "y": 553.0636880055982
        },
        "dragging": false
      },
      {
        "id": "AzureOpenAIModel-Hj312",
        "type": "genericNode",
        "position": {
          "x": 2689.13009106818,
          "y": -406.05741529846136
        },
        "data": {
          "type": "AzureOpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "api_version": {
                "trace_as_metadata": true,
                "options": [
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview",
                  "2023-09-01-preview",
                  "2023-12-01-preview",
                  "2024-04-09",
                  "2024-05-13"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "2024-05-13",
                "name": "api_version",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_deployment",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "azure_endpoint": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "azure_endpoint",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.7,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generate text using Azure OpenAI LLMs.",
            "icon": "Azure",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens",
              "input_value",
              "stream",
              "system_message"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AzureOpenAIModel-Hj312"
        },
        "selected": false,
        "width": 384,
        "height": 814,
        "positionAbsolute": {
          "x": 2689.13009106818,
          "y": -406.05741529846136
        },
        "dragging": false
      },
      {
        "id": "ConversationChain-x5Ebk",
        "type": "genericNode",
        "position": {
          "x": 3241.97469484934,
          "y": 442.4947672493662
        },
        "data": {
          "type": "ConversationChain",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMemory"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input value to pass to the chain.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Chain to have a conversation and load context from memory.",
            "base_classes": [
              "Message"
            ],
            "display_name": "ConversationChain",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "invoke_chain",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "llm",
              "memory"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ConversationChain-x5Ebk"
        },
        "selected": false,
        "width": 384,
        "height": 433,
        "positionAbsolute": {
          "x": 3241.97469484934,
          "y": 442.4947672493662
        },
        "dragging": false
      },
      {
        "id": "TextOutput-FGCgR",
        "type": "genericNode",
        "position": {
          "x": 3879.6745168852835,
          "y": 331.92584649313426
        },
        "data": {
          "type": "TextOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as output.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Display a text output in the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": false
          },
          "id": "TextOutput-FGCgR"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "positionAbsolute": {
          "x": 3879.6745168852835,
          "y": 331.92584649313426
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "AzureOpenAIModel-gKaGl",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-gKaGlœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ConversationChain-LIs7J",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationChain-LIs7J",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-gKaGl",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-gKaGl{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-gKaGlœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-LIs7J{œfieldNameœ:œllmœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "source": "ChatInput-z2Wlh",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-z2Wlhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConversationChain-LIs7J",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ConversationChain-LIs7J",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-z2Wlh",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-z2Wlh{œdataTypeœ:œChatInputœ,œidœ:œChatInput-z2Wlhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-LIs7J{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "AzureOpenAIModel-s7Qkp",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-s7Qkpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ConversationChain-tE8x7",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationChain-tE8x7",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-s7Qkp",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-s7Qkp{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-s7Qkpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-tE8x7{œfieldNameœ:œllmœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "source": "ConversationChain-LIs7J",
        "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-LIs7Jœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConversationChain-tE8x7",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ConversationChain-tE8x7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConversationChain",
            "id": "ConversationChain-LIs7J",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConversationChain-LIs7J{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-LIs7Jœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-tE8x7{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "AzureOpenAIModel-Hj312",
        "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Hj312œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ConversationChain-x5Ebk",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationChain-x5Ebk",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AzureOpenAIModel",
            "id": "AzureOpenAIModel-Hj312",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-AzureOpenAIModel-Hj312{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Hj312œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-x5Ebk{œfieldNameœ:œllmœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "source": "ConversationChain-tE8x7",
        "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-tE8x7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConversationChain-x5Ebk",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ConversationChain-x5Ebk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConversationChain",
            "id": "ConversationChain-tE8x7",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConversationChain-tE8x7{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-tE8x7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-x5Ebk{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "ConversationChain-x5Ebk",
        "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-x5Ebkœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-FGCgR",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-FGCgRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-FGCgR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConversationChain",
            "id": "ConversationChain-x5Ebk",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConversationChain-x5Ebk{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-x5Ebkœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-FGCgR{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-FGCgRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": 271.26364248176856,
      "y": 350.37759190084256,
      "zoom": 0.317689086952148
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "AzureOpenAIModel": {
      "count": 3
    },
    "ConversationChain": {
      "count": 3
    },
    "TextOutput": {
      "count": 1
    },
    "total": 8
  },
  "original": {
    "id": "d9c23aec-e04b-43b0-b12f-54a9d5740d3a",
    "name": "Untitled document",
    "description": "Empowering Language Engineering.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "3",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "AzureOpenAIModel": {
        "count": 3
      },
      "ConversationChain": {
        "count": 3
      },
      "TextOutput": {
        "count": 1
      },
      "total": 8
    },
    "last_tested_version": "1.0.9",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-z2Wlh",
          "type": "genericNode",
          "position": {
            "x": 873.5757828887203,
            "y": 405.2161825488851
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                },
                "store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "store_message",
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatInput-z2Wlh"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "positionAbsolute": {
            "x": 873.5757828887203,
            "y": 405.2161825488851
          },
          "dragging": false
        },
        {
          "id": "AzureOpenAIModel-gKaGl",
          "type": "genericNode",
          "position": {
            "x": 944.0567616069204,
            "y": -503.9393433608303
          },
          "data": {
            "type": "AzureOpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "api_version": {
                  "trace_as_metadata": true,
                  "options": [
                    "2023-03-15-preview",
                    "2023-05-15",
                    "2023-06-01-preview",
                    "2023-07-01-preview",
                    "2023-08-01-preview",
                    "2023-09-01-preview",
                    "2023-12-01-preview",
                    "2024-04-09",
                    "2024-05-13"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "2024-05-13",
                  "name": "api_version",
                  "display_name": "API Version",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_deployment",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_endpoint": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_endpoint",
                  "display_name": "Azure Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": false,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.7,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generate text using Azure OpenAI LLMs.",
              "icon": "Azure",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Azure OpenAI",
              "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "azure_endpoint",
                "azure_deployment",
                "api_key",
                "api_version",
                "temperature",
                "max_tokens",
                "input_value",
                "stream",
                "system_message"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AzureOpenAIModel-gKaGl"
          },
          "selected": false,
          "width": 384,
          "height": 814,
          "positionAbsolute": {
            "x": 944.0567616069204,
            "y": -503.9393433608303
          },
          "dragging": false
        },
        {
          "id": "ConversationChain-LIs7J",
          "type": "genericNode",
          "position": {
            "x": 1461.3911286985663,
            "y": 554.0327406914548
          },
          "data": {
            "type": "ConversationChain",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMemory"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The input value to pass to the chain.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Chain to have a conversation and load context from memory.",
              "base_classes": [
                "Message"
              ],
              "display_name": "ConversationChain",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "invoke_chain",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "llm",
                "memory"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ConversationChain-LIs7J"
          },
          "selected": false,
          "width": 384,
          "height": 433,
          "positionAbsolute": {
            "x": 1461.3911286985663,
            "y": 554.0327406914548
          },
          "dragging": false
        },
        {
          "id": "AzureOpenAIModel-s7Qkp",
          "type": "genericNode",
          "position": {
            "x": 1832.8637977699173,
            "y": -413.77152604889613
          },
          "data": {
            "type": "AzureOpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "api_version": {
                  "trace_as_metadata": true,
                  "options": [
                    "2023-03-15-preview",
                    "2023-05-15",
                    "2023-06-01-preview",
                    "2023-07-01-preview",
                    "2023-08-01-preview",
                    "2023-09-01-preview",
                    "2023-12-01-preview",
                    "2024-04-09",
                    "2024-05-13"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "2024-05-13",
                  "name": "api_version",
                  "display_name": "API Version",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_deployment",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_endpoint": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_endpoint",
                  "display_name": "Azure Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": false,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.7,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generate text using Azure OpenAI LLMs.",
              "icon": "Azure",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Azure OpenAI",
              "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "azure_endpoint",
                "azure_deployment",
                "api_key",
                "api_version",
                "temperature",
                "max_tokens",
                "input_value",
                "stream",
                "system_message"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AzureOpenAIModel-s7Qkp"
          },
          "selected": false,
          "width": 384,
          "height": 814,
          "positionAbsolute": {
            "x": 1832.8637977699173,
            "y": -413.77152604889613
          },
          "dragging": false
        },
        {
          "id": "ConversationChain-tE8x7",
          "type": "genericNode",
          "position": {
            "x": 2233.997556792527,
            "y": 553.0636880055982
          },
          "data": {
            "type": "ConversationChain",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMemory"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The input value to pass to the chain.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Chain to have a conversation and load context from memory.",
              "base_classes": [
                "Message"
              ],
              "display_name": "ConversationChain",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "invoke_chain",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "llm",
                "memory"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ConversationChain-tE8x7"
          },
          "selected": false,
          "width": 384,
          "height": 433,
          "positionAbsolute": {
            "x": 2233.997556792527,
            "y": 553.0636880055982
          },
          "dragging": false
        },
        {
          "id": "AzureOpenAIModel-Hj312",
          "type": "genericNode",
          "position": {
            "x": 2689.13009106818,
            "y": -406.05741529846136
          },
          "data": {
            "type": "AzureOpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "api_version": {
                  "trace_as_metadata": true,
                  "options": [
                    "2023-03-15-preview",
                    "2023-05-15",
                    "2023-06-01-preview",
                    "2023-07-01-preview",
                    "2023-08-01-preview",
                    "2023-09-01-preview",
                    "2023-12-01-preview",
                    "2024-04-09",
                    "2024-05-13"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "2024-05-13",
                  "name": "api_version",
                  "display_name": "API Version",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_deployment",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "azure_endpoint": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "azure_endpoint",
                  "display_name": "Azure Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": false,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageInput, SecretStrInput, StrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            advanced=True,\n            info=\"System message to pass to the model.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.7,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generate text using Azure OpenAI LLMs.",
              "icon": "Azure",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Azure OpenAI",
              "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "azure_endpoint",
                "azure_deployment",
                "api_key",
                "api_version",
                "temperature",
                "max_tokens",
                "input_value",
                "stream",
                "system_message"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AzureOpenAIModel-Hj312"
          },
          "selected": false,
          "width": 384,
          "height": 814,
          "positionAbsolute": {
            "x": 2689.13009106818,
            "y": -406.05741529846136
          },
          "dragging": false
        },
        {
          "id": "ConversationChain-x5Ebk",
          "type": "genericNode",
          "position": {
            "x": 3241.97469484934,
            "y": 442.4947672493662
          },
          "data": {
            "type": "ConversationChain",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMemory"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.chains import ConversationChain\n\nfrom axiestudio.base.chains.model import LCChainComponent\nfrom axiestudio.field_typing import Message\nfrom axiestudio.inputs import MultilineInput, HandleInput\n\n\nclass ConversationChainComponent(LCChainComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n    name = \"ConversationChain\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        if not self.memory:\n            chain = ConversationChain(llm=self.llm)\n        else:\n            chain = ConversationChain(llm=self.llm, memory=self.memory)\n\n        result = chain.invoke({\"input\": self.input_value})\n        if isinstance(result, dict):\n            result = result.get(chain.output_key, \"\")  # type: ignore\n\n        elif isinstance(result, str):\n            result = result\n        else:\n            result = result.get(\"response\")\n        result = str(result)\n        self.status = result\n        return Message(text=result)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The input value to pass to the chain.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Chain to have a conversation and load context from memory.",
              "base_classes": [
                "Message"
              ],
              "display_name": "ConversationChain",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "invoke_chain",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "llm",
                "memory"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ConversationChain-x5Ebk"
          },
          "selected": false,
          "width": 384,
          "height": 433,
          "positionAbsolute": {
            "x": 3241.97469484934,
            "y": 442.4947672493662
          },
          "dragging": false
        },
        {
          "id": "TextOutput-FGCgR",
          "type": "genericNode",
          "position": {
            "x": 3879.6745168852835,
            "y": 331.92584649313426
          },
          "data": {
            "type": "TextOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Text to be passed as output.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Display a text output in the Playground.",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "Text Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": false
            },
            "id": "TextOutput-FGCgR"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "positionAbsolute": {
            "x": 3879.6745168852835,
            "y": 331.92584649313426
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "AzureOpenAIModel-gKaGl",
          "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-gKaGlœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ConversationChain-LIs7J",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ConversationChain-LIs7J",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AzureOpenAIModel",
              "id": "AzureOpenAIModel-gKaGl",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-AzureOpenAIModel-gKaGl{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-gKaGlœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-LIs7J{œfieldNameœ:œllmœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
        },
        {
          "source": "ChatInput-z2Wlh",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-z2Wlhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ConversationChain-LIs7J",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ConversationChain-LIs7J",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-z2Wlh",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-z2Wlh{œdataTypeœ:œChatInputœ,œidœ:œChatInput-z2Wlhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-LIs7J{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-LIs7Jœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "AzureOpenAIModel-s7Qkp",
          "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-s7Qkpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ConversationChain-tE8x7",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ConversationChain-tE8x7",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AzureOpenAIModel",
              "id": "AzureOpenAIModel-s7Qkp",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-AzureOpenAIModel-s7Qkp{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-s7Qkpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-tE8x7{œfieldNameœ:œllmœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
        },
        {
          "source": "ConversationChain-LIs7J",
          "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-LIs7Jœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ConversationChain-tE8x7",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ConversationChain-tE8x7",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConversationChain",
              "id": "ConversationChain-LIs7J",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConversationChain-LIs7J{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-LIs7Jœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-tE8x7{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-tE8x7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "AzureOpenAIModel-Hj312",
          "sourceHandle": "{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Hj312œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ConversationChain-x5Ebk",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ConversationChain-x5Ebk",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AzureOpenAIModel",
              "id": "AzureOpenAIModel-Hj312",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-AzureOpenAIModel-Hj312{œdataTypeœ:œAzureOpenAIModelœ,œidœ:œAzureOpenAIModel-Hj312œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ConversationChain-x5Ebk{œfieldNameœ:œllmœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
        },
        {
          "source": "ConversationChain-tE8x7",
          "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-tE8x7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ConversationChain-x5Ebk",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ConversationChain-x5Ebk",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConversationChain",
              "id": "ConversationChain-tE8x7",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConversationChain-tE8x7{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-tE8x7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ConversationChain-x5Ebk{œfieldNameœ:œinput_valueœ,œidœ:œConversationChain-x5Ebkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false
        },
        {
          "source": "ConversationChain-x5Ebk",
          "sourceHandle": "{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-x5Ebkœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "TextOutput-FGCgR",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-FGCgRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "TextOutput-FGCgR",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConversationChain",
              "id": "ConversationChain-x5Ebk",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConversationChain-x5Ebk{œdataTypeœ:œConversationChainœ,œidœ:œConversationChain-x5Ebkœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-FGCgR{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-FGCgRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": 271.26364248176856,
        "y": 350.37759190084256,
        "zoom": 0.317689086952148
      }
    },
    "date_created": "2024-07-14T13:32:04.976Z",
    "date_updated": "2024-07-14T13:32:05.043Z",
    "status": "Public",
    "sort": null,
    "user_updated": "fe937923-6052-46fb-9bf7-ed6531f3a396",
    "user_created": {
      "username": "Tonic",
      "first_name": "Joseph",
      "last_name": "Pollack",
      "id": "fe937923-6052-46fb-9bf7-ed6531f3a396"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.427Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 66,
    "converter_version": "1.0.0"
  }
}