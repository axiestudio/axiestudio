{
  "id": "9c4aecc0-e0f3-4b5a-b9b7-85e2466d03b4",
  "name": "Agente com composio(Teste)",
  "description": "Criando um agente com composio\n (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "Thalis360Global",
    "first_name": "Thalis",
    "last_name": "Developer",
    "id": "c7f5daed-ba4f-4b62-82d7-c47dc562881e",
    "full_name": "Thalis Developer"
  },
  "store_url": "https://www.langflow.store/store/component/9c4aecc0-e0f3-4b5a-b9b7-85e2466d03b4",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-26T17:38:11.165Z",
    "updated": "2024-09-26T18:30:41.268Z",
    "downloaded": "2025-08-19T17:50:06.958Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.0.96",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
          "display_name": "Hierarchical Crew",
          "id": "HierarchicalCrewComponent-RFMOg",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "display_name": "Hierarchical Crew",
            "documentation": "",
            "edited": false,
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "agents",
              "tasks",
              "manager_llm",
              "manager_agent"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Output",
                "method": "build_output",
                "name": "output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agents": {
                "advanced": false,
                "display_name": "Agents",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Agent"
                ],
                "list": true,
                "name": "agents",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n"
              },
              "function_calling_llm": {
                "advanced": true,
                "display_name": "Function Calling LLM",
                "dynamic": false,
                "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "function_calling_llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "manager_agent": {
                "advanced": false,
                "display_name": "Manager Agent",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Agent"
                ],
                "list": false,
                "name": "manager_agent",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "manager_llm": {
                "advanced": false,
                "display_name": "Manager LLM",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "manager_llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_rpm": {
                "advanced": true,
                "display_name": "Max RPM",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_rpm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "share_crew": {
                "advanced": true,
                "display_name": "Share Crew",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "share_crew",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tasks": {
                "advanced": false,
                "display_name": "Tasks",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "HierarchicalTask"
                ],
                "list": true,
                "name": "tasks",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "use_cache": {
                "advanced": true,
                "display_name": "Cache",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "use_cache",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "verbose": {
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "HierarchicalCrewComponent"
        },
        "height": 460,
        "id": "HierarchicalCrewComponent-RFMOg",
        "position": {
          "x": 2776.3568176564536,
          "y": 649.6596099240163
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "positionAbsolute": {
          "x": 2776.3568176564536,
          "y": 649.6596099240163
        },
        "dragging": false
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-9aqsp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "ChatOutput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "data_template": {
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "ChatOutput"
        },
        "height": 303,
        "id": "ChatOutput-9aqsp",
        "position": {
          "x": 3368.4175183697535,
          "y": 769.3124344428455
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "positionAbsolute": {
          "x": 3368.4175183697535,
          "y": 769.3124344428455
        },
        "dragging": false
      },
      {
        "data": {
          "description": "Each task must have a description, an expected output and an agent responsible for execution.",
          "display_name": "Hierarchical Task",
          "id": "HierarchicalTaskComponent-ysXYI",
          "node": {
            "base_classes": [
              "HierarchicalTask"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "display_name": "Hierarchical Task",
            "documentation": "",
            "edited": false,
            "field_order": [
              "task_description",
              "expected_output",
              "tools"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Task",
                "method": "build_task",
                "name": "task_output",
                "selected": "HierarchicalTask",
                "types": [
                  "HierarchicalTask"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n"
              },
              "expected_output": {
                "advanced": false,
                "display_name": "Expected Output",
                "dynamic": false,
                "info": "Clear definition of expected task outcome.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "expected_output",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Succinct response that answers the User's query."
              },
              "task_description": {
                "advanced": false,
                "display_name": "Description",
                "dynamic": false,
                "info": "Descriptive text detailing task's purpose and execution.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "task_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "tools": {
                "advanced": true,
                "display_name": "Tools",
                "dynamic": false,
                "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "HierarchicalTaskComponent"
        },
        "height": 413,
        "id": "HierarchicalTaskComponent-ysXYI",
        "position": {
          "x": 1998.6192209565584,
          "y": 752.6478253929832
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "positionAbsolute": {
          "x": 1998.6192209565584,
          "y": 752.6478253929832
        },
        "dragging": false
      },
      {
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-P5KkL",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Represents an agent of CrewAI.",
            "display_name": "Manager agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Backstory:\nO manager de agentes supervisiona um ambiente colaborativo onde cada agente desempenha um papel crucial no fluxo de produção de conteúdo. Desde a coleta inicial de informações pelo pesquisador, até a criação de textos pelo copywriter e a revisão final pelo editor revisor, o manager garante que cada tarefa seja executada com precisão e que o fluxo de trabalho seja organizado. Em casos de perguntas relacionadas a produtos específicos, o manager tem a flexibilidade de encaminhar a questão diretamente para um especialista, garantindo uma resposta rápida e precisa sem precisar acionar os outros agentes. No final, o manager organiza e apresenta as respostas de forma estruturada, com destaque para os agentes que participaram de cada etapa, e continua o fluxo de trabalho mesmo se algum agente não for encontrado."
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Goal:\n\nRealiza a tarefa de gerenciar e delegar tarefas entre os agentes de forma ordenada e eficiente, seguindo estas etapas:\n\nPesquisador (Analista de conteúdo digital especializado em tecnologia, com foco no mercado de Inteligência Artificial - IA): Ao acionar o pesquisador, ele deve coletar informações detalhadas e relevantes sobre o tema solicitado.\n\nSe o pesquisador não for encontrado, as informações disponíveis devem ser repassadas diretamente ao copywriter, e o fluxo segue normalmente.\nCopywriter (Copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão): Após o pesquisador concluir sua tarefa, ou caso o pesquisador não seja encontrado, o manager deve passar o material diretamente ao copywriter, que transformará as informações em um texto criativo e persuasivo.\n\nSe o copywriter não for encontrado, o material deve ser enviado diretamente para o editor revisor, mas o resultado final exibido será do copywriter, caso tenha participado.\nEditor Revisor (Agente Editor Revisor): Após o copywriter finalizar o texto, ou caso o copywriter não seja encontrado, o manager encaminha o material para o editor revisor, que revisa o conteúdo para garantir clareza, coesão e correção de erros.\n\nEmbora o editor revisor participe do fluxo para garantir a qualidade do texto, o resultado final a ser apresentado ao solicitante não incluirá a contribuição direta do editor.\nFluxo de Respostas: A resposta não deve ser enviada ao solicitante até que o manager tenha tentado passar as informações pelos três agentes (pesquisador, copywriter e editor revisor). Mesmo que algum dos agentes não seja encontrado, o fluxo deve continuar com os agentes disponíveis, e a resposta será gerada com os dados fornecidos por aqueles que participaram do processo.\n\nApós a conclusão das tarefas pelos agentes disponíveis, o manager deve estruturar a resposta final, exibindo o nome de cada agente e seus respectivos resultados de forma clara e em negrito, seguindo a ordem cronológica do fluxo de trabalho. A resposta final incluirá apenas os tópicos encontrados pelo pesquisador e o texto gerado pelo copywriter, ignorando a contribuição do editor revisor no resultado exibido.\n\nPor exemplo:\n\nPesquisador (Analista de conteúdo digital especializado em tecnologia, com foco em IA):\n\nTópico 1: [detalhe da pesquisa]\nTópico 2: [detalhe da pesquisa]\nTópico 3: [detalhe da pesquisa]\n(quebra de linha)\nCopywriter (Copywriter especializado em campanhas de marketing e conversão):\nTexto criativo baseado nos tópicos gerados pelo pesquisador.\n\nExceção:\nCaso a pergunta seja sobre um produto específico ou tema especializado da Furestpet, o manager deve direcionar a pergunta diretamente ao Agente Especialista em Produtos da Furestpet. Nesse caso, a resposta pode ser enviada imediatamente pelo especialista, sem necessidade de envolver os outros agentes (pesquisador, copywriter e editor revisor)."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Role:\nAtua com a personalidade de um manager de agentes, responsável por coordenar e delegar tarefas entre diferentes agentes, incluindo o pesquisador, o copywriter, o editor revisor e especialistas em produtos ou tópicos específicos. Seu papel é garantir o fluxo eficiente de informações entre os agentes, organizar cada etapa do processo de criação e revisão de conteúdo e estruturar a resposta final de forma clara, destacando os agentes e suas contribuições."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "dragging": false,
        "height": 712,
        "id": "CrewAIAgentComponent-P5KkL",
        "position": {
          "x": 1997.096695650694,
          "y": 1255.534535025709
        },
        "positionAbsolute": {
          "x": 1997.096695650694,
          "y": 1255.534535025709
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-cxeAa",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 607,
        "id": "OpenAIModel-cxeAa",
        "position": {
          "x": 1365.400497898475,
          "y": 1507.9746660403787
        },
        "positionAbsolute": {
          "x": 1365.400497898475,
          "y": 1507.9746660403787
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-K18mo",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "name": "prompt",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "query": {
                "advanced": false,
                "display_name": "query",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message",
                  "Text"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "query",
                "password": false,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly."
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 418,
        "id": "Prompt-K18mo",
        "position": {
          "x": 1200.1577612116853,
          "y": 655.9216455662466
        },
        "selected": false,
        "type": "genericNode",
        "width": 384,
        "positionAbsolute": {
          "x": 1200.1577612116853,
          "y": 655.9216455662466
        }
      },
      {
        "data": {
          "id": "ChatInput-yH1am",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "ChatInput",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Tendencias em IA para analise de Imagens"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 303,
        "id": "ChatInput-yH1am",
        "position": {
          "x": -1105.275607442421,
          "y": 599.8702735570906
        },
        "positionAbsolute": {
          "x": -1105.275607442421,
          "y": 599.8702735570906
        },
        "selected": true,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "CrewAIAgentComponent-k7Ea3",
        "type": "genericNode",
        "position": {
          "x": 1195.9300729812198,
          "y": -1285.6775979595816
        },
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-k7Ea3",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão.",
            "display_name": "copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão.",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Em um mercado saturado de informações, as marcas enfrentam o desafio de se destacar e capturar a atenção de seus consumidores. O copywriter é essencial nesse contexto, criando conteúdos que não apenas comunicam a mensagem da marca, mas que também incentivam ações concretas do público. Através de uma linguagem persuasiva e eficaz, o copywriter é capaz de transformar simples visitantes ou leitores em clientes e seguidores fiéis, sempre com foco nos objetivos comerciais e no público da campanha.\n\n"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Realiza a tarefa de desenvolver textos criativos e persuasivos para campanhas de marketing digital, voltadas para maximizar conversões e engajamento do público. O copywriter deve adaptar o tom e estilo da escrita para o público-alvo de cada campanha, seja em redes sociais, e-mails, anúncios ou páginas de vendas. Os textos devem ser claros, envolventes e com chamadas para ação diretas e eficazes, sempre priorizando o alinhamento com a identidade da marca e os objetivos estratégicos da campanha, sempre responda no mesmo idioma da pergunta."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Atua com a personalidade de um copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão. Seu papel é produzir textos estratégicos que engajam o público-alvo e incentivam ações específicas, como compras, assinaturas ou interações."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "selected": false,
        "width": 384,
        "height": 768,
        "positionAbsolute": {
          "x": 1195.9300729812198,
          "y": -1285.6775979595816
        },
        "dragging": false
      },
      {
        "id": "SearchAPI-hnrpV",
        "type": "genericNode",
        "position": {
          "x": 135.36494975125436,
          "y": -1740.3901791956043
        },
        "data": {
          "description": "Call the searchapi.io API",
          "display_name": "Search API",
          "id": "SearchAPI-hnrpV",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Call the searchapi.io API with result limiting",
            "display_name": "Search API",
            "documentation": "https://www.searchapi.io/docs/google",
            "edited": false,
            "field_order": [
              "engine",
              "api_key",
              "input_value",
              "search_params"
            ],
            "frozen": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Data",
                "method": "run_model",
                "name": "api_run_model",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "method": "build_tool",
                "name": "api_build_tool",
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "advanced": false,
                "display_name": "SearchAPI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Dict, Any, Optional, List\nfrom pydantic import BaseModel, Field\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, DictInput, MessageTextInput, IntInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\nfrom langchain.tools import StructuredTool\n\n\nclass SearchAPIComponent(LCToolComponent):\n    display_name: str = \"Search API\"\n    description: str = \"Call the searchapi.io API with result limiting\"\n    name = \"SearchAPI\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n\n    inputs = [\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class SearchAPISchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        params: Optional[Dict[str, Any]] = Field(default_factory=dict, description=\"Additional search parameters\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(\n            query: str, params: Optional[Dict[str, Any]] = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> List[Dict[str, Any]]:\n            params = params or {}\n            full_results = wrapper.results(query=query, **params)\n            organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n            limited_results = []\n            for result in organic_results:\n                limited_result = {\n                    \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                    \"link\": result.get(\"link\", \"\"),\n                    \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"search_api\",\n            description=\"Search for recent results using searchapi.io with result limiting\",\n            func=search_func,\n            args_schema=self.SearchAPISchema,\n        )\n\n        self.status = f\"Search API Tool created with engine: {self.engine}\"\n        return tool\n\n    def run_model(self) -> List[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"params\": self.search_params or {},\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n\n        self.status = data_list\n        return data_list\n"
              },
              "engine": {
                "advanced": false,
                "display_name": "Engine",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "engine",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "google"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Results",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_snippet_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Snippet Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "max_snippet_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "search_params": {
                "advanced": true,
                "display_name": "Search parameters",
                "dynamic": false,
                "info": "",
                "list": true,
                "name": "search_params",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "SearchAPI"
        },
        "selected": false,
        "width": 384,
        "height": 521,
        "dragging": false,
        "positionAbsolute": {
          "x": 135.36494975125436,
          "y": -1740.3901791956043
        }
      },
      {
        "id": "OpenAIModel-3lCHz",
        "type": "genericNode",
        "position": {
          "x": 132.32173575908644,
          "y": -1182.8691783301506
        },
        "data": {
          "id": "OpenAIModel-3lCHz",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "OpenAIModel"
        },
        "selected": false,
        "width": 384,
        "height": 607,
        "positionAbsolute": {
          "x": 132.32173575908644,
          "y": -1182.8691783301506
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-VF3Dz",
        "type": "genericNode",
        "position": {
          "x": 1201.6293693212303,
          "y": -2069.526879295477
        },
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-VF3Dz",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "analista de conteúdo digital especializado em tecnologia, com foco no mercado de inteligência artificial (ia)",
            "display_name": "analista de conteúdo digital especializado em tecnologia, com foco no mercado de inteligência artificial (ia)",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A demanda por dados precisos e recentes no campo de IA está crescendo rapidamente entre executivos e investidores que precisam de insights estratégicos para a tomada de decisões. O agente foi projetado para atender essa necessidade, garantindo que as informações coletadas sejam atualizadas e provenientes de fontes respeitadas. O agente não precisa analisar ou interpretar os dados, apenas coletá-los de forma estruturada e organizada em relatórios detalhados que podem ser solicitados conforme a demanda."
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Realiza a tarefa de coletar relatórios detalhados e conteúdos recentes sobre tópicos-chave em Inteligência Artificial, focados no impacto e nas tendências de mercado para investidores e executivos. A pesquisa deve ser realizada por meio da Google Search API e priorizar fontes confiáveis como Google, Bing e DuckDuckGo. O agente coletará informações tanto em português quanto em inglês, e apresentará os resultados em relatórios organizados e detalhados, sempre responda no mesmo idioma da pergunta."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Atua com a personalidade de um analista de conteúdo digital especializado em tecnologia, com foco no mercado de Inteligência Artificial (IA). Seu papel é realizar pesquisas de conteúdo relevantes e específicos para investidores e executivos, utilizando plataformas de busca confiáveis e uma abordagem orientada a dados."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "selected": false,
        "width": 384,
        "height": 768,
        "positionAbsolute": {
          "x": 1201.6293693212303,
          "y": -2069.526879295477
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-fl7KA",
        "type": "genericNode",
        "position": {
          "x": 1193.5755732549603,
          "y": -497.56678854719144
        },
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-fl7KA",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Agente Editor Revisor",
            "display_name": "Agente Editor Revisor",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A demanda por dados precisos e recentes no campo de IA está crescendo rapidamente entre executivos e investidores que precisam de insights estratégicos para a tomada de decisões. O agente foi projetado para atender essa necessidade, garantindo que as informações coletadas sejam atualizadas e provenientes de fontes respeitadas. O agente não precisa analisar ou interpretar os dados, apenas coletá-los de forma estruturada e organizada em relatórios detalhados que podem ser solicitados conforme a demanda."
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Com a crescente demanda por conteúdo de alta qualidade e comunicação precisa, o papel do editor revisor é essencial para assegurar que todos os materiais escritos reflitam a credibilidade e a excelência da marca ou empresa. Desde a revisão de pequenos erros até ajustes de estrutura e estilo, o editor revisor garante que o texto seja impactante, coeso e sem falhas, contribuindo diretamente para a reputação e a eficácia da comunicação da organização, responda sempre no Idioma da pergunta.\n\n"
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Atua com a personalidade de um editor revisor especializado em garantir a clareza, precisão e qualidade de textos. Seu papel é revisar e editar conteúdos escritos, corrigindo erros gramaticais, de estilo, ortografia e aprimorando a fluidez e consistência da comunicação."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "selected": false,
        "width": 384,
        "height": 712,
        "positionAbsolute": {
          "x": 1193.5755732549603,
          "y": -497.56678854719144
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-ZMVIC",
        "type": "genericNode",
        "position": {
          "x": 1195.1532229698776,
          "y": -2837.9497804375774
        },
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-ZMVIC",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Analista de conteúdo digital, especializado em tecnologia.",
            "display_name": "Agente Especialista em Produtos da Furest pet",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "## Objetivo\n\nNa Furest Pet, a conexão entre cães, humanos e natureza está no centro de quem somos. Nosso nome, uma mistura de \"fur\" (pelo) e \"forest\" (floresta), representa nosso profundo respeito pelos pets e nossa promessa de contribuir com o meio ambiente.\n\nCada produto Furest Pet, enriquecido com ingredientes incríveis encontrados na Floresta Amazônica, é uma fonte de qualidade de vida e longevidade para o seu amigo canino, e também uma maneira de fortalecer a sua ligação com ele.\n\nDiferentes produtos, mesmo objetivo: conectar as maravilhas da natureza à vida diária de seu pet e de quem o ama.\n\n## missão\n\nNossa missão é profundamente concentrada no cuidado e bem-estar canino. Nosso propósito é promover ao pet uma vida mais saudável, longa e feliz, onde ele pode aproveitar por mais tempo o vínculo lindo entre ele e seu tutor.\n\nInspirados pela beleza majestosa e o ecossistema único da Floresta Amazônica, desenvolvemos produtos naturais que encantam nossos amigos de quatro patas. Nosso objetivo é trazer as maravilhas dessa floresta pulsante e incrível para a vida de seu melhor amigo.\n\n## Valores\n\n- Sustentabilidade\nA Floresta Amazônica, em sua imensidão e majestosidade, é um tesouro vivo que nos brinda com riquezas naturais inestimáveis. Cada elemento que ela nos oferece é um presente, e é nossa filosofia dar de volta aquilo que elas nos oferece.\n\nEm cada produto Furest Pet, há uma promessa de respeito e harmonia com a natureza. Com o \"Paws For The Forest\", não apenas plantamos árvores, mas também desenvolvemos parcerias com famílias e comunidades locais. Nossa missão transcende os negócios, alimentando a essência vital do ciclo de conservação e sustentabilidade. A cada compra, fortalecemos o legado de um futuro mais verde e sustentável para as próximas gerações.\n\n\n- Cultura Brasileira\nA cultura brasileira é uma das mais ricas e diversas do mundo, com variedades de cores que se estendem aos verdes da sua linda Floresta Amazônica. \n\nAs cores singulares da nossa terra refletem a essência de ser brasileiro.\n\nEstamos trazendo toda essa diversidade para o seu amigo canino, por meio de uma linha de produtos feitos com ingredientes naturais encontrados na Floresta Amazônica.\n\n## Produtos\n\n\nProduto nome : **Calming Zen**   \nEste suplemento é a solução serena da Furest Pet para o bem-estar emocional dos pets. Calming Zen é um suplemento natural, desenvolvido para acalmar e relaxar cães e gatos que apresentam sinais de ansiedade, estresse ou hiperatividade. Com ingredientes selecionados pela sua eficácia e segurança, este suplemento atua suavemente no sistema nervoso dos pets, proporcionando uma sensação de calma sem causar sonolência ou dependência. Principais Benefícios: Promove a calma e reduz o estresse sem sedar. Ajuda a controlar comportamentos ansiosos e hiperativos. Composto por ingredientes naturais \n✅ Situações que podemos sugerir o uso do Calming Zen:\n Cachorros ansiosos Cachorros estressados Cachorros com problema de sono Cachorros agitados Pode ser um complemento natural a um tratamento medicamentoso \n🚫 NÃO PODEMOS:   \n1 Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.   \n/-  \nProduto nome: **Immune Power**   \nImmune Power é um suplemento robusto de reforço imunológico. Sua fórmula rica em antioxidantes, vitaminas e minerais essenciais, foi criteriosamente escolhida para fortalecer o sistema imunológico dos pets, ajudando a proteger contra doenças e a promover uma recuperação mais rápida. Este suplemento é ideal para todos os cães e gatos, especialmente aqueles em recuperação ou que precisam de um impulso extra em sua saúde geral. Principais Benefícios: Fortalece o sistema imunológico. Favorece uma pele saudável e pelagem brilhante. Apoia a vitalidade e a saúde geral. \n✅ Situações que podemos sugerir o uso do Immune Power: Cachorros mais idosos Cachorros com problema de coceira Cachorros com problema de alergia Cachorros com necessidade de fortalecer o sistema imunológico Pode ser um complemento natural a um tratamento medicamentoso 🚫 NÃO PODEMOS: Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.\n\n/-\n\nProduto nome: **Bálsamo Hidratante Pata Power** \n\nPata Power é um bálsamo hidratante premium para cuidar das patinhas e do focinho do seu pet. Enriquecido com ingredientes da Floresta Amazônica, oferece uma mistura exclusiva de manteigas e óleos vegetais que nutrem, protegem e restauram a pele exposta às condições adversas, como pavimentos quentes, gelo ou areia. Este produto é um must-have para tutores que procuram o melhor em cuidado e proteção para as áreas mais sensíveis dos seus animais de estimação. Principais Benefícios: Hidrata e protege patas e focinhos. Promove a cicatrização de rachaduras e feridas. Ingredientes naturais de origem sustentável e cruelty-free. \n\n/- \n**Mordedores Naturais** \n\n**Casquinho**   \nDescrição: Casco bovino desidratado, ideal para uma mastigação duradoura que ajuda na limpeza dos dentes e gengivas. \n\n- Unidades no pacote: 2 \n\n**Fêmur**   \nDescrição: Fêmur bovino desidratado, rico em cálcio e outros minerais, promove a saúde dental e fortalece os ossos.   \nUnidades no pacote: 1   \n**Rosquinha de Carne** Descrição: Rosquinha feita de bexiga bovina desidratada, proporciona entretenimento e auxilia na higiene oral.   \n\\-  Unidades no pacote: 1 ou 3   \n**Espetinho Rústico**   \nDescrição: Palitinho de esôfago bovino desidratado, fonte de proteína e colágeno, suporta a saúde das articulações e pele.   \n\\-  Unidades no pacote: 10   \n**Trancinha Mista** Descrição: Trança de bexiga e esôfago bovinos, combina texturas para uma experiência de mastigação variada.   \n\\- Unidades no pacote: 3   \n**Bifinho de Carne**   \nDescrição: Bife de bexiga bovina desidratada, uma opção saborosa e nutritiva para recompensar seu pet.   \n\\-  Unidades no pacote: 2   \n**Orelhinha**   \nDescrição: Orelha bovina sem aurícula, rica em cartilagem e colágeno, promove saúde articular e dental.   \n\\-  Unidades no pacote: 3   \n**Orelhinha com carne**   \nDescrição: Orelha bovina com aurícula, uma guloseima crocante e cheia de sabor que ajuda na limpeza dos dentes.   \n\\-  Unidades no pacote: 1 ou 2   \n**Palitinho de Colágeno \\- Açaí**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e açaí, rico em antioxidantes e vitaminas.   \n\\-  Unidades no pacote: 200g   \n**Palitinho de Colágeno \\- Urucum**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e urucum, oferece benefícios anti-inflamatórios e promove a saúde da pele.   \nUnidades no pacote: 200g \n\n/-\n**Informações importantes**  \nObservações Importantes: Todos os produtos da Furest Pet são formulados com base em pesquisas científicas e são seguros para uso em cães e gatos de todos os tamanhos e idades. A Furest Pet valoriza a sustentabilidade e o compromisso com a preservação da Floresta Amazônica, incorporando práticas que respeitam o meio ambiente em todas as etapas da produção. Como uma marca premium, a Furest Pet assegura a mais alta qualidade em todos os seus produtos, com atenção rigorosa aos detalhes e à experiência do cliente.\n\n## Dicas\n\n#PawsForTheForest \n#Sustentabilidade \n#FurestPet"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\nRealiza a tarefa de responder perguntas sobre os produtos da Furestpet, sempre utilizando as informações contidas no backstory. O especialista deve:\n\nBasear suas respostas exclusivamente nos detalhes do backstory. Se houver informações sobre o produto no backstory, ele deve fornecer uma resposta clara e completa.\nNunca inventar ou extrapolar informações além do que está presente no backstory.\nCaso a pergunta não possa ser respondida com base nas informações disponíveis no backstory, o especialista deve responder: \"No momento eu não sei te responder.\"\n\nSempre responda no mesmo idioma da pergunta."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Atua com a personalidade de um especialista em venda de palitos de carne premium para animais de estimação, focado em responder perguntas e fornecer informações detalhadas sobre os benefícios dos produtos com base em seu backstory. Seu papel é educar e orientar os clientes sobre as qualidades exclusivas dos palitos de carne, além de destacar os benefícios para a saúde e bem-estar dos animais."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "selected": false,
        "width": 384,
        "height": 740,
        "positionAbsolute": {
          "x": 1195.1532229698776,
          "y": -2837.9497804375774
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-2Re1E",
        "type": "genericNode",
        "position": {
          "x": 188.05986691893906,
          "y": -2873.9533869586594
        },
        "data": {
          "id": "OpenAIModel-2Re1E",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": false,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": false,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "OpenAIModel"
        },
        "selected": false,
        "width": 384,
        "height": 780,
        "positionAbsolute": {
          "x": 188.05986691893906,
          "y": -2873.9533869586594
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-D2zPF",
        "type": "genericNode",
        "position": {
          "x": -1462.7139747635383,
          "y": -3743.8538781568063
        },
        "data": {
          "description": "Represents an agent of CrewAI.",
          "display_name": "CrewAI Agent",
          "id": "CrewAIAgentComponent-D2zPF",
          "node": {
            "base_classes": [
              "Agent"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Agente para postar Conteúdos no Notion",
            "display_name": "Agente de postagem no notion",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "edited": false,
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "frozen": false,
            "icon": "CrewAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Agent",
                "method": "build_output",
                "name": "output",
                "selected": "Agent",
                "types": [
                  "Agent"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "allow_code_execution": {
                "advanced": true,
                "display_name": "Allow Code Execution",
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "list": false,
                "name": "allow_code_execution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "allow_delegation": {
                "advanced": false,
                "display_name": "Allow Delegation",
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "list": false,
                "name": "allow_delegation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "backstory": {
                "advanced": false,
                "display_name": "Backstory",
                "dynamic": false,
                "info": "The backstory of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "backstory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "## Objetivo\n\nNa Furest Pet, a conexão entre cães, humanos e natureza está no centro de quem somos. Nosso nome, uma mistura de \"fur\" (pelo) e \"forest\" (floresta), representa nosso profundo respeito pelos pets e nossa promessa de contribuir com o meio ambiente.\n\nCada produto Furest Pet, enriquecido com ingredientes incríveis encontrados na Floresta Amazônica, é uma fonte de qualidade de vida e longevidade para o seu amigo canino, e também uma maneira de fortalecer a sua ligação com ele.\n\nDiferentes produtos, mesmo objetivo: conectar as maravilhas da natureza à vida diária de seu pet e de quem o ama.\n\n## missão\n\nNossa missão é profundamente concentrada no cuidado e bem-estar canino. Nosso propósito é promover ao pet uma vida mais saudável, longa e feliz, onde ele pode aproveitar por mais tempo o vínculo lindo entre ele e seu tutor.\n\nInspirados pela beleza majestosa e o ecossistema único da Floresta Amazônica, desenvolvemos produtos naturais que encantam nossos amigos de quatro patas. Nosso objetivo é trazer as maravilhas dessa floresta pulsante e incrível para a vida de seu melhor amigo.\n\n## Valores\n\n- Sustentabilidade\nA Floresta Amazônica, em sua imensidão e majestosidade, é um tesouro vivo que nos brinda com riquezas naturais inestimáveis. Cada elemento que ela nos oferece é um presente, e é nossa filosofia dar de volta aquilo que elas nos oferece.\n\nEm cada produto Furest Pet, há uma promessa de respeito e harmonia com a natureza. Com o \"Paws For The Forest\", não apenas plantamos árvores, mas também desenvolvemos parcerias com famílias e comunidades locais. Nossa missão transcende os negócios, alimentando a essência vital do ciclo de conservação e sustentabilidade. A cada compra, fortalecemos o legado de um futuro mais verde e sustentável para as próximas gerações.\n\n\n- Cultura Brasileira\nA cultura brasileira é uma das mais ricas e diversas do mundo, com variedades de cores que se estendem aos verdes da sua linda Floresta Amazônica. \n\nAs cores singulares da nossa terra refletem a essência de ser brasileiro.\n\nEstamos trazendo toda essa diversidade para o seu amigo canino, por meio de uma linha de produtos feitos com ingredientes naturais encontrados na Floresta Amazônica.\n\n## Produtos\n\n\nProduto nome : **Calming Zen**   \nEste suplemento é a solução serena da Furest Pet para o bem-estar emocional dos pets. Calming Zen é um suplemento natural, desenvolvido para acalmar e relaxar cães e gatos que apresentam sinais de ansiedade, estresse ou hiperatividade. Com ingredientes selecionados pela sua eficácia e segurança, este suplemento atua suavemente no sistema nervoso dos pets, proporcionando uma sensação de calma sem causar sonolência ou dependência. Principais Benefícios: Promove a calma e reduz o estresse sem sedar. Ajuda a controlar comportamentos ansiosos e hiperativos. Composto por ingredientes naturais \n✅ Situações que podemos sugerir o uso do Calming Zen:\n Cachorros ansiosos Cachorros estressados Cachorros com problema de sono Cachorros agitados Pode ser um complemento natural a um tratamento medicamentoso \n🚫 NÃO PODEMOS:   \n1 Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.   \n/-  \nProduto nome: **Immune Power**   \nImmune Power é um suplemento robusto de reforço imunológico. Sua fórmula rica em antioxidantes, vitaminas e minerais essenciais, foi criteriosamente escolhida para fortalecer o sistema imunológico dos pets, ajudando a proteger contra doenças e a promover uma recuperação mais rápida. Este suplemento é ideal para todos os cães e gatos, especialmente aqueles em recuperação ou que precisam de um impulso extra em sua saúde geral. Principais Benefícios: Fortalece o sistema imunológico. Favorece uma pele saudável e pelagem brilhante. Apoia a vitalidade e a saúde geral. \n✅ Situações que podemos sugerir o uso do Immune Power: Cachorros mais idosos Cachorros com problema de coceira Cachorros com problema de alergia Cachorros com necessidade de fortalecer o sistema imunológico Pode ser um complemento natural a um tratamento medicamentoso 🚫 NÃO PODEMOS: Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.\n\n/-\n\nProduto nome: **Bálsamo Hidratante Pata Power** \n\nPata Power é um bálsamo hidratante premium para cuidar das patinhas e do focinho do seu pet. Enriquecido com ingredientes da Floresta Amazônica, oferece uma mistura exclusiva de manteigas e óleos vegetais que nutrem, protegem e restauram a pele exposta às condições adversas, como pavimentos quentes, gelo ou areia. Este produto é um must-have para tutores que procuram o melhor em cuidado e proteção para as áreas mais sensíveis dos seus animais de estimação. Principais Benefícios: Hidrata e protege patas e focinhos. Promove a cicatrização de rachaduras e feridas. Ingredientes naturais de origem sustentável e cruelty-free. \n\n/- \n**Mordedores Naturais** \n\n**Casquinho**   \nDescrição: Casco bovino desidratado, ideal para uma mastigação duradoura que ajuda na limpeza dos dentes e gengivas. \n\n- Unidades no pacote: 2 \n\n**Fêmur**   \nDescrição: Fêmur bovino desidratado, rico em cálcio e outros minerais, promove a saúde dental e fortalece os ossos.   \nUnidades no pacote: 1   \n**Rosquinha de Carne** Descrição: Rosquinha feita de bexiga bovina desidratada, proporciona entretenimento e auxilia na higiene oral.   \n\\-  Unidades no pacote: 1 ou 3   \n**Espetinho Rústico**   \nDescrição: Palitinho de esôfago bovino desidratado, fonte de proteína e colágeno, suporta a saúde das articulações e pele.   \n\\-  Unidades no pacote: 10   \n**Trancinha Mista** Descrição: Trança de bexiga e esôfago bovinos, combina texturas para uma experiência de mastigação variada.   \n\\- Unidades no pacote: 3   \n**Bifinho de Carne**   \nDescrição: Bife de bexiga bovina desidratada, uma opção saborosa e nutritiva para recompensar seu pet.   \n\\-  Unidades no pacote: 2   \n**Orelhinha**   \nDescrição: Orelha bovina sem aurícula, rica em cartilagem e colágeno, promove saúde articular e dental.   \n\\-  Unidades no pacote: 3   \n**Orelhinha com carne**   \nDescrição: Orelha bovina com aurícula, uma guloseima crocante e cheia de sabor que ajuda na limpeza dos dentes.   \n\\-  Unidades no pacote: 1 ou 2   \n**Palitinho de Colágeno \\- Açaí**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e açaí, rico em antioxidantes e vitaminas.   \n\\-  Unidades no pacote: 200g   \n**Palitinho de Colágeno \\- Urucum**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e urucum, oferece benefícios anti-inflamatórios e promove a saúde da pele.   \nUnidades no pacote: 200g \n\n/-\n**Informações importantes**  \nObservações Importantes: Todos os produtos da Furest Pet são formulados com base em pesquisas científicas e são seguros para uso em cães e gatos de todos os tamanhos e idades. A Furest Pet valoriza a sustentabilidade e o compromisso com a preservação da Floresta Amazônica, incorporando práticas que respeitam o meio ambiente em todas as etapas da produção. Como uma marca premium, a Furest Pet assegura a mais alta qualidade em todos os seus produtos, com atenção rigorosa aos detalhes e à experiência do cliente.\n\n## Dicas\n\n#PawsForTheForest \n#Sustentabilidade \n#FurestPet"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
              },
              "goal": {
                "advanced": false,
                "display_name": "Goal",
                "dynamic": false,
                "info": "The objective of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "goal",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\nRealiza a tarefa de responder perguntas sobre os produtos da Furestpet, sempre utilizando as informações contidas no backstory. O especialista deve:\n\nBasear suas respostas exclusivamente nos detalhes do backstory. Se houver informações sobre o produto no backstory, ele deve fornecer uma resposta clara e completa.\nNunca inventar ou extrapolar informações além do que está presente no backstory.\nCaso a pergunta não possa ser respondida com base nas informações disponíveis no backstory, o especialista deve responder: \"No momento eu não sei te responder.\"\n\nSempre responda no mesmo idioma da pergunta."
              },
              "kwargs": {
                "advanced": true,
                "display_name": "kwargs",
                "dynamic": false,
                "info": "kwargs of agent.",
                "list": true,
                "name": "kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "llm": {
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "memory": {
                "advanced": true,
                "display_name": "Memory",
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "list": false,
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "role": {
                "advanced": false,
                "display_name": "Role",
                "dynamic": false,
                "info": "The role of the agent.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "role",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Atua com a personalidade de um especialista em venda de palitos de carne premium para animais de estimação, focado em responder perguntas e fornecer informações detalhadas sobre os benefícios dos produtos com base em seu backstory. Seu papel é educar e orientar os clientes sobre as qualidades exclusivas dos palitos de carne, além de destacar os benefícios para a saúde e bem-estar dos animais."
              },
              "tools": {
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "Tools at agents disposal",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": []
              },
              "verbose": {
                "advanced": false,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "CrewAIAgentComponent"
        },
        "selected": false,
        "width": 384,
        "height": 712,
        "positionAbsolute": {
          "x": -1462.7139747635383,
          "y": -3743.8538781568063
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-WKePu",
        "type": "genericNode",
        "position": {
          "x": -1891.1635882157223,
          "y": -3545.5968279582826
        },
        "data": {
          "id": "OpenAIModel-WKePu",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Text",
                "method": "text_response",
                "name": "text_output",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Language Model",
                "method": "build_model",
                "name": "model_output",
                "selected": "LanguageModel",
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [
                  "Message"
                ],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
              },
              "input_value": {
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_tokens": {
                "advanced": false,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "name": "max_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 0
              },
              "model_kwargs": {
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "advanced": false,
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-3.5-turbo"
              },
              "openai_api_base": {
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_schema": {
                "advanced": true,
                "display_name": "Schema",
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "seed": {
                "advanced": false,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "advanced": true,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "list": false,
                "load_from_db": false,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "list": false,
                "name": "temperature",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": 0.1
              }
            },
            "lf_version": "0.0.96"
          },
          "type": "OpenAIModel"
        },
        "selected": false,
        "width": 384,
        "height": 780,
        "positionAbsolute": {
          "x": -1891.1635882157223,
          "y": -3545.5968279582826
        },
        "dragging": false
      },
      {
        "id": "note-iohW7",
        "type": "noteNode",
        "position": {
          "x": 262.8175553100831,
          "y": -461.37489016509517
        },
        "data": {
          "node": {
            "description": "Agentes para Criação de Conteúdo:\n\n- Pesquisador;\n- CopyWriter;\n- Editor Revisor;",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-iohW7"
        },
        "selected": false,
        "width": 324,
        "height": 324,
        "positionAbsolute": {
          "x": 262.8175553100831,
          "y": -461.37489016509517
        },
        "dragging": false
      },
      {
        "id": "note-Vmxvn",
        "type": "noteNode",
        "position": {
          "x": -1520.0363586011997,
          "y": -4469.284580443696
        },
        "data": {
          "node": {
            "description": "Agentes de Utilidades:\n\n- postagem no notion;",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "amber"
            }
          },
          "type": "note",
          "id": "note-Vmxvn"
        },
        "selected": false,
        "width": 324,
        "height": 324,
        "positionAbsolute": {
          "x": -1520.0363586011997,
          "y": -4469.284580443696
        },
        "dragging": false
      },
      {
        "id": "ComposioAPI-K2XQ0",
        "type": "genericNode",
        "position": {
          "x": -2298.1009428075113,
          "y": -4053.1663166895482
        },
        "data": {
          "type": "ComposioAPI",
          "node": {
            "template": {
              "_type": "Component",
              "action_names": {
                "trace_as_metadata": true,
                "options": [
                  "NOTION_ADD_PAGE_CONTENT",
                  "NOTION_ARCHIVE_NOTION_PAGE",
                  "NOTION_CREATE_COMMENT",
                  "NOTION_CREATE_DATABASE",
                  "NOTION_CREATE_NOTION_PAGE",
                  "NOTION_DELETE_BLOCK",
                  "NOTION_FETCH_COMMENTS",
                  "NOTION_FETCH_DATABASE",
                  "NOTION_FETCH_NOTION_BLOCK",
                  "NOTION_FETCH_NOTION_CHILD_BLOCK",
                  "NOTION_FETCH_ROW",
                  "NOTION_GET_ABOUT_ME",
                  "NOTION_GET_ABOUT_USER",
                  "NOTION_INSERT_ROW_DATABASE",
                  "NOTION_LIST_USERS",
                  "NOTION_QUERY_DATABASE",
                  "NOTION_SEARCH_NOTION_PAGE",
                  "NOTION_UPDATE_ROW_DATABASE",
                  "NOTION_UPDATE_SCHEMA_DATABASE"
                ],
                "combobox": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "action_names",
                "value": [
                  "NOTION_ADD_PAGE_CONTENT"
                ],
                "display_name": "Actions to use",
                "advanced": false,
                "dynamic": false,
                "info": "The actions to pass to agent to execute",
                "title_case": false,
                "type": "str",
                "_input_type": "MultiselectInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Composio API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key",
                "refresh_button": true,
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "app_names": {
                "trace_as_metadata": true,
                "options": [
                  "APALEO",
                  "APIFY",
                  "ASANA",
                  "ATTIO",
                  "BITBUCKET",
                  "BREVO",
                  "BROWSERBASE_TOOL",
                  "BROWSER_TOOL",
                  "CLICKUP",
                  "CODEINTERPRETER",
                  "CODE_FORMAT_TOOL",
                  "CODE_GREP_TOOL",
                  "CODE_INDEX_TOOL",
                  "CODE_MAP_TOOL",
                  "COMPOSIO",
                  "DISCORD",
                  "DROPBOX",
                  "ELEVENLABS",
                  "EMBED_TOOL",
                  "EXA",
                  "FIGMA",
                  "FILETOOL",
                  "FIRECRAWL",
                  "GIT",
                  "GITHUB",
                  "GITLAB",
                  "GMAIL",
                  "GOOGLECALENDAR",
                  "GOOGLEDOCS",
                  "GOOGLEDRIVE",
                  "GOOGLEMEET",
                  "GOOGLESHEETS",
                  "GOOGLETASKS",
                  "GREPTILE",
                  "HACKERNEWS",
                  "HEROKU",
                  "HISTORY_FETCHER",
                  "HUBSPOT",
                  "IMAGE_ANALYSER",
                  "INDUCED_AI",
                  "JIRA",
                  "KLAVIYO",
                  "LINEAR",
                  "LISTENNOTES",
                  "MATHEMATICAL",
                  "MULTIONAI",
                  "NASA",
                  "NOTION",
                  "OKTA",
                  "PAGERDUTY",
                  "PERPLEXITYAI",
                  "PIPEDRIVE",
                  "POSTHOG",
                  "RAGTOOL",
                  "SCHEDULER",
                  "SERPAPI",
                  "SHELLTOOL",
                  "SLACK",
                  "SLACKBOT",
                  "SNOWFLAKE",
                  "SOUNDCLOUD",
                  "SPIDERTOOL",
                  "SPLITWISE",
                  "SPOTIFY",
                  "SQLTOOL",
                  "STRAVA",
                  "TASKADE",
                  "TAVILY",
                  "TRELLO",
                  "TWILIO",
                  "TWITTER",
                  "TYPEFORM",
                  "WEATHERMAP",
                  "WEBTOOL",
                  "WHATSAPP",
                  "WORKABLE",
                  "WORKSPACE_TOOL",
                  "YOUSEARCH",
                  "YOUTUBE",
                  "ZENDESK",
                  "ZEPTOOL",
                  "ZOOM"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "app_names",
                "value": "NOTION",
                "display_name": "App Name",
                "advanced": false,
                "dynamic": false,
                "info": "The app name to use. Please refresh after selecting app name",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "auth_status_config": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "auth_status_config",
                "value": "NOTION CONNECTED",
                "display_name": "Auth status",
                "advanced": false,
                "dynamic": false,
                "info": "Open link or enter api key. Then refresh button",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, Sequence\n\nfrom composio_langchain import Action, App, ComposioToolSet  # type: ignore\nfrom langchain_core.tools import Tool\nfrom loguru import logger\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import DropdownInput, MessageTextInput, MultiselectInput, SecretStrInput, StrInput\n\n\nclass ComposioAPIComponent(LCToolComponent):\n    display_name: str = \"Composio Tools\"\n    description: str = \"Use Composio toolset to run actions with your agent\"\n    name = \"ComposioAPI\"\n    icon = \"Composio\"\n    documentation: str = \"https://docs.composio.dev\"\n\n    inputs = [\n        MessageTextInput(name=\"entity_id\", display_name=\"Entity ID\", value=\"default\", advanced=True),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Composio API Key\",\n            required=True,\n            refresh_button=True,\n            info=\"Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key\",\n        ),\n        DropdownInput(\n            name=\"app_names\",\n            display_name=\"App Name\",\n            options=[app_name for app_name in App.__annotations__],\n            value=\"\",\n            info=\"The app name to use. Please refresh after selecting app name\",\n            refresh_button=True,\n        ),\n        MultiselectInput(\n            name=\"action_names\",\n            display_name=\"Actions to use\",\n            required=False,\n            options=[],\n            value=[],\n            info=\"The actions to pass to agent to execute\",\n        ),\n        StrInput(\n            name=\"auth_status_config\",\n            display_name=\"Auth status\",\n            value=\"\",\n            refresh_button=True,\n            info=\"Open link or enter api key. Then refresh button\",\n        ),\n    ]\n\n    def _check_for_authorization(self, app: str) -> str:\n        \"\"\"\n        Checks if the app is authorized.\n\n        Args:\n            app (str): The app name to check authorization for.\n\n        Returns:\n            str: The authorization status.\n        \"\"\"\n        toolset = self._build_wrapper()\n        entity = toolset.client.get_entity(id=self.entity_id)\n        try:\n            entity.get_connection(app=app)\n            return f\"{app} CONNECTED\"\n        except Exception:\n            return self._handle_authorization_failure(toolset, entity, app)\n\n    def _handle_authorization_failure(self, toolset: ComposioToolSet, entity: Any, app: str) -> str:\n        \"\"\"\n        Handles the authorization failure by attempting to process API key auth or initiate default connection.\n\n        Args:\n            toolset (ComposioToolSet): The toolset instance.\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The result of the authorization failure message.\n        \"\"\"\n        try:\n            auth_schemes = toolset.client.apps.get(app).auth_schemes\n            if auth_schemes[0].auth_mode == \"API_KEY\":\n                return self._process_api_key_auth(entity, app)\n            else:\n                return self._initiate_default_connection(entity, app)\n        except Exception as exc:\n            logger.error(f\"Authorization error: {str(exc)}\")\n            return \"Error\"\n\n    def _process_api_key_auth(self, entity: Any, app: str) -> str:\n        \"\"\"\n        Processes the API key authentication.\n\n        Args:\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The status of the API key authentication.\n        \"\"\"\n        auth_status_config = self.auth_status_config\n        is_url = \"http\" in auth_status_config or \"https\" in auth_status_config\n        is_different_app = \"CONNECTED\" in auth_status_config and app not in auth_status_config\n        is_default_api_key_message = \"API Key\" in auth_status_config\n\n        if is_different_app or is_url or is_default_api_key_message:\n            return \"Enter API Key\"\n        else:\n            if not is_default_api_key_message:\n                entity.initiate_connection(\n                    app_name=app,\n                    auth_mode=\"API_KEY\",\n                    auth_config={\"api_key\": self.auth_status_config},\n                    use_composio_auth=False,\n                    force_new_integration=True,\n                )\n                return f\"{app} CONNECTED\"\n            else:\n                return \"Enter API Key\"\n\n    def _initiate_default_connection(self, entity: Any, app: str) -> str:\n        connection = entity.initiate_connection(app_name=app, use_composio_auth=True, force_new_integration=True)\n        return connection.redirectUrl\n\n    def _get_connected_app_names_for_entity(self) -> list[str]:\n        toolset = self._build_wrapper()\n        connections = toolset.client.get_entity(id=self.entity_id).get_connections()\n        return list(set(connection.appUniqueId for connection in connections))\n\n    def _update_app_names_with_connected_status(self, build_config: dict) -> dict:\n        connected_app_names = self._get_connected_app_names_for_entity()\n\n        app_names = [\n            f\"{app_name}_CONNECTED\" for app_name in App.__annotations__ if app_name.lower() in connected_app_names\n        ]\n        non_connected_app_names = [\n            app_name for app_name in App.__annotations__ if app_name.lower() not in connected_app_names\n        ]\n        build_config[\"app_names\"][\"options\"] = app_names + non_connected_app_names\n        build_config[\"app_names\"][\"value\"] = app_names[0] if app_names else \"\"\n        return build_config\n\n    def _get_normalized_app_name(self) -> str:\n        return self.app_names.replace(\"_CONNECTED\", \"\").replace(\"_connected\", \"\")\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name == \"api_key\":\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config = self._update_app_names_with_connected_status(build_config)\n            return build_config\n\n        if field_name in {\"app_names\", \"auth_status_config\"}:\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config[\"auth_status_config\"][\"value\"] = self._check_for_authorization(\n                    self._get_normalized_app_name()\n                )\n            all_action_names = [action_name for action_name in Action.__annotations__]\n            app_action_names = [\n                action_name\n                for action_name in all_action_names\n                if action_name.lower().startswith(self._get_normalized_app_name().lower() + \"_\")\n            ]\n            build_config[\"action_names\"][\"options\"] = app_action_names\n            build_config[\"action_names\"][\"value\"] = [app_action_names[0]] if app_action_names else [\"\"]\n        return build_config\n\n    def build_tool(self) -> Sequence[Tool]:\n        composio_toolset = self._build_wrapper()\n        composio_tools = composio_toolset.get_tools(actions=self.action_names)\n        return composio_tools\n\n    def _build_wrapper(self) -> ComposioToolSet:\n        return ComposioToolSet(api_key=self.api_key)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "entity_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "entity_id",
                "value": "default",
                "display_name": "Entity ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Use Composio toolset to run actions with your agent",
            "icon": "Composio",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "Composio Tools",
            "documentation": "https://docs.composio.dev",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "entity_id",
              "api_key",
              "app_names",
              "action_names",
              "auth_status_config"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ComposioAPI-K2XQ0"
        },
        "selected": false,
        "width": 384,
        "height": 635,
        "positionAbsolute": {
          "x": -2298.1009428075113,
          "y": -4053.1663166895482
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "HierarchicalCrewComponent",
            "id": "HierarchicalCrewComponent-RFMOg",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-9aqsp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-HierarchicalCrewComponent-RFMOg{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-9aqsp{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9aqspœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "HierarchicalCrewComponent-RFMOg",
        "sourceHandle": "{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-9aqsp",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9aqspœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "HierarchicalTaskComponent",
            "id": "HierarchicalTaskComponent-ysXYI",
            "name": "task_output",
            "output_types": [
              "HierarchicalTask"
            ]
          },
          "targetHandle": {
            "fieldName": "tasks",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "HierarchicalTask"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-HierarchicalTaskComponent-ysXYI{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "HierarchicalTaskComponent-ysXYI",
        "sourceHandle": "{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-P5KkL",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          },
          "targetHandle": {
            "fieldName": "manager_agent",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-P5KkL{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œmanager_agentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CrewAIAgentComponent-P5KkL",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œmanager_agentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-cxeAa",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-P5KkL",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-cxeAa{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cxeAaœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-P5KkL{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-cxeAa",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cxeAaœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-P5KkL",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-K18mo",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "task_description",
            "id": "HierarchicalTaskComponent-ysXYI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-K18mo{œdataTypeœ:œPromptœ,œidœ:œPrompt-K18moœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-HierarchicalTaskComponent-ysXYI{œfieldNameœ:œtask_descriptionœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-K18mo",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-K18moœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "HierarchicalTaskComponent-ysXYI",
        "targetHandle": "{œfieldNameœ:œtask_descriptionœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yH1am",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-K18mo",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-yH1am{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yH1amœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-K18mo{œfieldNameœ:œqueryœ,œidœ:œPrompt-K18moœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-yH1am",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yH1amœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-K18mo",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-K18moœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "OpenAIModel-3lCHz",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-k7Ea3",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-k7Ea3",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3lCHz",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-k7Ea3{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-3lCHz",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-VF3Dz",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-VF3Dz",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3lCHz",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-VF3Dz{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "SearchAPI-hnrpV",
        "sourceHandle": "{œdataTypeœ:œSearchAPIœ,œidœ:œSearchAPI-hnrpVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "CrewAIAgentComponent-VF3Dz",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-VF3Dz",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SearchAPI",
            "id": "SearchAPI-hnrpV",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-SearchAPI-hnrpV{œdataTypeœ:œSearchAPIœ,œidœ:œSearchAPI-hnrpVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-VF3Dz{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-3lCHz",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-fl7KA",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-fl7KA",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3lCHz",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-fl7KA{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-fl7KA",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-fl7KA",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-fl7KA{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-k7Ea3",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-k7Ea3",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-k7Ea3{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-VF3Dz",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-VF3Dz",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-VF3Dz{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-2Re1E",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-2Re1Eœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-ZMVIC",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-ZMVIC",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-2Re1E",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-2Re1E{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-2Re1Eœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-ZMVIC{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-ZMVIC",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "HierarchicalCrewComponent-RFMOg",
        "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "agents",
            "id": "HierarchicalCrewComponent-RFMOg",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-ZMVIC",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-ZMVIC{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-WKePu",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WKePuœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-D2zPF",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-D2zPF",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-WKePu",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-WKePu{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WKePuœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-D2zPF{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ComposioAPI-K2XQ0",
        "sourceHandle": "{œdataTypeœ:œComposioAPIœ,œidœ:œComposioAPI-K2XQ0œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "CrewAIAgentComponent-D2zPF",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-D2zPF",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "ComposioAPI",
            "id": "ComposioAPI-K2XQ0",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-ComposioAPI-K2XQ0{œdataTypeœ:œComposioAPIœ,œidœ:œComposioAPI-K2XQ0œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-D2zPF{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 958.7775439111286,
      "y": 581.7967076150758,
      "zoom": 0.19621210437571884
    }
  },
  "metadata": {
    "HierarchicalCrewComponent": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "HierarchicalTaskComponent": {
      "count": 1
    },
    "CrewAIAgentComponent": {
      "count": 6
    },
    "OpenAIModel": {
      "count": 4
    },
    "Prompt": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "SearchAPI": {
      "count": 1
    },
    "note": {
      "count": 2
    },
    "ComposioAPI": {
      "count": 1
    },
    "total": 19
  },
  "original": {
    "id": "9c4aecc0-e0f3-4b5a-b9b7-85e2466d03b4",
    "name": "Agente com composio(Teste)",
    "description": "Criando um agente com composio\n",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "HierarchicalCrewComponent": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "HierarchicalTaskComponent": {
        "count": 1
      },
      "CrewAIAgentComponent": {
        "count": 6
      },
      "OpenAIModel": {
        "count": 4
      },
      "Prompt": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "SearchAPI": {
        "count": 1
      },
      "note": {
        "count": 2
      },
      "ComposioAPI": {
        "count": 1
      },
      "total": 19
    },
    "last_tested_version": "0.0.96",
    "private": true,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
            "display_name": "Hierarchical Crew",
            "id": "HierarchicalCrewComponent-RFMOg",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Represents a group of agents, defining how they should collaborate and the tasks they should perform.",
              "display_name": "Hierarchical Crew",
              "documentation": "",
              "edited": false,
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "agents",
                "tasks",
                "manager_llm",
                "manager_agent"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Output",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "agents": {
                  "advanced": false,
                  "display_name": "Agents",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Agent"
                  ],
                  "list": true,
                  "name": "agents",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Crew, Process  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\n\n\nclass HierarchicalCrewComponent(BaseCrewComponent):\n    display_name: str = \"Hierarchical Crew\"\n    description: str = (\n        \"Represents a group of agents, defining how they should collaborate and the tasks they should perform.\"\n    )\n    documentation: str = \"https://docs.crewai.com/how-to/Hierarchical/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"agents\", display_name=\"Agents\", input_types=[\"Agent\"], is_list=True),\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"HierarchicalTask\"], is_list=True),\n        HandleInput(name=\"manager_llm\", display_name=\"Manager LLM\", input_types=[\"LanguageModel\"], required=False),\n        HandleInput(name=\"manager_agent\", display_name=\"Manager Agent\", input_types=[\"Agent\"], required=False),\n    ]\n\n    def build_crew(self) -> Crew:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.hierarchical,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            manager_agent=self.manager_agent,\n            manager_llm=self.manager_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n"
                },
                "function_calling_llm": {
                  "advanced": true,
                  "display_name": "Function Calling LLM",
                  "dynamic": false,
                  "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "function_calling_llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "manager_agent": {
                  "advanced": false,
                  "display_name": "Manager Agent",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Agent"
                  ],
                  "list": false,
                  "name": "manager_agent",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "manager_llm": {
                  "advanced": false,
                  "display_name": "Manager LLM",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "manager_llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "max_rpm": {
                  "advanced": true,
                  "display_name": "Max RPM",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "max_rpm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 100
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "share_crew": {
                  "advanced": true,
                  "display_name": "Share Crew",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "share_crew",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "tasks": {
                  "advanced": false,
                  "display_name": "Tasks",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "HierarchicalTask"
                  ],
                  "list": true,
                  "name": "tasks",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "use_cache": {
                  "advanced": true,
                  "display_name": "Cache",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "use_cache",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "verbose": {
                  "advanced": true,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 0
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "HierarchicalCrewComponent"
          },
          "height": 460,
          "id": "HierarchicalCrewComponent-RFMOg",
          "position": {
            "x": 2776.3568176564536,
            "y": 649.6596099240163
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "positionAbsolute": {
            "x": 2776.3568176564536,
            "y": 649.6596099240163
          },
          "dragging": false
        },
        {
          "data": {
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "id": "ChatOutput-9aqsp",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Display a chat message in the Playground.",
              "display_name": "Chat Output",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "frozen": false,
              "icon": "ChatOutput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "data_template": {
                  "advanced": true,
                  "display_name": "Data Template",
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "data_template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "{text}"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Machine"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "AI"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "should_store_message": {
                  "advanced": true,
                  "display_name": "Store Messages",
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "should_store_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "ChatOutput"
          },
          "height": 303,
          "id": "ChatOutput-9aqsp",
          "position": {
            "x": 3368.4175183697535,
            "y": 769.3124344428455
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "positionAbsolute": {
            "x": 3368.4175183697535,
            "y": 769.3124344428455
          },
          "dragging": false
        },
        {
          "data": {
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "display_name": "Hierarchical Task",
            "id": "HierarchicalTaskComponent-ysXYI",
            "node": {
              "base_classes": [
                "HierarchicalTask"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Each task must have a description, an expected output and an agent responsible for execution.",
              "display_name": "Hierarchical Task",
              "documentation": "",
              "edited": false,
              "field_order": [
                "task_description",
                "expected_output",
                "tools"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Task",
                  "method": "build_task",
                  "name": "task_output",
                  "selected": "HierarchicalTask",
                  "types": [
                    "HierarchicalTask"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.agents.crewai.tasks import HierarchicalTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, MultilineInput, Output\n\n\nclass HierarchicalTaskComponent(Component):\n    display_name: str = \"Hierarchical Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> HierarchicalTask:\n        task = HierarchicalTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.tools or [],\n        )\n        self.status = task\n        return task\n"
                },
                "expected_output": {
                  "advanced": false,
                  "display_name": "Expected Output",
                  "dynamic": false,
                  "info": "Clear definition of expected task outcome.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "expected_output",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Succinct response that answers the User's query."
                },
                "task_description": {
                  "advanced": false,
                  "display_name": "Description",
                  "dynamic": false,
                  "info": "Descriptive text detailing task's purpose and execution.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "task_description",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "tools": {
                  "advanced": true,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "HierarchicalTaskComponent"
          },
          "height": 413,
          "id": "HierarchicalTaskComponent-ysXYI",
          "position": {
            "x": 1998.6192209565584,
            "y": 752.6478253929832
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "positionAbsolute": {
            "x": 1998.6192209565584,
            "y": 752.6478253929832
          },
          "dragging": false
        },
        {
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-P5KkL",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Represents an agent of CrewAI.",
              "display_name": "Manager agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Backstory:\nO manager de agentes supervisiona um ambiente colaborativo onde cada agente desempenha um papel crucial no fluxo de produção de conteúdo. Desde a coleta inicial de informações pelo pesquisador, até a criação de textos pelo copywriter e a revisão final pelo editor revisor, o manager garante que cada tarefa seja executada com precisão e que o fluxo de trabalho seja organizado. Em casos de perguntas relacionadas a produtos específicos, o manager tem a flexibilidade de encaminhar a questão diretamente para um especialista, garantindo uma resposta rápida e precisa sem precisar acionar os outros agentes. No final, o manager organiza e apresenta as respostas de forma estruturada, com destaque para os agentes que participaram de cada etapa, e continua o fluxo de trabalho mesmo se algum agente não for encontrado."
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Goal:\n\nRealiza a tarefa de gerenciar e delegar tarefas entre os agentes de forma ordenada e eficiente, seguindo estas etapas:\n\nPesquisador (Analista de conteúdo digital especializado em tecnologia, com foco no mercado de Inteligência Artificial - IA): Ao acionar o pesquisador, ele deve coletar informações detalhadas e relevantes sobre o tema solicitado.\n\nSe o pesquisador não for encontrado, as informações disponíveis devem ser repassadas diretamente ao copywriter, e o fluxo segue normalmente.\nCopywriter (Copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão): Após o pesquisador concluir sua tarefa, ou caso o pesquisador não seja encontrado, o manager deve passar o material diretamente ao copywriter, que transformará as informações em um texto criativo e persuasivo.\n\nSe o copywriter não for encontrado, o material deve ser enviado diretamente para o editor revisor, mas o resultado final exibido será do copywriter, caso tenha participado.\nEditor Revisor (Agente Editor Revisor): Após o copywriter finalizar o texto, ou caso o copywriter não seja encontrado, o manager encaminha o material para o editor revisor, que revisa o conteúdo para garantir clareza, coesão e correção de erros.\n\nEmbora o editor revisor participe do fluxo para garantir a qualidade do texto, o resultado final a ser apresentado ao solicitante não incluirá a contribuição direta do editor.\nFluxo de Respostas: A resposta não deve ser enviada ao solicitante até que o manager tenha tentado passar as informações pelos três agentes (pesquisador, copywriter e editor revisor). Mesmo que algum dos agentes não seja encontrado, o fluxo deve continuar com os agentes disponíveis, e a resposta será gerada com os dados fornecidos por aqueles que participaram do processo.\n\nApós a conclusão das tarefas pelos agentes disponíveis, o manager deve estruturar a resposta final, exibindo o nome de cada agente e seus respectivos resultados de forma clara e em negrito, seguindo a ordem cronológica do fluxo de trabalho. A resposta final incluirá apenas os tópicos encontrados pelo pesquisador e o texto gerado pelo copywriter, ignorando a contribuição do editor revisor no resultado exibido.\n\nPor exemplo:\n\nPesquisador (Analista de conteúdo digital especializado em tecnologia, com foco em IA):\n\nTópico 1: [detalhe da pesquisa]\nTópico 2: [detalhe da pesquisa]\nTópico 3: [detalhe da pesquisa]\n(quebra de linha)\nCopywriter (Copywriter especializado em campanhas de marketing e conversão):\nTexto criativo baseado nos tópicos gerados pelo pesquisador.\n\nExceção:\nCaso a pergunta seja sobre um produto específico ou tema especializado da Furestpet, o manager deve direcionar a pergunta diretamente ao Agente Especialista em Produtos da Furestpet. Nesse caso, a resposta pode ser enviada imediatamente pelo especialista, sem necessidade de envolver os outros agentes (pesquisador, copywriter e editor revisor)."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Role:\nAtua com a personalidade de um manager de agentes, responsável por coordenar e delegar tarefas entre diferentes agentes, incluindo o pesquisador, o copywriter, o editor revisor e especialistas em produtos ou tópicos específicos. Seu papel é garantir o fluxo eficiente de informações entre os agentes, organizar cada etapa do processo de criação e revisão de conteúdo e estruturar a resposta final de forma clara, destacando os agentes e suas contribuições."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "dragging": false,
          "height": 712,
          "id": "CrewAIAgentComponent-P5KkL",
          "position": {
            "x": 1997.096695650694,
            "y": 1255.534535025709
          },
          "positionAbsolute": {
            "x": 1997.096695650694,
            "y": 1255.534535025709
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-cxeAa",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "_input_type": "SecretStrInput",
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-4-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "OpenAIModel"
          },
          "dragging": false,
          "height": 607,
          "id": "OpenAIModel-cxeAa",
          "position": {
            "x": 1365.400497898475,
            "y": 1507.9746660403787
          },
          "positionAbsolute": {
            "x": 1365.400497898475,
            "y": 1507.9746660403787
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-K18mo",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {
                "template": [
                  "query"
                ]
              },
              "description": "Create a prompt template with dynamic variables.",
              "display_name": "Prompt",
              "documentation": "",
              "edited": false,
              "error": null,
              "field_order": [
                "template"
              ],
              "frozen": false,
              "full_path": null,
              "icon": "prompts",
              "is_composition": null,
              "is_input": null,
              "is_output": null,
              "name": "",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "name": "prompt",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
                },
                "query": {
                  "advanced": false,
                  "display_name": "query",
                  "dynamic": false,
                  "field_type": "str",
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "query",
                  "password": false,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "template": {
                  "advanced": false,
                  "display_name": "Template",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "template",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "prompt",
                  "value": "User's query:\n{query}\n\nRespond to the user with as much as information as you can about the topic. Delete if needed. If it is just a general query (e.g a greeting) you can respond them directly."
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 418,
          "id": "Prompt-K18mo",
          "position": {
            "x": 1200.1577612116853,
            "y": 655.9216455662466
          },
          "selected": false,
          "type": "genericNode",
          "width": 384,
          "positionAbsolute": {
            "x": 1200.1577612116853,
            "y": 655.9216455662466
          }
        },
        {
          "data": {
            "id": "ChatInput-yH1am",
            "node": {
              "base_classes": [
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Get chat inputs from the Playground.",
              "display_name": "Chat Input",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "frozen": false,
              "icon": "ChatInput",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Message",
                  "method": "message_response",
                  "name": "message",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n"
                },
                "files": {
                  "advanced": true,
                  "display_name": "Files",
                  "dynamic": false,
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "file_path": "",
                  "info": "Files to be sent with the message.",
                  "list": true,
                  "name": "files",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "file",
                  "value": ""
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Text",
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Tendencias em IA para analise de Imagens"
                },
                "sender": {
                  "advanced": true,
                  "display_name": "Sender Type",
                  "dynamic": false,
                  "info": "Type of sender.",
                  "name": "sender",
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "sender_name": {
                  "advanced": true,
                  "display_name": "Sender Name",
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "sender_name",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "User"
                },
                "session_id": {
                  "advanced": true,
                  "display_name": "Session ID",
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "session_id",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "should_store_message": {
                  "advanced": true,
                  "display_name": "Store Messages",
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "should_store_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "ChatInput"
          },
          "dragging": false,
          "height": 303,
          "id": "ChatInput-yH1am",
          "position": {
            "x": -1105.275607442421,
            "y": 599.8702735570906
          },
          "positionAbsolute": {
            "x": -1105.275607442421,
            "y": 599.8702735570906
          },
          "selected": true,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "CrewAIAgentComponent-k7Ea3",
          "type": "genericNode",
          "position": {
            "x": 1195.9300729812198,
            "y": -1285.6775979595816
          },
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-k7Ea3",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão.",
              "display_name": "copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão.",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Em um mercado saturado de informações, as marcas enfrentam o desafio de se destacar e capturar a atenção de seus consumidores. O copywriter é essencial nesse contexto, criando conteúdos que não apenas comunicam a mensagem da marca, mas que também incentivam ações concretas do público. Através de uma linguagem persuasiva e eficaz, o copywriter é capaz de transformar simples visitantes ou leitores em clientes e seguidores fiéis, sempre com foco nos objetivos comerciais e no público da campanha.\n\n"
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Realiza a tarefa de desenvolver textos criativos e persuasivos para campanhas de marketing digital, voltadas para maximizar conversões e engajamento do público. O copywriter deve adaptar o tom e estilo da escrita para o público-alvo de cada campanha, seja em redes sociais, e-mails, anúncios ou páginas de vendas. Os textos devem ser claros, envolventes e com chamadas para ação diretas e eficazes, sempre priorizando o alinhamento com a identidade da marca e os objetivos estratégicos da campanha, sempre responda no mesmo idioma da pergunta."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Atua com a personalidade de um copywriter especializado em criar conteúdo persuasivo e atrativo, focado em campanhas de marketing e conversão. Seu papel é produzir textos estratégicos que engajam o público-alvo e incentivam ações específicas, como compras, assinaturas ou interações."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "selected": false,
          "width": 384,
          "height": 768,
          "positionAbsolute": {
            "x": 1195.9300729812198,
            "y": -1285.6775979595816
          },
          "dragging": false
        },
        {
          "id": "SearchAPI-hnrpV",
          "type": "genericNode",
          "position": {
            "x": 135.36494975125436,
            "y": -1740.3901791956043
          },
          "data": {
            "description": "Call the searchapi.io API",
            "display_name": "Search API",
            "id": "SearchAPI-hnrpV",
            "node": {
              "base_classes": [
                "Data",
                "Tool"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Call the searchapi.io API with result limiting",
              "display_name": "Search API",
              "documentation": "https://www.searchapi.io/docs/google",
              "edited": false,
              "field_order": [
                "engine",
                "api_key",
                "input_value",
                "search_params"
              ],
              "frozen": false,
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Data",
                  "method": "run_model",
                  "name": "api_run_model",
                  "selected": "Data",
                  "types": [
                    "Data"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Tool",
                  "method": "build_tool",
                  "name": "api_build_tool",
                  "selected": "Tool",
                  "types": [
                    "Tool"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "advanced": false,
                  "display_name": "SearchAPI API Key",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from typing import Dict, Any, Optional, List\nfrom pydantic import BaseModel, Field\nfrom langchain_community.utilities.searchapi import SearchApiAPIWrapper\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, DictInput, MessageTextInput, IntInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\nfrom langchain.tools import StructuredTool\n\n\nclass SearchAPIComponent(LCToolComponent):\n    display_name: str = \"Search API\"\n    description: str = \"Call the searchapi.io API with result limiting\"\n    name = \"SearchAPI\"\n    documentation: str = \"https://www.searchapi.io/docs/google\"\n\n    inputs = [\n        MessageTextInput(name=\"engine\", display_name=\"Engine\", value=\"google\"),\n        SecretStrInput(name=\"api_key\", display_name=\"SearchAPI API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        DictInput(name=\"search_params\", display_name=\"Search parameters\", advanced=True, is_list=True),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class SearchAPISchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        params: Optional[Dict[str, Any]] = Field(default_factory=dict, description=\"Additional search parameters\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return SearchApiAPIWrapper(engine=self.engine, searchapi_api_key=self.api_key)\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(\n            query: str, params: Optional[Dict[str, Any]] = None, max_results: int = 5, max_snippet_length: int = 100\n        ) -> List[Dict[str, Any]]:\n            params = params or {}\n            full_results = wrapper.results(query=query, **params)\n            organic_results = full_results.get(\"organic_results\", [])[:max_results]\n\n            limited_results = []\n            for result in organic_results:\n                limited_result = {\n                    \"title\": result.get(\"title\", \"\")[:max_snippet_length],\n                    \"link\": result.get(\"link\", \"\"),\n                    \"snippet\": result.get(\"snippet\", \"\")[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"search_api\",\n            description=\"Search for recent results using searchapi.io with result limiting\",\n            func=search_func,\n            args_schema=self.SearchAPISchema,\n        )\n\n        self.status = f\"Search API Tool created with engine: {self.engine}\"\n        return tool\n\n    def run_model(self) -> List[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"params\": self.search_params or {},\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n\n        self.status = data_list\n        return data_list\n"
                },
                "engine": {
                  "advanced": false,
                  "display_name": "Engine",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "engine",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "google"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "max_results": {
                  "_input_type": "IntInput",
                  "advanced": true,
                  "display_name": "Max Results",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "max_results",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 5
                },
                "max_snippet_length": {
                  "_input_type": "IntInput",
                  "advanced": true,
                  "display_name": "Max Snippet Length",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "max_snippet_length",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 100
                },
                "search_params": {
                  "advanced": true,
                  "display_name": "Search parameters",
                  "dynamic": false,
                  "info": "",
                  "list": true,
                  "name": "search_params",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "SearchAPI"
          },
          "selected": false,
          "width": 384,
          "height": 521,
          "dragging": false,
          "positionAbsolute": {
            "x": 135.36494975125436,
            "y": -1740.3901791956043
          }
        },
        {
          "id": "OpenAIModel-3lCHz",
          "type": "genericNode",
          "position": {
            "x": 132.32173575908644,
            "y": -1182.8691783301506
          },
          "data": {
            "id": "OpenAIModel-3lCHz",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "_input_type": "SecretStrInput",
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": true,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": ""
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": true,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "OpenAIModel"
          },
          "selected": false,
          "width": 384,
          "height": 607,
          "positionAbsolute": {
            "x": 132.32173575908644,
            "y": -1182.8691783301506
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-VF3Dz",
          "type": "genericNode",
          "position": {
            "x": 1201.6293693212303,
            "y": -2069.526879295477
          },
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-VF3Dz",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "analista de conteúdo digital especializado em tecnologia, com foco no mercado de inteligência artificial (ia)",
              "display_name": "analista de conteúdo digital especializado em tecnologia, com foco no mercado de inteligência artificial (ia)",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "A demanda por dados precisos e recentes no campo de IA está crescendo rapidamente entre executivos e investidores que precisam de insights estratégicos para a tomada de decisões. O agente foi projetado para atender essa necessidade, garantindo que as informações coletadas sejam atualizadas e provenientes de fontes respeitadas. O agente não precisa analisar ou interpretar os dados, apenas coletá-los de forma estruturada e organizada em relatórios detalhados que podem ser solicitados conforme a demanda."
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Realiza a tarefa de coletar relatórios detalhados e conteúdos recentes sobre tópicos-chave em Inteligência Artificial, focados no impacto e nas tendências de mercado para investidores e executivos. A pesquisa deve ser realizada por meio da Google Search API e priorizar fontes confiáveis como Google, Bing e DuckDuckGo. O agente coletará informações tanto em português quanto em inglês, e apresentará os resultados em relatórios organizados e detalhados, sempre responda no mesmo idioma da pergunta."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Atua com a personalidade de um analista de conteúdo digital especializado em tecnologia, com foco no mercado de Inteligência Artificial (IA). Seu papel é realizar pesquisas de conteúdo relevantes e específicos para investidores e executivos, utilizando plataformas de busca confiáveis e uma abordagem orientada a dados."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "selected": false,
          "width": 384,
          "height": 768,
          "positionAbsolute": {
            "x": 1201.6293693212303,
            "y": -2069.526879295477
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-fl7KA",
          "type": "genericNode",
          "position": {
            "x": 1193.5755732549603,
            "y": -497.56678854719144
          },
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-fl7KA",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Agente Editor Revisor",
              "display_name": "Agente Editor Revisor",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "A demanda por dados precisos e recentes no campo de IA está crescendo rapidamente entre executivos e investidores que precisam de insights estratégicos para a tomada de decisões. O agente foi projetado para atender essa necessidade, garantindo que as informações coletadas sejam atualizadas e provenientes de fontes respeitadas. O agente não precisa analisar ou interpretar os dados, apenas coletá-los de forma estruturada e organizada em relatórios detalhados que podem ser solicitados conforme a demanda."
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Com a crescente demanda por conteúdo de alta qualidade e comunicação precisa, o papel do editor revisor é essencial para assegurar que todos os materiais escritos reflitam a credibilidade e a excelência da marca ou empresa. Desde a revisão de pequenos erros até ajustes de estrutura e estilo, o editor revisor garante que o texto seja impactante, coeso e sem falhas, contribuindo diretamente para a reputação e a eficácia da comunicação da organização, responda sempre no Idioma da pergunta.\n\n"
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Atua com a personalidade de um editor revisor especializado em garantir a clareza, precisão e qualidade de textos. Seu papel é revisar e editar conteúdos escritos, corrigindo erros gramaticais, de estilo, ortografia e aprimorando a fluidez e consistência da comunicação."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "selected": false,
          "width": 384,
          "height": 712,
          "positionAbsolute": {
            "x": 1193.5755732549603,
            "y": -497.56678854719144
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-ZMVIC",
          "type": "genericNode",
          "position": {
            "x": 1195.1532229698776,
            "y": -2837.9497804375774
          },
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-ZMVIC",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Analista de conteúdo digital, especializado em tecnologia.",
              "display_name": "Agente Especialista em Produtos da Furest pet",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "## Objetivo\n\nNa Furest Pet, a conexão entre cães, humanos e natureza está no centro de quem somos. Nosso nome, uma mistura de \"fur\" (pelo) e \"forest\" (floresta), representa nosso profundo respeito pelos pets e nossa promessa de contribuir com o meio ambiente.\n\nCada produto Furest Pet, enriquecido com ingredientes incríveis encontrados na Floresta Amazônica, é uma fonte de qualidade de vida e longevidade para o seu amigo canino, e também uma maneira de fortalecer a sua ligação com ele.\n\nDiferentes produtos, mesmo objetivo: conectar as maravilhas da natureza à vida diária de seu pet e de quem o ama.\n\n## missão\n\nNossa missão é profundamente concentrada no cuidado e bem-estar canino. Nosso propósito é promover ao pet uma vida mais saudável, longa e feliz, onde ele pode aproveitar por mais tempo o vínculo lindo entre ele e seu tutor.\n\nInspirados pela beleza majestosa e o ecossistema único da Floresta Amazônica, desenvolvemos produtos naturais que encantam nossos amigos de quatro patas. Nosso objetivo é trazer as maravilhas dessa floresta pulsante e incrível para a vida de seu melhor amigo.\n\n## Valores\n\n- Sustentabilidade\nA Floresta Amazônica, em sua imensidão e majestosidade, é um tesouro vivo que nos brinda com riquezas naturais inestimáveis. Cada elemento que ela nos oferece é um presente, e é nossa filosofia dar de volta aquilo que elas nos oferece.\n\nEm cada produto Furest Pet, há uma promessa de respeito e harmonia com a natureza. Com o \"Paws For The Forest\", não apenas plantamos árvores, mas também desenvolvemos parcerias com famílias e comunidades locais. Nossa missão transcende os negócios, alimentando a essência vital do ciclo de conservação e sustentabilidade. A cada compra, fortalecemos o legado de um futuro mais verde e sustentável para as próximas gerações.\n\n\n- Cultura Brasileira\nA cultura brasileira é uma das mais ricas e diversas do mundo, com variedades de cores que se estendem aos verdes da sua linda Floresta Amazônica. \n\nAs cores singulares da nossa terra refletem a essência de ser brasileiro.\n\nEstamos trazendo toda essa diversidade para o seu amigo canino, por meio de uma linha de produtos feitos com ingredientes naturais encontrados na Floresta Amazônica.\n\n## Produtos\n\n\nProduto nome : **Calming Zen**   \nEste suplemento é a solução serena da Furest Pet para o bem-estar emocional dos pets. Calming Zen é um suplemento natural, desenvolvido para acalmar e relaxar cães e gatos que apresentam sinais de ansiedade, estresse ou hiperatividade. Com ingredientes selecionados pela sua eficácia e segurança, este suplemento atua suavemente no sistema nervoso dos pets, proporcionando uma sensação de calma sem causar sonolência ou dependência. Principais Benefícios: Promove a calma e reduz o estresse sem sedar. Ajuda a controlar comportamentos ansiosos e hiperativos. Composto por ingredientes naturais \n✅ Situações que podemos sugerir o uso do Calming Zen:\n Cachorros ansiosos Cachorros estressados Cachorros com problema de sono Cachorros agitados Pode ser um complemento natural a um tratamento medicamentoso \n🚫 NÃO PODEMOS:   \n1 Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.   \n/-  \nProduto nome: **Immune Power**   \nImmune Power é um suplemento robusto de reforço imunológico. Sua fórmula rica em antioxidantes, vitaminas e minerais essenciais, foi criteriosamente escolhida para fortalecer o sistema imunológico dos pets, ajudando a proteger contra doenças e a promover uma recuperação mais rápida. Este suplemento é ideal para todos os cães e gatos, especialmente aqueles em recuperação ou que precisam de um impulso extra em sua saúde geral. Principais Benefícios: Fortalece o sistema imunológico. Favorece uma pele saudável e pelagem brilhante. Apoia a vitalidade e a saúde geral. \n✅ Situações que podemos sugerir o uso do Immune Power: Cachorros mais idosos Cachorros com problema de coceira Cachorros com problema de alergia Cachorros com necessidade de fortalecer o sistema imunológico Pode ser um complemento natural a um tratamento medicamentoso 🚫 NÃO PODEMOS: Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.\n\n/-\n\nProduto nome: **Bálsamo Hidratante Pata Power** \n\nPata Power é um bálsamo hidratante premium para cuidar das patinhas e do focinho do seu pet. Enriquecido com ingredientes da Floresta Amazônica, oferece uma mistura exclusiva de manteigas e óleos vegetais que nutrem, protegem e restauram a pele exposta às condições adversas, como pavimentos quentes, gelo ou areia. Este produto é um must-have para tutores que procuram o melhor em cuidado e proteção para as áreas mais sensíveis dos seus animais de estimação. Principais Benefícios: Hidrata e protege patas e focinhos. Promove a cicatrização de rachaduras e feridas. Ingredientes naturais de origem sustentável e cruelty-free. \n\n/- \n**Mordedores Naturais** \n\n**Casquinho**   \nDescrição: Casco bovino desidratado, ideal para uma mastigação duradoura que ajuda na limpeza dos dentes e gengivas. \n\n- Unidades no pacote: 2 \n\n**Fêmur**   \nDescrição: Fêmur bovino desidratado, rico em cálcio e outros minerais, promove a saúde dental e fortalece os ossos.   \nUnidades no pacote: 1   \n**Rosquinha de Carne** Descrição: Rosquinha feita de bexiga bovina desidratada, proporciona entretenimento e auxilia na higiene oral.   \n\\-  Unidades no pacote: 1 ou 3   \n**Espetinho Rústico**   \nDescrição: Palitinho de esôfago bovino desidratado, fonte de proteína e colágeno, suporta a saúde das articulações e pele.   \n\\-  Unidades no pacote: 10   \n**Trancinha Mista** Descrição: Trança de bexiga e esôfago bovinos, combina texturas para uma experiência de mastigação variada.   \n\\- Unidades no pacote: 3   \n**Bifinho de Carne**   \nDescrição: Bife de bexiga bovina desidratada, uma opção saborosa e nutritiva para recompensar seu pet.   \n\\-  Unidades no pacote: 2   \n**Orelhinha**   \nDescrição: Orelha bovina sem aurícula, rica em cartilagem e colágeno, promove saúde articular e dental.   \n\\-  Unidades no pacote: 3   \n**Orelhinha com carne**   \nDescrição: Orelha bovina com aurícula, uma guloseima crocante e cheia de sabor que ajuda na limpeza dos dentes.   \n\\-  Unidades no pacote: 1 ou 2   \n**Palitinho de Colágeno \\- Açaí**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e açaí, rico em antioxidantes e vitaminas.   \n\\-  Unidades no pacote: 200g   \n**Palitinho de Colágeno \\- Urucum**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e urucum, oferece benefícios anti-inflamatórios e promove a saúde da pele.   \nUnidades no pacote: 200g \n\n/-\n**Informações importantes**  \nObservações Importantes: Todos os produtos da Furest Pet são formulados com base em pesquisas científicas e são seguros para uso em cães e gatos de todos os tamanhos e idades. A Furest Pet valoriza a sustentabilidade e o compromisso com a preservação da Floresta Amazônica, incorporando práticas que respeitam o meio ambiente em todas as etapas da produção. Como uma marca premium, a Furest Pet assegura a mais alta qualidade em todos os seus produtos, com atenção rigorosa aos detalhes e à experiência do cliente.\n\n## Dicas\n\n#PawsForTheForest \n#Sustentabilidade \n#FurestPet"
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "\nRealiza a tarefa de responder perguntas sobre os produtos da Furestpet, sempre utilizando as informações contidas no backstory. O especialista deve:\n\nBasear suas respostas exclusivamente nos detalhes do backstory. Se houver informações sobre o produto no backstory, ele deve fornecer uma resposta clara e completa.\nNunca inventar ou extrapolar informações além do que está presente no backstory.\nCaso a pergunta não possa ser respondida com base nas informações disponíveis no backstory, o especialista deve responder: \"No momento eu não sei te responder.\"\n\nSempre responda no mesmo idioma da pergunta."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Atua com a personalidade de um especialista em venda de palitos de carne premium para animais de estimação, focado em responder perguntas e fornecer informações detalhadas sobre os benefícios dos produtos com base em seu backstory. Seu papel é educar e orientar os clientes sobre as qualidades exclusivas dos palitos de carne, além de destacar os benefícios para a saúde e bem-estar dos animais."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "selected": false,
          "width": 384,
          "height": 740,
          "positionAbsolute": {
            "x": 1195.1532229698776,
            "y": -2837.9497804375774
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-2Re1E",
          "type": "genericNode",
          "position": {
            "x": 188.05986691893906,
            "y": -2873.9533869586594
          },
          "data": {
            "id": "OpenAIModel-2Re1E",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "_input_type": "SecretStrInput",
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": false,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 0
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": false,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "OpenAIModel"
          },
          "selected": false,
          "width": 384,
          "height": 780,
          "positionAbsolute": {
            "x": 188.05986691893906,
            "y": -2873.9533869586594
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-D2zPF",
          "type": "genericNode",
          "position": {
            "x": -1462.7139747635383,
            "y": -3743.8538781568063
          },
          "data": {
            "description": "Represents an agent of CrewAI.",
            "display_name": "CrewAI Agent",
            "id": "CrewAIAgentComponent-D2zPF",
            "node": {
              "base_classes": [
                "Agent"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Agente para postar Conteúdos no Notion",
              "display_name": "Agente de postagem no notion",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "edited": false,
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "frozen": false,
              "icon": "CrewAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Agent",
                  "method": "build_output",
                  "name": "output",
                  "selected": "Agent",
                  "types": [
                    "Agent"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "allow_code_execution": {
                  "advanced": true,
                  "display_name": "Allow Code Execution",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "list": false,
                  "name": "allow_code_execution",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "allow_delegation": {
                  "advanced": false,
                  "display_name": "Allow Delegation",
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "list": false,
                  "name": "allow_delegation",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "backstory": {
                  "advanced": false,
                  "display_name": "Backstory",
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "backstory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "## Objetivo\n\nNa Furest Pet, a conexão entre cães, humanos e natureza está no centro de quem somos. Nosso nome, uma mistura de \"fur\" (pelo) e \"forest\" (floresta), representa nosso profundo respeito pelos pets e nossa promessa de contribuir com o meio ambiente.\n\nCada produto Furest Pet, enriquecido com ingredientes incríveis encontrados na Floresta Amazônica, é uma fonte de qualidade de vida e longevidade para o seu amigo canino, e também uma maneira de fortalecer a sua ligação com ele.\n\nDiferentes produtos, mesmo objetivo: conectar as maravilhas da natureza à vida diária de seu pet e de quem o ama.\n\n## missão\n\nNossa missão é profundamente concentrada no cuidado e bem-estar canino. Nosso propósito é promover ao pet uma vida mais saudável, longa e feliz, onde ele pode aproveitar por mais tempo o vínculo lindo entre ele e seu tutor.\n\nInspirados pela beleza majestosa e o ecossistema único da Floresta Amazônica, desenvolvemos produtos naturais que encantam nossos amigos de quatro patas. Nosso objetivo é trazer as maravilhas dessa floresta pulsante e incrível para a vida de seu melhor amigo.\n\n## Valores\n\n- Sustentabilidade\nA Floresta Amazônica, em sua imensidão e majestosidade, é um tesouro vivo que nos brinda com riquezas naturais inestimáveis. Cada elemento que ela nos oferece é um presente, e é nossa filosofia dar de volta aquilo que elas nos oferece.\n\nEm cada produto Furest Pet, há uma promessa de respeito e harmonia com a natureza. Com o \"Paws For The Forest\", não apenas plantamos árvores, mas também desenvolvemos parcerias com famílias e comunidades locais. Nossa missão transcende os negócios, alimentando a essência vital do ciclo de conservação e sustentabilidade. A cada compra, fortalecemos o legado de um futuro mais verde e sustentável para as próximas gerações.\n\n\n- Cultura Brasileira\nA cultura brasileira é uma das mais ricas e diversas do mundo, com variedades de cores que se estendem aos verdes da sua linda Floresta Amazônica. \n\nAs cores singulares da nossa terra refletem a essência de ser brasileiro.\n\nEstamos trazendo toda essa diversidade para o seu amigo canino, por meio de uma linha de produtos feitos com ingredientes naturais encontrados na Floresta Amazônica.\n\n## Produtos\n\n\nProduto nome : **Calming Zen**   \nEste suplemento é a solução serena da Furest Pet para o bem-estar emocional dos pets. Calming Zen é um suplemento natural, desenvolvido para acalmar e relaxar cães e gatos que apresentam sinais de ansiedade, estresse ou hiperatividade. Com ingredientes selecionados pela sua eficácia e segurança, este suplemento atua suavemente no sistema nervoso dos pets, proporcionando uma sensação de calma sem causar sonolência ou dependência. Principais Benefícios: Promove a calma e reduz o estresse sem sedar. Ajuda a controlar comportamentos ansiosos e hiperativos. Composto por ingredientes naturais \n✅ Situações que podemos sugerir o uso do Calming Zen:\n Cachorros ansiosos Cachorros estressados Cachorros com problema de sono Cachorros agitados Pode ser um complemento natural a um tratamento medicamentoso \n🚫 NÃO PODEMOS:   \n1 Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.   \n/-  \nProduto nome: **Immune Power**   \nImmune Power é um suplemento robusto de reforço imunológico. Sua fórmula rica em antioxidantes, vitaminas e minerais essenciais, foi criteriosamente escolhida para fortalecer o sistema imunológico dos pets, ajudando a proteger contra doenças e a promover uma recuperação mais rápida. Este suplemento é ideal para todos os cães e gatos, especialmente aqueles em recuperação ou que precisam de um impulso extra em sua saúde geral. Principais Benefícios: Fortalece o sistema imunológico. Favorece uma pele saudável e pelagem brilhante. Apoia a vitalidade e a saúde geral. \n✅ Situações que podemos sugerir o uso do Immune Power: Cachorros mais idosos Cachorros com problema de coceira Cachorros com problema de alergia Cachorros com necessidade de fortalecer o sistema imunológico Pode ser um complemento natural a um tratamento medicamentoso 🚫 NÃO PODEMOS: Considerar o produto como um medicamentoso, ele é um SUPLEMENTO Dizer que o produto cura sob todas as circunstâncias se o problema não for grave ou clínico, o suplemento certamente irá ajudar a tranquilizar, mas dependendo do cachorro e de seu quadro, pode não ser suficiente.\n\n/-\n\nProduto nome: **Bálsamo Hidratante Pata Power** \n\nPata Power é um bálsamo hidratante premium para cuidar das patinhas e do focinho do seu pet. Enriquecido com ingredientes da Floresta Amazônica, oferece uma mistura exclusiva de manteigas e óleos vegetais que nutrem, protegem e restauram a pele exposta às condições adversas, como pavimentos quentes, gelo ou areia. Este produto é um must-have para tutores que procuram o melhor em cuidado e proteção para as áreas mais sensíveis dos seus animais de estimação. Principais Benefícios: Hidrata e protege patas e focinhos. Promove a cicatrização de rachaduras e feridas. Ingredientes naturais de origem sustentável e cruelty-free. \n\n/- \n**Mordedores Naturais** \n\n**Casquinho**   \nDescrição: Casco bovino desidratado, ideal para uma mastigação duradoura que ajuda na limpeza dos dentes e gengivas. \n\n- Unidades no pacote: 2 \n\n**Fêmur**   \nDescrição: Fêmur bovino desidratado, rico em cálcio e outros minerais, promove a saúde dental e fortalece os ossos.   \nUnidades no pacote: 1   \n**Rosquinha de Carne** Descrição: Rosquinha feita de bexiga bovina desidratada, proporciona entretenimento e auxilia na higiene oral.   \n\\-  Unidades no pacote: 1 ou 3   \n**Espetinho Rústico**   \nDescrição: Palitinho de esôfago bovino desidratado, fonte de proteína e colágeno, suporta a saúde das articulações e pele.   \n\\-  Unidades no pacote: 10   \n**Trancinha Mista** Descrição: Trança de bexiga e esôfago bovinos, combina texturas para uma experiência de mastigação variada.   \n\\- Unidades no pacote: 3   \n**Bifinho de Carne**   \nDescrição: Bife de bexiga bovina desidratada, uma opção saborosa e nutritiva para recompensar seu pet.   \n\\-  Unidades no pacote: 2   \n**Orelhinha**   \nDescrição: Orelha bovina sem aurícula, rica em cartilagem e colágeno, promove saúde articular e dental.   \n\\-  Unidades no pacote: 3   \n**Orelhinha com carne**   \nDescrição: Orelha bovina com aurícula, uma guloseima crocante e cheia de sabor que ajuda na limpeza dos dentes.   \n\\-  Unidades no pacote: 1 ou 2   \n**Palitinho de Colágeno \\- Açaí**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e açaí, rico em antioxidantes e vitaminas.   \n\\-  Unidades no pacote: 200g   \n**Palitinho de Colágeno \\- Urucum**   \nDescrição: Palitinho de colágeno de frango com farinha de mandioca e urucum, oferece benefícios anti-inflamatórios e promove a saúde da pele.   \nUnidades no pacote: 200g \n\n/-\n**Informações importantes**  \nObservações Importantes: Todos os produtos da Furest Pet são formulados com base em pesquisas científicas e são seguros para uso em cães e gatos de todos os tamanhos e idades. A Furest Pet valoriza a sustentabilidade e o compromisso com a preservação da Floresta Amazônica, incorporando práticas que respeitam o meio ambiente em todas as etapas da produção. Como uma marca premium, a Furest Pet assegura a mais alta qualidade em todos os seus produtos, com atenção rigorosa aos detalhes e à experiência do cliente.\n\n## Dicas\n\n#PawsForTheForest \n#Sustentabilidade \n#FurestPet"
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n"
                },
                "goal": {
                  "advanced": false,
                  "display_name": "Goal",
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "goal",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "\nRealiza a tarefa de responder perguntas sobre os produtos da Furestpet, sempre utilizando as informações contidas no backstory. O especialista deve:\n\nBasear suas respostas exclusivamente nos detalhes do backstory. Se houver informações sobre o produto no backstory, ele deve fornecer uma resposta clara e completa.\nNunca inventar ou extrapolar informações além do que está presente no backstory.\nCaso a pergunta não possa ser respondida com base nas informações disponíveis no backstory, o especialista deve responder: \"No momento eu não sei te responder.\"\n\nSempre responda no mesmo idioma da pergunta."
                },
                "kwargs": {
                  "advanced": true,
                  "display_name": "kwargs",
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "list": true,
                  "name": "kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "llm": {
                  "advanced": false,
                  "display_name": "Language Model",
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "input_types": [
                    "LanguageModel"
                  ],
                  "list": false,
                  "name": "llm",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": ""
                },
                "memory": {
                  "advanced": true,
                  "display_name": "Memory",
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "list": false,
                  "name": "memory",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                },
                "role": {
                  "advanced": false,
                  "display_name": "Role",
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "role",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "Atua com a personalidade de um especialista em venda de palitos de carne premium para animais de estimação, focado em responder perguntas e fornecer informações detalhadas sobre os benefícios dos produtos com base em seu backstory. Seu papel é educar e orientar os clientes sobre as qualidades exclusivas dos palitos de carne, além de destacar os benefícios para a saúde e bem-estar dos animais."
                },
                "tools": {
                  "advanced": false,
                  "display_name": "Tools",
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "input_types": [
                    "Tool"
                  ],
                  "list": true,
                  "name": "tools",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "other",
                  "value": []
                },
                "verbose": {
                  "advanced": false,
                  "display_name": "Verbose",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "verbose",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": true
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "CrewAIAgentComponent"
          },
          "selected": false,
          "width": 384,
          "height": 712,
          "positionAbsolute": {
            "x": -1462.7139747635383,
            "y": -3743.8538781568063
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-WKePu",
          "type": "genericNode",
          "position": {
            "x": -1891.1635882157223,
            "y": -3545.5968279582826
          },
          "data": {
            "id": "OpenAIModel-WKePu",
            "node": {
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "beta": false,
              "conditional_paths": [],
              "custom_fields": {},
              "description": "Generates text using OpenAI LLMs.",
              "display_name": "OpenAI",
              "documentation": "",
              "edited": false,
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "frozen": false,
              "icon": "OpenAI",
              "output_types": [],
              "outputs": [
                {
                  "cache": true,
                  "display_name": "Text",
                  "method": "text_response",
                  "name": "text_output",
                  "selected": "Message",
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__"
                },
                {
                  "cache": true,
                  "display_name": "Language Model",
                  "method": "build_model",
                  "name": "model_output",
                  "selected": "LanguageModel",
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__"
                }
              ],
              "pinned": false,
              "template": {
                "_type": "Component",
                "api_key": {
                  "_input_type": "SecretStrInput",
                  "advanced": false,
                  "display_name": "OpenAI API Key",
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "input_types": [
                    "Message"
                  ],
                  "load_from_db": true,
                  "name": "api_key",
                  "password": true,
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "type": "str",
                  "value": ""
                },
                "code": {
                  "advanced": true,
                  "dynamic": true,
                  "fileTypes": [],
                  "file_path": "",
                  "info": "",
                  "list": false,
                  "load_from_db": false,
                  "multiline": true,
                  "name": "code",
                  "password": false,
                  "placeholder": "",
                  "required": true,
                  "show": true,
                  "title_case": false,
                  "type": "code",
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n"
                },
                "input_value": {
                  "advanced": false,
                  "display_name": "Input",
                  "dynamic": false,
                  "info": "",
                  "input_types": [
                    "Message"
                  ],
                  "list": false,
                  "load_from_db": false,
                  "name": "input_value",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "json_mode": {
                  "advanced": true,
                  "display_name": "JSON Mode",
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "list": false,
                  "name": "json_mode",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "max_tokens": {
                  "advanced": false,
                  "display_name": "Max Tokens",
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "list": false,
                  "name": "max_tokens",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 0
                },
                "model_kwargs": {
                  "advanced": true,
                  "display_name": "Model Kwargs",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "model_kwargs",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "model_name": {
                  "advanced": false,
                  "display_name": "Model Name",
                  "dynamic": false,
                  "info": "",
                  "name": "model_name",
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": "gpt-3.5-turbo"
                },
                "openai_api_base": {
                  "advanced": true,
                  "display_name": "OpenAI API Base",
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "list": false,
                  "load_from_db": false,
                  "name": "openai_api_base",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "output_schema": {
                  "advanced": true,
                  "display_name": "Schema",
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "list": true,
                  "name": "output_schema",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_input": true,
                  "type": "dict",
                  "value": {}
                },
                "seed": {
                  "advanced": false,
                  "display_name": "Seed",
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "list": false,
                  "name": "seed",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "int",
                  "value": 1
                },
                "stream": {
                  "advanced": true,
                  "display_name": "Stream",
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "bool",
                  "value": false
                },
                "system_message": {
                  "advanced": true,
                  "display_name": "System Message",
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "list": false,
                  "load_from_db": false,
                  "name": "system_message",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "str",
                  "value": ""
                },
                "temperature": {
                  "advanced": false,
                  "display_name": "Temperature",
                  "dynamic": false,
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "placeholder": "",
                  "required": false,
                  "show": true,
                  "title_case": false,
                  "trace_as_metadata": true,
                  "type": "float",
                  "value": 0.1
                }
              },
              "lf_version": "0.0.96"
            },
            "type": "OpenAIModel"
          },
          "selected": false,
          "width": 384,
          "height": 780,
          "positionAbsolute": {
            "x": -1891.1635882157223,
            "y": -3545.5968279582826
          },
          "dragging": false
        },
        {
          "id": "note-iohW7",
          "type": "noteNode",
          "position": {
            "x": 262.8175553100831,
            "y": -461.37489016509517
          },
          "data": {
            "node": {
              "description": "Agentes para Criação de Conteúdo:\n\n- Pesquisador;\n- CopyWriter;\n- Editor Revisor;",
              "display_name": "",
              "documentation": "",
              "template": {}
            },
            "type": "note",
            "id": "note-iohW7"
          },
          "selected": false,
          "width": 324,
          "height": 324,
          "positionAbsolute": {
            "x": 262.8175553100831,
            "y": -461.37489016509517
          },
          "dragging": false
        },
        {
          "id": "note-Vmxvn",
          "type": "noteNode",
          "position": {
            "x": -1520.0363586011997,
            "y": -4469.284580443696
          },
          "data": {
            "node": {
              "description": "Agentes de Utilidades:\n\n- postagem no notion;",
              "display_name": "",
              "documentation": "",
              "template": {
                "backgroundColor": "amber"
              }
            },
            "type": "note",
            "id": "note-Vmxvn"
          },
          "selected": false,
          "width": 324,
          "height": 324,
          "positionAbsolute": {
            "x": -1520.0363586011997,
            "y": -4469.284580443696
          },
          "dragging": false
        },
        {
          "id": "ComposioAPI-K2XQ0",
          "type": "genericNode",
          "position": {
            "x": -2298.1009428075113,
            "y": -4053.1663166895482
          },
          "data": {
            "type": "ComposioAPI",
            "node": {
              "template": {
                "_type": "Component",
                "action_names": {
                  "trace_as_metadata": true,
                  "options": [
                    "NOTION_ADD_PAGE_CONTENT",
                    "NOTION_ARCHIVE_NOTION_PAGE",
                    "NOTION_CREATE_COMMENT",
                    "NOTION_CREATE_DATABASE",
                    "NOTION_CREATE_NOTION_PAGE",
                    "NOTION_DELETE_BLOCK",
                    "NOTION_FETCH_COMMENTS",
                    "NOTION_FETCH_DATABASE",
                    "NOTION_FETCH_NOTION_BLOCK",
                    "NOTION_FETCH_NOTION_CHILD_BLOCK",
                    "NOTION_FETCH_ROW",
                    "NOTION_GET_ABOUT_ME",
                    "NOTION_GET_ABOUT_USER",
                    "NOTION_INSERT_ROW_DATABASE",
                    "NOTION_LIST_USERS",
                    "NOTION_QUERY_DATABASE",
                    "NOTION_SEARCH_NOTION_PAGE",
                    "NOTION_UPDATE_ROW_DATABASE",
                    "NOTION_UPDATE_SCHEMA_DATABASE"
                  ],
                  "combobox": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "action_names",
                  "value": [
                    "NOTION_ADD_PAGE_CONTENT"
                  ],
                  "display_name": "Actions to use",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The actions to pass to agent to execute",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultiselectInput"
                },
                "api_key": {
                  "load_from_db": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "Composio API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key",
                  "refresh_button": true,
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "app_names": {
                  "trace_as_metadata": true,
                  "options": [
                    "APALEO",
                    "APIFY",
                    "ASANA",
                    "ATTIO",
                    "BITBUCKET",
                    "BREVO",
                    "BROWSERBASE_TOOL",
                    "BROWSER_TOOL",
                    "CLICKUP",
                    "CODEINTERPRETER",
                    "CODE_FORMAT_TOOL",
                    "CODE_GREP_TOOL",
                    "CODE_INDEX_TOOL",
                    "CODE_MAP_TOOL",
                    "COMPOSIO",
                    "DISCORD",
                    "DROPBOX",
                    "ELEVENLABS",
                    "EMBED_TOOL",
                    "EXA",
                    "FIGMA",
                    "FILETOOL",
                    "FIRECRAWL",
                    "GIT",
                    "GITHUB",
                    "GITLAB",
                    "GMAIL",
                    "GOOGLECALENDAR",
                    "GOOGLEDOCS",
                    "GOOGLEDRIVE",
                    "GOOGLEMEET",
                    "GOOGLESHEETS",
                    "GOOGLETASKS",
                    "GREPTILE",
                    "HACKERNEWS",
                    "HEROKU",
                    "HISTORY_FETCHER",
                    "HUBSPOT",
                    "IMAGE_ANALYSER",
                    "INDUCED_AI",
                    "JIRA",
                    "KLAVIYO",
                    "LINEAR",
                    "LISTENNOTES",
                    "MATHEMATICAL",
                    "MULTIONAI",
                    "NASA",
                    "NOTION",
                    "OKTA",
                    "PAGERDUTY",
                    "PERPLEXITYAI",
                    "PIPEDRIVE",
                    "POSTHOG",
                    "RAGTOOL",
                    "SCHEDULER",
                    "SERPAPI",
                    "SHELLTOOL",
                    "SLACK",
                    "SLACKBOT",
                    "SNOWFLAKE",
                    "SOUNDCLOUD",
                    "SPIDERTOOL",
                    "SPLITWISE",
                    "SPOTIFY",
                    "SQLTOOL",
                    "STRAVA",
                    "TASKADE",
                    "TAVILY",
                    "TRELLO",
                    "TWILIO",
                    "TWITTER",
                    "TYPEFORM",
                    "WEATHERMAP",
                    "WEBTOOL",
                    "WHATSAPP",
                    "WORKABLE",
                    "WORKSPACE_TOOL",
                    "YOUSEARCH",
                    "YOUTUBE",
                    "ZENDESK",
                    "ZEPTOOL",
                    "ZOOM"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "app_names",
                  "value": "NOTION",
                  "display_name": "App Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The app name to use. Please refresh after selecting app name",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "auth_status_config": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "auth_status_config",
                  "value": "NOTION CONNECTED",
                  "display_name": "Auth status",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Open link or enter api key. Then refresh button",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, Sequence\n\nfrom composio_langchain import Action, App, ComposioToolSet  # type: ignore\nfrom langchain_core.tools import Tool\nfrom loguru import logger\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import DropdownInput, MessageTextInput, MultiselectInput, SecretStrInput, StrInput\n\n\nclass ComposioAPIComponent(LCToolComponent):\n    display_name: str = \"Composio Tools\"\n    description: str = \"Use Composio toolset to run actions with your agent\"\n    name = \"ComposioAPI\"\n    icon = \"Composio\"\n    documentation: str = \"https://docs.composio.dev\"\n\n    inputs = [\n        MessageTextInput(name=\"entity_id\", display_name=\"Entity ID\", value=\"default\", advanced=True),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Composio API Key\",\n            required=True,\n            refresh_button=True,\n            info=\"Refer to https://docs.composio.dev/introduction/foundations/howtos/get_api_key\",\n        ),\n        DropdownInput(\n            name=\"app_names\",\n            display_name=\"App Name\",\n            options=[app_name for app_name in App.__annotations__],\n            value=\"\",\n            info=\"The app name to use. Please refresh after selecting app name\",\n            refresh_button=True,\n        ),\n        MultiselectInput(\n            name=\"action_names\",\n            display_name=\"Actions to use\",\n            required=False,\n            options=[],\n            value=[],\n            info=\"The actions to pass to agent to execute\",\n        ),\n        StrInput(\n            name=\"auth_status_config\",\n            display_name=\"Auth status\",\n            value=\"\",\n            refresh_button=True,\n            info=\"Open link or enter api key. Then refresh button\",\n        ),\n    ]\n\n    def _check_for_authorization(self, app: str) -> str:\n        \"\"\"\n        Checks if the app is authorized.\n\n        Args:\n            app (str): The app name to check authorization for.\n\n        Returns:\n            str: The authorization status.\n        \"\"\"\n        toolset = self._build_wrapper()\n        entity = toolset.client.get_entity(id=self.entity_id)\n        try:\n            entity.get_connection(app=app)\n            return f\"{app} CONNECTED\"\n        except Exception:\n            return self._handle_authorization_failure(toolset, entity, app)\n\n    def _handle_authorization_failure(self, toolset: ComposioToolSet, entity: Any, app: str) -> str:\n        \"\"\"\n        Handles the authorization failure by attempting to process API key auth or initiate default connection.\n\n        Args:\n            toolset (ComposioToolSet): The toolset instance.\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The result of the authorization failure message.\n        \"\"\"\n        try:\n            auth_schemes = toolset.client.apps.get(app).auth_schemes\n            if auth_schemes[0].auth_mode == \"API_KEY\":\n                return self._process_api_key_auth(entity, app)\n            else:\n                return self._initiate_default_connection(entity, app)\n        except Exception as exc:\n            logger.error(f\"Authorization error: {str(exc)}\")\n            return \"Error\"\n\n    def _process_api_key_auth(self, entity: Any, app: str) -> str:\n        \"\"\"\n        Processes the API key authentication.\n\n        Args:\n            entity (Any): The entity instance.\n            app (str): The app name.\n\n        Returns:\n            str: The status of the API key authentication.\n        \"\"\"\n        auth_status_config = self.auth_status_config\n        is_url = \"http\" in auth_status_config or \"https\" in auth_status_config\n        is_different_app = \"CONNECTED\" in auth_status_config and app not in auth_status_config\n        is_default_api_key_message = \"API Key\" in auth_status_config\n\n        if is_different_app or is_url or is_default_api_key_message:\n            return \"Enter API Key\"\n        else:\n            if not is_default_api_key_message:\n                entity.initiate_connection(\n                    app_name=app,\n                    auth_mode=\"API_KEY\",\n                    auth_config={\"api_key\": self.auth_status_config},\n                    use_composio_auth=False,\n                    force_new_integration=True,\n                )\n                return f\"{app} CONNECTED\"\n            else:\n                return \"Enter API Key\"\n\n    def _initiate_default_connection(self, entity: Any, app: str) -> str:\n        connection = entity.initiate_connection(app_name=app, use_composio_auth=True, force_new_integration=True)\n        return connection.redirectUrl\n\n    def _get_connected_app_names_for_entity(self) -> list[str]:\n        toolset = self._build_wrapper()\n        connections = toolset.client.get_entity(id=self.entity_id).get_connections()\n        return list(set(connection.appUniqueId for connection in connections))\n\n    def _update_app_names_with_connected_status(self, build_config: dict) -> dict:\n        connected_app_names = self._get_connected_app_names_for_entity()\n\n        app_names = [\n            f\"{app_name}_CONNECTED\" for app_name in App.__annotations__ if app_name.lower() in connected_app_names\n        ]\n        non_connected_app_names = [\n            app_name for app_name in App.__annotations__ if app_name.lower() not in connected_app_names\n        ]\n        build_config[\"app_names\"][\"options\"] = app_names + non_connected_app_names\n        build_config[\"app_names\"][\"value\"] = app_names[0] if app_names else \"\"\n        return build_config\n\n    def _get_normalized_app_name(self) -> str:\n        return self.app_names.replace(\"_CONNECTED\", \"\").replace(\"_connected\", \"\")\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name == \"api_key\":\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config = self._update_app_names_with_connected_status(build_config)\n            return build_config\n\n        if field_name in {\"app_names\", \"auth_status_config\"}:\n            if hasattr(self, \"api_key\") and self.api_key != \"\":\n                build_config[\"auth_status_config\"][\"value\"] = self._check_for_authorization(\n                    self._get_normalized_app_name()\n                )\n            all_action_names = [action_name for action_name in Action.__annotations__]\n            app_action_names = [\n                action_name\n                for action_name in all_action_names\n                if action_name.lower().startswith(self._get_normalized_app_name().lower() + \"_\")\n            ]\n            build_config[\"action_names\"][\"options\"] = app_action_names\n            build_config[\"action_names\"][\"value\"] = [app_action_names[0]] if app_action_names else [\"\"]\n        return build_config\n\n    def build_tool(self) -> Sequence[Tool]:\n        composio_toolset = self._build_wrapper()\n        composio_tools = composio_toolset.get_tools(actions=self.action_names)\n        return composio_tools\n\n    def _build_wrapper(self) -> ComposioToolSet:\n        return ComposioToolSet(api_key=self.api_key)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "entity_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "entity_id",
                  "value": "default",
                  "display_name": "Entity ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Use Composio toolset to run actions with your agent",
              "icon": "Composio",
              "base_classes": [
                "Data",
                "Tool"
              ],
              "display_name": "Composio Tools",
              "documentation": "https://docs.composio.dev",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "entity_id",
                "api_key",
                "app_names",
                "action_names",
                "auth_status_config"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ComposioAPI-K2XQ0"
          },
          "selected": false,
          "width": 384,
          "height": 635,
          "positionAbsolute": {
            "x": -2298.1009428075113,
            "y": -4053.1663166895482
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "HierarchicalCrewComponent",
              "id": "HierarchicalCrewComponent-RFMOg",
              "name": "output",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-9aqsp",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-HierarchicalCrewComponent-RFMOg{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-9aqsp{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9aqspœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "source": "HierarchicalCrewComponent-RFMOg",
          "sourceHandle": "{œdataTypeœ:œHierarchicalCrewComponentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-9aqsp",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-9aqspœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "HierarchicalTaskComponent",
              "id": "HierarchicalTaskComponent-ysXYI",
              "name": "task_output",
              "output_types": [
                "HierarchicalTask"
              ]
            },
            "targetHandle": {
              "fieldName": "tasks",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "HierarchicalTask"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-HierarchicalTaskComponent-ysXYI{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}",
          "selected": false,
          "source": "HierarchicalTaskComponent-ysXYI",
          "sourceHandle": "{œdataTypeœ:œHierarchicalTaskComponentœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œHierarchicalTaskœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œtasksœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œHierarchicalTaskœ],œtypeœ:œotherœ}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-P5KkL",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            },
            "targetHandle": {
              "fieldName": "manager_agent",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-P5KkL{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œmanager_agentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "selected": false,
          "source": "CrewAIAgentComponent-P5KkL",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œmanager_agentœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-cxeAa",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            },
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-P5KkL",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            }
          },
          "id": "reactflow__edge-OpenAIModel-cxeAa{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cxeAaœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-P5KkL{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "selected": false,
          "source": "OpenAIModel-cxeAa",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cxeAaœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-P5KkL",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-P5KkLœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-K18mo",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "task_description",
              "id": "HierarchicalTaskComponent-ysXYI",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-Prompt-K18mo{œdataTypeœ:œPromptœ,œidœ:œPrompt-K18moœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-HierarchicalTaskComponent-ysXYI{œfieldNameœ:œtask_descriptionœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "source": "Prompt-K18mo",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-K18moœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "HierarchicalTaskComponent-ysXYI",
          "targetHandle": "{œfieldNameœ:œtask_descriptionœ,œidœ:œHierarchicalTaskComponent-ysXYIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "className": "",
          "data": {
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-yH1am",
              "name": "message",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "fieldName": "query",
              "id": "Prompt-K18mo",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            }
          },
          "id": "reactflow__edge-ChatInput-yH1am{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yH1amœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-K18mo{œfieldNameœ:œqueryœ,œidœ:œPrompt-K18moœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "selected": false,
          "source": "ChatInput-yH1am",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yH1amœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-K18mo",
          "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-K18moœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "OpenAIModel-3lCHz",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-k7Ea3",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-k7Ea3",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-3lCHz",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-k7Ea3{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-3lCHz",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-VF3Dz",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-VF3Dz",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-3lCHz",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-VF3Dz{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "SearchAPI-hnrpV",
          "sourceHandle": "{œdataTypeœ:œSearchAPIœ,œidœ:œSearchAPI-hnrpVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "CrewAIAgentComponent-VF3Dz",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-VF3Dz",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SearchAPI",
              "id": "SearchAPI-hnrpV",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-SearchAPI-hnrpV{œdataTypeœ:œSearchAPIœ,œidœ:œSearchAPI-hnrpVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-VF3Dz{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-3lCHz",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-fl7KA",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-fl7KA",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-3lCHz",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-3lCHz{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3lCHzœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-fl7KA{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-fl7KA",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-fl7KA",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-fl7KA{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-fl7KAœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-k7Ea3",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-k7Ea3",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-k7Ea3{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-k7Ea3œ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-VF3Dz",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-VF3Dz",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-VF3Dz{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-VF3Dzœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-2Re1E",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-2Re1Eœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-ZMVIC",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-ZMVIC",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-2Re1E",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-2Re1E{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-2Re1Eœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-ZMVIC{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-ZMVIC",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "HierarchicalCrewComponent-RFMOg",
          "targetHandle": "{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "agents",
              "id": "HierarchicalCrewComponent-RFMOg",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-ZMVIC",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-ZMVIC{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-ZMVICœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-HierarchicalCrewComponent-RFMOg{œfieldNameœ:œagentsœ,œidœ:œHierarchicalCrewComponent-RFMOgœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-WKePu",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WKePuœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-D2zPF",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-D2zPF",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-WKePu",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-WKePu{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WKePuœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-D2zPF{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ComposioAPI-K2XQ0",
          "sourceHandle": "{œdataTypeœ:œComposioAPIœ,œidœ:œComposioAPI-K2XQ0œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "CrewAIAgentComponent-D2zPF",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-D2zPF",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "ComposioAPI",
              "id": "ComposioAPI-K2XQ0",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-ComposioAPI-K2XQ0{œdataTypeœ:œComposioAPIœ,œidœ:œComposioAPI-K2XQ0œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-D2zPF{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-D2zPFœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 958.7775439111286,
        "y": 581.7967076150758,
        "zoom": 0.19621210437571884
      }
    },
    "date_created": "2024-09-26T17:38:11.165Z",
    "date_updated": "2024-09-26T18:30:41.268Z",
    "status": "Public",
    "sort": null,
    "user_updated": "c7f5daed-ba4f-4b62-82d7-c47dc562881e",
    "user_created": {
      "username": "Thalis360Global",
      "first_name": "Thalis",
      "last_name": "Developer",
      "id": "c7f5daed-ba4f-4b62-82d7-c47dc562881e"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:02.600Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 124,
    "converter_version": "1.0.0"
  }
}