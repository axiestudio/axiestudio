{
  "id": "d382be7f-06d5-4a5f-bd51-da8f8434e624",
  "name": "Langflow Component Helper",
  "description": "Assists creating or editing Langflow Components (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "NamastexLabs",
    "first_name": "Felipe",
    "last_name": "Rosa",
    "id": "37095b75-b1f7-4e35-aea6-bcc9bbf1e2c7",
    "full_name": "Felipe Rosa"
  },
  "store_url": "https://www.langflow.store/store/component/d382be7f-06d5-4a5f-bd51-da8f8434e624",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-07-10T20:23:47.382Z",
    "updated": "2024-07-10T21:47:18.064Z",
    "downloaded": "2025-08-19T17:50:05.807Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.7",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-Mnwrf",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "As the Langflow Component Helper, my role is to assist users with queries and guidance on Langflow Components. I provide examples, reference documentation, and support to help users navigate and utilize CustomComponents effectively. My conversational style is casual and friendly, aiming to create a comfortable and engaging experience. I rely on concrete examples and documents to inform my responses, ensuring accuracy and relevance. When users have questions about Langflow Components, I guide them through the process, from placing a Custom Component on the canvas to writing and saving the code in the Langflow UI. I am here to clarify any confusion and provide support for users to succeed with CustomComponents.\n\n\n# Custom Components\n\n\nBuild custom components in Langflow for various data processing and transformation tasks.\n\nThis guide provides a comprehensive overview of how to create custom components using Langflow.\n\n## Basic Structure of a Custom Component\n\nA custom component in Langflow typically includes the following parts:\n\n1. **Class Definition**: Inherits from the `Component` class.\n2. **Component Metadata**: Defines display name, description, and icon.\n3. **Inputs and Outputs**: Specifies the inputs and outputs for the component.\n4. **Processing Logic**: Implements the logic for processing data within the component.\n\nA custom component in Python looks like this:\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, IntInput, BoolInput, DropdownInput, HandleInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema import Data, Message\nfrom typing import List, Optional\n\nclass ExampleComponent(Component):\n    display_name = \"Example Component\"\n    description = \"A template for creating custom components.\"\n    icon = \"icon-name\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"Text input for the component.\",\n        ),\n        IntInput(\n            name=\"input_number\",\n            display_name=\"Input Number\",\n            info=\"Numeric input for the component.\",\n        ),\n        BoolInput(\n            name=\"input_boolean\",\n            display_name=\"Input Boolean\",\n            info=\"Boolean input for the component.\",\n        ),\n        DropdownInput(\n            name=\"input_choice\",\n            display_name=\"Input Choice\",\n            options=[\"Option1\", \"Option2\", \"Option3\"],\n            info=\"Dropdown input for the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n    ]\n\n    def process_data(self) -> Data:\n        input_text = self.input_text\n        input_number = self.input_number\n        input_boolean = self.input_boolean\n        input_choice = self.input_choice\n\n        # Implement your processing logic here\n        result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n        self.status = result\n        return Data(data=(\"result\": result))\n\n```\n\n## Create a Custom Component Step-by-Step\n\n1. Create a class that inherits from the `Component` class.\n\n```python\nclass ExampleComponent(Component):\n    # Class content\n```\n\n2. Define metadata such as `display_name`, `description`, and `icon`.\n\n```python\ndisplay_name = \"Example Component\"\ndescription = \"A template for creating custom components.\"\nicon = \"icon-name\"\n```\n\n3. Define the inputs and outputs for the component using the `inputs` and `outputs` lists.\n\n**Inputs** can be of various types such as `TextInput`, `IntInput`, `BoolInput`, `DropdownInput`, etc.\n\n```python\ninputs = [\n    MessageTextInput(\n        name=\"input_text\",\n        display_name=\"Input Text\",\n        info=\"Text input for the component.\",\n    ),\n    IntInput(\n        name=\"input_number\",\n        display_name=\"Input Number\",\n        info=\"Numeric input for the component.\",\n    ),\n    BoolInput(\n        name=\"input_boolean\",\n        display_name=\"Input Boolean\",\n        info=\"Boolean input for the component.\",\n    ),\n    DropdownInput(\n        name=\"input_choice\",\n        display_name=\"Input Choice\",\n        options=[\"Option1\", \"Option2\", \"Option3\"],\n        info=\"Dropdown input for the component.\",\n    ),\n]\n\n```\n\n**Outputs** define the output methods for the component.\n\n```python\noutputs = [\n    Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n]\n```\n\n4. Implement the logic for processing data within the component. Define methods for processing data and returning results.\n\n```python\ndef process_data(self) -> Data:\n    input_text = self.input_text\n    input_number = self.input_number\n    input_boolean = self.input_boolean\n    input_choice = self.input_choice\n\n    # Implement your processing logic here\n    result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n    self.status = result\n    return Data(data=(\"result\": result))\n\n```\n\n## Advanced Example: Create a Conditional Router Component\n\nThis example demonstrates a more complex component that routes data based on a condition.\n\nNotice that this component has two outputs associated with the methods `true_response` and `false_response`.\n\nThese methods trigger `self.stop` to block the transmission for the selected output, allowing for logic operations to be implemented visually.\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.field_typing import Text\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes input based on a specified condition.\"\n    icon = \"router\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"Value to be evaluated.\",\n        ),\n        MessageTextInput(\n            name=\"comparison_value\",\n            display_name=\"Comparison Value\",\n            info=\"Value to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\"],\n            info=\"Comparison operator.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"true_response\"),\n        Output(display_name=\"False Output\", name=\"false_response\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_value: str, comparison_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return input_value == comparison_value\n        elif operator == \"not equals\":\n            return input_value != comparison_value\n        elif operator == \"contains\":\n            return comparison_value in input_value\n        return False\n\n    def true_response(self) -> Text:\n        if self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"false_response\")\n            return self.input_value\n        else:\n            self.stop(\"true_response\")\n            return \"\"\n\n    def false_response(self) -> Text:\n        if not self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"true_response\")\n            return self.input_value\n        else:\n            self.stop(\"false_response\")\n            return \"\"\n\n```\n\nBy following these steps and examples, you can create custom components in Langflow tailored to your specific needs. The modular structure of Custom Components allows for flexible and reusable components that can be easily integrated into your workflows.",
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "load_from_db": false
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": false,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 329,
        "id": "Prompt-Mnwrf",
        "position": {
          "x": 1311.4419087802376,
          "y": 356.9763642406291
        },
        "positionAbsolute": {
          "x": 1311.4419087802376,
          "y": 356.9763642406291
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "OpenAIModel-pyBXp",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "json_mode",
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "gpt-4o",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "output_schema",
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 1,
                "name": "seed",
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.1,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message",
              "seed"
            ],
            "beta": false,
            "edited": false
          },
          "type": "OpenAIModel",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI"
        },
        "dragging": false,
        "height": 623,
        "id": "OpenAIModel-pyBXp",
        "position": {
          "x": 1937.3823955656867,
          "y": 528.2951118303126
        },
        "positionAbsolute": {
          "x": 1937.3823955656867,
          "y": 528.2951118303126
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "Memory-E0mu5",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\", \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"Session ID of the chat history.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chat History\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        messages = get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        self.status = messages\n        return messages\n\n    def retrieve_messages_as_text(self) -> Message:\n        messages_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = messages_text\n        return Message(text=messages_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 100,
                "name": "n_messages",
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Ascending",
                "name": "order",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Machine and User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID of the chat history.",
                "title_case": false,
                "type": "str"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{sender_name}: {text}",
                "name": "template",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Retrieves stored chat messages.",
            "icon": "message-square-more",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Chat History",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false
          },
          "type": "Memory",
          "description": "Retrieves stored chat messages.",
          "display_name": "Chat Memory"
        },
        "dragging": false,
        "height": 267,
        "id": "Memory-E0mu5",
        "position": {
          "x": 1915.3738908511268,
          "y": 218.92423212034515
        },
        "positionAbsolute": {
          "x": 1915.3738908511268,
          "y": 218.92423212034515
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "ToolCallingAgent-CZLV6",
        "type": "genericNode",
        "position": {
          "x": 2433.938644691249,
          "y": 606.7831803074981
        },
        "data": {
          "type": "ToolCallingAgent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Memory to use for the agent.",
                "title_case": false,
                "type": "other"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "tools",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Dict, List, cast\n\nfrom langchain.agents import AgentExecutor, BaseSingleActionAgent\nfrom langchain.agents.tool_calling_agent.base import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass ToolCallingAgentComponent(Component):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools. Only models that are compatible with function calling are supported.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Input text to pass to the agent.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Prompt\",\n            info=\"This prompt must contain 'input' key.\",\n            value=\"{input}\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"handle_parsing_errors\",\n            display_name=\"Handle Parsing Errors\",\n            info=\"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"Data\"],\n            info=\"Memory to use for the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"run_agent\"),\n    ]\n\n    async def run_agent(self) -> Message:\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", self.user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_tool_calling_agent(self.llm, self.tools, prompt)\n\n        runnable = AgentExecutor.from_agent_and_tools(\n            agent=cast(BaseSingleActionAgent, agent),\n            tools=self.tools,\n            verbose=True,\n            handle_parsing_errors=self.handle_parsing_errors,\n        )\n        input_dict: dict[str, str | list[Dict[str, str]]] = {\"input\": self.input_value}\n        if hasattr(self, \"memory\") and self.memory:\n            input_dict[\"chat_history\"] = self.convert_chat_history(self.memory)\n        result = await runnable.ainvoke(input_dict)\n\n        if \"output\" not in result:\n            raise ValueError(\"Output key not found in result. Tried 'output'.\")\n\n        results = result[\"output\"]\n        if isinstance(results, list):\n            result_string = \"\\n\".join([r[\"text\"] for r in results if \"text\" in r and r.get(\"type\") == \"text\"])\n        else:\n            result_string = results\n        self.status = result_string\n        return Message(text=result_string)\n\n    def convert_chat_history(self, chat_history: List[Data]) -> List[Dict[str, str]]:\n        messages = []\n        for item in chat_history:\n            role = \"user\" if item.sender == \"User\" else \"assistant\"\n            messages.append({\"role\": role, \"content\": item.text})\n        return messages\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "handle_parsing_errors",
                "display_name": "Handle Parsing Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
                "title_case": false,
                "type": "bool"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Inputs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Input text to pass to the agent.",
                "title_case": false,
                "type": "str"
              },
              "system_prompt": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_prompt",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str"
              },
              "user_prompt": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{input}",
                "name": "user_prompt",
                "display_name": "Prompt",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "This prompt must contain 'input' key.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
            "icon": "LangChain",
            "base_classes": [
              "Message"
            ],
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "run_agent",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "system_prompt",
              "input_value",
              "user_prompt",
              "handle_parsing_errors",
              "memory",
              "tools",
              "llm"
            ],
            "beta": true,
            "edited": false
          },
          "id": "ToolCallingAgent-CZLV6"
        },
        "selected": false,
        "width": 384,
        "height": 575,
        "positionAbsolute": {
          "x": 2433.938644691249,
          "y": 606.7831803074981
        },
        "dragging": false
      },
      {
        "id": "JsonToolkit-Embk8",
        "type": "genericNode",
        "position": {
          "x": 1325.7195952380903,
          "y": 1101.448711416714
        },
        "data": {
          "type": "CalculatorToolComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom langchain.tools import Tool\r\nimport ast\r\nimport operator\r\n\r\nclass CalculatorToolComponent(Component):\r\n    display_name = \"Calculator Tool\"\r\n    description = \"A tool that evaluates mathematical expressions.\"\r\n    icon = \"🧮\"\r\n\r\n    inputs = []  # No inputs for the component itself\r\n\r\n    outputs = [\r\n        Output(display_name=\"Calculator Tool\", name=\"calculator_tool\", method=\"create_tool\"),\r\n    ]\r\n\r\n    def safe_eval(self, node):\r\n        operators = {\r\n            ast.Add: operator.add,\r\n            ast.Sub: operator.sub,\r\n            ast.Mult: operator.mul,\r\n            ast.Div: operator.truediv,\r\n            ast.Pow: operator.pow,\r\n            ast.USub: operator.neg,\r\n        }\r\n\r\n        if isinstance(node, ast.Num):\r\n            return node.n\r\n        elif isinstance(node, ast.BinOp):\r\n            return operators[type(node.op)](self.safe_eval(node.left), self.safe_eval(node.right))\r\n        elif isinstance(node, ast.UnaryOp):\r\n            return operators[type(node.op)](self.safe_eval(node.operand))\r\n        else:\r\n            raise TypeError(f\"Unsupported operation: {node}\")\r\n\r\n    def evaluate_expression(self, expression: str) -> float:\r\n        try:\r\n            tree = ast.parse(expression, mode='eval')\r\n            result = self.safe_eval(tree.body)\r\n            return result\r\n        except (SyntaxError, TypeError, ZeroDivisionError) as e:\r\n            raise ValueError(f\"Invalid expression: {str(e)}\")\r\n\r\n    def create_tool(self) -> Tool:\r\n        def calculator_function(expression: str) -> str:\r\n            try:\r\n                result = self.evaluate_expression(expression)\r\n                return f\"The result of '{expression}' is: {result}\"\r\n            except ValueError as e:\r\n                return str(e)\r\n            except Exception as e:\r\n                return f\"An unexpected error occurred: {str(e)}\"\r\n\r\n        tool = Tool(\r\n            name=\"Calculator\",\r\n            func=calculator_function,\r\n            description=\"Evaluates mathematical expressions. Input should be a string containing a valid mathematical expression (e.g., '2+2/3', '(5*3)^2').\"\r\n        )\r\n\r\n        self.status = \"Calculator tool created successfully\"\r\n        return tool",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "A tool that evaluates mathematical expressions.",
            "icon": "🧮",
            "base_classes": [
              "Tool"
            ],
            "display_name": "Calculator Tool",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "calculator_tool",
                "display_name": "Calculator Tool",
                "method": "create_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [],
            "beta": false,
            "edited": false
          },
          "id": "JsonToolkit-Embk8",
          "description": "A tool that evaluates mathematical expressions.",
          "display_name": "JsonToolkit"
        },
        "selected": false,
        "width": 384,
        "height": 215,
        "dragging": false,
        "positionAbsolute": {
          "x": 1325.7195952380903,
          "y": 1101.448711416714
        }
      },
      {
        "id": "ChatInput-ZIIXU",
        "type": "genericNode",
        "position": {
          "x": 1338.725291761324,
          "y": 716.3034823817471
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "oi",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatInput-ZIIXU"
        },
        "selected": true,
        "width": 384,
        "height": 309,
        "positionAbsolute": {
          "x": 1338.725291761324,
          "y": 716.3034823817471
        },
        "dragging": true
      },
      {
        "id": "ChatOutput-aQAxO",
        "type": "genericNode",
        "position": {
          "x": 2895.528063605672,
          "y": 607.8292167953482
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "data_template",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Machine",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "AI",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatOutput-aQAxO"
        },
        "selected": false,
        "width": 384,
        "height": 307,
        "positionAbsolute": {
          "x": 2895.528063605672,
          "y": 607.8292167953482
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "OpenAIModel-pyBXp",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pyBXpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ToolCallingAgent-CZLV6",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-CZLV6",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pyBXp",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pyBXp{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pyBXpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "Prompt-Mnwrf",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Mnwrfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ToolCallingAgent-CZLV6",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "ToolCallingAgent-CZLV6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-Mnwrf",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-Mnwrf{œdataTypeœ:œPromptœ,œidœ:œPrompt-Mnwrfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Memory-E0mu5",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-E0mu5œ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}",
        "target": "ToolCallingAgent-CZLV6",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "ToolCallingAgent-CZLV6",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-E0mu5",
            "name": "messages",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Memory-E0mu5{œdataTypeœ:œMemoryœ,œidœ:œMemory-E0mu5œ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œmemoryœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "JsonToolkit-Embk8",
        "sourceHandle": "{œdataTypeœ:œCalculatorToolComponentœ,œidœ:œJsonToolkit-Embk8œ,œnameœ:œcalculator_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "ToolCallingAgent-CZLV6",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-CZLV6",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CalculatorToolComponent",
            "id": "JsonToolkit-Embk8",
            "name": "calculator_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-JsonToolkit-Embk8{œdataTypeœ:œCalculatorToolComponentœ,œidœ:œJsonToolkit-Embk8œ,œnameœ:œcalculator_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ChatInput-ZIIXU",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ZIIXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-pyBXp",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pyBXpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-pyBXp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-ZIIXU",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-ZIIXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ZIIXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pyBXp{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pyBXpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ToolCallingAgent-CZLV6",
        "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-CZLV6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-aQAxO",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aQAxOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-aQAxO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-CZLV6",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ToolCallingAgent-CZLV6{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-CZLV6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-aQAxO{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aQAxOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": -590.514062946188,
      "y": -98.87092581758787,
      "zoom": 0.6597539553864472
    }
  },
  "metadata": {
    "Prompt": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "ToolCallingAgent": {
      "count": 1
    },
    "JsonToolkit": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "total": 7
  },
  "original": {
    "id": "d382be7f-06d5-4a5f-bd51-da8f8434e624",
    "name": "Langflow Component Helper",
    "description": "Assists creating or editing Langflow Components",
    "is_component": false,
    "liked_by_count": "21",
    "downloads_count": "149",
    "metadata": {
      "Prompt": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "ToolCallingAgent": {
        "count": 1
      },
      "JsonToolkit": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "total": 7
    },
    "last_tested_version": "1.0.7",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "id": "Prompt-Mnwrf",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "As the Langflow Component Helper, my role is to assist users with queries and guidance on Langflow Components. I provide examples, reference documentation, and support to help users navigate and utilize CustomComponents effectively. My conversational style is casual and friendly, aiming to create a comfortable and engaging experience. I rely on concrete examples and documents to inform my responses, ensuring accuracy and relevance. When users have questions about Langflow Components, I guide them through the process, from placing a Custom Component on the canvas to writing and saving the code in the Langflow UI. I am here to clarify any confusion and provide support for users to succeed with CustomComponents.\n\n\n# Custom Components\n\n\nBuild custom components in Langflow for various data processing and transformation tasks.\n\nThis guide provides a comprehensive overview of how to create custom components using Langflow.\n\n## Basic Structure of a Custom Component\n\nA custom component in Langflow typically includes the following parts:\n\n1. **Class Definition**: Inherits from the `Component` class.\n2. **Component Metadata**: Defines display name, description, and icon.\n3. **Inputs and Outputs**: Specifies the inputs and outputs for the component.\n4. **Processing Logic**: Implements the logic for processing data within the component.\n\nA custom component in Python looks like this:\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, IntInput, BoolInput, DropdownInput, HandleInput\nfrom axiestudio.template import Output\nfrom axiestudio.schema import Data, Message\nfrom typing import List, Optional\n\nclass ExampleComponent(Component):\n    display_name = \"Example Component\"\n    description = \"A template for creating custom components.\"\n    icon = \"icon-name\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"Text input for the component.\",\n        ),\n        IntInput(\n            name=\"input_number\",\n            display_name=\"Input Number\",\n            info=\"Numeric input for the component.\",\n        ),\n        BoolInput(\n            name=\"input_boolean\",\n            display_name=\"Input Boolean\",\n            info=\"Boolean input for the component.\",\n        ),\n        DropdownInput(\n            name=\"input_choice\",\n            display_name=\"Input Choice\",\n            options=[\"Option1\", \"Option2\", \"Option3\"],\n            info=\"Dropdown input for the component.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n    ]\n\n    def process_data(self) -> Data:\n        input_text = self.input_text\n        input_number = self.input_number\n        input_boolean = self.input_boolean\n        input_choice = self.input_choice\n\n        # Implement your processing logic here\n        result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n        self.status = result\n        return Data(data=(\"result\": result))\n\n```\n\n## Create a Custom Component Step-by-Step\n\n1. Create a class that inherits from the `Component` class.\n\n```python\nclass ExampleComponent(Component):\n    # Class content\n```\n\n2. Define metadata such as `display_name`, `description`, and `icon`.\n\n```python\ndisplay_name = \"Example Component\"\ndescription = \"A template for creating custom components.\"\nicon = \"icon-name\"\n```\n\n3. Define the inputs and outputs for the component using the `inputs` and `outputs` lists.\n\n**Inputs** can be of various types such as `TextInput`, `IntInput`, `BoolInput`, `DropdownInput`, etc.\n\n```python\ninputs = [\n    MessageTextInput(\n        name=\"input_text\",\n        display_name=\"Input Text\",\n        info=\"Text input for the component.\",\n    ),\n    IntInput(\n        name=\"input_number\",\n        display_name=\"Input Number\",\n        info=\"Numeric input for the component.\",\n    ),\n    BoolInput(\n        name=\"input_boolean\",\n        display_name=\"Input Boolean\",\n        info=\"Boolean input for the component.\",\n    ),\n    DropdownInput(\n        name=\"input_choice\",\n        display_name=\"Input Choice\",\n        options=[\"Option1\", \"Option2\", \"Option3\"],\n        info=\"Dropdown input for the component.\",\n    ),\n]\n\n```\n\n**Outputs** define the output methods for the component.\n\n```python\noutputs = [\n    Output(display_name=\"Output Data\", name=\"output_data\", method=\"process_data\"),\n]\n```\n\n4. Implement the logic for processing data within the component. Define methods for processing data and returning results.\n\n```python\ndef process_data(self) -> Data:\n    input_text = self.input_text\n    input_number = self.input_number\n    input_boolean = self.input_boolean\n    input_choice = self.input_choice\n\n    # Implement your processing logic here\n    result = f\"Processed: (input_text), (input_number), (input_boolean), (input_choice)\"\n\n    self.status = result\n    return Data(data=(\"result\": result))\n\n```\n\n## Advanced Example: Create a Conditional Router Component\n\nThis example demonstrates a more complex component that routes data based on a condition.\n\nNotice that this component has two outputs associated with the methods `true_response` and `false_response`.\n\nThese methods trigger `self.stop` to block the transmission for the selected output, allowing for logic operations to be implemented visually.\n\n```python\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs import MessageTextInput, DropdownInput, BoolInput\nfrom axiestudio.template import Output\nfrom axiestudio.field_typing import Text\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes input based on a specified condition.\"\n    icon = \"router\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"Value to be evaluated.\",\n        ),\n        MessageTextInput(\n            name=\"comparison_value\",\n            display_name=\"Comparison Value\",\n            info=\"Value to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\"],\n            info=\"Comparison operator.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"true_response\"),\n        Output(display_name=\"False Output\", name=\"false_response\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_value: str, comparison_value: str, operator: str) -> bool:\n        if operator == \"equals\":\n            return input_value == comparison_value\n        elif operator == \"not equals\":\n            return input_value != comparison_value\n        elif operator == \"contains\":\n            return comparison_value in input_value\n        return False\n\n    def true_response(self) -> Text:\n        if self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"false_response\")\n            return self.input_value\n        else:\n            self.stop(\"true_response\")\n            return \"\"\n\n    def false_response(self) -> Text:\n        if not self.evaluate_condition(self.input_value, self.comparison_value, self.operator):\n            self.stop(\"true_response\")\n            return self.input_value\n        else:\n            self.stop(\"false_response\")\n            return \"\"\n\n```\n\nBy following these steps and examples, you can create custom components in Langflow tailored to your specific needs. The modular structure of Custom Components allows for flexible and reusable components that can be easily integrated into your workflows.",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "load_from_db": false
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": []
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": false,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 329,
          "id": "Prompt-Mnwrf",
          "position": {
            "x": 1311.4419087802376,
            "y": 356.9763642406291
          },
          "positionAbsolute": {
            "x": 1311.4419087802376,
            "y": 356.9763642406291
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "OpenAIModel-pyBXp",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "json_mode",
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "gpt-4o",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str"
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "openai_api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "output_schema",
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 1,
                  "name": "seed",
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.1,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message",
                "seed"
              ],
              "beta": false,
              "edited": false
            },
            "type": "OpenAIModel",
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI"
          },
          "dragging": false,
          "height": 623,
          "id": "OpenAIModel-pyBXp",
          "position": {
            "x": 1937.3823955656867,
            "y": 528.2951118303126
          },
          "positionAbsolute": {
            "x": 1937.3823955656867,
            "y": 528.2951118303126
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "Memory-E0mu5",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\", \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"Session ID of the chat history.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chat History\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        messages = get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        self.status = messages\n        return messages\n\n    def retrieve_messages_as_text(self) -> Message:\n        messages_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = messages_text\n        return Message(text=messages_text)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 100,
                  "name": "n_messages",
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Ascending",
                  "name": "order",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Machine and User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID of the chat history.",
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{sender_name}: {text}",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Retrieves stored chat messages.",
              "icon": "message-square-more",
              "base_classes": [
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Chat History",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false
            },
            "type": "Memory",
            "description": "Retrieves stored chat messages.",
            "display_name": "Chat Memory"
          },
          "dragging": false,
          "height": 267,
          "id": "Memory-E0mu5",
          "position": {
            "x": 1915.3738908511268,
            "y": 218.92423212034515
          },
          "positionAbsolute": {
            "x": 1915.3738908511268,
            "y": 218.92423212034515
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "ToolCallingAgent-CZLV6",
          "type": "genericNode",
          "position": {
            "x": 2433.938644691249,
            "y": 606.7831803074981
          },
          "data": {
            "type": "ToolCallingAgent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "Memory to use for the agent.",
                  "title_case": false,
                  "type": "other"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "tools",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Dict, List, cast\n\nfrom langchain.agents import AgentExecutor, BaseSingleActionAgent\nfrom langchain.agents.tool_calling_agent.base import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass ToolCallingAgentComponent(Component):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools. Only models that are compatible with function calling are supported.\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Input text to pass to the agent.\",\n        ),\n        MessageTextInput(\n            name=\"user_prompt\",\n            display_name=\"Prompt\",\n            info=\"This prompt must contain 'input' key.\",\n            value=\"{input}\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"handle_parsing_errors\",\n            display_name=\"Handle Parsing Errors\",\n            info=\"If True, the agent will handle parsing errors. If False, the agent will raise an error.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"Data\"],\n            info=\"Memory to use for the agent.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"LLM\",\n            input_types=[\"LanguageModel\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text_output\", method=\"run_agent\"),\n    ]\n\n    async def run_agent(self) -> Message:\n        if \"input\" not in self.user_prompt:\n            raise ValueError(\"Prompt must contain 'input' key.\")\n        messages = [\n            (\"system\", self.system_prompt),\n            (\n                \"placeholder\",\n                \"{chat_history}\",\n            ),\n            (\"human\", self.user_prompt),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        agent = create_tool_calling_agent(self.llm, self.tools, prompt)\n\n        runnable = AgentExecutor.from_agent_and_tools(\n            agent=cast(BaseSingleActionAgent, agent),\n            tools=self.tools,\n            verbose=True,\n            handle_parsing_errors=self.handle_parsing_errors,\n        )\n        input_dict: dict[str, str | list[Dict[str, str]]] = {\"input\": self.input_value}\n        if hasattr(self, \"memory\") and self.memory:\n            input_dict[\"chat_history\"] = self.convert_chat_history(self.memory)\n        result = await runnable.ainvoke(input_dict)\n\n        if \"output\" not in result:\n            raise ValueError(\"Output key not found in result. Tried 'output'.\")\n\n        results = result[\"output\"]\n        if isinstance(results, list):\n            result_string = \"\\n\".join([r[\"text\"] for r in results if \"text\" in r and r.get(\"type\") == \"text\"])\n        else:\n            result_string = results\n        self.status = result_string\n        return Message(text=result_string)\n\n    def convert_chat_history(self, chat_history: List[Data]) -> List[Dict[str, str]]:\n        messages = []\n        for item in chat_history:\n            role = \"user\" if item.sender == \"User\" else \"assistant\"\n            messages.append({\"role\": role, \"content\": item.text})\n        return messages\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "handle_parsing_errors",
                  "display_name": "Handle Parsing Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, the agent will handle parsing errors. If False, the agent will raise an error.",
                  "title_case": false,
                  "type": "bool"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Inputs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Input text to pass to the agent.",
                  "title_case": false,
                  "type": "str"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_prompt",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str"
                },
                "user_prompt": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{input}",
                  "name": "user_prompt",
                  "display_name": "Prompt",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "This prompt must contain 'input' key.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Agent that uses tools. Only models that are compatible with function calling are supported.",
              "icon": "LangChain",
              "base_classes": [
                "Message"
              ],
              "display_name": "Tool Calling Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "run_agent",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "system_prompt",
                "input_value",
                "user_prompt",
                "handle_parsing_errors",
                "memory",
                "tools",
                "llm"
              ],
              "beta": true,
              "edited": false
            },
            "id": "ToolCallingAgent-CZLV6"
          },
          "selected": false,
          "width": 384,
          "height": 575,
          "positionAbsolute": {
            "x": 2433.938644691249,
            "y": 606.7831803074981
          },
          "dragging": false
        },
        {
          "id": "JsonToolkit-Embk8",
          "type": "genericNode",
          "position": {
            "x": 1325.7195952380903,
            "y": 1101.448711416714
          },
          "data": {
            "type": "CalculatorToolComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom langchain.tools import Tool\r\nimport ast\r\nimport operator\r\n\r\nclass CalculatorToolComponent(Component):\r\n    display_name = \"Calculator Tool\"\r\n    description = \"A tool that evaluates mathematical expressions.\"\r\n    icon = \"🧮\"\r\n\r\n    inputs = []  # No inputs for the component itself\r\n\r\n    outputs = [\r\n        Output(display_name=\"Calculator Tool\", name=\"calculator_tool\", method=\"create_tool\"),\r\n    ]\r\n\r\n    def safe_eval(self, node):\r\n        operators = {\r\n            ast.Add: operator.add,\r\n            ast.Sub: operator.sub,\r\n            ast.Mult: operator.mul,\r\n            ast.Div: operator.truediv,\r\n            ast.Pow: operator.pow,\r\n            ast.USub: operator.neg,\r\n        }\r\n\r\n        if isinstance(node, ast.Num):\r\n            return node.n\r\n        elif isinstance(node, ast.BinOp):\r\n            return operators[type(node.op)](self.safe_eval(node.left), self.safe_eval(node.right))\r\n        elif isinstance(node, ast.UnaryOp):\r\n            return operators[type(node.op)](self.safe_eval(node.operand))\r\n        else:\r\n            raise TypeError(f\"Unsupported operation: {node}\")\r\n\r\n    def evaluate_expression(self, expression: str) -> float:\r\n        try:\r\n            tree = ast.parse(expression, mode='eval')\r\n            result = self.safe_eval(tree.body)\r\n            return result\r\n        except (SyntaxError, TypeError, ZeroDivisionError) as e:\r\n            raise ValueError(f\"Invalid expression: {str(e)}\")\r\n\r\n    def create_tool(self) -> Tool:\r\n        def calculator_function(expression: str) -> str:\r\n            try:\r\n                result = self.evaluate_expression(expression)\r\n                return f\"The result of '{expression}' is: {result}\"\r\n            except ValueError as e:\r\n                return str(e)\r\n            except Exception as e:\r\n                return f\"An unexpected error occurred: {str(e)}\"\r\n\r\n        tool = Tool(\r\n            name=\"Calculator\",\r\n            func=calculator_function,\r\n            description=\"Evaluates mathematical expressions. Input should be a string containing a valid mathematical expression (e.g., '2+2/3', '(5*3)^2').\"\r\n        )\r\n\r\n        self.status = \"Calculator tool created successfully\"\r\n        return tool",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "A tool that evaluates mathematical expressions.",
              "icon": "🧮",
              "base_classes": [
                "Tool"
              ],
              "display_name": "Calculator Tool",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "calculator_tool",
                  "display_name": "Calculator Tool",
                  "method": "create_tool",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [],
              "beta": false,
              "edited": false
            },
            "id": "JsonToolkit-Embk8",
            "description": "A tool that evaluates mathematical expressions.",
            "display_name": "JsonToolkit"
          },
          "selected": false,
          "width": 384,
          "height": 215,
          "dragging": false,
          "positionAbsolute": {
            "x": 1325.7195952380903,
            "y": 1101.448711416714
          }
        },
        {
          "id": "ChatInput-ZIIXU",
          "type": "genericNode",
          "position": {
            "x": 1338.725291761324,
            "y": 716.3034823817471
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "oi",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatInput-ZIIXU"
          },
          "selected": true,
          "width": 384,
          "height": 309,
          "positionAbsolute": {
            "x": 1338.725291761324,
            "y": 716.3034823817471
          },
          "dragging": true
        },
        {
          "id": "ChatOutput-aQAxO",
          "type": "genericNode",
          "position": {
            "x": 2895.528063605672,
            "y": 607.8292167953482
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "data_template",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Machine",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "AI",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatOutput-aQAxO"
          },
          "selected": false,
          "width": 384,
          "height": 307,
          "positionAbsolute": {
            "x": 2895.528063605672,
            "y": 607.8292167953482
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "OpenAIModel-pyBXp",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pyBXpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ToolCallingAgent-CZLV6",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ToolCallingAgent-CZLV6",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pyBXp",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pyBXp{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pyBXpœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "Prompt-Mnwrf",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Mnwrfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ToolCallingAgent-CZLV6",
          "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "system_prompt",
              "id": "ToolCallingAgent-CZLV6",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-Mnwrf",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-Mnwrf{œdataTypeœ:œPromptœ,œidœ:œPrompt-Mnwrfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œsystem_promptœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Memory-E0mu5",
          "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-E0mu5œ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}",
          "target": "ToolCallingAgent-CZLV6",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "ToolCallingAgent-CZLV6",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-E0mu5",
              "name": "messages",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-Memory-E0mu5{œdataTypeœ:œMemoryœ,œidœ:œMemory-E0mu5œ,œnameœ:œmessagesœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œmemoryœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "JsonToolkit-Embk8",
          "sourceHandle": "{œdataTypeœ:œCalculatorToolComponentœ,œidœ:œJsonToolkit-Embk8œ,œnameœ:œcalculator_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "ToolCallingAgent-CZLV6",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "ToolCallingAgent-CZLV6",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CalculatorToolComponent",
              "id": "JsonToolkit-Embk8",
              "name": "calculator_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-JsonToolkit-Embk8{œdataTypeœ:œCalculatorToolComponentœ,œidœ:œJsonToolkit-Embk8œ,œnameœ:œcalculator_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-CZLV6{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-CZLV6œ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ChatInput-ZIIXU",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ZIIXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-pyBXp",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pyBXpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-pyBXp",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-ZIIXU",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-ZIIXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ZIIXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pyBXp{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pyBXpœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ToolCallingAgent-CZLV6",
          "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-CZLV6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-aQAxO",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aQAxOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-aQAxO",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ToolCallingAgent",
              "id": "ToolCallingAgent-CZLV6",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ToolCallingAgent-CZLV6{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-CZLV6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-aQAxO{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aQAxOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": -590.514062946188,
        "y": -98.87092581758787,
        "zoom": 0.6597539553864472
      }
    },
    "date_created": "2024-07-10T20:23:47.382Z",
    "date_updated": "2024-07-10T21:47:18.064Z",
    "status": "Public",
    "sort": null,
    "user_updated": "37095b75-b1f7-4e35-aea6-bcc9bbf1e2c7",
    "user_created": {
      "username": "NamastexLabs",
      "first_name": "Felipe",
      "last_name": "Rosa",
      "id": "37095b75-b1f7-4e35-aea6-bcc9bbf1e2c7"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.077Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 74,
    "converter_version": "1.0.0"
  }
}