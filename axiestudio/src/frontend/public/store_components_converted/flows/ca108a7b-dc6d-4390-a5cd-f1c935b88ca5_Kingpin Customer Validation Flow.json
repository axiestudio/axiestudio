{
  "id": "ca108a7b-dc6d-4390-a5cd-f1c935b88ca5",
  "name": "Kingpin Customer Validation Flow",
  "description": "Use this flow to validate Kingpin's distributor customers from a Metabase export (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "Keyana-Indigo",
    "first_name": "Keyana",
    "last_name": "Sapp",
    "id": "c736115b-5fb8-4417-b747-6d1ab9357c93",
    "full_name": "Keyana Sapp"
  },
  "store_url": "https://www.langflow.store/store/component/ca108a7b-dc6d-4390-a5cd-f1c935b88ca5",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-05T20:23:02.025Z",
    "updated": "2024-10-08T15:18:35.770Z",
    "downloaded": "2025-08-19T17:50:07.483Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "Prompt-KP3PY",
        "type": "genericNode",
        "position": {
          "x": 748.9901796666117,
          "y": 747.4832098056579
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Find the role of the person called {first_name} {last_name} at the company {company_name} - {company_website}. The company will be operational in the Middle East. Use the exact title you find. If no name is provided, just pass the company name and website in your output.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "first_name": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "Suzanne",
                "fileTypes": [],
                "file_path": "",
                "name": "first_name",
                "display_name": "first_name",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "last_name": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "Ponsen",
                "fileTypes": [],
                "file_path": "",
                "name": "last_name",
                "display_name": "last_name",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "company_name": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "Eleganza",
                "fileTypes": [],
                "file_path": "",
                "name": "company_name",
                "display_name": "company_name",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "company_website": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "eleganza.nl",
                "fileTypes": [],
                "file_path": "",
                "name": "company_website",
                "display_name": "company_website",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "first_name",
                "last_name",
                "company_name",
                "company_website"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-KP3PY"
        },
        "selected": false,
        "width": 384,
        "height": 674,
        "positionAbsolute": {
          "x": 748.9901796666117,
          "y": 747.4832098056579
        },
        "dragging": false
      },
      {
        "id": "PerplexityModel-7bhDx",
        "type": "genericNode",
        "position": {
          "x": 1230.0342569511797,
          "y": 473.0835195078075
        },
        "data": {
          "type": "PerplexityModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Perplexity API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Perplexity API Key to use for the Perplexity model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": 10000,
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "llama-3.1-sonar-small-128k-online",
                  "llama-3.1-sonar-large-128k-online",
                  "llama-3.1-sonar-huge-128k-online",
                  "llama-3.1-sonar-small-128k-chat",
                  "llama-3.1-sonar-large-128k-chat",
                  "llama-3.1-8b-instruct",
                  "llama-3.1-70b-instruct"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.1-sonar-large-128k-online",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.75,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Perplexity LLMs.",
            "icon": "Perplexity",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Perplexity",
            "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "model_name",
              "max_output_tokens",
              "api_key",
              "temperature",
              "top_p",
              "n",
              "top_k"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PerplexityModel-7bhDx"
        },
        "selected": false,
        "width": 384,
        "height": 646,
        "positionAbsolute": {
          "x": 1230.0342569511797,
          "y": 473.0835195078075
        },
        "dragging": false
      },
      {
        "id": "PerplexityModel-qYnm0",
        "type": "genericNode",
        "position": {
          "x": 2171.808473868493,
          "y": 291.15667715221696
        },
        "data": {
          "type": "PerplexityModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Perplexity API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Perplexity API Key to use for the Perplexity model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": 10000,
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "llama-3.1-sonar-small-128k-online",
                  "llama-3.1-sonar-large-128k-online",
                  "llama-3.1-sonar-huge-128k-online",
                  "llama-3.1-sonar-small-128k-chat",
                  "llama-3.1-sonar-large-128k-chat",
                  "llama-3.1-8b-instruct",
                  "llama-3.1-70b-instruct"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.1-sonar-large-128k-online",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.75,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Perplexity LLMs.",
            "icon": "Perplexity",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Perplexity",
            "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "model_name",
              "max_output_tokens",
              "api_key",
              "temperature",
              "top_p",
              "n",
              "top_k"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PerplexityModel-qYnm0"
        },
        "selected": false,
        "width": 384,
        "height": 646,
        "positionAbsolute": {
          "x": 2171.808473868493,
          "y": 291.15667715221696
        },
        "dragging": false
      },
      {
        "id": "Prompt-kf3Y2",
        "type": "genericNode",
        "position": {
          "x": 1702.6910396253743,
          "y": 522.2730103313761
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Given the following context: \n\n{context}\n\nFind out whether or not this company is a distributor working with brands. If they look like a retailer selling multiple brands, then you can assume they are a distributor.\n\nHere is the company's extracted homepage content:\n\n{website_content}\n\nAlso include the contact name and job title provided here in your output.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "website_content": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "website_content",
                "display_name": "website_content",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "website_content"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-kf3Y2"
        },
        "selected": false,
        "width": 384,
        "height": 502,
        "positionAbsolute": {
          "x": 1702.6910396253743,
          "y": 522.2730103313761
        },
        "dragging": false
      },
      {
        "id": "Prompt-JAm5Z",
        "type": "genericNode",
        "position": {
          "x": 2641.608390146163,
          "y": 162.16590696964755
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Given the following context: \n\n{context}\n\nFind out whether the company works with international brands to distribute their products to the Middle East. If they are a distributor, go to the company website to find:\n\n1. the regions they distribute to\n2. The brands they work with (if more than 10, find the 10 largest brands) - to find this crawl the website and look at product listings, information pages and other sources.\n3. How many employees the company has (this is very important, try hard).\n\nPlease format the output in a simple format that I can easily copy into my customer spreadsheet.\n\nInclude the following in your output:\n1. Company Name (from previous prompt context)\n2. Contact First Name (from previous prompt context)\n3. Contact Last Name (from previous prompt context)\n4. Contact Job Title (from previous prompt context)\n5. Number of employees (This is very important - navigate to the company LinkedIn page to find information on the number of employees. Do not skip this. If you can't find information on LinkedIn, look at other sources and provide your best estimate)\n6. Brief description of whether the company is a distributor or not.\n7. Brands they work with (list the top ten separated by commas in a format that I can copy easily into a CSV) - find these by scraping all pages of the company website\n8. The countries they distribute to\n\nInclude your sources.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-JAm5Z"
        },
        "selected": false,
        "width": 384,
        "height": 416,
        "positionAbsolute": {
          "x": 2641.608390146163,
          "y": 162.16590696964755
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-eP1o5",
        "type": "genericNode",
        "position": {
          "x": 3605.3765807719133,
          "y": -20.42473614826102
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "ChatOutput-eP1o5"
        },
        "selected": true,
        "width": 384,
        "height": 302,
        "dragging": false,
        "positionAbsolute": {
          "x": 3605.3765807719133,
          "y": -20.42473614826102
        }
      },
      {
        "id": "PerplexityModel-IsYWP",
        "type": "genericNode",
        "position": {
          "x": 3126.872967111986,
          "y": 23.62711401168849
        },
        "data": {
          "type": "PerplexityModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Perplexity API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Perplexity API Key to use for the Perplexity model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": 100000,
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "llama-3.1-sonar-small-128k-online",
                  "llama-3.1-sonar-large-128k-online",
                  "llama-3.1-sonar-huge-128k-online",
                  "llama-3.1-sonar-small-128k-chat",
                  "llama-3.1-sonar-large-128k-chat",
                  "llama-3.1-8b-instruct",
                  "llama-3.1-70b-instruct"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.1-sonar-huge-128k-online",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.75,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Perplexity LLMs.",
            "icon": "Perplexity",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Perplexity",
            "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "model_name",
              "max_output_tokens",
              "api_key",
              "temperature",
              "top_p",
              "n",
              "top_k"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "PerplexityModel-IsYWP"
        },
        "selected": false,
        "width": 384,
        "height": 646,
        "positionAbsolute": {
          "x": 3126.872967111986,
          "y": 23.62711401168849
        },
        "dragging": false
      },
      {
        "id": "URL-rHPko",
        "type": "genericNode",
        "position": {
          "x": -86.7121067944696,
          "y": 1208.6492438275427
        },
        "data": {
          "type": "URL",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\n\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Fetch content from one or more URLs.\"\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs, by clicking the '+' button.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Text\", name=\"text\", method=\"fetch_content_text\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            raise ValueError(f\"Invalid URL: {string}\")\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n\n    def fetch_content_text(self) -> Message:\n        data = self.fetch_content()\n\n        result_string = data_to_text(\"{text}\", data)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "urls": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "urls",
                "value": [
                  "Namshi.com"
                ],
                "display_name": "URLs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter one or more URLs, by clicking the '+' button.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Fetch content from one or more URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "URL",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "fetch_content_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "urls"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "URL-rHPko"
        },
        "selected": false,
        "width": 384,
        "height": 345,
        "positionAbsolute": {
          "x": -86.7121067944696,
          "y": 1208.6492438275427
        },
        "dragging": false
      },
      {
        "id": "FirecrawlCrawlApi-7pWwM",
        "type": "genericNode",
        "position": {
          "x": 719.8961537269909,
          "y": 1485.6746342152971
        },
        "data": {
          "type": "FirecrawlCrawlApi",
          "node": {
            "template": {
              "_type": "CustomComponent",
              "crawlerOptions": {
                "type": "Data",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "crawlerOptions",
                "display_name": "Crawler Options",
                "advanced": false,
                "dynamic": false,
                "info": "Options for the crawler behavior.",
                "load_from_db": false,
                "title_case": false
              },
              "pageOptions": {
                "type": "Data",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "pageOptions",
                "display_name": "Page Options",
                "advanced": false,
                "dynamic": false,
                "info": "The page options to send with the request.",
                "load_from_db": false,
                "title_case": false
              },
              "api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "dynamic": false,
                "info": "The API key to use Firecrawl API.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": ""
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import uuid\nfrom typing import Optional\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Data\n\n\nclass FirecrawlCrawlApi(CustomComponent):\n    display_name: str = \"FirecrawlCrawlApi\"\n    description: str = \"Firecrawl Crawl API.\"\n    name = \"FirecrawlCrawlApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/crawl\"\n    field_config = {\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use Firecrawl API.\",\n        },\n        \"url\": {\n            \"display_name\": \"URL\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"info\": \"The base URL to start crawling from.\",\n        },\n        \"timeout\": {\n            \"display_name\": \"Timeout\",\n            \"field_type\": \"int\",\n            \"info\": \"The timeout in milliseconds.\",\n        },\n        \"crawlerOptions\": {\n            \"display_name\": \"Crawler Options\",\n            \"info\": \"Options for the crawler behavior.\",\n        },\n        \"pageOptions\": {\n            \"display_name\": \"Page Options\",\n            \"info\": \"The page options to send with the request.\",\n        },\n        \"idempotency_key\": {\n            \"display_name\": \"Idempotency Key\",\n            \"field_type\": \"str\",\n            \"info\": \"Optional idempotency key to ensure unique requests.\",\n        },\n    }\n\n    def build(\n        self,\n        api_key: str,\n        url: str,\n        timeout: int = 30000,\n        crawlerOptions: Optional[Data] = None,\n        pageOptions: Optional[Data] = None,\n        idempotency_key: Optional[str] = None,\n    ) -> Data:\n        try:\n            from firecrawl.firecrawl import FirecrawlApp  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import firecrawl integration package. \" \"Please install it with `pip install firecrawl-py`.\"\n            )\n        if crawlerOptions:\n            crawler_options_dict = crawlerOptions.__dict__[\"data\"][\"text\"]\n        else:\n            crawler_options_dict = {}\n\n        if pageOptions:\n            page_options_dict = pageOptions.__dict__[\"data\"][\"text\"]\n        else:\n            page_options_dict = {}\n\n        if not idempotency_key:\n            idempotency_key = str(uuid.uuid4())\n\n        app = FirecrawlApp(api_key=api_key)\n        crawl_result = app.crawl_url(\n            url,\n            {\n                \"crawlerOptions\": crawler_options_dict,\n                \"pageOptions\": page_options_dict,\n            },\n            True,\n            int(timeout / 1000),\n            idempotency_key,\n        )\n\n        records = Data(data={\"results\": crawl_result})\n        return records\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "idempotency_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "idempotency_key",
                "display_name": "Idempotency Key",
                "advanced": false,
                "dynamic": false,
                "info": "Optional idempotency key to ensure unique requests.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "timeout": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 30000,
                "fileTypes": [],
                "file_path": "",
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": false,
                "dynamic": false,
                "info": "The timeout in milliseconds.",
                "load_from_db": false,
                "title_case": false
              },
              "url": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "url",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "The base URL to start crawling from.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "Namshi.com"
              }
            },
            "description": "Firecrawl Crawl API.",
            "base_classes": [
              "Data"
            ],
            "display_name": "FirecrawlCrawlApi",
            "documentation": "https://docs.firecrawl.dev/api-reference/endpoint/crawl",
            "custom_fields": {
              "api_key": null,
              "url": null,
              "timeout": null,
              "crawlerOptions": null,
              "pageOptions": null,
              "idempotency_key": null
            },
            "output_types": [
              "Data"
            ],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": null,
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "api_key",
              "url",
              "timeout",
              "crawlerOptions",
              "pageOptions",
              "idempotency_key"
            ],
            "beta": false,
            "edited": false
          },
          "id": "FirecrawlCrawlApi-7pWwM"
        },
        "selected": false,
        "width": 384,
        "height": 652,
        "positionAbsolute": {
          "x": 719.8961537269909,
          "y": 1485.6746342152971
        },
        "dragging": false
      },
      {
        "id": "ParseData-0Il4o",
        "type": "genericNode",
        "position": {
          "x": 1279.0112427236224,
          "y": 1367.7554919849579
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{content}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "ParseData-0Il4o"
        },
        "selected": false,
        "width": 384,
        "height": 378,
        "positionAbsolute": {
          "x": 1279.0112427236224,
          "y": 1367.7554919849579
        },
        "dragging": false
      },
      {
        "id": "FirecrawlScrapeApi-N1HSr",
        "type": "genericNode",
        "position": {
          "x": 741.4872808914279,
          "y": 2184.805746314941
        },
        "data": {
          "type": "FirecrawlScrapeApi",
          "node": {
            "template": {
              "_type": "CustomComponent",
              "extractorOptions": {
                "type": "Data",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "extractorOptions",
                "display_name": "Extractor Options",
                "advanced": false,
                "dynamic": false,
                "info": "The extractor options to send with the request.",
                "load_from_db": false,
                "title_case": false
              },
              "pageOptions": {
                "type": "Data",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "pageOptions",
                "display_name": "Page Options",
                "advanced": false,
                "dynamic": false,
                "info": "The page options to send with the request.",
                "load_from_db": false,
                "title_case": false
              },
              "api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "api_key",
                "display_name": "API Key",
                "advanced": false,
                "dynamic": false,
                "info": "The API key to use Firecrawl API.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": ""
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Data\n\n\nclass FirecrawlScrapeApi(CustomComponent):\n    display_name: str = \"FirecrawlScrapeApi\"\n    description: str = \"Firecrawl Scrape API.\"\n    name = \"FirecrawlScrapeApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/scrape\"\n    field_config = {\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use Firecrawl API.\",\n        },\n        \"url\": {\n            \"display_name\": \"URL\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"info\": \"The URL to scrape.\",\n        },\n        \"timeout\": {\n            \"display_name\": \"Timeout\",\n            \"info\": \"Timeout in milliseconds for the request.\",\n            \"field_type\": \"int\",\n            \"default_value\": 10000,\n        },\n        \"pageOptions\": {\n            \"display_name\": \"Page Options\",\n            \"info\": \"The page options to send with the request.\",\n        },\n        \"extractorOptions\": {\n            \"display_name\": \"Extractor Options\",\n            \"info\": \"The extractor options to send with the request.\",\n        },\n    }\n\n    def build(\n        self,\n        api_key: str,\n        url: str,\n        timeout: int = 10000,\n        pageOptions: Optional[Data] = None,\n        extractorOptions: Optional[Data] = None,\n    ) -> Data:\n        try:\n            from firecrawl.firecrawl import FirecrawlApp  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import firecrawl integration package. \" \"Please install it with `pip install firecrawl-py`.\"\n            )\n        if extractorOptions:\n            extractor_options_dict = extractorOptions.__dict__[\"data\"][\"text\"]\n        else:\n            extractor_options_dict = {}\n\n        if pageOptions:\n            page_options_dict = pageOptions.__dict__[\"data\"][\"text\"]\n        else:\n            page_options_dict = {}\n\n        app = FirecrawlApp(api_key=api_key)\n        results = app.scrape_url(\n            url,\n            {\n                \"timeout\": str(timeout),\n                \"extractorOptions\": extractor_options_dict,\n                \"pageOptions\": page_options_dict,\n            },\n        )\n\n        record = Data(data=results)\n        return record\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "timeout": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 10000,
                "fileTypes": [],
                "file_path": "",
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": false,
                "dynamic": false,
                "info": "Timeout in milliseconds for the request.",
                "load_from_db": false,
                "title_case": false
              },
              "url": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "url",
                "display_name": "URL",
                "advanced": false,
                "dynamic": false,
                "info": "The URL to scrape.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "eleganza.nl"
              }
            },
            "description": "Firecrawl Scrape API.",
            "base_classes": [
              "Data"
            ],
            "display_name": "FirecrawlScrapeApi",
            "documentation": "https://docs.firecrawl.dev/api-reference/endpoint/scrape",
            "custom_fields": {
              "api_key": null,
              "url": null,
              "timeout": null,
              "pageOptions": null,
              "extractorOptions": null
            },
            "output_types": [
              "Data"
            ],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": null,
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "api_key",
              "url",
              "timeout",
              "pageOptions",
              "extractorOptions"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "FirecrawlScrapeApi-N1HSr"
        },
        "selected": false,
        "width": 384,
        "height": 566,
        "dragging": false,
        "positionAbsolute": {
          "x": 741.4872808914279,
          "y": 2184.805746314941
        }
      },
      {
        "id": "ChatInput-bmz9k",
        "type": "genericNode",
        "position": {
          "x": 3858.279971631615,
          "y": 403.8587234606223
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatInput-bmz9k"
        },
        "selected": false,
        "width": 384,
        "height": 302,
        "positionAbsolute": {
          "x": 3858.279971631615,
          "y": 403.8587234606223
        },
        "dragging": false
      },
      {
        "id": "PDFGeneratorComponent-rpBsX",
        "type": "genericNode",
        "position": {
          "x": -227.472694091522,
          "y": 310.61530367344426
        },
        "data": {
          "type": "PDFGeneratorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\"\"\"\r\nCriando por Professor Sandeco\r\n\r\nhttps://www.youtube.com/@canalsandeco\r\n\r\n\"\"\"\r\n\r\n\r\n\r\n\r\n\r\nfrom axiestudio.custom import Component  # Importação correta de Component\r\nfrom axiestudio.io import MessageTextInput, Output  # Importação correta para MessageTextInput e Output\r\nfrom axiestudio.schema import Data\r\nfrom fpdf import FPDF  # Usando FPDF para gerar o PDF\r\nimport os\r\n\r\nclass PDFGeneratorComponent(Component):\r\n    display_name = \"PDF Generator\"\r\n    description = \"Generates a PDF from a given text and saves it in the Downloads folder.\"\r\n    icon = \"custom_components\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"pdf_title\",\r\n            display_name=\"PDF Title\",\r\n            info=\"Title of the generated PDF.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text_content\",\r\n            display_name=\"Text Content\",\r\n            info=\"The text content to be included in the PDF.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"PDF Creation Status\", name=\"pdf_status\", method=\"create_pdf\"),\r\n    ]\r\n\r\n    def create_pdf(self) -> Data:\r\n        # Obter inputs: título e conteúdo de texto\r\n        pdf_title = self._attributes.get(\"pdf_title\", \"Untitled\")\r\n        text_content = self._attributes.get(\"text_content\", \"\")\r\n\r\n        # Obter o caminho da pasta Downloads no Windows\r\n        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\r\n        pdf_filename = f\"{pdf_title.replace(' ', '_')}.pdf\"\r\n        pdf_path = os.path.join(downloads_folder, pdf_filename)\r\n\r\n        # Criar o PDF usando FPDF com margens ajustadas\r\n        pdf = FPDF()\r\n        pdf.set_left_margin(15)  # Definir a margem esquerda\r\n        pdf.set_right_margin(15)  # Definir a margem direita\r\n        pdf.add_page()\r\n\r\n        # Adicionar título ao PDF\r\n        pdf.set_font(\"Arial\", 'B', 16)\r\n        pdf.cell(0, 10, txt=pdf_title, ln=True, align='C')\r\n\r\n        # Adicionar conteúdo de texto ao PDF com multi_cell para respeitar margens e quebra de linha\r\n        pdf.set_font(\"Arial\", size=12)\r\n        pdf.ln(10)  # Espaçamento entre o título e o texto\r\n\r\n        # Usar multi_cell para quebra de linha automática e ajustar espaçamento entre linhas\r\n        pdf.multi_cell(0, 10, txt=text_content)  # O valor '10' ajusta o espaçamento entre linhas\r\n\r\n        # Salvar o arquivo PDF\r\n        pdf.output(pdf_path)\r\n\r\n        # Abrir o PDF automaticamente no Windows\r\n        try:\r\n            os.startfile(pdf_path)  # Apenas no Windows\r\n        except Exception as e:\r\n            return Data(data={\"status\": f\"Error: {str(e)}\"})\r\n\r\n        # Retornar o status da criação do PDF\r\n        return Data(data={\"status\": f\"PDF created successfully and opened: {pdf_path}\"})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "pdf_title": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "pdf_title",
                "value": "",
                "display_name": "PDF Title",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Title of the generated PDF.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text_content": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_content",
                "value": "",
                "display_name": "Text Content",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text content to be included in the PDF.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generates a PDF from a given text and saves it in the Downloads folder.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "PDF Generator by Sandeco",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "pdf_status",
                "display_name": "PDF Creation Status",
                "method": "create_pdf",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "pdf_title",
              "text_content"
            ],
            "beta": false,
            "edited": true,
            "official": false
          },
          "id": "PDFGeneratorComponent-rpBsX"
        },
        "selected": false,
        "width": 384,
        "height": 416,
        "positionAbsolute": {
          "x": -227.472694091522,
          "y": 310.61530367344426
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Prompt-KP3PY",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KP3PYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityModel-7bhDx",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-7bhDxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "PerplexityModel-7bhDx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-KP3PY",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-KP3PY{œdataTypeœ:œPromptœ,œidœ:œPrompt-KP3PYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-7bhDx{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-7bhDxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-kf3Y2",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-kf3Y2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityModel-qYnm0",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-qYnm0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "PerplexityModel-qYnm0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-kf3Y2",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-kf3Y2{œdataTypeœ:œPromptœ,œidœ:œPrompt-kf3Y2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-qYnm0{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-qYnm0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "PerplexityModel-qYnm0",
        "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-qYnm0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-JAm5Z",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-JAm5Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-JAm5Z",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "PerplexityModel",
            "id": "PerplexityModel-qYnm0",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-PerplexityModel-qYnm0{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-qYnm0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-JAm5Z{œfieldNameœ:œcontextœ,œidœ:œPrompt-JAm5Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "PerplexityModel-IsYWP",
        "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-IsYWPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-eP1o5",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eP1o5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-eP1o5",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "PerplexityModel",
            "id": "PerplexityModel-IsYWP",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-PerplexityModel-IsYWP{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-IsYWPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-eP1o5{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eP1o5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-JAm5Z",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-JAm5Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PerplexityModel-IsYWP",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-IsYWPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "PerplexityModel-IsYWP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-JAm5Z",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-JAm5Z{œdataTypeœ:œPromptœ,œidœ:œPrompt-JAm5Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-IsYWP{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-IsYWPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "PerplexityModel-7bhDx",
        "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-7bhDxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-kf3Y2",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-kf3Y2",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "PerplexityModel",
            "id": "PerplexityModel-7bhDx",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-PerplexityModel-7bhDx{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-7bhDxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-kf3Y2{œfieldNameœ:œcontextœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "ParseData-0Il4o",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-0Il4oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-kf3Y2",
        "targetHandle": "{œfieldNameœ:œwebsite_contentœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "website_content",
            "id": "Prompt-kf3Y2",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-0Il4o",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-0Il4o{œdataTypeœ:œParseDataœ,œidœ:œParseData-0Il4oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-kf3Y2{œfieldNameœ:œwebsite_contentœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "FirecrawlScrapeApi-N1HSr",
        "sourceHandle": "{œdataTypeœ:œFirecrawlScrapeApiœ,œidœ:œFirecrawlScrapeApi-N1HSrœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-0Il4o",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-0Il4oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-0Il4o",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FirecrawlScrapeApi",
            "id": "FirecrawlScrapeApi-N1HSr",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FirecrawlScrapeApi-N1HSr{œdataTypeœ:œFirecrawlScrapeApiœ,œidœ:œFirecrawlScrapeApi-N1HSrœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-0Il4o{œfieldNameœ:œdataœ,œidœ:œParseData-0Il4oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false
      }
    ],
    "viewport": {
      "x": -238.80438056945127,
      "y": 158.86953110985968,
      "zoom": 0.3418446315699358
    }
  },
  "metadata": {
    "Prompt": {
      "count": 3
    },
    "PerplexityModel": {
      "count": 3
    },
    "ChatOutput": {
      "count": 1
    },
    "URL": {
      "count": 1
    },
    "FirecrawlCrawlApi": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "FirecrawlScrapeApi": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "PDFGeneratorComponent": {
      "count": 1
    },
    "total": 13
  },
  "original": {
    "id": "ca108a7b-dc6d-4390-a5cd-f1c935b88ca5",
    "name": "Kingpin Customer Validation Flow",
    "description": "Use this flow to validate Kingpin's distributor customers from a Metabase export",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "2",
    "metadata": {
      "Prompt": {
        "count": 3
      },
      "PerplexityModel": {
        "count": 3
      },
      "ChatOutput": {
        "count": 1
      },
      "URL": {
        "count": 1
      },
      "FirecrawlCrawlApi": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "FirecrawlScrapeApi": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "PDFGeneratorComponent": {
        "count": 1
      },
      "total": 13
    },
    "last_tested_version": "1.0.18",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "Prompt-KP3PY",
          "type": "genericNode",
          "position": {
            "x": 748.9901796666117,
            "y": 747.4832098056579
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Find the role of the person called {first_name} {last_name} at the company {company_name} - {company_website}. The company will be operational in the Middle East. Use the exact title you find. If no name is provided, just pass the company name and website in your output.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "first_name": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "Suzanne",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "first_name",
                  "display_name": "first_name",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "last_name": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "Ponsen",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "last_name",
                  "display_name": "last_name",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "company_name": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "Eleganza",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "company_name",
                  "display_name": "company_name",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "company_website": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "eleganza.nl",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "company_website",
                  "display_name": "company_website",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "first_name",
                  "last_name",
                  "company_name",
                  "company_website"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-KP3PY"
          },
          "selected": false,
          "width": 384,
          "height": 674,
          "positionAbsolute": {
            "x": 748.9901796666117,
            "y": 747.4832098056579
          },
          "dragging": false
        },
        {
          "id": "PerplexityModel-7bhDx",
          "type": "genericNode",
          "position": {
            "x": 1230.0342569511797,
            "y": 473.0835195078075
          },
          "data": {
            "type": "PerplexityModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "Perplexity API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The Perplexity API Key to use for the Perplexity model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_output_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_output_tokens",
                  "value": 10000,
                  "display_name": "Max Output Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "llama-3.1-sonar-small-128k-online",
                    "llama-3.1-sonar-large-128k-online",
                    "llama-3.1-sonar-huge-128k-online",
                    "llama-3.1-sonar-small-128k-chat",
                    "llama-3.1-sonar-large-128k-chat",
                    "llama-3.1-8b-instruct",
                    "llama-3.1-70b-instruct"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "llama-3.1-sonar-large-128k-online",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "n": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n",
                  "value": "",
                  "display_name": "N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.75,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "top_k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_k",
                  "value": "",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "top_p": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_p",
                  "value": "",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum cumulative probability of tokens to consider when sampling.",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Perplexity LLMs.",
              "icon": "Perplexity",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Perplexity",
              "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "model_name",
                "max_output_tokens",
                "api_key",
                "temperature",
                "top_p",
                "n",
                "top_k"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PerplexityModel-7bhDx"
          },
          "selected": false,
          "width": 384,
          "height": 646,
          "positionAbsolute": {
            "x": 1230.0342569511797,
            "y": 473.0835195078075
          },
          "dragging": false
        },
        {
          "id": "PerplexityModel-qYnm0",
          "type": "genericNode",
          "position": {
            "x": 2171.808473868493,
            "y": 291.15667715221696
          },
          "data": {
            "type": "PerplexityModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "Perplexity API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The Perplexity API Key to use for the Perplexity model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_output_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_output_tokens",
                  "value": 10000,
                  "display_name": "Max Output Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "llama-3.1-sonar-small-128k-online",
                    "llama-3.1-sonar-large-128k-online",
                    "llama-3.1-sonar-huge-128k-online",
                    "llama-3.1-sonar-small-128k-chat",
                    "llama-3.1-sonar-large-128k-chat",
                    "llama-3.1-8b-instruct",
                    "llama-3.1-70b-instruct"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "llama-3.1-sonar-large-128k-online",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "n": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n",
                  "value": "",
                  "display_name": "N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.75,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "top_k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_k",
                  "value": "",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "top_p": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_p",
                  "value": "",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum cumulative probability of tokens to consider when sampling.",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Perplexity LLMs.",
              "icon": "Perplexity",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Perplexity",
              "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "model_name",
                "max_output_tokens",
                "api_key",
                "temperature",
                "top_p",
                "n",
                "top_k"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PerplexityModel-qYnm0"
          },
          "selected": false,
          "width": 384,
          "height": 646,
          "positionAbsolute": {
            "x": 2171.808473868493,
            "y": 291.15667715221696
          },
          "dragging": false
        },
        {
          "id": "Prompt-kf3Y2",
          "type": "genericNode",
          "position": {
            "x": 1702.6910396253743,
            "y": 522.2730103313761
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Given the following context: \n\n{context}\n\nFind out whether or not this company is a distributor working with brands. If they look like a retailer selling multiple brands, then you can assume they are a distributor.\n\nHere is the company's extracted homepage content:\n\n{website_content}\n\nAlso include the contact name and job title provided here in your output.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput",
                  "load_from_db": false
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "website_content": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "website_content",
                  "display_name": "website_content",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "website_content"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-kf3Y2"
          },
          "selected": false,
          "width": 384,
          "height": 502,
          "positionAbsolute": {
            "x": 1702.6910396253743,
            "y": 522.2730103313761
          },
          "dragging": false
        },
        {
          "id": "Prompt-JAm5Z",
          "type": "genericNode",
          "position": {
            "x": 2641.608390146163,
            "y": 162.16590696964755
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Given the following context: \n\n{context}\n\nFind out whether the company works with international brands to distribute their products to the Middle East. If they are a distributor, go to the company website to find:\n\n1. the regions they distribute to\n2. The brands they work with (if more than 10, find the 10 largest brands) - to find this crawl the website and look at product listings, information pages and other sources.\n3. How many employees the company has (this is very important, try hard).\n\nPlease format the output in a simple format that I can easily copy into my customer spreadsheet.\n\nInclude the following in your output:\n1. Company Name (from previous prompt context)\n2. Contact First Name (from previous prompt context)\n3. Contact Last Name (from previous prompt context)\n4. Contact Job Title (from previous prompt context)\n5. Number of employees (This is very important - navigate to the company LinkedIn page to find information on the number of employees. Do not skip this. If you can't find information on LinkedIn, look at other sources and provide your best estimate)\n6. Brief description of whether the company is a distributor or not.\n7. Brands they work with (list the top ten separated by commas in a format that I can copy easily into a CSV) - find these by scraping all pages of the company website\n8. The countries they distribute to\n\nInclude your sources.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-JAm5Z"
          },
          "selected": false,
          "width": 384,
          "height": 416,
          "positionAbsolute": {
            "x": 2641.608390146163,
            "y": 162.16590696964755
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-eP1o5",
          "type": "genericNode",
          "position": {
            "x": 3605.3765807719133,
            "y": -20.42473614826102
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "ChatOutput-eP1o5"
          },
          "selected": true,
          "width": 384,
          "height": 302,
          "dragging": false,
          "positionAbsolute": {
            "x": 3605.3765807719133,
            "y": -20.42473614826102
          }
        },
        {
          "id": "PerplexityModel-IsYWP",
          "type": "genericNode",
          "position": {
            "x": 3126.872967111986,
            "y": 23.62711401168849
          },
          "data": {
            "type": "PerplexityModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "Perplexity API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The Perplexity API Key to use for the Perplexity model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.chat_models import ChatPerplexity\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import FloatInput, SecretStrInput, DropdownInput, IntInput\n\n\nclass PerplexityComponent(LCModelComponent):\n    display_name = \"Perplexity\"\n    description = \"Generate text using Perplexity LLMs.\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/\"\n    icon = \"Perplexity\"\n    name = \"PerplexityModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[\n                \"llama-3.1-sonar-small-128k-online\",\n                \"llama-3.1-sonar-large-128k-online\",\n                \"llama-3.1-sonar-huge-128k-online\",\n                \"llama-3.1-sonar-small-128k-chat\",\n                \"llama-3.1-sonar-large-128k-chat\",\n                \"llama-3.1-8b-instruct\",\n                \"llama-3.1-70b-instruct\",\n            ],\n            value=\"llama-3.1-sonar-small-128k-online\",\n        ),\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Perplexity API Key\",\n            info=\"The Perplexity API Key to use for the Perplexity model.\",\n            advanced=False,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        api_key = SecretStr(self.api_key).get_secret_value()\n        temperature = self.temperature\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatPerplexity(\n            model=model,\n            temperature=temperature or 0.75,\n            pplx_api_key=api_key,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            max_output_tokens=max_output_tokens,\n        )\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_output_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_output_tokens",
                  "value": 100000,
                  "display_name": "Max Output Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "llama-3.1-sonar-small-128k-online",
                    "llama-3.1-sonar-large-128k-online",
                    "llama-3.1-sonar-huge-128k-online",
                    "llama-3.1-sonar-small-128k-chat",
                    "llama-3.1-sonar-large-128k-chat",
                    "llama-3.1-8b-instruct",
                    "llama-3.1-70b-instruct"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "llama-3.1-sonar-huge-128k-online",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "n": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n",
                  "value": "",
                  "display_name": "N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.75,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "top_k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_k",
                  "value": "",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "top_p": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_p",
                  "value": "",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum cumulative probability of tokens to consider when sampling.",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Perplexity LLMs.",
              "icon": "Perplexity",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Perplexity",
              "documentation": "https://python.langchain.com/v0.2/docs/integrations/chat/perplexity/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "model_name",
                "max_output_tokens",
                "api_key",
                "temperature",
                "top_p",
                "n",
                "top_k"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "PerplexityModel-IsYWP"
          },
          "selected": false,
          "width": 384,
          "height": 646,
          "positionAbsolute": {
            "x": 3126.872967111986,
            "y": 23.62711401168849
          },
          "dragging": false
        },
        {
          "id": "URL-rHPko",
          "type": "genericNode",
          "position": {
            "x": -86.7121067944696,
            "y": 1208.6492438275427
          },
          "data": {
            "type": "URL",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\n\nfrom langchain_community.document_loaders.web_base import WebBaseLoader\n\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Fetch content from one or more URLs.\"\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs, by clicking the '+' button.\",\n            is_list=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Text\", name=\"text\", method=\"fetch_content_text\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"\n        Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            raise ValueError(f\"Invalid URL: {string}\")\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n\n    def fetch_content_text(self) -> Message:\n        data = self.fetch_content()\n\n        result_string = data_to_text(\"{text}\", data)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "urls": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "urls",
                  "value": [
                    "Namshi.com"
                  ],
                  "display_name": "URLs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter one or more URLs, by clicking the '+' button.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Fetch content from one or more URLs.",
              "icon": "layout-template",
              "base_classes": [
                "Data",
                "Message"
              ],
              "display_name": "URL",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": true,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "fetch_content",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "fetch_content_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "urls"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "URL-rHPko"
          },
          "selected": false,
          "width": 384,
          "height": 345,
          "positionAbsolute": {
            "x": -86.7121067944696,
            "y": 1208.6492438275427
          },
          "dragging": false
        },
        {
          "id": "FirecrawlCrawlApi-7pWwM",
          "type": "genericNode",
          "position": {
            "x": 719.8961537269909,
            "y": 1485.6746342152971
          },
          "data": {
            "type": "FirecrawlCrawlApi",
            "node": {
              "template": {
                "_type": "CustomComponent",
                "crawlerOptions": {
                  "type": "Data",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "crawlerOptions",
                  "display_name": "Crawler Options",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Options for the crawler behavior.",
                  "load_from_db": false,
                  "title_case": false
                },
                "pageOptions": {
                  "type": "Data",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "pageOptions",
                  "display_name": "Page Options",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The page options to send with the request.",
                  "load_from_db": false,
                  "title_case": false
                },
                "api_key": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The API key to use Firecrawl API.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": ""
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import uuid\nfrom typing import Optional\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Data\n\n\nclass FirecrawlCrawlApi(CustomComponent):\n    display_name: str = \"FirecrawlCrawlApi\"\n    description: str = \"Firecrawl Crawl API.\"\n    name = \"FirecrawlCrawlApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/crawl\"\n    field_config = {\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use Firecrawl API.\",\n        },\n        \"url\": {\n            \"display_name\": \"URL\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"info\": \"The base URL to start crawling from.\",\n        },\n        \"timeout\": {\n            \"display_name\": \"Timeout\",\n            \"field_type\": \"int\",\n            \"info\": \"The timeout in milliseconds.\",\n        },\n        \"crawlerOptions\": {\n            \"display_name\": \"Crawler Options\",\n            \"info\": \"Options for the crawler behavior.\",\n        },\n        \"pageOptions\": {\n            \"display_name\": \"Page Options\",\n            \"info\": \"The page options to send with the request.\",\n        },\n        \"idempotency_key\": {\n            \"display_name\": \"Idempotency Key\",\n            \"field_type\": \"str\",\n            \"info\": \"Optional idempotency key to ensure unique requests.\",\n        },\n    }\n\n    def build(\n        self,\n        api_key: str,\n        url: str,\n        timeout: int = 30000,\n        crawlerOptions: Optional[Data] = None,\n        pageOptions: Optional[Data] = None,\n        idempotency_key: Optional[str] = None,\n    ) -> Data:\n        try:\n            from firecrawl.firecrawl import FirecrawlApp  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import firecrawl integration package. \" \"Please install it with `pip install firecrawl-py`.\"\n            )\n        if crawlerOptions:\n            crawler_options_dict = crawlerOptions.__dict__[\"data\"][\"text\"]\n        else:\n            crawler_options_dict = {}\n\n        if pageOptions:\n            page_options_dict = pageOptions.__dict__[\"data\"][\"text\"]\n        else:\n            page_options_dict = {}\n\n        if not idempotency_key:\n            idempotency_key = str(uuid.uuid4())\n\n        app = FirecrawlApp(api_key=api_key)\n        crawl_result = app.crawl_url(\n            url,\n            {\n                \"crawlerOptions\": crawler_options_dict,\n                \"pageOptions\": page_options_dict,\n            },\n            True,\n            int(timeout / 1000),\n            idempotency_key,\n        )\n\n        records = Data(data={\"results\": crawl_result})\n        return records\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "idempotency_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "idempotency_key",
                  "display_name": "Idempotency Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Optional idempotency key to ensure unique requests.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "timeout": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 30000,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The timeout in milliseconds.",
                  "load_from_db": false,
                  "title_case": false
                },
                "url": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "url",
                  "display_name": "URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The base URL to start crawling from.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "Namshi.com"
                }
              },
              "description": "Firecrawl Crawl API.",
              "base_classes": [
                "Data"
              ],
              "display_name": "FirecrawlCrawlApi",
              "documentation": "https://docs.firecrawl.dev/api-reference/endpoint/crawl",
              "custom_fields": {
                "api_key": null,
                "url": null,
                "timeout": null,
                "crawlerOptions": null,
                "pageOptions": null,
                "idempotency_key": null
              },
              "output_types": [
                "Data"
              ],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "hidden": null,
                  "display_name": "Data",
                  "method": null,
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "api_key",
                "url",
                "timeout",
                "crawlerOptions",
                "pageOptions",
                "idempotency_key"
              ],
              "beta": false,
              "edited": false
            },
            "id": "FirecrawlCrawlApi-7pWwM"
          },
          "selected": false,
          "width": 384,
          "height": 652,
          "positionAbsolute": {
            "x": 719.8961537269909,
            "y": 1485.6746342152971
          },
          "dragging": false
        },
        {
          "id": "ParseData-0Il4o",
          "type": "genericNode",
          "position": {
            "x": 1279.0112427236224,
            "y": 1367.7554919849579
          },
          "data": {
            "type": "ParseData",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sep",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{content}",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Convert Data into plain text following a specified template.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "ParseData-0Il4o"
          },
          "selected": false,
          "width": 384,
          "height": 378,
          "positionAbsolute": {
            "x": 1279.0112427236224,
            "y": 1367.7554919849579
          },
          "dragging": false
        },
        {
          "id": "FirecrawlScrapeApi-N1HSr",
          "type": "genericNode",
          "position": {
            "x": 741.4872808914279,
            "y": 2184.805746314941
          },
          "data": {
            "type": "FirecrawlScrapeApi",
            "node": {
              "template": {
                "_type": "CustomComponent",
                "extractorOptions": {
                  "type": "Data",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "extractorOptions",
                  "display_name": "Extractor Options",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The extractor options to send with the request.",
                  "load_from_db": false,
                  "title_case": false
                },
                "pageOptions": {
                  "type": "Data",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "pageOptions",
                  "display_name": "Page Options",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The page options to send with the request.",
                  "load_from_db": false,
                  "title_case": false
                },
                "api_key": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "api_key",
                  "display_name": "API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The API key to use Firecrawl API.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": ""
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Data\n\n\nclass FirecrawlScrapeApi(CustomComponent):\n    display_name: str = \"FirecrawlScrapeApi\"\n    description: str = \"Firecrawl Scrape API.\"\n    name = \"FirecrawlScrapeApi\"\n\n    output_types: list[str] = [\"Document\"]\n    documentation: str = \"https://docs.firecrawl.dev/api-reference/endpoint/scrape\"\n    field_config = {\n        \"api_key\": {\n            \"display_name\": \"API Key\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"password\": True,\n            \"info\": \"The API key to use Firecrawl API.\",\n        },\n        \"url\": {\n            \"display_name\": \"URL\",\n            \"field_type\": \"str\",\n            \"required\": True,\n            \"info\": \"The URL to scrape.\",\n        },\n        \"timeout\": {\n            \"display_name\": \"Timeout\",\n            \"info\": \"Timeout in milliseconds for the request.\",\n            \"field_type\": \"int\",\n            \"default_value\": 10000,\n        },\n        \"pageOptions\": {\n            \"display_name\": \"Page Options\",\n            \"info\": \"The page options to send with the request.\",\n        },\n        \"extractorOptions\": {\n            \"display_name\": \"Extractor Options\",\n            \"info\": \"The extractor options to send with the request.\",\n        },\n    }\n\n    def build(\n        self,\n        api_key: str,\n        url: str,\n        timeout: int = 10000,\n        pageOptions: Optional[Data] = None,\n        extractorOptions: Optional[Data] = None,\n    ) -> Data:\n        try:\n            from firecrawl.firecrawl import FirecrawlApp  # type: ignore\n        except ImportError:\n            raise ImportError(\n                \"Could not import firecrawl integration package. \" \"Please install it with `pip install firecrawl-py`.\"\n            )\n        if extractorOptions:\n            extractor_options_dict = extractorOptions.__dict__[\"data\"][\"text\"]\n        else:\n            extractor_options_dict = {}\n\n        if pageOptions:\n            page_options_dict = pageOptions.__dict__[\"data\"][\"text\"]\n        else:\n            page_options_dict = {}\n\n        app = FirecrawlApp(api_key=api_key)\n        results = app.scrape_url(\n            url,\n            {\n                \"timeout\": str(timeout),\n                \"extractorOptions\": extractor_options_dict,\n                \"pageOptions\": page_options_dict,\n            },\n        )\n\n        record = Data(data=results)\n        return record\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "timeout": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 10000,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Timeout in milliseconds for the request.",
                  "load_from_db": false,
                  "title_case": false
                },
                "url": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "name": "url",
                  "display_name": "URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The URL to scrape.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "eleganza.nl"
                }
              },
              "description": "Firecrawl Scrape API.",
              "base_classes": [
                "Data"
              ],
              "display_name": "FirecrawlScrapeApi",
              "documentation": "https://docs.firecrawl.dev/api-reference/endpoint/scrape",
              "custom_fields": {
                "api_key": null,
                "url": null,
                "timeout": null,
                "pageOptions": null,
                "extractorOptions": null
              },
              "output_types": [
                "Data"
              ],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "hidden": null,
                  "display_name": "Data",
                  "method": null,
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "api_key",
                "url",
                "timeout",
                "pageOptions",
                "extractorOptions"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "FirecrawlScrapeApi-N1HSr"
          },
          "selected": false,
          "width": 384,
          "height": 566,
          "dragging": false,
          "positionAbsolute": {
            "x": 741.4872808914279,
            "y": 2184.805746314941
          }
        },
        {
          "id": "ChatInput-bmz9k",
          "type": "genericNode",
          "position": {
            "x": 3858.279971631615,
            "y": 403.8587234606223
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatInput-bmz9k"
          },
          "selected": false,
          "width": 384,
          "height": 302,
          "positionAbsolute": {
            "x": 3858.279971631615,
            "y": 403.8587234606223
          },
          "dragging": false
        },
        {
          "id": "PDFGeneratorComponent-rpBsX",
          "type": "genericNode",
          "position": {
            "x": -227.472694091522,
            "y": 310.61530367344426
          },
          "data": {
            "type": "PDFGeneratorComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "\"\"\"\r\nCriando por Professor Sandeco\r\n\r\nhttps://www.youtube.com/@canalsandeco\r\n\r\n\"\"\"\r\n\r\n\r\n\r\n\r\n\r\nfrom axiestudio.custom import Component  # Importação correta de Component\r\nfrom axiestudio.io import MessageTextInput, Output  # Importação correta para MessageTextInput e Output\r\nfrom axiestudio.schema import Data\r\nfrom fpdf import FPDF  # Usando FPDF para gerar o PDF\r\nimport os\r\n\r\nclass PDFGeneratorComponent(Component):\r\n    display_name = \"PDF Generator\"\r\n    description = \"Generates a PDF from a given text and saves it in the Downloads folder.\"\r\n    icon = \"custom_components\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"pdf_title\",\r\n            display_name=\"PDF Title\",\r\n            info=\"Title of the generated PDF.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text_content\",\r\n            display_name=\"Text Content\",\r\n            info=\"The text content to be included in the PDF.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"PDF Creation Status\", name=\"pdf_status\", method=\"create_pdf\"),\r\n    ]\r\n\r\n    def create_pdf(self) -> Data:\r\n        # Obter inputs: título e conteúdo de texto\r\n        pdf_title = self._attributes.get(\"pdf_title\", \"Untitled\")\r\n        text_content = self._attributes.get(\"text_content\", \"\")\r\n\r\n        # Obter o caminho da pasta Downloads no Windows\r\n        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\r\n        pdf_filename = f\"{pdf_title.replace(' ', '_')}.pdf\"\r\n        pdf_path = os.path.join(downloads_folder, pdf_filename)\r\n\r\n        # Criar o PDF usando FPDF com margens ajustadas\r\n        pdf = FPDF()\r\n        pdf.set_left_margin(15)  # Definir a margem esquerda\r\n        pdf.set_right_margin(15)  # Definir a margem direita\r\n        pdf.add_page()\r\n\r\n        # Adicionar título ao PDF\r\n        pdf.set_font(\"Arial\", 'B', 16)\r\n        pdf.cell(0, 10, txt=pdf_title, ln=True, align='C')\r\n\r\n        # Adicionar conteúdo de texto ao PDF com multi_cell para respeitar margens e quebra de linha\r\n        pdf.set_font(\"Arial\", size=12)\r\n        pdf.ln(10)  # Espaçamento entre o título e o texto\r\n\r\n        # Usar multi_cell para quebra de linha automática e ajustar espaçamento entre linhas\r\n        pdf.multi_cell(0, 10, txt=text_content)  # O valor '10' ajusta o espaçamento entre linhas\r\n\r\n        # Salvar o arquivo PDF\r\n        pdf.output(pdf_path)\r\n\r\n        # Abrir o PDF automaticamente no Windows\r\n        try:\r\n            os.startfile(pdf_path)  # Apenas no Windows\r\n        except Exception as e:\r\n            return Data(data={\"status\": f\"Error: {str(e)}\"})\r\n\r\n        # Retornar o status da criação do PDF\r\n        return Data(data={\"status\": f\"PDF created successfully and opened: {pdf_path}\"})\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "pdf_title": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "pdf_title",
                  "value": "",
                  "display_name": "PDF Title",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Title of the generated PDF.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text_content": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_content",
                  "value": "",
                  "display_name": "Text Content",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The text content to be included in the PDF.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generates a PDF from a given text and saves it in the Downloads folder.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "PDF Generator by Sandeco",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "pdf_status",
                  "display_name": "PDF Creation Status",
                  "method": "create_pdf",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "pdf_title",
                "text_content"
              ],
              "beta": false,
              "edited": true,
              "official": false
            },
            "id": "PDFGeneratorComponent-rpBsX"
          },
          "selected": false,
          "width": 384,
          "height": 416,
          "positionAbsolute": {
            "x": -227.472694091522,
            "y": 310.61530367344426
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Prompt-KP3PY",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KP3PYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "PerplexityModel-7bhDx",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-7bhDxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "PerplexityModel-7bhDx",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-KP3PY",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-KP3PY{œdataTypeœ:œPromptœ,œidœ:œPrompt-KP3PYœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-7bhDx{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-7bhDxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-kf3Y2",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-kf3Y2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "PerplexityModel-qYnm0",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-qYnm0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "PerplexityModel-qYnm0",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-kf3Y2",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-kf3Y2{œdataTypeœ:œPromptœ,œidœ:œPrompt-kf3Y2œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-qYnm0{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-qYnm0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "PerplexityModel-qYnm0",
          "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-qYnm0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-JAm5Z",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-JAm5Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-JAm5Z",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "PerplexityModel",
              "id": "PerplexityModel-qYnm0",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-PerplexityModel-qYnm0{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-qYnm0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-JAm5Z{œfieldNameœ:œcontextœ,œidœ:œPrompt-JAm5Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "PerplexityModel-IsYWP",
          "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-IsYWPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-eP1o5",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eP1o5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-eP1o5",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "PerplexityModel",
              "id": "PerplexityModel-IsYWP",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-PerplexityModel-IsYWP{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-IsYWPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-eP1o5{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eP1o5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "Prompt-JAm5Z",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-JAm5Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "PerplexityModel-IsYWP",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-IsYWPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "PerplexityModel-IsYWP",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-JAm5Z",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-JAm5Z{œdataTypeœ:œPromptœ,œidœ:œPrompt-JAm5Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-PerplexityModel-IsYWP{œfieldNameœ:œinput_valueœ,œidœ:œPerplexityModel-IsYWPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "PerplexityModel-7bhDx",
          "sourceHandle": "{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-7bhDxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-kf3Y2",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-kf3Y2",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "PerplexityModel",
              "id": "PerplexityModel-7bhDx",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-PerplexityModel-7bhDx{œdataTypeœ:œPerplexityModelœ,œidœ:œPerplexityModel-7bhDxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-kf3Y2{œfieldNameœ:œcontextœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "ParseData-0Il4o",
          "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-0Il4oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-kf3Y2",
          "targetHandle": "{œfieldNameœ:œwebsite_contentœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "website_content",
              "id": "Prompt-kf3Y2",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParseData",
              "id": "ParseData-0Il4o",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ParseData-0Il4o{œdataTypeœ:œParseDataœ,œidœ:œParseData-0Il4oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-kf3Y2{œfieldNameœ:œwebsite_contentœ,œidœ:œPrompt-kf3Y2œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "FirecrawlScrapeApi-N1HSr",
          "sourceHandle": "{œdataTypeœ:œFirecrawlScrapeApiœ,œidœ:œFirecrawlScrapeApi-N1HSrœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
          "target": "ParseData-0Il4o",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-0Il4oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-0Il4o",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FirecrawlScrapeApi",
              "id": "FirecrawlScrapeApi-N1HSr",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-FirecrawlScrapeApi-N1HSr{œdataTypeœ:œFirecrawlScrapeApiœ,œidœ:œFirecrawlScrapeApi-N1HSrœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-0Il4o{œfieldNameœ:œdataœ,œidœ:œParseData-0Il4oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": "",
          "selected": false
        }
      ],
      "viewport": {
        "x": -238.80438056945127,
        "y": 158.86953110985968,
        "zoom": 0.3418446315699358
      }
    },
    "date_created": "2024-10-05T20:23:02.025Z",
    "date_updated": "2024-10-08T15:18:35.770Z",
    "status": "Public",
    "sort": null,
    "user_updated": "c736115b-5fb8-4417-b747-6d1ab9357c93",
    "user_created": {
      "username": "Keyana-Indigo",
      "first_name": "Keyana",
      "last_name": "Sapp",
      "id": "c736115b-5fb8-4417-b747-6d1ab9357c93"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:05.482Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 112,
    "converter_version": "1.0.0"
  }
}