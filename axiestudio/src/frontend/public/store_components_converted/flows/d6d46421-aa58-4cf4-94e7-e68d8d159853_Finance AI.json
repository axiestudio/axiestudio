{
  "id": "d6d46421-aa58-4cf4-94e7-e68d8d159853",
  "name": "Finance AI",
  "description": "Building Powerful Solutions with Language Models. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "matheus-borges",
    "first_name": "Matheus",
    "last_name": "Borges",
    "id": "194e9ebd-684c-49cc-a4aa-d0dceccd24e8",
    "full_name": "Matheus Borges"
  },
  "store_url": "https://www.langflow.store/store/component/d6d46421-aa58-4cf4-94e7-e68d8d159853",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-18T03:54:57.296Z",
    "updated": "2024-10-18T19:12:03.918Z",
    "downloaded": "2025-08-19T17:50:07.500Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.18",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "CustomComponent-uPmjj",
        "type": "genericNode",
        "position": {
          "x": -621.5035041921883,
          "y": 461.1360842823604
        },
        "data": {
          "type": "OCRProcessor",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n# Importar bibliotecas necessárias\nfrom PIL import Image\nimport pytesseract\nimport pdf2image  # Para processar PDFs\nimport cv2  # Para manipulação de imagem\nimport numpy as np\nimport os\n\nclass CustomComponent(Component):\n    display_name = \"OCR Processor\"  # Nome personalizado para o componente\n    description = \"Processa imagens ou PDFs e extrai texto usando OCR\"\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"OCRProcessor\"\n\n    # Definindo as entradas do componente\n    inputs = [\n        MessageTextInput(name=\"file_path\", display_name=\"File Path\", value=\"\"),  # Caminho do arquivo como input\n    ]\n\n    # Definindo as saídas do componente\n    outputs = [\n        Output(display_name=\"Extracted Text\", name=\"extracted_text\", method=\"build_output\"),  # Texto extraído como output\n    ]\n\n    # Função de pré-processamento de imagem\n    def preprocess_image(self, image_path):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        gray_image = cv2.medianBlur(gray_image, 3)\n        gray_image = cv2.adaptiveThreshold(gray_image, 255, \n                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n                                           cv2.THRESH_BINARY, 11, 2)\n        return gray_image\n\n    # Função para extrair texto de uma imagem\n    def extract_text_from_image(self, image_path):\n        try:\n            image = Image.open(image_path)\n            extracted_text = pytesseract.image_to_string(image, lang='por')\n            return extracted_text\n        except Exception as e:\n            return f\"Erro ao processar a imagem: {e}\"\n\n    # Função para processar um arquivo PDF e extrair texto\n    def extract_text_from_pdf(self, pdf_path):\n        try:\n            pages = pdf2image.convert_from_path(pdf_path)\n            text = \"\"\n            for page_num, page in enumerate(pages):\n                temp_image_path = f\"temp_page_{page_num}.png\"\n                page.save(temp_image_path, 'PNG')\n                text += self.extract_text_from_image(temp_image_path)\n                os.remove(temp_image_path)\n            return text\n        except Exception as e:\n            return f\"Erro ao processar o PDF: {e}\"\n\n    # Função para processar um comprovante (imagem ou PDF)\n    def process_receipt(self, file_path):\n        # Definir o caminho para o executável do Tesseract manualmente\n        pytesseract.pytesseract.tesseract_cmd = r'D:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n        file_ext = os.path.splitext(file_path)[1].lower()#Extrai o formato do arquivo\n        if file_ext in ['.png', '.jpg', '.jpeg']:\n            return self.extract_text_from_image(file_path)\n        elif file_ext == '.pdf':\n            return self.extract_text_from_pdf(file_path)\n        else:\n            return \"Formato de arquivo não suportado.\"\n\n    # Função para construir a saída do componente\n    def build_output(self) -> str:\n        # Extraia o valor do caminho do arquivo corretamente\n        path = self.file_path.value if hasattr(self.file_path, 'value') else self.file_path  # Pega o caminho do arquivo da entrada\n        # Substitui barras simples por barras duplas para garantir compatibilidade\n        file_path = path.replace(\"\\\\\", \"\\\\\\\\\")\n        if not file_path:\n            return \"Nenhum arquivo fornecido.\"\n\n        # Processar o arquivo e extrair texto\n        extracted_text = self.process_receipt(file_path)\n        return extracted_text",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "file_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_path",
                "value": "G:\\Meu Drive\\Data Science\\Projects\\Langflow\\Comprovantes_Despesas\\comprovanteEnergia.jpg",
                "display_name": "File Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Processa imagens ou PDFs e extrai texto usando OCR",
            "icon": "custom_components",
            "base_classes": [
              "Text"
            ],
            "display_name": "Reconhecimento de Texto",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "extracted_text",
                "display_name": "Extracted Text",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_path"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18"
          },
          "id": "CustomComponent-uPmjj"
        },
        "selected": false,
        "width": 384,
        "height": 328,
        "positionAbsolute": {
          "x": -621.5035041921883,
          "y": 461.1360842823604
        },
        "dragging": false
      },
      {
        "id": "SequentialTaskComponent-XnHYO",
        "type": "genericNode",
        "position": {
          "x": 2187.464383869555,
          "y": 766.2989754313695
        },
        "data": {
          "type": "SequentialTaskComponent",
          "node": {
            "template": {
              "_type": "Component",
              "agent": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "agent",
                "value": "",
                "display_name": "Agent",
                "advanced": false,
                "input_types": [
                  "Agent"
                ],
                "dynamic": false,
                "info": "CrewAI Agent that will perform the task",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "task": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "task",
                "value": "",
                "display_name": "Task",
                "advanced": false,
                "input_types": [
                  "SequentialTask"
                ],
                "dynamic": false,
                "info": "CrewAI Task that will perform the task",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": true,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "async_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "async_execution",
                "value": true,
                "display_name": "Async Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag indicating asynchronous task execution.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.agents.crewai.tasks import SequentialTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MultilineInput, Output\n\n\nclass SequentialTaskComponent(Component):\n    display_name: str = \"Sequential Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"agent\",\n            display_name=\"Agent\",\n            input_types=[\"Agent\"],\n            info=\"CrewAI Agent that will perform the task\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"task\",\n            display_name=\"Task\",\n            input_types=[\"SequentialTask\"],\n            info=\"CrewAI Task that will perform the task\",\n        ),\n        BoolInput(\n            name=\"async_execution\",\n            display_name=\"Async Execution\",\n            value=True,\n            advanced=True,\n            info=\"Boolean flag indicating asynchronous task execution.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> list[SequentialTask]:\n        tasks: list[SequentialTask] = []\n        task = SequentialTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.agent.tools,\n            async_execution=False,\n            agent=self.agent,\n        )\n        tasks.append(task)\n        self.status = task\n        if self.task:\n            if isinstance(self.task, list) and all(isinstance(task, SequentialTask) for task in self.task):\n                tasks = self.task + tasks\n            elif isinstance(self.task, SequentialTask):\n                tasks = [self.task] + tasks\n        return tasks\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "expected_output": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "expected_output",
                "value": "",
                "display_name": "Expected Output",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Clear definition of expected task outcome.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "task_description": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "task_description",
                "value": "",
                "display_name": "Description",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Descriptive text detailing task's purpose and execution.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Each task must have a description, an expected output and an agent responsible for execution.",
            "icon": "CrewAI",
            "base_classes": [
              "SequentialTask"
            ],
            "display_name": "Sequential Task",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "SequentialTask"
                ],
                "selected": "SequentialTask",
                "name": "task_output",
                "display_name": "Task",
                "method": "build_task",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "task_description",
              "expected_output",
              "tools",
              "agent",
              "task",
              "async_execution"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "SequentialTaskComponent-XnHYO"
        },
        "selected": false,
        "width": 384,
        "height": 506,
        "positionAbsolute": {
          "x": 2187.464383869555,
          "y": 766.2989754313695
        },
        "dragging": false
      },
      {
        "id": "GoogleGenerativeAIModel-95LTV",
        "type": "genericNode",
        "position": {
          "x": 927.6351208907231,
          "y": 1586.33753883171
        },
        "data": {
          "type": "GoogleGenerativeAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError:\n            raise ImportError(\"The 'langchain_google_genai' package is required to use the Google Generative AI model.\")\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatGoogleGenerativeAI(  # type: ignore\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key),\n        )\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "google_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "google_api_key",
                "value": "",
                "display_name": "Google API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": 500,
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "gemini-1.5-pro",
                  "gemini-1.5-flash",
                  "gemini-1.0-pro",
                  "gemini-1.0-pro-vision"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "gemini-1.5-flash",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the model to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Google Generative AI.",
            "icon": "GoogleGenerativeAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Google Generative AI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model",
              "google_api_key",
              "top_p",
              "temperature",
              "n",
              "top_k"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "GoogleGenerativeAIModel-95LTV"
        },
        "selected": false,
        "width": 384,
        "height": 686,
        "positionAbsolute": {
          "x": 927.6351208907231,
          "y": 1586.33753883171
        },
        "dragging": false
      },
      {
        "id": "CrewAIAgentComponent-03rxB",
        "type": "genericNode",
        "position": {
          "x": 1432.8042627575169,
          "y": 668.8460581121353
        },
        "data": {
          "type": "CrewAIAgentComponent",
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Language model that will run the agent.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": [],
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "Tools at agents disposal",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "allow_code_execution": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_code_execution",
                "value": false,
                "display_name": "Allow Code Execution",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent is allowed to execute code.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "allow_delegation": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_delegation",
                "value": false,
                "display_name": "Allow Delegation",
                "advanced": false,
                "dynamic": false,
                "info": "Whether the agent is allowed to delegate tasks to other agents.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "backstory": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "backstory",
                "value": "",
                "display_name": "Backstory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The backstory of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "goal": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "goal",
                "value": "",
                "display_name": "Goal",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The objective of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "kwargs": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "kwargs",
                "value": {},
                "display_name": "kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "kwargs of agent.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": true,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "Whether the agent should have memory or not",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "role": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "role",
                "value": "Classificador de Despesas",
                "display_name": "Role",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The role of the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": false,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Represents an agent of CrewAI.",
            "icon": "CrewAI",
            "base_classes": [
              "Agent"
            ],
            "display_name": "CrewAI Agent",
            "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Agent"
                ],
                "selected": "Agent",
                "name": "output",
                "display_name": "Agent",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "role",
              "goal",
              "backstory",
              "tools",
              "llm",
              "memory",
              "verbose",
              "allow_delegation",
              "allow_code_execution",
              "kwargs"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "CrewAIAgentComponent-03rxB"
        },
        "selected": false,
        "width": 384,
        "height": 635,
        "positionAbsolute": {
          "x": 1432.8042627575169,
          "y": 668.8460581121353
        },
        "dragging": false
      },
      {
        "id": "Prompt-hrHHB",
        "type": "genericNode",
        "position": {
          "x": 907.1855571227247,
          "y": -171.5242025754452
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "O objetivo deste agente é receber um texto:\n  {Extract_text}.\nO texto contém informações detalhadas sobre uma transação financeira, como nome do pagador, valor, data e descrição do pagamento. O agente deve processar esse texto, identificando padrões, termos específicos ou informações relevantes que permitam categorizar automaticamente a despesa em uma das seguintes categorias predefinidas em {categorias}.\nSe possível você pode usar o código de barras para tirar mais informações sobre conta em questão. Leia o código de barras e pesquise o boleto para identificar as informações contidas nele.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "Extract_text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Extract_text",
                "display_name": "Extract_text",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "categorias": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "categorias",
                "display_name": "categorias",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Extract_text",
                "categorias"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-hrHHB"
        },
        "selected": false,
        "width": 384,
        "height": 499,
        "positionAbsolute": {
          "x": 907.1855571227247,
          "y": -171.5242025754452
        },
        "dragging": false
      },
      {
        "id": "Prompt-KHfAD",
        "type": "genericNode",
        "position": {
          "x": 845.5682700592165,
          "y": 463.9049736736458
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Este agente foi treinado e otimizado para lidar com a categorização automática de despesas financeiras, processando textos extraídos de comprovantes de pagamento, como é o caso do texto {Extract_text}. Ele é capaz de analisar padrões comuns em transações financeiras e reconhecer os principais campos presentes nesses documentos, como nome do cliente, valor, data e descrição do pagamento.\n\nCom uma vasta base de dados e conhecimento sobre categorias típicas de despesas (como Alimentação, Transporte, Saúde, etc.) que estão apresentadas em {categoria}\nO agente utiliza algoritmos de processamento de linguagem natural (NLP) para identificar informações-chave no texto, como o tipo de serviço ou produto relacionado à transação, estabelecimentos, códigos de pagamento, ou descrições associadas. A partir dessa análise, o agente pode classificar a transação corretamente dentro de categorias predefinidas.\n\nAlém disso, o agente tem a capacidade de aprender com novos padrões que possam surgir em comprovantes, adaptando-se a variações na forma como as transações são descritas. Ele também poderá fazer uma busca na internet, para verificar se encontra referência daquela despesa para poder auxiliar no processo de classificação.\n\nSua função principal é auxiliar no gerenciamento financeiro ao automatizar o processo de categorização de despesas, otimizando a organização e a visualização das finanças familiares ou empresariais.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "Extract_text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Extract_text",
                "display_name": "Extract_text",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "categoria": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "categoria",
                "display_name": "categoria",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Extract_text",
                "categoria"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-KHfAD"
        },
        "selected": false,
        "width": 384,
        "height": 499,
        "positionAbsolute": {
          "x": 845.5682700592165,
          "y": 463.9049736736458
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-f0myE",
        "type": "genericNode",
        "position": {
          "x": 3490.4971267757796,
          "y": 873.7029546970407
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "ChatOutput-f0myE"
        },
        "selected": false,
        "width": 384,
        "height": 300,
        "positionAbsolute": {
          "x": 3490.4971267757796,
          "y": 873.7029546970407
        },
        "dragging": false
      },
      {
        "id": "Prompt-jeRYR",
        "type": "genericNode",
        "position": {
          "x": 497.5580825964339,
          "y": 944.8657215350918
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "O agente deve processar o texto em português fornecido em {Extract_text} e retornar uma saída estruturada em português, contendo as seguintes informações:\n\nCategoria da despesa:\nO agente deve identificar e classificar a transação em uma das categorias predefinidas, como {categoria}\n\nValor da despesa:\nO agente deve extrair o valor total da despesa no formato monetário (ex: R$ 76,05).\n\nData da transação:\nA data da transação deve ser identificada e retornada no formato correto (ex: 23/09/2024). Deve haver apenas uma data, a qual se refere quando foi feito o pagamento, a data de vencimento deve ser ignorada.\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "Extract_text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Extract_text",
                "display_name": "Extract_text",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "categoria": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "categoria",
                "display_name": "categoria",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Extract_text",
                "categoria"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-jeRYR"
        },
        "selected": false,
        "width": 384,
        "height": 499,
        "positionAbsolute": {
          "x": 497.5580825964339,
          "y": 944.8657215350918
        },
        "dragging": false
      },
      {
        "id": "GoogleSerperAPI-gxVaT",
        "type": "genericNode",
        "position": {
          "x": -149.7633358817037,
          "y": 1304.8530248728373
        },
        "data": {
          "type": "GoogleSerperAPI",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Union\n\nfrom langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, IntInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\n\n\nclass GoogleSerperAPIComponent(LCToolComponent):\n    display_name = \"Google Serper API\"\n    description = \"Call the Serper.dev Google Search API.\"\n    name = \"GoogleSerperAPI\"\n\n    inputs = [\n        SecretStrInput(name=\"serper_api_key\", display_name=\"Serper API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n    ]\n\n    def run_model(self) -> Union[Data, list[Data]]:\n        wrapper = self._build_wrapper()\n        results = wrapper.results(query=self.input_value)\n        list_results = results.get(\"organic\", [])\n        data = [Data(data=result, text=result[\"snippet\"]) for result in list_results]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(\n            name=\"google_search\",\n            description=\"Search Google for recent results.\",\n            func=wrapper.run,\n        )\n\n    def _build_wrapper(self):\n        return GoogleSerperAPIWrapper(serper_api_key=self.serper_api_key, k=self.k)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "k": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "k",
                "value": 10,
                "display_name": "Number of results",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "serper_api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "serper_api_key",
                "value": "",
                "display_name": "Serper API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Call the Serper.dev Google Search API.",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "Google Serper API",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "serper_api_key",
              "input_value",
              "k"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "GoogleSerperAPI-gxVaT"
        },
        "selected": true,
        "width": 384,
        "height": 515,
        "positionAbsolute": {
          "x": -149.7633358817037,
          "y": 1304.8530248728373
        },
        "dragging": false
      },
      {
        "id": "Prompt-vQNbF",
        "type": "genericNode",
        "position": {
          "x": -333.2494667534377,
          "y": -169.65831900710822
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Categorias das despesas estão definidas em:\n\nAlimentação\nTransporte\nSaúde\nEducação\nLazer\nMoradia\nÁgua\nLuz\nInternet\nImposto DAS - Simples Nacional\nFatura Banco do Brasil\nFatura Renner\nFatura LuizaCred\nFatura Neon\nPlano Telefone\nIPTU\nIPVA\nDespesas Eventuais\nOutros",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-vQNbF"
        },
        "selected": false,
        "width": 384,
        "height": 328,
        "positionAbsolute": {
          "x": -333.2494667534377,
          "y": -169.65831900710822
        },
        "dragging": false
      },
      {
        "id": "SequentialCrewComponent-2GHRc",
        "type": "genericNode",
        "position": {
          "x": 2792.9023648520015,
          "y": 986.67458600618
        },
        "data": {
          "type": "SequentialCrewComponent",
          "node": {
            "template": {
              "_type": "Component",
              "function_calling_llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "function_calling_llm",
                "value": "",
                "display_name": "Function Calling LLM",
                "advanced": true,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tasks": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tasks",
                "value": "",
                "display_name": "Tasks",
                "advanced": false,
                "input_types": [
                  "SequentialTask"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from crewai import Agent, Crew, Process, Task  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\nfrom axiestudio.schema.message import Message\n\n\nclass SequentialCrewComponent(BaseCrewComponent):\n    display_name: str = \"Sequential Crew\"\n    description: str = \"Represents a group of agents with tasks that are executed sequentially.\"\n    documentation: str = \"https://docs.crewai.com/how-to/Sequential/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"SequentialTask\"], is_list=True),\n    ]\n\n    def get_tasks_and_agents(self) -> tuple[list[Task], list[Agent]]:\n        return self.tasks, [task.agent for task in self.tasks]\n\n    def build_crew(self) -> Message:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.sequential,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_rpm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_rpm",
                "value": 100,
                "display_name": "Max RPM",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": false,
                "display_name": "Memory",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "share_crew": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "share_crew",
                "value": false,
                "display_name": "Share Crew",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "use_cache": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_cache",
                "value": true,
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": 0,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Represents a group of agents with tasks that are executed sequentially.",
            "icon": "CrewAI",
            "base_classes": [
              "Message"
            ],
            "display_name": "Sequential Crew",
            "documentation": "https://docs.crewai.com/how-to/Sequential/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "verbose",
              "memory",
              "use_cache",
              "max_rpm",
              "share_crew",
              "function_calling_llm",
              "tasks"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "SequentialCrewComponent-2GHRc"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "positionAbsolute": {
          "x": 2792.9023648520015,
          "y": 986.67458600618
        },
        "dragging": false
      },
      {
        "id": "Prompt-BzXwE",
        "type": "genericNode",
        "position": {
          "x": 988.3790973300524,
          "y": -782.1068119064145
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "O agente deve receber um texto extraído de comprovantes de pagamento conforme apresentado em {Extract_text} e processá-lo para identificar as seguintes informações:\n\nCategoria da despesa – Classificar a despesa em uma das categorias predefinidas em {categorias}.\nValor da despesa – Extrair o valor total da transação.\nData da transação – Identificar a data em que o pagamento foi realizado.\nA tarefa principal do agente é analisar o texto, localizar os elementos relevantes e devolver as informações categorizadas e organizadas em um formato estruturado.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "Extract_text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "Extract_text",
                "display_name": "Extract_text",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "categorias": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "categorias",
                "display_name": "categorias",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Extract_text",
                "categorias"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.18"
          },
          "id": "Prompt-BzXwE"
        },
        "selected": false,
        "width": 384,
        "height": 499,
        "positionAbsolute": {
          "x": 988.3790973300524,
          "y": -782.1068119064145
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Prompt-hrHHB",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-hrHHBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CrewAIAgentComponent-03rxB",
        "targetHandle": "{œfieldNameœ:œgoalœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "goal",
            "id": "CrewAIAgentComponent-03rxB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-hrHHB",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-hrHHB{œdataTypeœ:œPromptœ,œidœ:œPrompt-hrHHBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œgoalœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": ""
      },
      {
        "source": "Prompt-KHfAD",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KHfADœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CrewAIAgentComponent-03rxB",
        "targetHandle": "{œfieldNameœ:œbackstoryœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "backstory",
            "id": "CrewAIAgentComponent-03rxB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-KHfAD",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-KHfAD{œdataTypeœ:œPromptœ,œidœ:œPrompt-KHfADœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œbackstoryœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GoogleGenerativeAIModel-95LTV",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-95LTVœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "CrewAIAgentComponent-03rxB",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "CrewAIAgentComponent-03rxB",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-95LTV",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-95LTV{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-95LTVœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CrewAIAgentComponent-03rxB",
        "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-03rxBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
        "target": "SequentialTaskComponent-XnHYO",
        "targetHandle": "{œfieldNameœ:œagentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "agent",
            "id": "SequentialTaskComponent-XnHYO",
            "inputTypes": [
              "Agent"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CrewAIAgentComponent",
            "id": "CrewAIAgentComponent-03rxB",
            "name": "output",
            "output_types": [
              "Agent"
            ]
          }
        },
        "id": "reactflow__edge-CrewAIAgentComponent-03rxB{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-03rxBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œagentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "Prompt-jeRYR",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-jeRYRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SequentialTaskComponent-XnHYO",
        "targetHandle": "{œfieldNameœ:œexpected_outputœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "expected_output",
            "id": "SequentialTaskComponent-XnHYO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-jeRYR",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-jeRYR{œdataTypeœ:œPromptœ,œidœ:œPrompt-jeRYRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œexpected_outputœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false
      },
      {
        "source": "Prompt-vQNbF",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-jeRYR",
        "targetHandle": "{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "categoria",
            "id": "Prompt-jeRYR",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-vQNbF",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-jeRYR{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-vQNbF",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-KHfAD",
        "targetHandle": "{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "categoria",
            "id": "Prompt-KHfAD",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-vQNbF",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-KHfAD{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "SequentialTaskComponent-XnHYO",
        "sourceHandle": "{œdataTypeœ:œSequentialTaskComponentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œSequentialTaskœ]}",
        "target": "SequentialCrewComponent-2GHRc",
        "targetHandle": "{œfieldNameœ:œtasksœ,œidœ:œSequentialCrewComponent-2GHRcœ,œinputTypesœ:[œSequentialTaskœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tasks",
            "id": "SequentialCrewComponent-2GHRc",
            "inputTypes": [
              "SequentialTask"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SequentialTaskComponent",
            "id": "SequentialTaskComponent-XnHYO",
            "name": "task_output",
            "output_types": [
              "SequentialTask"
            ]
          }
        },
        "id": "reactflow__edge-SequentialTaskComponent-XnHYO{œdataTypeœ:œSequentialTaskComponentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œSequentialTaskœ]}-SequentialCrewComponent-2GHRc{œfieldNameœ:œtasksœ,œidœ:œSequentialCrewComponent-2GHRcœ,œinputTypesœ:[œSequentialTaskœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "SequentialCrewComponent-2GHRc",
        "sourceHandle": "{œdataTypeœ:œSequentialCrewComponentœ,œidœ:œSequentialCrewComponent-2GHRcœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-f0myE",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-f0myEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-f0myE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "SequentialCrewComponent",
            "id": "SequentialCrewComponent-2GHRc",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-SequentialCrewComponent-2GHRc{œdataTypeœ:œSequentialCrewComponentœ,œidœ:œSequentialCrewComponent-2GHRcœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-f0myE{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-f0myEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-BzXwE",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-BzXwEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SequentialTaskComponent-XnHYO",
        "targetHandle": "{œfieldNameœ:œtask_descriptionœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "task_description",
            "id": "SequentialTaskComponent-XnHYO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-BzXwE",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-BzXwE{œdataTypeœ:œPromptœ,œidœ:œPrompt-BzXwEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œtask_descriptionœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GoogleSerperAPI-gxVaT",
        "sourceHandle": "{œdataTypeœ:œGoogleSerperAPIœ,œidœ:œGoogleSerperAPI-gxVaTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "CrewAIAgentComponent-03rxB",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "CrewAIAgentComponent-03rxB",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "GoogleSerperAPI",
            "id": "GoogleSerperAPI-gxVaT",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-GoogleSerperAPI-gxVaT{œdataTypeœ:œGoogleSerperAPIœ,œidœ:œGoogleSerperAPI-gxVaTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-uPmjj",
        "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-hrHHB",
        "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Extract_text",
            "id": "Prompt-hrHHB",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OCRProcessor",
            "id": "CustomComponent-uPmjj",
            "name": "extracted_text",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-hrHHB{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-uPmjj",
        "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-KHfAD",
        "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Extract_text",
            "id": "Prompt-KHfAD",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OCRProcessor",
            "id": "CustomComponent-uPmjj",
            "name": "extracted_text",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-KHfAD{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-uPmjj",
        "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-jeRYR",
        "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Extract_text",
            "id": "Prompt-jeRYR",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OCRProcessor",
            "id": "CustomComponent-uPmjj",
            "name": "extracted_text",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-jeRYR{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-uPmjj",
        "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-BzXwE",
        "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Extract_text",
            "id": "Prompt-BzXwE",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OCRProcessor",
            "id": "CustomComponent-uPmjj",
            "name": "extracted_text",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-BzXwE{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-vQNbF",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-BzXwE",
        "targetHandle": "{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "categorias",
            "id": "Prompt-BzXwE",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-vQNbF",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-BzXwE{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-vQNbF",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-hrHHB",
        "targetHandle": "{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "categorias",
            "id": "Prompt-hrHHB",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-vQNbF",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-hrHHB{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 284.2635546494979,
      "y": -515.275590541052,
      "zoom": 0.5938697336234863
    }
  },
  "metadata": {
    "CustomComponent": {
      "count": 1
    },
    "SequentialTaskComponent": {
      "count": 1
    },
    "GoogleGenerativeAIModel": {
      "count": 1
    },
    "CrewAIAgentComponent": {
      "count": 1
    },
    "Prompt": {
      "count": 5
    },
    "ChatOutput": {
      "count": 1
    },
    "GoogleSerperAPI": {
      "count": 1
    },
    "SequentialCrewComponent": {
      "count": 1
    },
    "total": 12
  },
  "original": {
    "id": "d6d46421-aa58-4cf4-94e7-e68d8d159853",
    "name": "Finance AI",
    "description": "Building Powerful Solutions with Language Models.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "6",
    "metadata": {
      "CustomComponent": {
        "count": 1
      },
      "SequentialTaskComponent": {
        "count": 1
      },
      "GoogleGenerativeAIModel": {
        "count": 1
      },
      "CrewAIAgentComponent": {
        "count": 1
      },
      "Prompt": {
        "count": 5
      },
      "ChatOutput": {
        "count": 1
      },
      "GoogleSerperAPI": {
        "count": 1
      },
      "SequentialCrewComponent": {
        "count": 1
      },
      "total": 12
    },
    "last_tested_version": "1.0.18",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "CustomComponent-uPmjj",
          "type": "genericNode",
          "position": {
            "x": -621.5035041921883,
            "y": 461.1360842823604
          },
          "data": {
            "type": "OCRProcessor",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\n\n# Importar bibliotecas necessárias\nfrom PIL import Image\nimport pytesseract\nimport pdf2image  # Para processar PDFs\nimport cv2  # Para manipulação de imagem\nimport numpy as np\nimport os\n\nclass CustomComponent(Component):\n    display_name = \"OCR Processor\"  # Nome personalizado para o componente\n    description = \"Processa imagens ou PDFs e extrai texto usando OCR\"\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"OCRProcessor\"\n\n    # Definindo as entradas do componente\n    inputs = [\n        MessageTextInput(name=\"file_path\", display_name=\"File Path\", value=\"\"),  # Caminho do arquivo como input\n    ]\n\n    # Definindo as saídas do componente\n    outputs = [\n        Output(display_name=\"Extracted Text\", name=\"extracted_text\", method=\"build_output\"),  # Texto extraído como output\n    ]\n\n    # Função de pré-processamento de imagem\n    def preprocess_image(self, image_path):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        gray_image = cv2.medianBlur(gray_image, 3)\n        gray_image = cv2.adaptiveThreshold(gray_image, 255, \n                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n                                           cv2.THRESH_BINARY, 11, 2)\n        return gray_image\n\n    # Função para extrair texto de uma imagem\n    def extract_text_from_image(self, image_path):\n        try:\n            image = Image.open(image_path)\n            extracted_text = pytesseract.image_to_string(image, lang='por')\n            return extracted_text\n        except Exception as e:\n            return f\"Erro ao processar a imagem: {e}\"\n\n    # Função para processar um arquivo PDF e extrair texto\n    def extract_text_from_pdf(self, pdf_path):\n        try:\n            pages = pdf2image.convert_from_path(pdf_path)\n            text = \"\"\n            for page_num, page in enumerate(pages):\n                temp_image_path = f\"temp_page_{page_num}.png\"\n                page.save(temp_image_path, 'PNG')\n                text += self.extract_text_from_image(temp_image_path)\n                os.remove(temp_image_path)\n            return text\n        except Exception as e:\n            return f\"Erro ao processar o PDF: {e}\"\n\n    # Função para processar um comprovante (imagem ou PDF)\n    def process_receipt(self, file_path):\n        # Definir o caminho para o executável do Tesseract manualmente\n        pytesseract.pytesseract.tesseract_cmd = r'D:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n        file_ext = os.path.splitext(file_path)[1].lower()#Extrai o formato do arquivo\n        if file_ext in ['.png', '.jpg', '.jpeg']:\n            return self.extract_text_from_image(file_path)\n        elif file_ext == '.pdf':\n            return self.extract_text_from_pdf(file_path)\n        else:\n            return \"Formato de arquivo não suportado.\"\n\n    # Função para construir a saída do componente\n    def build_output(self) -> str:\n        # Extraia o valor do caminho do arquivo corretamente\n        path = self.file_path.value if hasattr(self.file_path, 'value') else self.file_path  # Pega o caminho do arquivo da entrada\n        # Substitui barras simples por barras duplas para garantir compatibilidade\n        file_path = path.replace(\"\\\\\", \"\\\\\\\\\")\n        if not file_path:\n            return \"Nenhum arquivo fornecido.\"\n\n        # Processar o arquivo e extrair texto\n        extracted_text = self.process_receipt(file_path)\n        return extracted_text",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "file_path": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "file_path",
                  "value": "G:\\Meu Drive\\Data Science\\Projects\\Langflow\\Comprovantes_Despesas\\comprovanteEnergia.jpg",
                  "display_name": "File Path",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Processa imagens ou PDFs e extrai texto usando OCR",
              "icon": "custom_components",
              "base_classes": [
                "Text"
              ],
              "display_name": "Reconhecimento de Texto",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Text"
                  ],
                  "selected": "Text",
                  "name": "extracted_text",
                  "display_name": "Extracted Text",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "file_path"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.18"
            },
            "id": "CustomComponent-uPmjj"
          },
          "selected": false,
          "width": 384,
          "height": 328,
          "positionAbsolute": {
            "x": -621.5035041921883,
            "y": 461.1360842823604
          },
          "dragging": false
        },
        {
          "id": "SequentialTaskComponent-XnHYO",
          "type": "genericNode",
          "position": {
            "x": 2187.464383869555,
            "y": 766.2989754313695
          },
          "data": {
            "type": "SequentialTaskComponent",
            "node": {
              "template": {
                "_type": "Component",
                "agent": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "agent",
                  "value": "",
                  "display_name": "Agent",
                  "advanced": false,
                  "input_types": [
                    "Agent"
                  ],
                  "dynamic": false,
                  "info": "CrewAI Agent that will perform the task",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "task": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "task",
                  "value": "",
                  "display_name": "Task",
                  "advanced": false,
                  "input_types": [
                    "SequentialTask"
                  ],
                  "dynamic": false,
                  "info": "CrewAI Task that will perform the task",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": true,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "List of tools/resources limited for task execution. Uses the Agent tools by default.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "async_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "async_execution",
                  "value": true,
                  "display_name": "Async Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Boolean flag indicating asynchronous task execution.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.agents.crewai.tasks import SequentialTask\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, HandleInput, MultilineInput, Output\n\n\nclass SequentialTaskComponent(Component):\n    display_name: str = \"Sequential Task\"\n    description: str = \"Each task must have a description, an expected output and an agent responsible for execution.\"\n    icon = \"CrewAI\"\n    inputs = [\n        MultilineInput(\n            name=\"task_description\",\n            display_name=\"Description\",\n            info=\"Descriptive text detailing task's purpose and execution.\",\n        ),\n        MultilineInput(\n            name=\"expected_output\",\n            display_name=\"Expected Output\",\n            info=\"Clear definition of expected task outcome.\",\n        ),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"List of tools/resources limited for task execution. Uses the Agent tools by default.\",\n            required=False,\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"agent\",\n            display_name=\"Agent\",\n            input_types=[\"Agent\"],\n            info=\"CrewAI Agent that will perform the task\",\n            required=True,\n        ),\n        HandleInput(\n            name=\"task\",\n            display_name=\"Task\",\n            input_types=[\"SequentialTask\"],\n            info=\"CrewAI Task that will perform the task\",\n        ),\n        BoolInput(\n            name=\"async_execution\",\n            display_name=\"Async Execution\",\n            value=True,\n            advanced=True,\n            info=\"Boolean flag indicating asynchronous task execution.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Task\", name=\"task_output\", method=\"build_task\"),\n    ]\n\n    def build_task(self) -> list[SequentialTask]:\n        tasks: list[SequentialTask] = []\n        task = SequentialTask(\n            description=self.task_description,\n            expected_output=self.expected_output,\n            tools=self.agent.tools,\n            async_execution=False,\n            agent=self.agent,\n        )\n        tasks.append(task)\n        self.status = task\n        if self.task:\n            if isinstance(self.task, list) and all(isinstance(task, SequentialTask) for task in self.task):\n                tasks = self.task + tasks\n            elif isinstance(self.task, SequentialTask):\n                tasks = [self.task] + tasks\n        return tasks\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "expected_output": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "expected_output",
                  "value": "",
                  "display_name": "Expected Output",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Clear definition of expected task outcome.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "task_description": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "task_description",
                  "value": "",
                  "display_name": "Description",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Descriptive text detailing task's purpose and execution.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Each task must have a description, an expected output and an agent responsible for execution.",
              "icon": "CrewAI",
              "base_classes": [
                "SequentialTask"
              ],
              "display_name": "Sequential Task",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "SequentialTask"
                  ],
                  "selected": "SequentialTask",
                  "name": "task_output",
                  "display_name": "Task",
                  "method": "build_task",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "task_description",
                "expected_output",
                "tools",
                "agent",
                "task",
                "async_execution"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "SequentialTaskComponent-XnHYO"
          },
          "selected": false,
          "width": 384,
          "height": 506,
          "positionAbsolute": {
            "x": 2187.464383869555,
            "y": 766.2989754313695
          },
          "dragging": false
        },
        {
          "id": "GoogleGenerativeAIModel-95LTV",
          "type": "genericNode",
          "position": {
            "x": 927.6351208907231,
            "y": 1586.33753883171
          },
          "data": {
            "type": "GoogleGenerativeAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_output_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=[\"gemini-1.5-pro\", \"gemini-1.5-flash\", \"gemini-1.0-pro\", \"gemini-1.0-pro-vision\"],\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError:\n            raise ImportError(\"The 'langchain_google_genai' package is required to use the Google Generative AI model.\")\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        output = ChatGoogleGenerativeAI(  # type: ignore\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key),\n        )\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "google_api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "google_api_key",
                  "value": "",
                  "display_name": "Google API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The Google API Key to use for the Google Generative AI.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_output_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_output_tokens",
                  "value": 500,
                  "display_name": "Max Output Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "gemini-1.5-pro",
                    "gemini-1.5-flash",
                    "gemini-1.0-pro",
                    "gemini-1.0-pro-vision"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "gemini-1.5-flash",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The name of the model to use.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "n": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n",
                  "value": "",
                  "display_name": "N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "top_k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_k",
                  "value": "",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "top_p": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "top_p",
                  "value": "",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum cumulative probability of tokens to consider when sampling.",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Google Generative AI.",
              "icon": "GoogleGenerativeAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Google Generative AI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_output_tokens",
                "model",
                "google_api_key",
                "top_p",
                "temperature",
                "n",
                "top_k"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "GoogleGenerativeAIModel-95LTV"
          },
          "selected": false,
          "width": 384,
          "height": 686,
          "positionAbsolute": {
            "x": 927.6351208907231,
            "y": 1586.33753883171
          },
          "dragging": false
        },
        {
          "id": "CrewAIAgentComponent-03rxB",
          "type": "genericNode",
          "position": {
            "x": 1432.8042627575169,
            "y": 668.8460581121353
          },
          "data": {
            "type": "CrewAIAgentComponent",
            "node": {
              "template": {
                "_type": "Component",
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Language model that will run the agent.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": [],
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool"
                  ],
                  "dynamic": false,
                  "info": "Tools at agents disposal",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "allow_code_execution": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_code_execution",
                  "value": false,
                  "display_name": "Allow Code Execution",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to execute code.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "allow_delegation": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "allow_delegation",
                  "value": false,
                  "display_name": "Allow Delegation",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether the agent is allowed to delegate tasks to other agents.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "backstory": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "backstory",
                  "value": "",
                  "display_name": "Backstory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The backstory of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent  # type: ignore\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DictInput, HandleInput, MultilineInput, Output\n\n\nclass CrewAIAgentComponent(Component):\n    display_name = \"CrewAI Agent\"\n    description = \"Represents an agent of CrewAI.\"\n    documentation: str = \"https://docs.crewai.com/how-to/LLM-Connections/\"\n    icon = \"CrewAI\"\n\n    inputs = [\n        MultilineInput(name=\"role\", display_name=\"Role\", info=\"The role of the agent.\"),\n        MultilineInput(name=\"goal\", display_name=\"Goal\", info=\"The objective of the agent.\"),\n        MultilineInput(name=\"backstory\", display_name=\"Backstory\", info=\"The backstory of the agent.\"),\n        HandleInput(\n            name=\"tools\",\n            display_name=\"Tools\",\n            input_types=[\"Tool\"],\n            is_list=True,\n            info=\"Tools at agents disposal\",\n            value=[],\n        ),\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"Language model that will run the agent.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        BoolInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            info=\"Whether the agent should have memory or not\",\n            advanced=True,\n            value=True,\n        ),\n        BoolInput(\n            name=\"verbose\",\n            display_name=\"Verbose\",\n            advanced=True,\n            value=False,\n        ),\n        BoolInput(\n            name=\"allow_delegation\",\n            display_name=\"Allow Delegation\",\n            info=\"Whether the agent is allowed to delegate tasks to other agents.\",\n            value=True,\n        ),\n        BoolInput(\n            name=\"allow_code_execution\",\n            display_name=\"Allow Code Execution\",\n            info=\"Whether the agent is allowed to execute code.\",\n            value=False,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"kwargs\",\n            display_name=\"kwargs\",\n            info=\"kwargs of agent.\",\n            is_list=True,\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Agent\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Agent:\n        kwargs = self.kwargs if self.kwargs else {}\n        agent = Agent(\n            role=self.role,\n            goal=self.goal,\n            backstory=self.backstory,\n            llm=self.llm,\n            verbose=self.verbose,\n            memory=self.memory,\n            tools=self.tools if self.tools else [],\n            allow_delegation=self.allow_delegation,\n            allow_code_execution=self.allow_code_execution,\n            **kwargs,\n        )\n        self.status = repr(agent)\n        return agent\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "goal": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "goal",
                  "value": "",
                  "display_name": "Goal",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The objective of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "kwargs": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "kwargs",
                  "value": {},
                  "display_name": "kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "kwargs of agent.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": true,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Whether the agent should have memory or not",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "role": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "role",
                  "value": "Classificador de Despesas",
                  "display_name": "Role",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The role of the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": false,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Represents an agent of CrewAI.",
              "icon": "CrewAI",
              "base_classes": [
                "Agent"
              ],
              "display_name": "CrewAI Agent",
              "documentation": "https://docs.crewai.com/how-to/LLM-Connections/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Agent"
                  ],
                  "selected": "Agent",
                  "name": "output",
                  "display_name": "Agent",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "role",
                "goal",
                "backstory",
                "tools",
                "llm",
                "memory",
                "verbose",
                "allow_delegation",
                "allow_code_execution",
                "kwargs"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "CrewAIAgentComponent-03rxB"
          },
          "selected": false,
          "width": 384,
          "height": 635,
          "positionAbsolute": {
            "x": 1432.8042627575169,
            "y": 668.8460581121353
          },
          "dragging": false
        },
        {
          "id": "Prompt-hrHHB",
          "type": "genericNode",
          "position": {
            "x": 907.1855571227247,
            "y": -171.5242025754452
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "O objetivo deste agente é receber um texto:\n  {Extract_text}.\nO texto contém informações detalhadas sobre uma transação financeira, como nome do pagador, valor, data e descrição do pagamento. O agente deve processar esse texto, identificando padrões, termos específicos ou informações relevantes que permitam categorizar automaticamente a despesa em uma das seguintes categorias predefinidas em {categorias}.\nSe possível você pode usar o código de barras para tirar mais informações sobre conta em questão. Leia o código de barras e pesquise o boleto para identificar as informações contidas nele.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "Extract_text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "Extract_text",
                  "display_name": "Extract_text",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "categorias": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "categorias",
                  "display_name": "categorias",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "Extract_text",
                  "categorias"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-hrHHB"
          },
          "selected": false,
          "width": 384,
          "height": 499,
          "positionAbsolute": {
            "x": 907.1855571227247,
            "y": -171.5242025754452
          },
          "dragging": false
        },
        {
          "id": "Prompt-KHfAD",
          "type": "genericNode",
          "position": {
            "x": 845.5682700592165,
            "y": 463.9049736736458
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Este agente foi treinado e otimizado para lidar com a categorização automática de despesas financeiras, processando textos extraídos de comprovantes de pagamento, como é o caso do texto {Extract_text}. Ele é capaz de analisar padrões comuns em transações financeiras e reconhecer os principais campos presentes nesses documentos, como nome do cliente, valor, data e descrição do pagamento.\n\nCom uma vasta base de dados e conhecimento sobre categorias típicas de despesas (como Alimentação, Transporte, Saúde, etc.) que estão apresentadas em {categoria}\nO agente utiliza algoritmos de processamento de linguagem natural (NLP) para identificar informações-chave no texto, como o tipo de serviço ou produto relacionado à transação, estabelecimentos, códigos de pagamento, ou descrições associadas. A partir dessa análise, o agente pode classificar a transação corretamente dentro de categorias predefinidas.\n\nAlém disso, o agente tem a capacidade de aprender com novos padrões que possam surgir em comprovantes, adaptando-se a variações na forma como as transações são descritas. Ele também poderá fazer uma busca na internet, para verificar se encontra referência daquela despesa para poder auxiliar no processo de classificação.\n\nSua função principal é auxiliar no gerenciamento financeiro ao automatizar o processo de categorização de despesas, otimizando a organização e a visualização das finanças familiares ou empresariais.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "Extract_text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "Extract_text",
                  "display_name": "Extract_text",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "categoria": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "categoria",
                  "display_name": "categoria",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "Extract_text",
                  "categoria"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-KHfAD"
          },
          "selected": false,
          "width": 384,
          "height": 499,
          "positionAbsolute": {
            "x": 845.5682700592165,
            "y": 463.9049736736458
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-f0myE",
          "type": "genericNode",
          "position": {
            "x": 3490.4971267757796,
            "y": 873.7029546970407
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "ChatOutput-f0myE"
          },
          "selected": false,
          "width": 384,
          "height": 300,
          "positionAbsolute": {
            "x": 3490.4971267757796,
            "y": 873.7029546970407
          },
          "dragging": false
        },
        {
          "id": "Prompt-jeRYR",
          "type": "genericNode",
          "position": {
            "x": 497.5580825964339,
            "y": 944.8657215350918
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "O agente deve processar o texto em português fornecido em {Extract_text} e retornar uma saída estruturada em português, contendo as seguintes informações:\n\nCategoria da despesa:\nO agente deve identificar e classificar a transação em uma das categorias predefinidas, como {categoria}\n\nValor da despesa:\nO agente deve extrair o valor total da despesa no formato monetário (ex: R$ 76,05).\n\nData da transação:\nA data da transação deve ser identificada e retornada no formato correto (ex: 23/09/2024). Deve haver apenas uma data, a qual se refere quando foi feito o pagamento, a data de vencimento deve ser ignorada.\n",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "Extract_text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "Extract_text",
                  "display_name": "Extract_text",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "categoria": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "categoria",
                  "display_name": "categoria",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "Extract_text",
                  "categoria"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-jeRYR"
          },
          "selected": false,
          "width": 384,
          "height": 499,
          "positionAbsolute": {
            "x": 497.5580825964339,
            "y": 944.8657215350918
          },
          "dragging": false
        },
        {
          "id": "GoogleSerperAPI-gxVaT",
          "type": "genericNode",
          "position": {
            "x": -149.7633358817037,
            "y": 1304.8530248728373
          },
          "data": {
            "type": "GoogleSerperAPI",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Union\n\nfrom langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.inputs import SecretStrInput, MultilineInput, IntInput\nfrom axiestudio.schema import Data\nfrom axiestudio.field_typing import Tool\n\n\nclass GoogleSerperAPIComponent(LCToolComponent):\n    display_name = \"Google Serper API\"\n    description = \"Call the Serper.dev Google Search API.\"\n    name = \"GoogleSerperAPI\"\n\n    inputs = [\n        SecretStrInput(name=\"serper_api_key\", display_name=\"Serper API Key\", required=True),\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n    ]\n\n    def run_model(self) -> Union[Data, list[Data]]:\n        wrapper = self._build_wrapper()\n        results = wrapper.results(query=self.input_value)\n        list_results = results.get(\"organic\", [])\n        data = [Data(data=result, text=result[\"snippet\"]) for result in list_results]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return Tool(\n            name=\"google_search\",\n            description=\"Search Google for recent results.\",\n            func=wrapper.run,\n        )\n\n    def _build_wrapper(self):\n        return GoogleSerperAPIWrapper(serper_api_key=self.serper_api_key, k=self.k)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "k",
                  "value": 10,
                  "display_name": "Number of results",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "serper_api_key": {
                  "load_from_db": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "serper_api_key",
                  "value": "",
                  "display_name": "Serper API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                }
              },
              "description": "Call the Serper.dev Google Search API.",
              "base_classes": [
                "Data",
                "Tool"
              ],
              "display_name": "Google Serper API",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "serper_api_key",
                "input_value",
                "k"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "GoogleSerperAPI-gxVaT"
          },
          "selected": true,
          "width": 384,
          "height": 515,
          "positionAbsolute": {
            "x": -149.7633358817037,
            "y": 1304.8530248728373
          },
          "dragging": false
        },
        {
          "id": "Prompt-vQNbF",
          "type": "genericNode",
          "position": {
            "x": -333.2494667534377,
            "y": -169.65831900710822
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Categorias das despesas estão definidas em:\n\nAlimentação\nTransporte\nSaúde\nEducação\nLazer\nMoradia\nÁgua\nLuz\nInternet\nImposto DAS - Simples Nacional\nFatura Banco do Brasil\nFatura Renner\nFatura LuizaCred\nFatura Neon\nPlano Telefone\nIPTU\nIPVA\nDespesas Eventuais\nOutros",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": []
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-vQNbF"
          },
          "selected": false,
          "width": 384,
          "height": 328,
          "positionAbsolute": {
            "x": -333.2494667534377,
            "y": -169.65831900710822
          },
          "dragging": false
        },
        {
          "id": "SequentialCrewComponent-2GHRc",
          "type": "genericNode",
          "position": {
            "x": 2792.9023648520015,
            "y": 986.67458600618
          },
          "data": {
            "type": "SequentialCrewComponent",
            "node": {
              "template": {
                "_type": "Component",
                "function_calling_llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "function_calling_llm",
                  "value": "",
                  "display_name": "Function Calling LLM",
                  "advanced": true,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "Turns the ReAct CrewAI agent into a function-calling agent",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tasks": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tasks",
                  "value": "",
                  "display_name": "Tasks",
                  "advanced": false,
                  "input_types": [
                    "SequentialTask"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from crewai import Agent, Crew, Process, Task  # type: ignore\n\nfrom axiestudio.base.agents.crewai.crew import BaseCrewComponent\nfrom axiestudio.io import HandleInput\nfrom axiestudio.schema.message import Message\n\n\nclass SequentialCrewComponent(BaseCrewComponent):\n    display_name: str = \"Sequential Crew\"\n    description: str = \"Represents a group of agents with tasks that are executed sequentially.\"\n    documentation: str = \"https://docs.crewai.com/how-to/Sequential/\"\n    icon = \"CrewAI\"\n\n    inputs = BaseCrewComponent._base_inputs + [\n        HandleInput(name=\"tasks\", display_name=\"Tasks\", input_types=[\"SequentialTask\"], is_list=True),\n    ]\n\n    def get_tasks_and_agents(self) -> tuple[list[Task], list[Agent]]:\n        return self.tasks, [task.agent for task in self.tasks]\n\n    def build_crew(self) -> Message:\n        tasks, agents = self.get_tasks_and_agents()\n        crew = Crew(\n            agents=agents,\n            tasks=tasks,\n            process=Process.sequential,\n            verbose=self.verbose,\n            memory=self.memory,\n            cache=self.use_cache,\n            max_rpm=self.max_rpm,\n            share_crew=self.share_crew,\n            function_calling_llm=self.function_calling_llm,\n            step_callback=self.get_step_callback(),\n            task_callback=self.get_task_callback(),\n        )\n        return crew\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "max_rpm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_rpm",
                  "value": 100,
                  "display_name": "Max RPM",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": false,
                  "display_name": "Memory",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "share_crew": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "share_crew",
                  "value": false,
                  "display_name": "Share Crew",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "use_cache": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "use_cache",
                  "value": true,
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": 0,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                }
              },
              "description": "Represents a group of agents with tasks that are executed sequentially.",
              "icon": "CrewAI",
              "base_classes": [
                "Message"
              ],
              "display_name": "Sequential Crew",
              "documentation": "https://docs.crewai.com/how-to/Sequential/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "verbose",
                "memory",
                "use_cache",
                "max_rpm",
                "share_crew",
                "function_calling_llm",
                "tasks"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "SequentialCrewComponent-2GHRc"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "positionAbsolute": {
            "x": 2792.9023648520015,
            "y": 986.67458600618
          },
          "dragging": false
        },
        {
          "id": "Prompt-BzXwE",
          "type": "genericNode",
          "position": {
            "x": 988.3790973300524,
            "y": -782.1068119064145
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "O agente deve receber um texto extraído de comprovantes de pagamento conforme apresentado em {Extract_text} e processá-lo para identificar as seguintes informações:\n\nCategoria da despesa – Classificar a despesa em uma das categorias predefinidas em {categorias}.\nValor da despesa – Extrair o valor total da transação.\nData da transação – Identificar a data em que o pagamento foi realizado.\nA tarefa principal do agente é analisar o texto, localizar os elementos relevantes e devolver as informações categorizadas e organizadas em um formato estruturado.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "Extract_text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "Extract_text",
                  "display_name": "Extract_text",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "categorias": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "name": "categorias",
                  "display_name": "categorias",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "Extract_text",
                  "categorias"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.18"
            },
            "id": "Prompt-BzXwE"
          },
          "selected": false,
          "width": 384,
          "height": 499,
          "positionAbsolute": {
            "x": 988.3790973300524,
            "y": -782.1068119064145
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Prompt-hrHHB",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-hrHHBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CrewAIAgentComponent-03rxB",
          "targetHandle": "{œfieldNameœ:œgoalœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "goal",
              "id": "CrewAIAgentComponent-03rxB",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-hrHHB",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-hrHHB{œdataTypeœ:œPromptœ,œidœ:œPrompt-hrHHBœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œgoalœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "selected": false,
          "className": ""
        },
        {
          "source": "Prompt-KHfAD",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-KHfADœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CrewAIAgentComponent-03rxB",
          "targetHandle": "{œfieldNameœ:œbackstoryœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "backstory",
              "id": "CrewAIAgentComponent-03rxB",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-KHfAD",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-KHfAD{œdataTypeœ:œPromptœ,œidœ:œPrompt-KHfADœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œbackstoryœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GoogleGenerativeAIModel-95LTV",
          "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-95LTVœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "CrewAIAgentComponent-03rxB",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "CrewAIAgentComponent-03rxB",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "GoogleGenerativeAIModel",
              "id": "GoogleGenerativeAIModel-95LTV",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-GoogleGenerativeAIModel-95LTV{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-95LTVœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œllmœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CrewAIAgentComponent-03rxB",
          "sourceHandle": "{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-03rxBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}",
          "target": "SequentialTaskComponent-XnHYO",
          "targetHandle": "{œfieldNameœ:œagentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "agent",
              "id": "SequentialTaskComponent-XnHYO",
              "inputTypes": [
                "Agent"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CrewAIAgentComponent",
              "id": "CrewAIAgentComponent-03rxB",
              "name": "output",
              "output_types": [
                "Agent"
              ]
            }
          },
          "id": "reactflow__edge-CrewAIAgentComponent-03rxB{œdataTypeœ:œCrewAIAgentComponentœ,œidœ:œCrewAIAgentComponent-03rxBœ,œnameœ:œoutputœ,œoutput_typesœ:[œAgentœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œagentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œAgentœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "Prompt-jeRYR",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-jeRYRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "SequentialTaskComponent-XnHYO",
          "targetHandle": "{œfieldNameœ:œexpected_outputœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "expected_output",
              "id": "SequentialTaskComponent-XnHYO",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-jeRYR",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-jeRYR{œdataTypeœ:œPromptœ,œidœ:œPrompt-jeRYRœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œexpected_outputœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": "",
          "selected": false
        },
        {
          "source": "Prompt-vQNbF",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-jeRYR",
          "targetHandle": "{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "categoria",
              "id": "Prompt-jeRYR",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-vQNbF",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-jeRYR{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-vQNbF",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-KHfAD",
          "targetHandle": "{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "categoria",
              "id": "Prompt-KHfAD",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-vQNbF",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-KHfAD{œfieldNameœ:œcategoriaœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "SequentialTaskComponent-XnHYO",
          "sourceHandle": "{œdataTypeœ:œSequentialTaskComponentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œSequentialTaskœ]}",
          "target": "SequentialCrewComponent-2GHRc",
          "targetHandle": "{œfieldNameœ:œtasksœ,œidœ:œSequentialCrewComponent-2GHRcœ,œinputTypesœ:[œSequentialTaskœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tasks",
              "id": "SequentialCrewComponent-2GHRc",
              "inputTypes": [
                "SequentialTask"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SequentialTaskComponent",
              "id": "SequentialTaskComponent-XnHYO",
              "name": "task_output",
              "output_types": [
                "SequentialTask"
              ]
            }
          },
          "id": "reactflow__edge-SequentialTaskComponent-XnHYO{œdataTypeœ:œSequentialTaskComponentœ,œidœ:œSequentialTaskComponent-XnHYOœ,œnameœ:œtask_outputœ,œoutput_typesœ:[œSequentialTaskœ]}-SequentialCrewComponent-2GHRc{œfieldNameœ:œtasksœ,œidœ:œSequentialCrewComponent-2GHRcœ,œinputTypesœ:[œSequentialTaskœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "SequentialCrewComponent-2GHRc",
          "sourceHandle": "{œdataTypeœ:œSequentialCrewComponentœ,œidœ:œSequentialCrewComponent-2GHRcœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-f0myE",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-f0myEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-f0myE",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "SequentialCrewComponent",
              "id": "SequentialCrewComponent-2GHRc",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-SequentialCrewComponent-2GHRc{œdataTypeœ:œSequentialCrewComponentœ,œidœ:œSequentialCrewComponent-2GHRcœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-f0myE{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-f0myEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-BzXwE",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-BzXwEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "SequentialTaskComponent-XnHYO",
          "targetHandle": "{œfieldNameœ:œtask_descriptionœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "task_description",
              "id": "SequentialTaskComponent-XnHYO",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-BzXwE",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-BzXwE{œdataTypeœ:œPromptœ,œidœ:œPrompt-BzXwEœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-SequentialTaskComponent-XnHYO{œfieldNameœ:œtask_descriptionœ,œidœ:œSequentialTaskComponent-XnHYOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GoogleSerperAPI-gxVaT",
          "sourceHandle": "{œdataTypeœ:œGoogleSerperAPIœ,œidœ:œGoogleSerperAPI-gxVaTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "CrewAIAgentComponent-03rxB",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "CrewAIAgentComponent-03rxB",
              "inputTypes": [
                "Tool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "GoogleSerperAPI",
              "id": "GoogleSerperAPI-gxVaT",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-GoogleSerperAPI-gxVaT{œdataTypeœ:œGoogleSerperAPIœ,œidœ:œGoogleSerperAPI-gxVaTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-CrewAIAgentComponent-03rxB{œfieldNameœ:œtoolsœ,œidœ:œCrewAIAgentComponent-03rxBœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-uPmjj",
          "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-hrHHB",
          "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Extract_text",
              "id": "Prompt-hrHHB",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OCRProcessor",
              "id": "CustomComponent-uPmjj",
              "name": "extracted_text",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-hrHHB{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-uPmjj",
          "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-KHfAD",
          "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Extract_text",
              "id": "Prompt-KHfAD",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OCRProcessor",
              "id": "CustomComponent-uPmjj",
              "name": "extracted_text",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-KHfAD{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-KHfADœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-uPmjj",
          "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-jeRYR",
          "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Extract_text",
              "id": "Prompt-jeRYR",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OCRProcessor",
              "id": "CustomComponent-uPmjj",
              "name": "extracted_text",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-jeRYR{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-jeRYRœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-uPmjj",
          "sourceHandle": "{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-BzXwE",
          "targetHandle": "{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Extract_text",
              "id": "Prompt-BzXwE",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OCRProcessor",
              "id": "CustomComponent-uPmjj",
              "name": "extracted_text",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-uPmjj{œdataTypeœ:œOCRProcessorœ,œidœ:œCustomComponent-uPmjjœ,œnameœ:œextracted_textœ,œoutput_typesœ:[œTextœ]}-Prompt-BzXwE{œfieldNameœ:œExtract_textœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-vQNbF",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-BzXwE",
          "targetHandle": "{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "categorias",
              "id": "Prompt-BzXwE",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-vQNbF",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-BzXwE{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-BzXwEœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-vQNbF",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-hrHHB",
          "targetHandle": "{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "categorias",
              "id": "Prompt-hrHHB",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-vQNbF",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-vQNbF{œdataTypeœ:œPromptœ,œidœ:œPrompt-vQNbFœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Prompt-hrHHB{œfieldNameœ:œcategoriasœ,œidœ:œPrompt-hrHHBœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 284.2635546494979,
        "y": -515.275590541052,
        "zoom": 0.5938697336234863
      }
    },
    "date_created": "2024-10-18T03:54:57.296Z",
    "date_updated": "2024-10-18T19:12:03.918Z",
    "status": "Public",
    "sort": null,
    "user_updated": "194e9ebd-684c-49cc-a4aa-d0dceccd24e8",
    "user_created": {
      "username": "matheus-borges",
      "first_name": "Matheus",
      "last_name": "Borges",
      "id": "194e9ebd-684c-49cc-a4aa-d0dceccd24e8"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.248Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 116,
    "converter_version": "1.0.0"
  }
}