{
  "id": "163b7f7d-3cbf-4f71-94a0-55b656ea003b",
  "name": "政策查询 -模板",
  "description": "Visit https://docs.langflow.org/tutorials/rag-with-astradb for a detailed guide of this project.\nThis project give you both Ingestion and RAG in a single file. You'll need to visit https://astra.datastax.com/ to create an Astra DB instance, your Token and (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "huangxinghui",
    "first_name": "xinghui",
    "last_name": "huang",
    "id": "64bd3aa6-538a-4107-8754-c4a63e128385",
    "full_name": "xinghui huang"
  },
  "store_url": "https://www.langflow.store/store/component/163b7f7d-3cbf-4f71-94a0-55b656ea003b",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-29T06:12:08.763Z",
    "updated": "2024-09-29T06:12:08.894Z",
    "downloaded": "2025-08-19T17:50:06.992Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.9",
    "private": false,
    "status": "Public"
  },
  "data": {
    "edges": [
      {
        "id": "reactflow__edge-UniOpenAICompatibleModel-ksEUL{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-V4kOh{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniOpenAICompatibleModel-ksEUL",
            "name": "text_output",
            "dataType": "UniOpenAICompatibleModel",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "ConditionalRouter-V4kOh",
            "type": "str",
            "fieldName": "input_text",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniOpenAICompatibleModel-ksEUL",
        "target": "ConditionalRouter-V4kOh",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-ConditionalRouter-V4kOh{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-UniOpenAICompatibleModel-KUPOm{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "ConditionalRouter-V4kOh",
            "name": "false_result",
            "dataType": "ConditionalRouter",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniOpenAICompatibleModel-KUPOm",
            "type": "str",
            "fieldName": "input_value",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "ConditionalRouter-V4kOh",
        "target": "UniOpenAICompatibleModel-KUPOm",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniOpenAICompatibleModel-KUPOm{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ZfNkT{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZfNkTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniOpenAICompatibleModel-KUPOm",
            "name": "text_output",
            "dataType": "UniOpenAICompatibleModel",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "ChatOutput-ZfNkT",
            "type": "str",
            "fieldName": "input_value",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniOpenAICompatibleModel-KUPOm",
        "target": "ChatOutput-ZfNkT",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZfNkTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-ChatInput-tFUGg{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-UniPrompt-1KHaO{œfieldNameœ:œquestionœ,œidœ:œUniPrompt-1KHaOœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "ChatInput-tFUGg",
            "name": "message",
            "dataType": "ChatInput",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniPrompt-1KHaO",
            "type": "str",
            "fieldName": "question",
            "inputTypes": [
              "Message",
              "Text"
            ]
          }
        },
        "source": "ChatInput-tFUGg",
        "target": "UniPrompt-1KHaO",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œUniPrompt-1KHaOœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-ChatInput-tFUGg{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-V4kOh{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "ChatInput-tFUGg",
            "name": "message",
            "dataType": "ChatInput",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "ConditionalRouter-V4kOh",
            "type": "str",
            "fieldName": "message",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "ChatInput-tFUGg",
        "target": "ConditionalRouter-V4kOh",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniPrompt-1KHaO{œdataTypeœ:œUniPromptœ,œidœ:œUniPrompt-1KHaOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-UniParseData-55eqf{œfieldNameœ:œtemplateœ,œidœ:œUniParseData-55eqfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniPrompt-1KHaO",
            "name": "prompt",
            "dataType": "UniPrompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniParseData-55eqf",
            "type": "str",
            "fieldName": "template",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniPrompt-1KHaO",
        "target": "UniParseData-55eqf",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniPromptœ,œidœ:œUniPrompt-1KHaOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œUniParseData-55eqfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniParseData-55eqf{œdataTypeœ:œUniParseDataœ,œidœ:œUniParseData-55eqfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-UniOpenAICompatibleModel-ksEUL{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniParseData-55eqf",
            "name": "text",
            "dataType": "UniParseData",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniOpenAICompatibleModel-ksEUL",
            "type": "str",
            "fieldName": "input_value",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniParseData-55eqf",
        "target": "UniOpenAICompatibleModel-ksEUL",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniParseDataœ,œidœ:œUniParseData-55eqfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniWeaviateQuery-HGzB4{œdataTypeœ:œUniWeaviateQueryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-UniParseJson-CfufR{œfieldNameœ:œdataœ,œidœ:œUniParseJson-CfufRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "id": "UniWeaviateQuery-HGzB4",
            "name": "search_results",
            "dataType": "UniWeaviateQuery",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "id": "UniParseJson-CfufR",
            "type": "other",
            "fieldName": "data",
            "inputTypes": [
              "Data"
            ]
          }
        },
        "source": "UniWeaviateQuery-HGzB4",
        "target": "UniParseJson-CfufR",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniWeaviateQueryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œUniParseJson-CfufRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "id": "reactflow__edge-ConditionalRouter-V4kOh{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-UniWeaviateQuery-HGzB4{œfieldNameœ:œsearch_queryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "ConditionalRouter-V4kOh",
            "name": "true_result",
            "dataType": "ConditionalRouter",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniWeaviateQuery-HGzB4",
            "type": "str",
            "fieldName": "search_query",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "ConditionalRouter-V4kOh",
        "target": "UniWeaviateQuery-HGzB4",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniXinferenceEmbeddings-xPy7F{œdataTypeœ:œUniXinferenceEmbeddingsœ,œidœ:œUniXinferenceEmbeddings-xPy7Fœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-UniWeaviateQuery-HGzB4{œfieldNameœ:œembeddingœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "id": "UniXinferenceEmbeddings-xPy7F",
            "name": "embeddings",
            "dataType": "UniXinferenceEmbeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "id": "UniWeaviateQuery-HGzB4",
            "type": "other",
            "fieldName": "embedding",
            "inputTypes": [
              "Embeddings"
            ]
          }
        },
        "source": "UniXinferenceEmbeddings-xPy7F",
        "target": "UniWeaviateQuery-HGzB4",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniXinferenceEmbeddingsœ,œidœ:œUniXinferenceEmbeddings-xPy7Fœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "id": "reactflow__edge-UniParseJson-CfufR{œdataTypeœ:œUniParseJsonœ,œidœ:œUniParseJson-CfufRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-UniStream-Dh1Qu{œfieldNameœ:œsystem_messageœ,œidœ:œUniStream-Dh1Quœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniParseJson-CfufR",
            "name": "text",
            "dataType": "UniParseJson",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "UniStream-Dh1Qu",
            "type": "str",
            "fieldName": "system_message",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniParseJson-CfufR",
        "target": "UniStream-Dh1Qu",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniParseJsonœ,œidœ:œUniParseJson-CfufRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œUniStream-Dh1Quœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "id": "reactflow__edge-UniStream-Dh1Qu{œdataTypeœ:œUniStreamœ,œidœ:œUniStream-Dh1Quœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-hya9U{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hya9Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "id": "UniStream-Dh1Qu",
            "name": "text_output",
            "dataType": "UniStream",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "id": "ChatOutput-hya9U",
            "type": "str",
            "fieldName": "input_value",
            "inputTypes": [
              "Message"
            ]
          }
        },
        "source": "UniStream-Dh1Qu",
        "target": "ChatOutput-hya9U",
        "className": "",
        "sourceHandle": "{œdataTypeœ:œUniStreamœ,œidœ:œUniStream-Dh1Quœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hya9Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "id": "UniXinferenceEmbeddings-xPy7F",
        "data": {
          "id": "UniXinferenceEmbeddings-xPy7F",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniXinferenceEmbeddingsComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "embeddings",
                "cache": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__",
                "method": "build_embeddings",
                "selected": "Embeddings",
                "display_name": "Embeddings"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\nfrom langchain_community.embeddings import XinferenceEmbeddings\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import FloatInput, MessageTextInput, Output\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniXinferenceEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Xinference Embeddings\"\n    description: str = \"Xinference Embeddings\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"UniXinferenceEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Xinference Model\",\n            value=\"bge-large-zh-v1.5\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Xinference Base URL\",\n            value=\"http://10.0.50.33:9997\",\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniXinferenceEmbeddingsComponent.png')\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = XinferenceEmbeddings(server_url=self.base_url,model_uid=self.model)\n        except Exception as e:\n            raise ValueError(\"无法连接到Xinference API。\") from e\n        return output\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "model": {
                "info": "",
                "list": false,
                "name": "model",
                "show": true,
                "type": "str",
                "value": "bge-large-zh-v1.5",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Xinference Model",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "base_url": {
                "info": "",
                "list": false,
                "name": "base_url",
                "show": true,
                "type": "str",
                "value": "$embedding_url$",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Xinference Base URL",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              }
            },
            "description": "Xinference Embeddings",
            "field_order": [
              "model",
              "base_url"
            ],
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Xinference Embeddings",
            "output_types": [],
            "custom_fields": {},
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
            "conditional_paths": []
          },
          "type": "UniXinferenceEmbeddings"
        },
        "type": "genericNode",
        "width": 384,
        "height": 403,
        "dragging": false,
        "position": {
          "x": 1258.1006065243969,
          "y": 812.9969168701826
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1258.1006065243969,
          "y": 812.9969168701826
        }
      },
      {
        "id": "UniParseJson-CfufR",
        "data": {
          "id": "UniParseJson-CfufR",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniParseJsonComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "text",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "parse_data",
                "selected": "Message",
                "display_name": "Text"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import FloatInput,BoolInput\nfrom axiestudio.io import DataInput, Output\nfrom axiestudio.schema.message import Message\nimport json\n\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\n\nclass UniParseJsonComponent(Component):\n    display_name = \"Parse Json\"\n    description = \"数据转json数组\"\n    icon = \"braces\"\n    name = \"UniParseJson\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"数据\", info=\"分片数据\"),\n        FloatInput(name=\"score\", display_name=\"文档检索最低分\", value=0.2,required=True),\n        BoolInput(name=\"keep_text\", display_name=\"保留text\", value=True,required=True)\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniParseJsonComponent.png')\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        mylist=[]\n        #0.2-0.4是低，0.4-0.6是中，大于0.6是高,低于0.2的不展示\n        for value in data:\n            myscore=value.data['score']\n            if(myscore<self.score):\n                continue\n            #\n            pipei='低'\n            if(myscore>=self.score and myscore<0.4):\n                pipei='低'\n            elif(myscore>=0.4 and myscore<0.6):\n                pipei='中'\n            elif(myscore>=0.6):\n                pipei='高'\n            else:\n                pipei='低'\n            #endif\n            value.data['pipei']=pipei\n            if(self.keep_text==False):\n                value.data.pop('text')\n            #\n            mylist.append(value.data)\n        #endfor\n        resultStr=json.dumps(mylist,ensure_ascii=False)\n        self.status =resultStr\n        return Message(text=resultStr)\n    #def\n#",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "data": {
                "info": "分片数据",
                "list": false,
                "name": "data",
                "show": true,
                "type": "other",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Data"
                ],
                "placeholder": "",
                "display_name": "数据",
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "_type": "Component",
              "score": {
                "info": "",
                "list": false,
                "name": "score",
                "show": true,
                "type": "float",
                "value": 0.2,
                "dynamic": false,
                "advanced": false,
                "required": true,
                "title_case": false,
                "placeholder": "",
                "display_name": "文档检索最低分",
                "trace_as_metadata": true
              },
              "keep_text": {
                "info": "",
                "list": false,
                "name": "keep_text",
                "show": true,
                "type": "bool",
                "value": false,
                "dynamic": false,
                "advanced": false,
                "required": true,
                "title_case": false,
                "placeholder": "",
                "display_name": "保留text",
                "load_from_db": false,
                "trace_as_metadata": true
              }
            },
            "description": "数据转json数组",
            "field_order": [
              "data",
              "score",
              "keep_text"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Json",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "UniParseJson",
          "description": "数据转json数组",
          "display_name": "Parse Json"
        },
        "type": "genericNode",
        "width": 384,
        "height": 425,
        "dragging": false,
        "position": {
          "x": 3014.453731755368,
          "y": 410.6294994433591
        },
        "selected": false,
        "positionAbsolute": {
          "x": 3014.453731755368,
          "y": 410.6294994433591
        }
      },
      {
        "id": "ChatOutput-hya9U",
        "data": {
          "id": "ChatOutput-hya9U",
          "node": {
            "beta": false,
            "icon": "ChatOutput",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "message",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "message_response",
                "selected": "Message",
                "display_name": "Message"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "sender": {
                "info": "Type of sender.",
                "name": "sender",
                "show": true,
                "type": "str",
                "value": "Machine",
                "dynamic": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Sender Type",
                "trace_as_metadata": true
              },
              "session_id": {
                "info": "Session ID for the message.",
                "list": false,
                "name": "session_id",
                "show": true,
                "type": "str",
                "value": "1",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Session ID",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "input_value": {
                "info": "Message to be passed as output.",
                "list": false,
                "name": "input_value",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Text",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "sender_name": {
                "info": "Name of the sender.",
                "list": false,
                "name": "sender_name",
                "show": true,
                "type": "str",
                "value": "AI",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Sender Name",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "data_template": {
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "list": false,
                "name": "data_template",
                "show": true,
                "type": "str",
                "value": "{text}",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Data Template",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "store_message": {
                "info": "Store the message in the history.",
                "list": false,
                "name": "store_message",
                "show": true,
                "type": "bool",
                "value": true,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Store Messages",
                "trace_as_metadata": true
              }
            },
            "description": "Display a chat message in the Playground.",
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "ChatOutput"
        },
        "type": "genericNode",
        "width": 384,
        "height": 403,
        "dragging": false,
        "position": {
          "x": 3620.472238081569,
          "y": 92.53470068630484
        },
        "selected": false,
        "positionAbsolute": {
          "x": 3620.472238081569,
          "y": 92.53470068630484
        }
      },
      {
        "id": "UniPrompt-1KHaO",
        "data": {
          "id": "UniPrompt-1KHaO",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniPromptComponent.png",
            "name": "",
            "error": null,
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "prompt",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "hidden": null,
                "method": "build_prompt",
                "selected": "Message",
                "display_name": "提示词消息"
              }
            ],
            "is_input": null,
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\nfrom axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniPromptComponent(Component):\n    display_name: str = \"提示词\"\n    description: str = \"创建一个包含动态变量的提示词模版。\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"UniPrompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"提示词模板\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"提示词消息\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniPromptComponent.png')\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "question": {
                "info": "",
                "list": false,
                "name": "question",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "password": false,
                "required": false,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "field_type": "str",
                "title_case": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "placeholder": "",
                "display_name": "question",
                "load_from_db": false
              },
              "template": {
                "info": "",
                "list": false,
                "name": "template",
                "show": true,
                "type": "prompt",
                "value": "{question}\n\n---\n\n上面是客户的提问，如果客户是问跟政策相关的问题就返回T，否则返回F",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "提示词模板",
                "trace_as_input": true
              }
            },
            "full_path": null,
            "is_output": null,
            "description": "创建一个包含动态变量的提示词模版。",
            "field_order": [
              "template"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "提示词",
            "output_types": [],
            "custom_fields": {
              "template": [
                "question"
              ]
            },
            "documentation": "",
            "is_composition": null,
            "conditional_paths": []
          },
          "type": "UniPrompt",
          "description": "创建一个包含动态变量的提示词模版。",
          "display_name": "提示词"
        },
        "type": "genericNode",
        "width": 384,
        "height": 395,
        "dragging": false,
        "position": {
          "x": -106.06923520285376,
          "y": -279.2006556565606
        },
        "selected": false,
        "positionAbsolute": {
          "x": -106.06923520285376,
          "y": -279.2006556565606
        }
      },
      {
        "id": "UniOpenAICompatibleModel-ksEUL",
        "data": {
          "id": "UniOpenAICompatibleModel-ksEUL",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "text_output",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "text_response",
                "selected": "Message",
                "display_name": "文本"
              },
              {
                "name": "model_output",
                "cache": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__",
                "method": "build_model",
                "selected": "LanguageModel",
                "display_name": "语言模型"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\nimport os\n\nfrom langfuse import Langfuse\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    StrInput,\n)\n\nfrom langchain_core.language_models.llms import LLM\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.custom import Component\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.field.base import Output\nimport json\nimport warnings\nfrom typing import Optional, Union\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniOpenAICompatibleModelComponent(LCModelComponent):\n    display_name = \"OpenAI Compatible\"\n    description = \"使用OpenAI大语言模型生成文本。\"\n    icon = \"OpenAI\"\n    name = \"UniOpenAICompatibleModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"输入\",value=\"\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"最大Token数\",\n            advanced=False,\n            info=\"能够生成的最大token数量，设置为0表示不限制token数量。\",\n        ),\n        StrInput(\n            name=\"model_name\",\n            display_name=\"模型名称\",\n            info=\"模型的名称，如果不标注则默认为‘chatglm3’。\",\n            value=\"chatglm3\",\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"API Base\",\n            value=\"http://10.0.50.33:9997/v1\",\n            info=\"OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。\",\n        ),\n        StrInput(\n            name=\"openai_api_key\",\n            display_name=\"API Key\",\n            info=\"填写 OpenAI API 密匙以使用OpenAI模型。\",\n            value=\"sk-2c3a4cb458884f9897529d26a44f403f\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"温度\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"流式生成\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"系统消息\",\n            info=\"传递给模型的系统消息。\",\n            advanced=True,\n        )\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        myopenai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        openai_api_base = self.openai_api_base or \"http://10.0.50.33:9997/v1\"\n        try:\n            output = ChatOpenAI(model=model_name,base_url=openai_api_base,openai_api_base=openai_api_base,openai_api_key=myopenai_api_key,model_name=model_name,openai_proxy=\"\",temperature=temperature)\n        except Exception as e:\n            raise ValueError(\"无法初始化 ChatOpenAI LLM.\") from e\n        #\n        return output  # type: ignore\n    #end\n    def text_response(self) -> Message:\n        input_value = self.input_value\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n        result = self.get_chat_result(output, stream, input_value, system_message)\n        self.status = result\n        return result\n    #\n    \n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: Optional[str] = None,\n    ):\n        messages: list[Union[BaseMessage]] = []\n        if not input_value and not system_message:\n            raise ValueError(\"向模型所发消息为空。\")\n        if system_message:\n            messages.append(SystemMessage(content=system_message))\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n                    #\n            else:\n                messages.append(HumanMessage(content=input_value))\n        inputs: Union[list, dict] = messages or {}\n        try:\n            runnable = runnable.with_config( \n                {\"run_name\": self.display_name, \"project_name\": self.tracing_service.project_name}\n            )\n            if stream:\n                return runnable.stream(inputs) \n            else:\n                #myLangfuse = Langfuse(secret_key=\"sk-lf-56f301e0-82c4-44c3-bee2-7bac283c984b\",public_key=\"pk-lf-96f4a175-d1f9-4a69-9d8f-f0559228fbb7\",host=\"http://10.0.53.214:3000\")\n                myLangfuse = Langfuse(secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),host=os.getenv(\"LANGFUSE_HOST\"))\n                trace = myLangfuse.trace(name='大模型trace',user_id=\"LLM\")\n                langfuse_handler_trace = trace.get_langchain_handler()\n                message = runnable.invoke(inputs,config={\"callbacks\": [langfuse_handler_trace]})\n                result = message.content if hasattr(message, \"content\") else message\n                if isinstance(message, AIMessage):\n                    status_message = self.build_status_message(message)\n                    self.status = status_message\n                elif isinstance(result, dict):\n                    result = json.dumps(message, indent=4)\n                    self.status = result\n                else:\n                    self.status = result\n                return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise e\n        #\n    #def",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "stream": {
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "show": true,
                "type": "bool",
                "value": false,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "流式生成",
                "trace_as_metadata": true
              },
              "max_tokens": {
                "info": "能够生成的最大token数量，设置为0表示不限制token数量。",
                "list": false,
                "name": "max_tokens",
                "show": true,
                "type": "int",
                "value": "16000",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "最大Token数",
                "trace_as_metadata": true
              },
              "model_name": {
                "info": "模型的名称，如果不标注则默认为‘chatglm3’。",
                "list": false,
                "name": "model_name",
                "show": true,
                "type": "str",
                "value": "glm4-chat",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "模型名称",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "input_value": {
                "info": "",
                "list": false,
                "name": "input_value",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "输入",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "temperature": {
                "info": "",
                "list": false,
                "name": "temperature",
                "show": true,
                "type": "float",
                "value": 0.1,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "温度",
                "trace_as_metadata": true
              },
              "openai_api_key": {
                "info": "填写 OpenAI API 密匙以使用OpenAI模型。",
                "list": false,
                "name": "openai_api_key",
                "show": true,
                "type": "str",
                "value": "$llm_api_key$",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "API Key",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "system_message": {
                "info": "传递给模型的系统消息。",
                "list": false,
                "name": "system_message",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "系统消息",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "openai_api_base": {
                "info": "OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。",
                "list": false,
                "name": "openai_api_base",
                "show": true,
                "type": "str",
                "value": "$llm_url$",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "API Base",
                "load_from_db": false,
                "trace_as_metadata": true
              }
            },
            "description": "使用OpenAI大语言模型生成文本。",
            "field_order": [
              "input_value",
              "max_tokens",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message"
            ],
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI Compatible",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "UniOpenAICompatibleModel"
        },
        "type": "genericNode",
        "width": 384,
        "height": 863,
        "dragging": false,
        "position": {
          "x": 1048.3400755315365,
          "y": -643.2409712089736
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1048.3400755315365,
          "y": -643.2409712089736
        }
      },
      {
        "id": "ConditionalRouter-V4kOh",
        "data": {
          "id": "ConditionalRouter-V4kOh",
          "node": {
            "beta": false,
            "icon": "equal",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "true_result",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "true_response",
                "selected": "Message",
                "display_name": "True Route"
              },
              {
                "name": "false_result",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "false_response",
                "selected": "Message",
                "display_name": "False Route"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n    name = \"ConditionalRouter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Route\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False Route\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"true_result\")\n            return None  # type: ignore\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"false_result\")\n            return None  # type: ignore\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "message": {
                "info": "The message to pass through either route.",
                "list": false,
                "name": "message",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Message",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "operator": {
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "show": true,
                "type": "str",
                "value": "equals",
                "dynamic": false,
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with"
                ],
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Operator",
                "trace_as_metadata": true
              },
              "input_text": {
                "info": "The primary text input for the operation.",
                "list": false,
                "name": "input_text",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Input Text",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "match_text": {
                "info": "The text input to compare against.",
                "list": false,
                "name": "match_text",
                "show": true,
                "type": "str",
                "value": "T",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Match Text",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "case_sensitive": {
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "name": "case_sensitive",
                "show": true,
                "type": "bool",
                "value": false,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Case Sensitive",
                "trace_as_metadata": true
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "field_order": [
              "input_text",
              "match_text",
              "operator",
              "case_sensitive",
              "message"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "Conditional Router",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "ConditionalRouter"
        },
        "type": "genericNode",
        "width": 384,
        "height": 573,
        "dragging": false,
        "position": {
          "x": 1661.217374679966,
          "y": -450.2704751763318
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1661.217374679966,
          "y": -450.2704751763318
        }
      },
      {
        "id": "ChatOutput-ZfNkT",
        "data": {
          "id": "ChatOutput-ZfNkT",
          "node": {
            "beta": false,
            "icon": "ChatOutput",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "message",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "message_response",
                "selected": "Message",
                "display_name": "Message"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "sender": {
                "info": "Type of sender.",
                "name": "sender",
                "show": true,
                "type": "str",
                "value": "Machine",
                "dynamic": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Sender Type",
                "trace_as_metadata": true
              },
              "session_id": {
                "info": "Session ID for the message.",
                "list": false,
                "name": "session_id",
                "show": true,
                "type": "str",
                "value": "1",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Session ID",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "input_value": {
                "info": "Message to be passed as output.",
                "list": false,
                "name": "input_value",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Text",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "sender_name": {
                "info": "Name of the sender.",
                "list": false,
                "name": "sender_name",
                "show": true,
                "type": "str",
                "value": "AI",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Sender Name",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "data_template": {
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "list": false,
                "name": "data_template",
                "show": true,
                "type": "str",
                "value": "{text}",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Data Template",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "store_message": {
                "info": "Store the message in the history.",
                "list": false,
                "name": "store_message",
                "show": true,
                "type": "bool",
                "value": true,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Store Messages",
                "trace_as_metadata": true
              }
            },
            "description": "Display a chat message in the Playground.",
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "ChatOutput"
        },
        "type": "genericNode",
        "width": 384,
        "height": 403,
        "dragging": false,
        "position": {
          "x": 3373.2173852157807,
          "y": -355.37494858235254
        },
        "selected": false,
        "positionAbsolute": {
          "x": 3373.2173852157807,
          "y": -355.37494858235254
        }
      },
      {
        "id": "UniOpenAICompatibleModel-KUPOm",
        "data": {
          "id": "UniOpenAICompatibleModel-KUPOm",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "text_output",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "text_response",
                "selected": "Message",
                "display_name": "文本"
              },
              {
                "name": "model_output",
                "cache": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__",
                "method": "build_model",
                "selected": "LanguageModel",
                "display_name": "语言模型"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\nimport os\n\nfrom langfuse import Langfuse\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    StrInput,\n)\n\nfrom langchain_core.language_models.llms import LLM\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.custom import Component\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.field.base import Output\nimport json\nimport warnings\nfrom typing import Optional, Union\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniOpenAICompatibleModelComponent(LCModelComponent):\n    display_name = \"OpenAI Compatible\"\n    description = \"使用OpenAI大语言模型生成文本。\"\n    icon = \"OpenAI\"\n    name = \"UniOpenAICompatibleModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"输入\",value=\"\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"最大Token数\",\n            advanced=False,\n            info=\"能够生成的最大token数量，设置为0表示不限制token数量。\",\n        ),\n        StrInput(\n            name=\"model_name\",\n            display_name=\"模型名称\",\n            info=\"模型的名称，如果不标注则默认为‘chatglm3’。\",\n            value=\"chatglm3\",\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"API Base\",\n            value=\"http://10.0.50.33:9997/v1\",\n            info=\"OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。\",\n        ),\n        StrInput(\n            name=\"openai_api_key\",\n            display_name=\"API Key\",\n            info=\"填写 OpenAI API 密匙以使用OpenAI模型。\",\n            value=\"sk-2c3a4cb458884f9897529d26a44f403f\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"温度\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"流式生成\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"系统消息\",\n            info=\"传递给模型的系统消息。\",\n            advanced=True,\n        )\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        myopenai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        openai_api_base = self.openai_api_base or \"http://10.0.50.33:9997/v1\"\n        try:\n            output = ChatOpenAI(model=model_name,base_url=openai_api_base,openai_api_base=openai_api_base,openai_api_key=myopenai_api_key,model_name=model_name,openai_proxy=\"\",temperature=temperature)\n        except Exception as e:\n            raise ValueError(\"无法初始化 ChatOpenAI LLM.\") from e\n        #\n        return output  # type: ignore\n    #end\n    def text_response(self) -> Message:\n        input_value = self.input_value\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n        result = self.get_chat_result(output, stream, input_value, system_message)\n        self.status = result\n        return result\n    #\n    \n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: Optional[str] = None,\n    ):\n        messages: list[Union[BaseMessage]] = []\n        if not input_value and not system_message:\n            raise ValueError(\"向模型所发消息为空。\")\n        if system_message:\n            messages.append(SystemMessage(content=system_message))\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n                    #\n            else:\n                messages.append(HumanMessage(content=input_value))\n        inputs: Union[list, dict] = messages or {}\n        try:\n            runnable = runnable.with_config( \n                {\"run_name\": self.display_name, \"project_name\": self.tracing_service.project_name}\n            )\n            if stream:\n                return runnable.stream(inputs) \n            else:\n                #myLangfuse = Langfuse(secret_key=\"sk-lf-56f301e0-82c4-44c3-bee2-7bac283c984b\",public_key=\"pk-lf-96f4a175-d1f9-4a69-9d8f-f0559228fbb7\",host=\"http://10.0.53.214:3000\")\n                myLangfuse = Langfuse(secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),host=os.getenv(\"LANGFUSE_HOST\"))\n                trace = myLangfuse.trace(name='大模型trace',user_id=\"LLM\")\n                langfuse_handler_trace = trace.get_langchain_handler()\n                message = runnable.invoke(inputs,config={\"callbacks\": [langfuse_handler_trace]})\n                result = message.content if hasattr(message, \"content\") else message\n                if isinstance(message, AIMessage):\n                    status_message = self.build_status_message(message)\n                    self.status = status_message\n                elif isinstance(result, dict):\n                    result = json.dumps(message, indent=4)\n                    self.status = result\n                else:\n                    self.status = result\n                return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise e\n        #\n    #def",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "stream": {
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "name": "stream",
                "show": true,
                "type": "bool",
                "value": true,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "流式生成",
                "trace_as_metadata": true
              },
              "max_tokens": {
                "info": "能够生成的最大token数量，设置为0表示不限制token数量。",
                "list": false,
                "name": "max_tokens",
                "show": true,
                "type": "int",
                "value": "16000",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "最大Token数",
                "trace_as_metadata": true
              },
              "model_name": {
                "info": "模型的名称，如果不标注则默认为‘chatglm3’。",
                "list": false,
                "name": "model_name",
                "show": true,
                "type": "str",
                "value": "glm4-chat",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "模型名称",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "input_value": {
                "info": "",
                "list": false,
                "name": "input_value",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "输入",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "temperature": {
                "info": "",
                "list": false,
                "name": "temperature",
                "show": true,
                "type": "float",
                "value": 0.1,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "温度",
                "trace_as_metadata": true
              },
              "openai_api_key": {
                "info": "填写 OpenAI API 密匙以使用OpenAI模型。",
                "list": false,
                "name": "openai_api_key",
                "show": true,
                "type": "str",
                "value": "$llm_api_key$",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "API Key",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "system_message": {
                "info": "传递给模型的系统消息。",
                "list": false,
                "name": "system_message",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "系统消息",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "openai_api_base": {
                "info": "OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。",
                "list": false,
                "name": "openai_api_base",
                "show": true,
                "type": "str",
                "value": "$llm_url$",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "API Base",
                "load_from_db": false,
                "trace_as_metadata": true
              }
            },
            "description": "使用OpenAI大语言模型生成文本。",
            "field_order": [
              "input_value",
              "max_tokens",
              "model_name",
              "openai_api_base",
              "openai_api_key",
              "temperature",
              "stream",
              "system_message"
            ],
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI Compatible",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "UniOpenAICompatibleModel"
        },
        "type": "genericNode",
        "width": 384,
        "height": 863,
        "dragging": false,
        "position": {
          "x": 2814.7654390900675,
          "y": -656.5130239540974
        },
        "selected": false,
        "positionAbsolute": {
          "x": 2814.7654390900675,
          "y": -656.5130239540974
        }
      },
      {
        "id": "ChatInput-tFUGg",
        "data": {
          "id": "ChatInput-tFUGg",
          "node": {
            "beta": false,
            "icon": "ChatInput",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "message",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "message_response",
                "selected": "Message",
                "display_name": "Message"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "files": {
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "show": true,
                "type": "file",
                "value": "",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "title_case": false,
                "placeholder": "",
                "display_name": "Files",
                "trace_as_metadata": true
              },
              "sender": {
                "info": "Type of sender.",
                "name": "sender",
                "show": true,
                "type": "str",
                "value": "User",
                "dynamic": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Sender Type",
                "trace_as_metadata": true
              },
              "session_id": {
                "info": "Session ID for the message.",
                "list": false,
                "name": "session_id",
                "show": true,
                "type": "str",
                "value": "1",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Session ID",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "input_value": {
                "info": "Message to be passed as input.",
                "list": false,
                "name": "input_value",
                "show": true,
                "type": "str",
                "value": "博士后",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Text",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "sender_name": {
                "info": "Name of the sender.",
                "list": false,
                "name": "sender_name",
                "show": true,
                "type": "str",
                "value": "User",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "Sender Name",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "store_message": {
                "info": "Store the message in the history.",
                "list": false,
                "name": "store_message",
                "show": true,
                "type": "bool",
                "value": true,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Store Messages",
                "trace_as_metadata": true
              }
            },
            "description": "Get chat inputs from the Playground.",
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "ChatInput"
        },
        "type": "genericNode",
        "width": 384,
        "height": 403,
        "dragging": false,
        "position": {
          "x": -533.1091943125101,
          "y": 386.6241903772259
        },
        "selected": false,
        "positionAbsolute": {
          "x": -533.1091943125101,
          "y": 386.6241903772259
        }
      },
      {
        "id": "UniParseData-55eqf",
        "data": {
          "id": "UniParseData-55eqf",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniParseDataComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "text",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "parse_data",
                "selected": "Message",
                "display_name": "文本"
              }
            ],
            "template": {
              "sep": {
                "info": "",
                "list": false,
                "name": "sep",
                "show": true,
                "type": "str",
                "value": "\n",
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Separator",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\nfrom axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniParseDataComponent(Component):\n    display_name = \"解析数据\"\n    description = \"根据指定的模板将数据转换为纯文本。\"\n    icon = \"braces\"\n    name = \"UniParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"数据\", info=\"需要转化为文本的数据。\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"模版\",\n            info=\"用于格式化数据的模板。它可以包含{text}，{sender}或消息数据中的任何其他键。\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"文本\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniParseDataComponent.png')\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "data": {
                "info": "需要转化为文本的数据。",
                "list": false,
                "name": "data",
                "show": true,
                "type": "other",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Data"
                ],
                "placeholder": "",
                "display_name": "数据",
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "_type": "Component",
              "template": {
                "info": "用于格式化数据的模板。它可以包含{text}，{sender}或消息数据中的任何其他键。",
                "list": false,
                "name": "template",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "模版",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              }
            },
            "description": "根据指定的模板将数据转换为纯文本。",
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "解析数据",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "UniParseData"
        },
        "type": "genericNode",
        "width": 384,
        "height": 357,
        "dragging": false,
        "position": {
          "x": 475.23476198985986,
          "y": -338.97973683950124
        },
        "selected": false,
        "positionAbsolute": {
          "x": 475.23476198985986,
          "y": -338.97973683950124
        }
      },
      {
        "id": "UniWeaviateQuery-HGzB4",
        "data": {
          "id": "UniWeaviateQuery-HGzB4",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniWeaviateQueryComponent.png",
            "edited": false,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "base_retriever",
                "cache": true,
                "types": [
                  "Retriever"
                ],
                "value": "__UNDEFINED__",
                "method": "build_base_retriever",
                "selected": "Retriever",
                "display_name": "Retriever"
              },
              {
                "name": "search_results",
                "cache": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__",
                "method": "search_documents",
                "selected": "Data",
                "display_name": "查询结果"
              },
              {
                "name": "vector_store",
                "cache": true,
                "types": [
                  "VectorStore"
                ],
                "value": "__UNDEFINED__",
                "method": "cast_vector_store",
                "selected": "VectorStore",
                "display_name": "向量存储"
              }
            ],
            "template": {
              "url": {
                "info": "",
                "list": false,
                "name": "url",
                "show": true,
                "type": "str",
                "value": "$weaviate_url$",
                "dynamic": false,
                "advanced": false,
                "required": true,
                "title_case": false,
                "placeholder": "",
                "display_name": "Weaviate URL",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "import json\nfrom typing import List\nimport requests\nimport weaviate\nfrom langchain_community.vectorstores import Weaviate\nfrom langchain.utils.math import cosine_similarity\nfrom langchain_core.documents import Document\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.inputs import FloatInput\nfrom axiestudio.io import BoolInput, HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\n\nclass UniWeaviateQueryVectorStoreComponent(LCVectorStoreComponent):\n    import warnings\n    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n    display_name = \"UniWeaviateQuery\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate\"\n    name = \"UniWeaviateQuery\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://10.0.53.214:19080\", required=True),\n        MultilineInput(name=\"api_key\", display_name=\"API Key\"),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"text_key\", display_name=\"向量化字段\", value=\"text\"),\n        MultilineInput(name=\"search_query\", display_name=\"查询请求\"),\n        # 指定属性的过滤\n        MultilineInput(name=\"filter_conditions\", display_name=\"过滤条件\"),\n        # 输出结果的属性配置\n        MultilineInput(name=\"output_fields\", display_name=\"输出字段\"),\n        StrInput(\n            name=\"rerank_url\",\n            display_name=\"Rerank API Base\",\n            value=\"http://10.0.50.33:9997/v1/rerank\"\n        ),\n        StrInput(\n            name=\"rerank_model\",\n            display_name=\"Rerank Model\",\n            value=\"bge-reranker-large\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(name=\"append_data\", display_name=\"Append data,do not delete existing documents\",value=False),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(name=\"number_of_results\", display_name=\"Top K\", value=4),\n        FloatInput(name=\"score\", display_name=\"score\", value=0.3),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniWeaviateQueryComponent.png')\n    def build_vector_store(self) -> Weaviate:\n        return self._build_weaviate()\n\n    def _build_weaviate(self) -> Weaviate:\n        #如果有api_key说明连接weaviate需要auth\n        if len(self.api_key)>10:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n        #\n        # 定义weaviate\n        return Weaviate(\n            client=client,\n            index_name=self.index_name.title(),\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_weaviate()\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            #对查询的文本做嵌入\n            embedded_query = vector_store._embedding.embed_query(self.search_query)\n            #获取用户自定义查询字段\n            if self.output_fields and isinstance(self.output_fields, str):\n                # 将逗号分割的字符串拆分为列表\n                outputfields = self.output_fields.split(',')\n                # 增加必填字段‘text’\n                outputfields.append('text')\n            else:\n                # 结果属性不过滤 查询所有属性结果\n                mytable = vector_store._client.schema.get(vector_store._index_name)\n                outputfields = [item['name'] for item in mytable['properties']]\n            #获取用户自定义查询条件\n            if self.filter_conditions and isinstance(self.filter_conditions, str):\n                filter_conditions = json.loads(self.filter_conditions)\n                #根据查询条件构建query对象\n                query_obj= vector_store._client.query.get(vector_store._index_name,outputfields).with_where(filter_conditions)\n            else:\n                # 发送查询请求\n                query_obj = vector_store._client.query.get(vector_store._index_name, outputfields)\n            #拼接search_query并进行向量化检索\n            result =(query_obj.with_near_vector({\"vector\": embedded_query}).with_limit(self.number_of_results).with_additional([\"distance\"]).do())\n            print(result)\n            #计算score\n            docs = []\n            contents=[]\n            similarity=[]\n            #根据用户自定义socre过滤数据\n            for res in result[\"data\"][\"Get\"][vector_store._index_name]:\n                mytext = res.pop('text')\n                additional=res.pop('_additional')\n                contents.append(mytext)\n                myscore=round(1-additional['distance'],5)\n                res['score']=myscore\n                #docs.append(Document(page_content=mytext, metadata=res))\n                docs.append({\"text\":mytext,\"metadata\":res,\"score\":myscore})\n                similarity.append(myscore)\n            #enddef\n            if(len(contents)==0):\n                data = docs_to_data([Document(page_content=\"None\", metadata={\"answer\":\"None\"})])\n                self.status = data\n                return data\n            #\n            #prompt_embeddings = vector_store._embedding.embed_documents(contents)\n            #similarity = cosine_similarity([embedded_query], prompt_embeddings)[0]\n            print(similarity)\n            count_ok=-1\n            for i in range(len(similarity)):\n                if(similarity[i]<self.score):\n                    count_ok=i\n                    break\n                #endif\n            #\n            if(count_ok==0):\n                data = docs_to_data([Document(page_content=\"None\", metadata={\"answer\":\"None\"})])\n                self.status = data\n                return data\n            elif(count_ok<0):\n                count_ok=len(similarity)\n            #\n            docs=docs[0:count_ok]\n            if(len(self.rerank_url)<4):\n                docs4=[]\n                for item in docs:\n                    docs4.append(Document(page_content=item['text'], metadata=item['metadata']))\n                #\n                data = docs_to_data(docs4)\n                self.status = data\n                return data\n\n            #print(count_ok)\n            contents=contents[0:count_ok]\n            rerankdata = {\n                \"model\": self.rerank_model,\n                \"query\": self.search_query,\n                \"documents\":contents,\n            }\n            response = requests.post(self.rerank_url,json=rerankdata)\n            response_dict = response.json()\n            results=response_dict['results']\n            score_dic={}\n            for item in results:\n                score_dic[item['index']]=item['relevance_score']\n            #endfor\n            for i in range(len(docs)):\n                docs[i]['score']=round(score_dic[i]*100,3)\n            #endfor\n            docs2=list(sorted(docs,key=lambda x:x[\"score\"],reverse=True))\n            docs3=[]\n            for item in docs2:\n                docs3.append(Document(page_content=item['text'], metadata=item['metadata']))\n            #\n            #print(docs3)\n            data = docs_to_data(docs3)\n            self.status = data\n            return data\n        else:\n            return []\n        #\n    #enddef\n#",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "score": {
                "info": "",
                "list": false,
                "name": "score",
                "show": true,
                "type": "float",
                "value": "0.1",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "score",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "api_key": {
                "info": "",
                "list": false,
                "name": "api_key",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "API Key",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "text_key": {
                "info": "",
                "list": false,
                "name": "text_key",
                "show": true,
                "type": "str",
                "value": "text",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "向量化字段",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "embedding": {
                "info": "",
                "list": false,
                "name": "embedding",
                "show": true,
                "type": "other",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Embeddings"
                ],
                "placeholder": "",
                "display_name": "Embedding",
                "trace_as_metadata": true
              },
              "index_name": {
                "info": "",
                "list": false,
                "name": "index_name",
                "show": true,
                "type": "str",
                "value": "$document_class$",
                "dynamic": false,
                "advanced": false,
                "required": true,
                "title_case": false,
                "placeholder": "",
                "display_name": "Index Name",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "rerank_url": {
                "info": "",
                "list": false,
                "name": "rerank_url",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Rerank API Base",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "append_data": {
                "info": "",
                "list": false,
                "name": "append_data",
                "show": true,
                "type": "bool",
                "value": false,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Append data,do not delete existing documents",
                "trace_as_metadata": true
              },
              "ingest_data": {
                "info": "",
                "list": true,
                "name": "ingest_data",
                "show": true,
                "type": "other",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Data"
                ],
                "placeholder": "",
                "display_name": "Ingest Data",
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "rerank_model": {
                "info": "",
                "list": false,
                "name": "rerank_model",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Rerank Model",
                "load_from_db": false,
                "trace_as_metadata": true
              },
              "search_query": {
                "info": "",
                "list": false,
                "name": "search_query",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "查询请求",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "output_fields": {
                "info": "",
                "list": false,
                "name": "output_fields",
                "show": true,
                "type": "str",
                "value": "title,source,summary",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "输出字段",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "search_by_text": {
                "info": "",
                "list": false,
                "name": "search_by_text",
                "show": true,
                "type": "bool",
                "value": false,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Search By Text",
                "trace_as_metadata": true
              },
              "filter_conditions": {
                "info": "",
                "list": false,
                "name": "filter_conditions",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "multiline": true,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "过滤条件",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              },
              "number_of_results": {
                "info": "",
                "list": false,
                "name": "number_of_results",
                "show": true,
                "type": "int",
                "value": 4,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "Top K",
                "trace_as_metadata": true
              }
            },
            "description": "Weaviate Vector Store with search capabilities",
            "field_order": [
              "url",
              "api_key",
              "index_name",
              "text_key",
              "search_query",
              "filter_conditions",
              "output_fields",
              "rerank_url",
              "rerank_model",
              "ingest_data",
              "append_data",
              "embedding",
              "number_of_results",
              "score",
              "search_by_text"
            ],
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "UniWeaviateQuery",
            "output_types": [],
            "custom_fields": {},
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate",
            "conditional_paths": []
          },
          "type": "UniWeaviateQuery",
          "description": "Weaviate Vector Store with search capabilities",
          "display_name": "UniWeaviateQuery"
        },
        "type": "genericNode",
        "width": 384,
        "height": 1461,
        "dragging": false,
        "position": {
          "x": 2309.199181976612,
          "y": 3.479518509313209
        },
        "selected": false,
        "positionAbsolute": {
          "x": 2309.199181976612,
          "y": 3.479518509313209
        }
      },
      {
        "id": "UniStream-Dh1Qu",
        "data": {
          "id": "UniStream-Dh1Qu",
          "node": {
            "beta": false,
            "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
            "edited": true,
            "frozen": false,
            "pinned": false,
            "outputs": [
              {
                "name": "text_output",
                "cache": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__",
                "method": "text_response",
                "selected": "Message",
                "display_name": "文本"
              }
            ],
            "template": {
              "code": {
                "info": "",
                "list": false,
                "name": "code",
                "show": true,
                "type": "code",
                "value": "# -*- coding: utf-8 -*-\r\nimport json\r\nimport random\r\nimport time\r\n\r\nfrom axiestudio.inputs import (\r\n    MessageTextInput, IntInput, StrInput, FloatInput, BoolInput,\r\n)\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.template.field.base import Output\r\nfrom typing import Iterator\r\nfrom axiestudio.utils.MinioUtils import MinioUtils\r\n\r\n\r\nclass UniStream(Component):\r\n    display_name = \"stream转换器\"\r\n    description = \"将文本转为stream\"\r\n    icon = \"OpenAI\"\r\n    name = \"UniStream\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"system_message\", display_name=\"系统消息\", info=\"系统消息\", advanced=False\r\n        ),\r\n        FloatInput(\r\n            name=\"min_delay\",\r\n            display_name=\"min_delay\",\r\n            value=0.03,\r\n            advanced=True,\r\n        ),\r\n        FloatInput(\r\n            name=\"max_delay\",\r\n            display_name=\"max_delay\",\r\n            value=0.1,\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"max_n\",\r\n            display_name=\"max_n\",\r\n            value=20,\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"stream\",\r\n            value=True,\r\n            advanced=False,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"文本\", name=\"text_output\", method=\"text_response\")\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        # 调用父类的初始化方法\r\n        super().__init__(**kwargs)\r\n        self.icon = MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\r\n\r\n    def text_response(self) -> Message:\r\n        if self.stream:\r\n            result = self.get_chat_result2()\r\n            self.status = result\r\n            return result\r\n        else:\r\n            self.status = self.system_message\r\n            return self.system_message\r\n\r\n    def check_type(self, s):\r\n        try:\r\n            parsed = json.loads(s)\r\n            if isinstance(parsed, list):\r\n                return \"list\"\r\n            elif isinstance(parsed, dict):\r\n                return \"dict\"\r\n            else:\r\n                return \"str\"\r\n        except json.JSONDecodeError:\r\n            return \"str\"\r\n\r\n    def get_chat_result(self) -> Iterator[str]:\r\n        text = self.system_message\r\n        text_type = self.check_type(text)\r\n        if \"str\" == text_type:\r\n            return self.get_chat_result2(text)\r\n        elif \"dict\" == text_type:\r\n            my_dict = json.loads(text)\r\n            items = [dict(key, value) for key, value in my_dict.items()]\r\n            for item in items:\r\n                yield json.dumps(item, ensure_ascii=False)\r\n                # 随机延迟\r\n                delay = random.uniform(self.min_delay, self.max_delay)\r\n                time.sleep(delay)\r\n        elif \"list\" == text_type:\r\n            result = []\r\n            data = json.loads(text)\r\n            for item in data:\r\n                for key, value in item.items():\r\n                    yield json.dumps({key : value}, ensure_ascii=False)\r\n                    # 随机延迟\r\n                    delay = random.uniform(self.min_delay, self.max_delay)\r\n                    time.sleep(delay)\r\n\r\n    def get_chat_result2(self) -> Iterator[str]:\r\n        text = self.system_message\r\n        index = 0  # 记录当前处理的位置\r\n        while index < len(text):\r\n            # 确定每次要输出的字符数\r\n            chunk_size = random.randint(1, min(self.max_n, len(text) - index))\r\n\r\n            selected_chars = text[index:index + chunk_size]\r\n\r\n            # 输出选中的字符\r\n            for char in selected_chars:\r\n                yield char\r\n\r\n            index += chunk_size  # 更新索引\r\n\r\n            # 随机延迟\r\n            delay = random.uniform(self.min_delay, self.max_delay)\r\n            time.sleep(delay)\r\n",
                "dynamic": true,
                "advanced": true,
                "password": false,
                "required": true,
                "fileTypes": [],
                "file_path": "",
                "multiline": true,
                "title_case": false,
                "placeholder": "",
                "load_from_db": false
              },
              "_type": "Component",
              "max_n": {
                "info": "",
                "list": false,
                "name": "max_n",
                "show": true,
                "type": "int",
                "value": 20,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "max_n",
                "trace_as_metadata": true
              },
              "stream": {
                "info": "",
                "list": false,
                "name": "stream",
                "show": true,
                "type": "bool",
                "value": true,
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "stream",
                "trace_as_metadata": true
              },
              "max_delay": {
                "info": "",
                "list": false,
                "name": "max_delay",
                "show": true,
                "type": "float",
                "value": 0.1,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "max_delay",
                "trace_as_metadata": true
              },
              "min_delay": {
                "info": "",
                "list": false,
                "name": "min_delay",
                "show": true,
                "type": "float",
                "value": 0.03,
                "dynamic": false,
                "advanced": true,
                "required": false,
                "title_case": false,
                "placeholder": "",
                "display_name": "min_delay",
                "trace_as_metadata": true
              },
              "system_message": {
                "info": "系统消息",
                "list": false,
                "name": "system_message",
                "show": true,
                "type": "str",
                "value": "",
                "dynamic": false,
                "advanced": false,
                "required": false,
                "title_case": false,
                "input_types": [
                  "Message"
                ],
                "placeholder": "",
                "display_name": "系统消息",
                "load_from_db": false,
                "trace_as_input": true,
                "trace_as_metadata": true
              }
            },
            "description": "将文本转为stream",
            "field_order": [
              "system_message",
              "min_delay",
              "max_delay",
              "max_n",
              "stream"
            ],
            "base_classes": [
              "Message"
            ],
            "display_name": "stream转换器",
            "output_types": [],
            "custom_fields": {},
            "documentation": "",
            "conditional_paths": []
          },
          "type": "UniStream",
          "description": "将文本转为stream",
          "display_name": "stream转换器"
        },
        "type": "genericNode",
        "width": 384,
        "height": 385,
        "dragging": false,
        "position": {
          "x": 3530.0403556084,
          "y": 744.1045377368457
        },
        "selected": false
      }
    ],
    "viewport": {
      "x": 465.105220522385,
      "y": 320.52509061248657,
      "zoom": 0.1996910816548735
    }
  },
  "metadata": {
    "UniXinferenceEmbeddings": {
      "count": 1
    },
    "UniParseJson": {
      "count": 1
    },
    "ChatOutput": {
      "count": 2
    },
    "UniPrompt": {
      "count": 1
    },
    "UniOpenAICompatibleModel": {
      "count": 2
    },
    "ConditionalRouter": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "UniParseData": {
      "count": 1
    },
    "UniWeaviateQuery": {
      "count": 1
    },
    "UniStream": {
      "count": 1
    },
    "total": 12
  },
  "original": {
    "id": "163b7f7d-3cbf-4f71-94a0-55b656ea003b",
    "name": "政策查询 -模板",
    "description": "Visit https://docs.langflow.org/tutorials/rag-with-astradb for a detailed guide of this project.\nThis project give you both Ingestion and RAG in a single file. You'll need to visit https://astra.datastax.com/ to create an Astra DB instance, your Token and",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "13",
    "metadata": {
      "UniXinferenceEmbeddings": {
        "count": 1
      },
      "UniParseJson": {
        "count": 1
      },
      "ChatOutput": {
        "count": 2
      },
      "UniPrompt": {
        "count": 1
      },
      "UniOpenAICompatibleModel": {
        "count": 2
      },
      "ConditionalRouter": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "UniParseData": {
        "count": 1
      },
      "UniWeaviateQuery": {
        "count": 1
      },
      "UniStream": {
        "count": 1
      },
      "total": 12
    },
    "last_tested_version": "1.0.9",
    "private": false,
    "data": {
      "edges": [
        {
          "id": "reactflow__edge-UniOpenAICompatibleModel-ksEUL{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-V4kOh{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniOpenAICompatibleModel-ksEUL",
              "name": "text_output",
              "dataType": "UniOpenAICompatibleModel",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "ConditionalRouter-V4kOh",
              "type": "str",
              "fieldName": "input_text",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniOpenAICompatibleModel-ksEUL",
          "target": "ConditionalRouter-V4kOh",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-ConditionalRouter-V4kOh{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-UniOpenAICompatibleModel-KUPOm{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "ConditionalRouter-V4kOh",
              "name": "false_result",
              "dataType": "ConditionalRouter",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniOpenAICompatibleModel-KUPOm",
              "type": "str",
              "fieldName": "input_value",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "ConditionalRouter-V4kOh",
          "target": "UniOpenAICompatibleModel-KUPOm",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniOpenAICompatibleModel-KUPOm{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ZfNkT{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZfNkTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniOpenAICompatibleModel-KUPOm",
              "name": "text_output",
              "dataType": "UniOpenAICompatibleModel",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "ChatOutput-ZfNkT",
              "type": "str",
              "fieldName": "input_value",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniOpenAICompatibleModel-KUPOm",
          "target": "ChatOutput-ZfNkT",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniOpenAICompatibleModelœ,œidœ:œUniOpenAICompatibleModel-KUPOmœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZfNkTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-ChatInput-tFUGg{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-UniPrompt-1KHaO{œfieldNameœ:œquestionœ,œidœ:œUniPrompt-1KHaOœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "ChatInput-tFUGg",
              "name": "message",
              "dataType": "ChatInput",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniPrompt-1KHaO",
              "type": "str",
              "fieldName": "question",
              "inputTypes": [
                "Message",
                "Text"
              ]
            }
          },
          "source": "ChatInput-tFUGg",
          "target": "UniPrompt-1KHaO",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œUniPrompt-1KHaOœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-ChatInput-tFUGg{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-V4kOh{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "ChatInput-tFUGg",
              "name": "message",
              "dataType": "ChatInput",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "ConditionalRouter-V4kOh",
              "type": "str",
              "fieldName": "message",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "ChatInput-tFUGg",
          "target": "ConditionalRouter-V4kOh",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-tFUGgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œConditionalRouter-V4kOhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniPrompt-1KHaO{œdataTypeœ:œUniPromptœ,œidœ:œUniPrompt-1KHaOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-UniParseData-55eqf{œfieldNameœ:œtemplateœ,œidœ:œUniParseData-55eqfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniPrompt-1KHaO",
              "name": "prompt",
              "dataType": "UniPrompt",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniParseData-55eqf",
              "type": "str",
              "fieldName": "template",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniPrompt-1KHaO",
          "target": "UniParseData-55eqf",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniPromptœ,œidœ:œUniPrompt-1KHaOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œUniParseData-55eqfœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniParseData-55eqf{œdataTypeœ:œUniParseDataœ,œidœ:œUniParseData-55eqfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-UniOpenAICompatibleModel-ksEUL{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniParseData-55eqf",
              "name": "text",
              "dataType": "UniParseData",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniOpenAICompatibleModel-ksEUL",
              "type": "str",
              "fieldName": "input_value",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniParseData-55eqf",
          "target": "UniOpenAICompatibleModel-ksEUL",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniParseDataœ,œidœ:œUniParseData-55eqfœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œUniOpenAICompatibleModel-ksEULœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniWeaviateQuery-HGzB4{œdataTypeœ:œUniWeaviateQueryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-UniParseJson-CfufR{œfieldNameœ:œdataœ,œidœ:œUniParseJson-CfufRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "sourceHandle": {
              "id": "UniWeaviateQuery-HGzB4",
              "name": "search_results",
              "dataType": "UniWeaviateQuery",
              "output_types": [
                "Data"
              ]
            },
            "targetHandle": {
              "id": "UniParseJson-CfufR",
              "type": "other",
              "fieldName": "data",
              "inputTypes": [
                "Data"
              ]
            }
          },
          "source": "UniWeaviateQuery-HGzB4",
          "target": "UniParseJson-CfufR",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniWeaviateQueryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œUniParseJson-CfufRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
        },
        {
          "id": "reactflow__edge-ConditionalRouter-V4kOh{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-UniWeaviateQuery-HGzB4{œfieldNameœ:œsearch_queryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "ConditionalRouter-V4kOh",
              "name": "true_result",
              "dataType": "ConditionalRouter",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniWeaviateQuery-HGzB4",
              "type": "str",
              "fieldName": "search_query",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "ConditionalRouter-V4kOh",
          "target": "UniWeaviateQuery-HGzB4",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-V4kOhœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniXinferenceEmbeddings-xPy7F{œdataTypeœ:œUniXinferenceEmbeddingsœ,œidœ:œUniXinferenceEmbeddings-xPy7Fœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-UniWeaviateQuery-HGzB4{œfieldNameœ:œembeddingœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "data": {
            "sourceHandle": {
              "id": "UniXinferenceEmbeddings-xPy7F",
              "name": "embeddings",
              "dataType": "UniXinferenceEmbeddings",
              "output_types": [
                "Embeddings"
              ]
            },
            "targetHandle": {
              "id": "UniWeaviateQuery-HGzB4",
              "type": "other",
              "fieldName": "embedding",
              "inputTypes": [
                "Embeddings"
              ]
            }
          },
          "source": "UniXinferenceEmbeddings-xPy7F",
          "target": "UniWeaviateQuery-HGzB4",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniXinferenceEmbeddingsœ,œidœ:œUniXinferenceEmbeddings-xPy7Fœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œUniWeaviateQuery-HGzB4œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
        },
        {
          "id": "reactflow__edge-UniParseJson-CfufR{œdataTypeœ:œUniParseJsonœ,œidœ:œUniParseJson-CfufRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-UniStream-Dh1Qu{œfieldNameœ:œsystem_messageœ,œidœ:œUniStream-Dh1Quœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniParseJson-CfufR",
              "name": "text",
              "dataType": "UniParseJson",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "UniStream-Dh1Qu",
              "type": "str",
              "fieldName": "system_message",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniParseJson-CfufR",
          "target": "UniStream-Dh1Qu",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniParseJsonœ,œidœ:œUniParseJson-CfufRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œUniStream-Dh1Quœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "id": "reactflow__edge-UniStream-Dh1Qu{œdataTypeœ:œUniStreamœ,œidœ:œUniStream-Dh1Quœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-hya9U{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hya9Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "sourceHandle": {
              "id": "UniStream-Dh1Qu",
              "name": "text_output",
              "dataType": "UniStream",
              "output_types": [
                "Message"
              ]
            },
            "targetHandle": {
              "id": "ChatOutput-hya9U",
              "type": "str",
              "fieldName": "input_value",
              "inputTypes": [
                "Message"
              ]
            }
          },
          "source": "UniStream-Dh1Qu",
          "target": "ChatOutput-hya9U",
          "className": "",
          "sourceHandle": "{œdataTypeœ:œUniStreamœ,œidœ:œUniStream-Dh1Quœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hya9Uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        }
      ],
      "nodes": [
        {
          "id": "UniXinferenceEmbeddings-xPy7F",
          "data": {
            "id": "UniXinferenceEmbeddings-xPy7F",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniXinferenceEmbeddingsComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "embeddings",
                  "cache": true,
                  "types": [
                    "Embeddings"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "build_embeddings",
                  "selected": "Embeddings",
                  "display_name": "Embeddings"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\nfrom langchain_community.embeddings import XinferenceEmbeddings\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import FloatInput, MessageTextInput, Output\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniXinferenceEmbeddingsComponent(LCModelComponent):\n    display_name: str = \"Xinference Embeddings\"\n    description: str = \"Xinference Embeddings\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n    icon = \"Ollama\"\n    name = \"UniXinferenceEmbeddings\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"model\",\n            display_name=\"Xinference Model\",\n            value=\"bge-large-zh-v1.5\",\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Xinference Base URL\",\n            value=\"http://10.0.50.33:9997\",\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniXinferenceEmbeddingsComponent.png')\n    def build_embeddings(self) -> Embeddings:\n        try:\n            output = XinferenceEmbeddings(server_url=self.base_url,model_uid=self.model)\n        except Exception as e:\n            raise ValueError(\"无法连接到Xinference API。\") from e\n        return output\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "model": {
                  "info": "",
                  "list": false,
                  "name": "model",
                  "show": true,
                  "type": "str",
                  "value": "bge-large-zh-v1.5",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Xinference Model",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "base_url": {
                  "info": "",
                  "list": false,
                  "name": "base_url",
                  "show": true,
                  "type": "str",
                  "value": "$embedding_url$",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Xinference Base URL",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                }
              },
              "description": "Xinference Embeddings",
              "field_order": [
                "model",
                "base_url"
              ],
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Xinference Embeddings",
              "output_types": [],
              "custom_fields": {},
              "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
              "conditional_paths": []
            },
            "type": "UniXinferenceEmbeddings"
          },
          "type": "genericNode",
          "width": 384,
          "height": 403,
          "dragging": false,
          "position": {
            "x": 1258.1006065243969,
            "y": 812.9969168701826
          },
          "selected": false,
          "positionAbsolute": {
            "x": 1258.1006065243969,
            "y": 812.9969168701826
          }
        },
        {
          "id": "UniParseJson-CfufR",
          "data": {
            "id": "UniParseJson-CfufR",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniParseJsonComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "text",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "parse_data",
                  "selected": "Message",
                  "display_name": "Text"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import FloatInput,BoolInput\nfrom axiestudio.io import DataInput, Output\nfrom axiestudio.schema.message import Message\nimport json\n\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\n\nclass UniParseJsonComponent(Component):\n    display_name = \"Parse Json\"\n    description = \"数据转json数组\"\n    icon = \"braces\"\n    name = \"UniParseJson\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"数据\", info=\"分片数据\"),\n        FloatInput(name=\"score\", display_name=\"文档检索最低分\", value=0.2,required=True),\n        BoolInput(name=\"keep_text\", display_name=\"保留text\", value=True,required=True)\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniParseJsonComponent.png')\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        mylist=[]\n        #0.2-0.4是低，0.4-0.6是中，大于0.6是高,低于0.2的不展示\n        for value in data:\n            myscore=value.data['score']\n            if(myscore<self.score):\n                continue\n            #\n            pipei='低'\n            if(myscore>=self.score and myscore<0.4):\n                pipei='低'\n            elif(myscore>=0.4 and myscore<0.6):\n                pipei='中'\n            elif(myscore>=0.6):\n                pipei='高'\n            else:\n                pipei='低'\n            #endif\n            value.data['pipei']=pipei\n            if(self.keep_text==False):\n                value.data.pop('text')\n            #\n            mylist.append(value.data)\n        #endfor\n        resultStr=json.dumps(mylist,ensure_ascii=False)\n        self.status =resultStr\n        return Message(text=resultStr)\n    #def\n#",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "data": {
                  "info": "分片数据",
                  "list": false,
                  "name": "data",
                  "show": true,
                  "type": "other",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Data"
                  ],
                  "placeholder": "",
                  "display_name": "数据",
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "_type": "Component",
                "score": {
                  "info": "",
                  "list": false,
                  "name": "score",
                  "show": true,
                  "type": "float",
                  "value": 0.2,
                  "dynamic": false,
                  "advanced": false,
                  "required": true,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "文档检索最低分",
                  "trace_as_metadata": true
                },
                "keep_text": {
                  "info": "",
                  "list": false,
                  "name": "keep_text",
                  "show": true,
                  "type": "bool",
                  "value": false,
                  "dynamic": false,
                  "advanced": false,
                  "required": true,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "保留text",
                  "load_from_db": false,
                  "trace_as_metadata": true
                }
              },
              "description": "数据转json数组",
              "field_order": [
                "data",
                "score",
                "keep_text"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Json",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "UniParseJson",
            "description": "数据转json数组",
            "display_name": "Parse Json"
          },
          "type": "genericNode",
          "width": 384,
          "height": 425,
          "dragging": false,
          "position": {
            "x": 3014.453731755368,
            "y": 410.6294994433591
          },
          "selected": false,
          "positionAbsolute": {
            "x": 3014.453731755368,
            "y": 410.6294994433591
          }
        },
        {
          "id": "ChatOutput-hya9U",
          "data": {
            "id": "ChatOutput-hya9U",
            "node": {
              "beta": false,
              "icon": "ChatOutput",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "message",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "message_response",
                  "selected": "Message",
                  "display_name": "Message"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "sender": {
                  "info": "Type of sender.",
                  "name": "sender",
                  "show": true,
                  "type": "str",
                  "value": "Machine",
                  "dynamic": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Sender Type",
                  "trace_as_metadata": true
                },
                "session_id": {
                  "info": "Session ID for the message.",
                  "list": false,
                  "name": "session_id",
                  "show": true,
                  "type": "str",
                  "value": "1",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Session ID",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "input_value": {
                  "info": "Message to be passed as output.",
                  "list": false,
                  "name": "input_value",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Text",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "sender_name": {
                  "info": "Name of the sender.",
                  "list": false,
                  "name": "sender_name",
                  "show": true,
                  "type": "str",
                  "value": "AI",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Sender Name",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "data_template": {
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "list": false,
                  "name": "data_template",
                  "show": true,
                  "type": "str",
                  "value": "{text}",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Data Template",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "store_message": {
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "store_message",
                  "show": true,
                  "type": "bool",
                  "value": true,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Store Messages",
                  "trace_as_metadata": true
                }
              },
              "description": "Display a chat message in the Playground.",
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "ChatOutput"
          },
          "type": "genericNode",
          "width": 384,
          "height": 403,
          "dragging": false,
          "position": {
            "x": 3620.472238081569,
            "y": 92.53470068630484
          },
          "selected": false,
          "positionAbsolute": {
            "x": 3620.472238081569,
            "y": 92.53470068630484
          }
        },
        {
          "id": "UniPrompt-1KHaO",
          "data": {
            "id": "UniPrompt-1KHaO",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniPromptComponent.png",
              "name": "",
              "error": null,
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "prompt",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "hidden": null,
                  "method": "build_prompt",
                  "selected": "Message",
                  "display_name": "提示词消息"
                }
              ],
              "is_input": null,
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\nfrom axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniPromptComponent(Component):\n    display_name: str = \"提示词\"\n    description: str = \"创建一个包含动态变量的提示词模版。\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"UniPrompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"提示词模板\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"提示词消息\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniPromptComponent.png')\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "question": {
                  "info": "",
                  "list": false,
                  "name": "question",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "password": false,
                  "required": false,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "field_type": "str",
                  "title_case": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "placeholder": "",
                  "display_name": "question",
                  "load_from_db": false
                },
                "template": {
                  "info": "",
                  "list": false,
                  "name": "template",
                  "show": true,
                  "type": "prompt",
                  "value": "{question}\n\n---\n\n上面是客户的提问，如果客户是问跟政策相关的问题就返回T，否则返回F",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "提示词模板",
                  "trace_as_input": true
                }
              },
              "full_path": null,
              "is_output": null,
              "description": "创建一个包含动态变量的提示词模版。",
              "field_order": [
                "template"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "提示词",
              "output_types": [],
              "custom_fields": {
                "template": [
                  "question"
                ]
              },
              "documentation": "",
              "is_composition": null,
              "conditional_paths": []
            },
            "type": "UniPrompt",
            "description": "创建一个包含动态变量的提示词模版。",
            "display_name": "提示词"
          },
          "type": "genericNode",
          "width": 384,
          "height": 395,
          "dragging": false,
          "position": {
            "x": -106.06923520285376,
            "y": -279.2006556565606
          },
          "selected": false,
          "positionAbsolute": {
            "x": -106.06923520285376,
            "y": -279.2006556565606
          }
        },
        {
          "id": "UniOpenAICompatibleModel-ksEUL",
          "data": {
            "id": "UniOpenAICompatibleModel-ksEUL",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "text_output",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "text_response",
                  "selected": "Message",
                  "display_name": "文本"
                },
                {
                  "name": "model_output",
                  "cache": true,
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "build_model",
                  "selected": "LanguageModel",
                  "display_name": "语言模型"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\nimport os\n\nfrom langfuse import Langfuse\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    StrInput,\n)\n\nfrom langchain_core.language_models.llms import LLM\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.custom import Component\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.field.base import Output\nimport json\nimport warnings\nfrom typing import Optional, Union\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniOpenAICompatibleModelComponent(LCModelComponent):\n    display_name = \"OpenAI Compatible\"\n    description = \"使用OpenAI大语言模型生成文本。\"\n    icon = \"OpenAI\"\n    name = \"UniOpenAICompatibleModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"输入\",value=\"\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"最大Token数\",\n            advanced=False,\n            info=\"能够生成的最大token数量，设置为0表示不限制token数量。\",\n        ),\n        StrInput(\n            name=\"model_name\",\n            display_name=\"模型名称\",\n            info=\"模型的名称，如果不标注则默认为‘chatglm3’。\",\n            value=\"chatglm3\",\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"API Base\",\n            value=\"http://10.0.50.33:9997/v1\",\n            info=\"OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。\",\n        ),\n        StrInput(\n            name=\"openai_api_key\",\n            display_name=\"API Key\",\n            info=\"填写 OpenAI API 密匙以使用OpenAI模型。\",\n            value=\"sk-2c3a4cb458884f9897529d26a44f403f\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"温度\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"流式生成\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"系统消息\",\n            info=\"传递给模型的系统消息。\",\n            advanced=True,\n        )\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        myopenai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        openai_api_base = self.openai_api_base or \"http://10.0.50.33:9997/v1\"\n        try:\n            output = ChatOpenAI(model=model_name,base_url=openai_api_base,openai_api_base=openai_api_base,openai_api_key=myopenai_api_key,model_name=model_name,openai_proxy=\"\",temperature=temperature)\n        except Exception as e:\n            raise ValueError(\"无法初始化 ChatOpenAI LLM.\") from e\n        #\n        return output  # type: ignore\n    #end\n    def text_response(self) -> Message:\n        input_value = self.input_value\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n        result = self.get_chat_result(output, stream, input_value, system_message)\n        self.status = result\n        return result\n    #\n    \n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: Optional[str] = None,\n    ):\n        messages: list[Union[BaseMessage]] = []\n        if not input_value and not system_message:\n            raise ValueError(\"向模型所发消息为空。\")\n        if system_message:\n            messages.append(SystemMessage(content=system_message))\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n                    #\n            else:\n                messages.append(HumanMessage(content=input_value))\n        inputs: Union[list, dict] = messages or {}\n        try:\n            runnable = runnable.with_config( \n                {\"run_name\": self.display_name, \"project_name\": self.tracing_service.project_name}\n            )\n            if stream:\n                return runnable.stream(inputs) \n            else:\n                #myLangfuse = Langfuse(secret_key=\"sk-lf-56f301e0-82c4-44c3-bee2-7bac283c984b\",public_key=\"pk-lf-96f4a175-d1f9-4a69-9d8f-f0559228fbb7\",host=\"http://10.0.53.214:3000\")\n                myLangfuse = Langfuse(secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),host=os.getenv(\"LANGFUSE_HOST\"))\n                trace = myLangfuse.trace(name='大模型trace',user_id=\"LLM\")\n                langfuse_handler_trace = trace.get_langchain_handler()\n                message = runnable.invoke(inputs,config={\"callbacks\": [langfuse_handler_trace]})\n                result = message.content if hasattr(message, \"content\") else message\n                if isinstance(message, AIMessage):\n                    status_message = self.build_status_message(message)\n                    self.status = status_message\n                elif isinstance(result, dict):\n                    result = json.dumps(message, indent=4)\n                    self.status = result\n                else:\n                    self.status = result\n                return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise e\n        #\n    #def",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "stream": {
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "show": true,
                  "type": "bool",
                  "value": false,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "流式生成",
                  "trace_as_metadata": true
                },
                "max_tokens": {
                  "info": "能够生成的最大token数量，设置为0表示不限制token数量。",
                  "list": false,
                  "name": "max_tokens",
                  "show": true,
                  "type": "int",
                  "value": "16000",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "最大Token数",
                  "trace_as_metadata": true
                },
                "model_name": {
                  "info": "模型的名称，如果不标注则默认为‘chatglm3’。",
                  "list": false,
                  "name": "model_name",
                  "show": true,
                  "type": "str",
                  "value": "glm4-chat",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "模型名称",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "input_value": {
                  "info": "",
                  "list": false,
                  "name": "input_value",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "输入",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "temperature": {
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "show": true,
                  "type": "float",
                  "value": 0.1,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "温度",
                  "trace_as_metadata": true
                },
                "openai_api_key": {
                  "info": "填写 OpenAI API 密匙以使用OpenAI模型。",
                  "list": false,
                  "name": "openai_api_key",
                  "show": true,
                  "type": "str",
                  "value": "$llm_api_key$",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "API Key",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "system_message": {
                  "info": "传递给模型的系统消息。",
                  "list": false,
                  "name": "system_message",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "系统消息",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "openai_api_base": {
                  "info": "OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。",
                  "list": false,
                  "name": "openai_api_base",
                  "show": true,
                  "type": "str",
                  "value": "$llm_url$",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "API Base",
                  "load_from_db": false,
                  "trace_as_metadata": true
                }
              },
              "description": "使用OpenAI大语言模型生成文本。",
              "field_order": [
                "input_value",
                "max_tokens",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message"
              ],
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI Compatible",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "UniOpenAICompatibleModel"
          },
          "type": "genericNode",
          "width": 384,
          "height": 863,
          "dragging": false,
          "position": {
            "x": 1048.3400755315365,
            "y": -643.2409712089736
          },
          "selected": false,
          "positionAbsolute": {
            "x": 1048.3400755315365,
            "y": -643.2409712089736
          }
        },
        {
          "id": "ConditionalRouter-V4kOh",
          "data": {
            "id": "ConditionalRouter-V4kOh",
            "node": {
              "beta": false,
              "icon": "equal",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "true_result",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "true_response",
                  "selected": "Message",
                  "display_name": "True Route"
                },
                {
                  "name": "false_result",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "false_response",
                  "selected": "Message",
                  "display_name": "False Route"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, DropdownInput, MessageInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Conditional Router\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"equal\"\n    name = \"ConditionalRouter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\"equals\", \"not equals\", \"contains\", \"starts with\", \"ends with\"],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=False,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True Route\", name=\"true_result\", method=\"true_response\"),\n        Output(display_name=\"False Route\", name=\"false_result\", method=\"false_response\"),\n    ]\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, case_sensitive: bool) -> bool:\n        if not case_sensitive:\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        elif operator == \"not equals\":\n            return input_text != match_text\n        elif operator == \"contains\":\n            return match_text in input_text\n        elif operator == \"starts with\":\n            return input_text.startswith(match_text)\n        elif operator == \"ends with\":\n            return input_text.endswith(match_text)\n        return False\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"true_result\")\n            return None  # type: ignore\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(self.input_text, self.match_text, self.operator, self.case_sensitive)\n        if not result:\n            self.status = self.message\n            return self.message\n        else:\n            self.stop(\"false_result\")\n            return None  # type: ignore\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "message": {
                  "info": "The message to pass through either route.",
                  "list": false,
                  "name": "message",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Message",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "operator": {
                  "info": "The operator to apply for comparing the texts.",
                  "name": "operator",
                  "show": true,
                  "type": "str",
                  "value": "equals",
                  "dynamic": false,
                  "options": [
                    "equals",
                    "not equals",
                    "contains",
                    "starts with",
                    "ends with"
                  ],
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Operator",
                  "trace_as_metadata": true
                },
                "input_text": {
                  "info": "The primary text input for the operation.",
                  "list": false,
                  "name": "input_text",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Input Text",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "match_text": {
                  "info": "The text input to compare against.",
                  "list": false,
                  "name": "match_text",
                  "show": true,
                  "type": "str",
                  "value": "T",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Match Text",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "case_sensitive": {
                  "info": "If true, the comparison will be case sensitive.",
                  "list": false,
                  "name": "case_sensitive",
                  "show": true,
                  "type": "bool",
                  "value": false,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Case Sensitive",
                  "trace_as_metadata": true
                }
              },
              "description": "Routes an input message to a corresponding output based on text comparison.",
              "field_order": [
                "input_text",
                "match_text",
                "operator",
                "case_sensitive",
                "message"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "Conditional Router",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "ConditionalRouter"
          },
          "type": "genericNode",
          "width": 384,
          "height": 573,
          "dragging": false,
          "position": {
            "x": 1661.217374679966,
            "y": -450.2704751763318
          },
          "selected": false,
          "positionAbsolute": {
            "x": 1661.217374679966,
            "y": -450.2704751763318
          }
        },
        {
          "id": "ChatOutput-ZfNkT",
          "data": {
            "id": "ChatOutput-ZfNkT",
            "node": {
              "beta": false,
              "icon": "ChatOutput",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "message",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "message_response",
                  "selected": "Message",
                  "display_name": "Message"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "sender": {
                  "info": "Type of sender.",
                  "name": "sender",
                  "show": true,
                  "type": "str",
                  "value": "Machine",
                  "dynamic": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Sender Type",
                  "trace_as_metadata": true
                },
                "session_id": {
                  "info": "Session ID for the message.",
                  "list": false,
                  "name": "session_id",
                  "show": true,
                  "type": "str",
                  "value": "1",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Session ID",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "input_value": {
                  "info": "Message to be passed as output.",
                  "list": false,
                  "name": "input_value",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Text",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "sender_name": {
                  "info": "Name of the sender.",
                  "list": false,
                  "name": "sender_name",
                  "show": true,
                  "type": "str",
                  "value": "AI",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Sender Name",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "data_template": {
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "list": false,
                  "name": "data_template",
                  "show": true,
                  "type": "str",
                  "value": "{text}",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Data Template",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "store_message": {
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "store_message",
                  "show": true,
                  "type": "bool",
                  "value": true,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Store Messages",
                  "trace_as_metadata": true
                }
              },
              "description": "Display a chat message in the Playground.",
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "ChatOutput"
          },
          "type": "genericNode",
          "width": 384,
          "height": 403,
          "dragging": false,
          "position": {
            "x": 3373.2173852157807,
            "y": -355.37494858235254
          },
          "selected": false,
          "positionAbsolute": {
            "x": 3373.2173852157807,
            "y": -355.37494858235254
          }
        },
        {
          "id": "UniOpenAICompatibleModel-KUPOm",
          "data": {
            "id": "UniOpenAICompatibleModel-KUPOm",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "text_output",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "text_response",
                  "selected": "Message",
                  "display_name": "文本"
                },
                {
                  "name": "model_output",
                  "cache": true,
                  "types": [
                    "LanguageModel"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "build_model",
                  "selected": "LanguageModel",
                  "display_name": "语言模型"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\nimport os\n\nfrom langfuse import Langfuse\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    StrInput,\n)\n\nfrom langchain_core.language_models.llms import LLM\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.custom import Component\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.field.base import Output\nimport json\nimport warnings\nfrom typing import Optional, Union\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniOpenAICompatibleModelComponent(LCModelComponent):\n    display_name = \"OpenAI Compatible\"\n    description = \"使用OpenAI大语言模型生成文本。\"\n    icon = \"OpenAI\"\n    name = \"UniOpenAICompatibleModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"输入\",value=\"\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"最大Token数\",\n            advanced=False,\n            info=\"能够生成的最大token数量，设置为0表示不限制token数量。\",\n        ),\n        StrInput(\n            name=\"model_name\",\n            display_name=\"模型名称\",\n            info=\"模型的名称，如果不标注则默认为‘chatglm3’。\",\n            value=\"chatglm3\",\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"API Base\",\n            value=\"http://10.0.50.33:9997/v1\",\n            info=\"OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。\",\n        ),\n        StrInput(\n            name=\"openai_api_key\",\n            display_name=\"API Key\",\n            info=\"填写 OpenAI API 密匙以使用OpenAI模型。\",\n            value=\"sk-2c3a4cb458884f9897529d26a44f403f\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"温度\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"流式生成\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"系统消息\",\n            info=\"传递给模型的系统消息。\",\n            advanced=True,\n        )\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        myopenai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        openai_api_base = self.openai_api_base or \"http://10.0.50.33:9997/v1\"\n        try:\n            output = ChatOpenAI(model=model_name,base_url=openai_api_base,openai_api_base=openai_api_base,openai_api_key=myopenai_api_key,model_name=model_name,openai_proxy=\"\",temperature=temperature)\n        except Exception as e:\n            raise ValueError(\"无法初始化 ChatOpenAI LLM.\") from e\n        #\n        return output  # type: ignore\n    #end\n    def text_response(self) -> Message:\n        input_value = self.input_value\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n        result = self.get_chat_result(output, stream, input_value, system_message)\n        self.status = result\n        return result\n    #\n    \n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: Optional[str] = None,\n    ):\n        messages: list[Union[BaseMessage]] = []\n        if not input_value and not system_message:\n            raise ValueError(\"向模型所发消息为空。\")\n        if system_message:\n            messages.append(SystemMessage(content=system_message))\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n                    #\n            else:\n                messages.append(HumanMessage(content=input_value))\n        inputs: Union[list, dict] = messages or {}\n        try:\n            runnable = runnable.with_config( \n                {\"run_name\": self.display_name, \"project_name\": self.tracing_service.project_name}\n            )\n            if stream:\n                return runnable.stream(inputs) \n            else:\n                #myLangfuse = Langfuse(secret_key=\"sk-lf-56f301e0-82c4-44c3-bee2-7bac283c984b\",public_key=\"pk-lf-96f4a175-d1f9-4a69-9d8f-f0559228fbb7\",host=\"http://10.0.53.214:3000\")\n                myLangfuse = Langfuse(secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),host=os.getenv(\"LANGFUSE_HOST\"))\n                trace = myLangfuse.trace(name='大模型trace',user_id=\"LLM\")\n                langfuse_handler_trace = trace.get_langchain_handler()\n                message = runnable.invoke(inputs,config={\"callbacks\": [langfuse_handler_trace]})\n                result = message.content if hasattr(message, \"content\") else message\n                if isinstance(message, AIMessage):\n                    status_message = self.build_status_message(message)\n                    self.status = status_message\n                elif isinstance(result, dict):\n                    result = json.dumps(message, indent=4)\n                    self.status = result\n                else:\n                    self.status = result\n                return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise e\n        #\n    #def",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "stream": {
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "list": false,
                  "name": "stream",
                  "show": true,
                  "type": "bool",
                  "value": true,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "流式生成",
                  "trace_as_metadata": true
                },
                "max_tokens": {
                  "info": "能够生成的最大token数量，设置为0表示不限制token数量。",
                  "list": false,
                  "name": "max_tokens",
                  "show": true,
                  "type": "int",
                  "value": "16000",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "最大Token数",
                  "trace_as_metadata": true
                },
                "model_name": {
                  "info": "模型的名称，如果不标注则默认为‘chatglm3’。",
                  "list": false,
                  "name": "model_name",
                  "show": true,
                  "type": "str",
                  "value": "glm4-chat",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "模型名称",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "input_value": {
                  "info": "",
                  "list": false,
                  "name": "input_value",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "输入",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "temperature": {
                  "info": "",
                  "list": false,
                  "name": "temperature",
                  "show": true,
                  "type": "float",
                  "value": 0.1,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "温度",
                  "trace_as_metadata": true
                },
                "openai_api_key": {
                  "info": "填写 OpenAI API 密匙以使用OpenAI模型。",
                  "list": false,
                  "name": "openai_api_key",
                  "show": true,
                  "type": "str",
                  "value": "$llm_api_key$",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "API Key",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "system_message": {
                  "info": "传递给模型的系统消息。",
                  "list": false,
                  "name": "system_message",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "系统消息",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "openai_api_base": {
                  "info": "OpenAI兼容版的API基础URL。默认为 http://10.0.50.33:9997/v1. 您也可以更改此项来使用其他API，例如JinaChat, LocalAI 和 Prem。",
                  "list": false,
                  "name": "openai_api_base",
                  "show": true,
                  "type": "str",
                  "value": "$llm_url$",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "API Base",
                  "load_from_db": false,
                  "trace_as_metadata": true
                }
              },
              "description": "使用OpenAI大语言模型生成文本。",
              "field_order": [
                "input_value",
                "max_tokens",
                "model_name",
                "openai_api_base",
                "openai_api_key",
                "temperature",
                "stream",
                "system_message"
              ],
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI Compatible",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "UniOpenAICompatibleModel"
          },
          "type": "genericNode",
          "width": 384,
          "height": 863,
          "dragging": false,
          "position": {
            "x": 2814.7654390900675,
            "y": -656.5130239540974
          },
          "selected": false,
          "positionAbsolute": {
            "x": 2814.7654390900675,
            "y": -656.5130239540974
          }
        },
        {
          "id": "ChatInput-tFUGg",
          "data": {
            "id": "ChatInput-tFUGg",
            "node": {
              "beta": false,
              "icon": "ChatInput",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "message",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "message_response",
                  "selected": "Message",
                  "display_name": "Message"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "files": {
                  "info": "Files to be sent with the message.",
                  "list": true,
                  "name": "files",
                  "show": true,
                  "type": "file",
                  "value": "",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "file_path": "",
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Files",
                  "trace_as_metadata": true
                },
                "sender": {
                  "info": "Type of sender.",
                  "name": "sender",
                  "show": true,
                  "type": "str",
                  "value": "User",
                  "dynamic": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Sender Type",
                  "trace_as_metadata": true
                },
                "session_id": {
                  "info": "Session ID for the message.",
                  "list": false,
                  "name": "session_id",
                  "show": true,
                  "type": "str",
                  "value": "1",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Session ID",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "input_value": {
                  "info": "Message to be passed as input.",
                  "list": false,
                  "name": "input_value",
                  "show": true,
                  "type": "str",
                  "value": "博士后",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Text",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "sender_name": {
                  "info": "Name of the sender.",
                  "list": false,
                  "name": "sender_name",
                  "show": true,
                  "type": "str",
                  "value": "User",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "Sender Name",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "store_message": {
                  "info": "Store the message in the history.",
                  "list": false,
                  "name": "store_message",
                  "show": true,
                  "type": "bool",
                  "value": true,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Store Messages",
                  "trace_as_metadata": true
                }
              },
              "description": "Get chat inputs from the Playground.",
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "ChatInput"
          },
          "type": "genericNode",
          "width": 384,
          "height": 403,
          "dragging": false,
          "position": {
            "x": -533.1091943125101,
            "y": 386.6241903772259
          },
          "selected": false,
          "positionAbsolute": {
            "x": -533.1091943125101,
            "y": 386.6241903772259
          }
        },
        {
          "id": "UniParseData-55eqf",
          "data": {
            "id": "UniParseData-55eqf",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniParseDataComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "text",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "parse_data",
                  "selected": "Message",
                  "display_name": "文本"
                }
              ],
              "template": {
                "sep": {
                  "info": "",
                  "list": false,
                  "name": "sep",
                  "show": true,
                  "type": "str",
                  "value": "\n",
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Separator",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\nfrom axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\nclass UniParseDataComponent(Component):\n    display_name = \"解析数据\"\n    description = \"根据指定的模板将数据转换为纯文本。\"\n    icon = \"braces\"\n    name = \"UniParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"数据\", info=\"需要转化为文本的数据。\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"模版\",\n            info=\"用于格式化数据的模板。它可以包含{text}，{sender}或消息数据中的任何其他键。\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"文本\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniParseDataComponent.png')\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "data": {
                  "info": "需要转化为文本的数据。",
                  "list": false,
                  "name": "data",
                  "show": true,
                  "type": "other",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Data"
                  ],
                  "placeholder": "",
                  "display_name": "数据",
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "_type": "Component",
                "template": {
                  "info": "用于格式化数据的模板。它可以包含{text}，{sender}或消息数据中的任何其他键。",
                  "list": false,
                  "name": "template",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "模版",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                }
              },
              "description": "根据指定的模板将数据转换为纯文本。",
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "解析数据",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "UniParseData"
          },
          "type": "genericNode",
          "width": 384,
          "height": 357,
          "dragging": false,
          "position": {
            "x": 475.23476198985986,
            "y": -338.97973683950124
          },
          "selected": false,
          "positionAbsolute": {
            "x": 475.23476198985986,
            "y": -338.97973683950124
          }
        },
        {
          "id": "UniWeaviateQuery-HGzB4",
          "data": {
            "id": "UniWeaviateQuery-HGzB4",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniWeaviateQueryComponent.png",
              "edited": false,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "base_retriever",
                  "cache": true,
                  "types": [
                    "Retriever"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "build_base_retriever",
                  "selected": "Retriever",
                  "display_name": "Retriever"
                },
                {
                  "name": "search_results",
                  "cache": true,
                  "types": [
                    "Data"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "search_documents",
                  "selected": "Data",
                  "display_name": "查询结果"
                },
                {
                  "name": "vector_store",
                  "cache": true,
                  "types": [
                    "VectorStore"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "cast_vector_store",
                  "selected": "VectorStore",
                  "display_name": "向量存储"
                }
              ],
              "template": {
                "url": {
                  "info": "",
                  "list": false,
                  "name": "url",
                  "show": true,
                  "type": "str",
                  "value": "$weaviate_url$",
                  "dynamic": false,
                  "advanced": false,
                  "required": true,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Weaviate URL",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "import json\nfrom typing import List\nimport requests\nimport weaviate\nfrom langchain_community.vectorstores import Weaviate\nfrom langchain.utils.math import cosine_similarity\nfrom langchain_core.documents import Document\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.inputs import FloatInput\nfrom axiestudio.io import BoolInput, HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.MinioUtils import MinioUtils\n\n\nclass UniWeaviateQueryVectorStoreComponent(LCVectorStoreComponent):\n    import warnings\n    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n    display_name = \"UniWeaviateQuery\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate\"\n    name = \"UniWeaviateQuery\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://10.0.53.214:19080\", required=True),\n        MultilineInput(name=\"api_key\", display_name=\"API Key\"),\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"text_key\", display_name=\"向量化字段\", value=\"text\"),\n        MultilineInput(name=\"search_query\", display_name=\"查询请求\"),\n        # 指定属性的过滤\n        MultilineInput(name=\"filter_conditions\", display_name=\"过滤条件\"),\n        # 输出结果的属性配置\n        MultilineInput(name=\"output_fields\", display_name=\"输出字段\"),\n        StrInput(\n            name=\"rerank_url\",\n            display_name=\"Rerank API Base\",\n            value=\"http://10.0.50.33:9997/v1/rerank\"\n        ),\n        StrInput(\n            name=\"rerank_model\",\n            display_name=\"Rerank Model\",\n            value=\"bge-reranker-large\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(name=\"append_data\", display_name=\"Append data,do not delete existing documents\",value=False),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(name=\"number_of_results\", display_name=\"Top K\", value=4),\n        FloatInput(name=\"score\", display_name=\"score\", value=0.3),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n    def __init__(self, **kwargs):\n        # 调用父类的初始化方法\n        super().__init__(**kwargs)\n        self.icon= MinioUtils().get_full_path('zy-icons', 'UniWeaviateQueryComponent.png')\n    def build_vector_store(self) -> Weaviate:\n        return self._build_weaviate()\n\n    def _build_weaviate(self) -> Weaviate:\n        #如果有api_key说明连接weaviate需要auth\n        if len(self.api_key)>10:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n        #\n        # 定义weaviate\n        return Weaviate(\n            client=client,\n            index_name=self.index_name.title(),\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_weaviate()\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            #对查询的文本做嵌入\n            embedded_query = vector_store._embedding.embed_query(self.search_query)\n            #获取用户自定义查询字段\n            if self.output_fields and isinstance(self.output_fields, str):\n                # 将逗号分割的字符串拆分为列表\n                outputfields = self.output_fields.split(',')\n                # 增加必填字段‘text’\n                outputfields.append('text')\n            else:\n                # 结果属性不过滤 查询所有属性结果\n                mytable = vector_store._client.schema.get(vector_store._index_name)\n                outputfields = [item['name'] for item in mytable['properties']]\n            #获取用户自定义查询条件\n            if self.filter_conditions and isinstance(self.filter_conditions, str):\n                filter_conditions = json.loads(self.filter_conditions)\n                #根据查询条件构建query对象\n                query_obj= vector_store._client.query.get(vector_store._index_name,outputfields).with_where(filter_conditions)\n            else:\n                # 发送查询请求\n                query_obj = vector_store._client.query.get(vector_store._index_name, outputfields)\n            #拼接search_query并进行向量化检索\n            result =(query_obj.with_near_vector({\"vector\": embedded_query}).with_limit(self.number_of_results).with_additional([\"distance\"]).do())\n            print(result)\n            #计算score\n            docs = []\n            contents=[]\n            similarity=[]\n            #根据用户自定义socre过滤数据\n            for res in result[\"data\"][\"Get\"][vector_store._index_name]:\n                mytext = res.pop('text')\n                additional=res.pop('_additional')\n                contents.append(mytext)\n                myscore=round(1-additional['distance'],5)\n                res['score']=myscore\n                #docs.append(Document(page_content=mytext, metadata=res))\n                docs.append({\"text\":mytext,\"metadata\":res,\"score\":myscore})\n                similarity.append(myscore)\n            #enddef\n            if(len(contents)==0):\n                data = docs_to_data([Document(page_content=\"None\", metadata={\"answer\":\"None\"})])\n                self.status = data\n                return data\n            #\n            #prompt_embeddings = vector_store._embedding.embed_documents(contents)\n            #similarity = cosine_similarity([embedded_query], prompt_embeddings)[0]\n            print(similarity)\n            count_ok=-1\n            for i in range(len(similarity)):\n                if(similarity[i]<self.score):\n                    count_ok=i\n                    break\n                #endif\n            #\n            if(count_ok==0):\n                data = docs_to_data([Document(page_content=\"None\", metadata={\"answer\":\"None\"})])\n                self.status = data\n                return data\n            elif(count_ok<0):\n                count_ok=len(similarity)\n            #\n            docs=docs[0:count_ok]\n            if(len(self.rerank_url)<4):\n                docs4=[]\n                for item in docs:\n                    docs4.append(Document(page_content=item['text'], metadata=item['metadata']))\n                #\n                data = docs_to_data(docs4)\n                self.status = data\n                return data\n\n            #print(count_ok)\n            contents=contents[0:count_ok]\n            rerankdata = {\n                \"model\": self.rerank_model,\n                \"query\": self.search_query,\n                \"documents\":contents,\n            }\n            response = requests.post(self.rerank_url,json=rerankdata)\n            response_dict = response.json()\n            results=response_dict['results']\n            score_dic={}\n            for item in results:\n                score_dic[item['index']]=item['relevance_score']\n            #endfor\n            for i in range(len(docs)):\n                docs[i]['score']=round(score_dic[i]*100,3)\n            #endfor\n            docs2=list(sorted(docs,key=lambda x:x[\"score\"],reverse=True))\n            docs3=[]\n            for item in docs2:\n                docs3.append(Document(page_content=item['text'], metadata=item['metadata']))\n            #\n            #print(docs3)\n            data = docs_to_data(docs3)\n            self.status = data\n            return data\n        else:\n            return []\n        #\n    #enddef\n#",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "score": {
                  "info": "",
                  "list": false,
                  "name": "score",
                  "show": true,
                  "type": "float",
                  "value": "0.1",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "score",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "api_key": {
                  "info": "",
                  "list": false,
                  "name": "api_key",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "API Key",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "text_key": {
                  "info": "",
                  "list": false,
                  "name": "text_key",
                  "show": true,
                  "type": "str",
                  "value": "text",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "向量化字段",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "embedding": {
                  "info": "",
                  "list": false,
                  "name": "embedding",
                  "show": true,
                  "type": "other",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "placeholder": "",
                  "display_name": "Embedding",
                  "trace_as_metadata": true
                },
                "index_name": {
                  "info": "",
                  "list": false,
                  "name": "index_name",
                  "show": true,
                  "type": "str",
                  "value": "$document_class$",
                  "dynamic": false,
                  "advanced": false,
                  "required": true,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Index Name",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "rerank_url": {
                  "info": "",
                  "list": false,
                  "name": "rerank_url",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Rerank API Base",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "append_data": {
                  "info": "",
                  "list": false,
                  "name": "append_data",
                  "show": true,
                  "type": "bool",
                  "value": false,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Append data,do not delete existing documents",
                  "trace_as_metadata": true
                },
                "ingest_data": {
                  "info": "",
                  "list": true,
                  "name": "ingest_data",
                  "show": true,
                  "type": "other",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Data"
                  ],
                  "placeholder": "",
                  "display_name": "Ingest Data",
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "rerank_model": {
                  "info": "",
                  "list": false,
                  "name": "rerank_model",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Rerank Model",
                  "load_from_db": false,
                  "trace_as_metadata": true
                },
                "search_query": {
                  "info": "",
                  "list": false,
                  "name": "search_query",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "查询请求",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "output_fields": {
                  "info": "",
                  "list": false,
                  "name": "output_fields",
                  "show": true,
                  "type": "str",
                  "value": "title,source,summary",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "输出字段",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "search_by_text": {
                  "info": "",
                  "list": false,
                  "name": "search_by_text",
                  "show": true,
                  "type": "bool",
                  "value": false,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Search By Text",
                  "trace_as_metadata": true
                },
                "filter_conditions": {
                  "info": "",
                  "list": false,
                  "name": "filter_conditions",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "multiline": true,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "过滤条件",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                },
                "number_of_results": {
                  "info": "",
                  "list": false,
                  "name": "number_of_results",
                  "show": true,
                  "type": "int",
                  "value": 4,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "Top K",
                  "trace_as_metadata": true
                }
              },
              "description": "Weaviate Vector Store with search capabilities",
              "field_order": [
                "url",
                "api_key",
                "index_name",
                "text_key",
                "search_query",
                "filter_conditions",
                "output_fields",
                "rerank_url",
                "rerank_model",
                "ingest_data",
                "append_data",
                "embedding",
                "number_of_results",
                "score",
                "search_by_text"
              ],
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "UniWeaviateQuery",
              "output_types": [],
              "custom_fields": {},
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate",
              "conditional_paths": []
            },
            "type": "UniWeaviateQuery",
            "description": "Weaviate Vector Store with search capabilities",
            "display_name": "UniWeaviateQuery"
          },
          "type": "genericNode",
          "width": 384,
          "height": 1461,
          "dragging": false,
          "position": {
            "x": 2309.199181976612,
            "y": 3.479518509313209
          },
          "selected": false,
          "positionAbsolute": {
            "x": 2309.199181976612,
            "y": 3.479518509313209
          }
        },
        {
          "id": "UniStream-Dh1Qu",
          "data": {
            "id": "UniStream-Dh1Qu",
            "node": {
              "beta": false,
              "icon": "/zy-icons/UniOpenAICompatibleModelComponent.png",
              "edited": true,
              "frozen": false,
              "pinned": false,
              "outputs": [
                {
                  "name": "text_output",
                  "cache": true,
                  "types": [
                    "Message"
                  ],
                  "value": "__UNDEFINED__",
                  "method": "text_response",
                  "selected": "Message",
                  "display_name": "文本"
                }
              ],
              "template": {
                "code": {
                  "info": "",
                  "list": false,
                  "name": "code",
                  "show": true,
                  "type": "code",
                  "value": "# -*- coding: utf-8 -*-\r\nimport json\r\nimport random\r\nimport time\r\n\r\nfrom axiestudio.inputs import (\r\n    MessageTextInput, IntInput, StrInput, FloatInput, BoolInput,\r\n)\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.template.field.base import Output\r\nfrom typing import Iterator\r\nfrom axiestudio.utils.MinioUtils import MinioUtils\r\n\r\n\r\nclass UniStream(Component):\r\n    display_name = \"stream转换器\"\r\n    description = \"将文本转为stream\"\r\n    icon = \"OpenAI\"\r\n    name = \"UniStream\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"system_message\", display_name=\"系统消息\", info=\"系统消息\", advanced=False\r\n        ),\r\n        FloatInput(\r\n            name=\"min_delay\",\r\n            display_name=\"min_delay\",\r\n            value=0.03,\r\n            advanced=True,\r\n        ),\r\n        FloatInput(\r\n            name=\"max_delay\",\r\n            display_name=\"max_delay\",\r\n            value=0.1,\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"max_n\",\r\n            display_name=\"max_n\",\r\n            value=20,\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"stream\",\r\n            value=True,\r\n            advanced=False,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"文本\", name=\"text_output\", method=\"text_response\")\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        # 调用父类的初始化方法\r\n        super().__init__(**kwargs)\r\n        self.icon = MinioUtils().get_full_path('zy-icons', 'UniOpenAICompatibleModelComponent.png')\r\n\r\n    def text_response(self) -> Message:\r\n        if self.stream:\r\n            result = self.get_chat_result2()\r\n            self.status = result\r\n            return result\r\n        else:\r\n            self.status = self.system_message\r\n            return self.system_message\r\n\r\n    def check_type(self, s):\r\n        try:\r\n            parsed = json.loads(s)\r\n            if isinstance(parsed, list):\r\n                return \"list\"\r\n            elif isinstance(parsed, dict):\r\n                return \"dict\"\r\n            else:\r\n                return \"str\"\r\n        except json.JSONDecodeError:\r\n            return \"str\"\r\n\r\n    def get_chat_result(self) -> Iterator[str]:\r\n        text = self.system_message\r\n        text_type = self.check_type(text)\r\n        if \"str\" == text_type:\r\n            return self.get_chat_result2(text)\r\n        elif \"dict\" == text_type:\r\n            my_dict = json.loads(text)\r\n            items = [dict(key, value) for key, value in my_dict.items()]\r\n            for item in items:\r\n                yield json.dumps(item, ensure_ascii=False)\r\n                # 随机延迟\r\n                delay = random.uniform(self.min_delay, self.max_delay)\r\n                time.sleep(delay)\r\n        elif \"list\" == text_type:\r\n            result = []\r\n            data = json.loads(text)\r\n            for item in data:\r\n                for key, value in item.items():\r\n                    yield json.dumps({key : value}, ensure_ascii=False)\r\n                    # 随机延迟\r\n                    delay = random.uniform(self.min_delay, self.max_delay)\r\n                    time.sleep(delay)\r\n\r\n    def get_chat_result2(self) -> Iterator[str]:\r\n        text = self.system_message\r\n        index = 0  # 记录当前处理的位置\r\n        while index < len(text):\r\n            # 确定每次要输出的字符数\r\n            chunk_size = random.randint(1, min(self.max_n, len(text) - index))\r\n\r\n            selected_chars = text[index:index + chunk_size]\r\n\r\n            # 输出选中的字符\r\n            for char in selected_chars:\r\n                yield char\r\n\r\n            index += chunk_size  # 更新索引\r\n\r\n            # 随机延迟\r\n            delay = random.uniform(self.min_delay, self.max_delay)\r\n            time.sleep(delay)\r\n",
                  "dynamic": true,
                  "advanced": true,
                  "password": false,
                  "required": true,
                  "fileTypes": [],
                  "file_path": "",
                  "multiline": true,
                  "title_case": false,
                  "placeholder": "",
                  "load_from_db": false
                },
                "_type": "Component",
                "max_n": {
                  "info": "",
                  "list": false,
                  "name": "max_n",
                  "show": true,
                  "type": "int",
                  "value": 20,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "max_n",
                  "trace_as_metadata": true
                },
                "stream": {
                  "info": "",
                  "list": false,
                  "name": "stream",
                  "show": true,
                  "type": "bool",
                  "value": true,
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "stream",
                  "trace_as_metadata": true
                },
                "max_delay": {
                  "info": "",
                  "list": false,
                  "name": "max_delay",
                  "show": true,
                  "type": "float",
                  "value": 0.1,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "max_delay",
                  "trace_as_metadata": true
                },
                "min_delay": {
                  "info": "",
                  "list": false,
                  "name": "min_delay",
                  "show": true,
                  "type": "float",
                  "value": 0.03,
                  "dynamic": false,
                  "advanced": true,
                  "required": false,
                  "title_case": false,
                  "placeholder": "",
                  "display_name": "min_delay",
                  "trace_as_metadata": true
                },
                "system_message": {
                  "info": "系统消息",
                  "list": false,
                  "name": "system_message",
                  "show": true,
                  "type": "str",
                  "value": "",
                  "dynamic": false,
                  "advanced": false,
                  "required": false,
                  "title_case": false,
                  "input_types": [
                    "Message"
                  ],
                  "placeholder": "",
                  "display_name": "系统消息",
                  "load_from_db": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true
                }
              },
              "description": "将文本转为stream",
              "field_order": [
                "system_message",
                "min_delay",
                "max_delay",
                "max_n",
                "stream"
              ],
              "base_classes": [
                "Message"
              ],
              "display_name": "stream转换器",
              "output_types": [],
              "custom_fields": {},
              "documentation": "",
              "conditional_paths": []
            },
            "type": "UniStream",
            "description": "将文本转为stream",
            "display_name": "stream转换器"
          },
          "type": "genericNode",
          "width": 384,
          "height": 385,
          "dragging": false,
          "position": {
            "x": 3530.0403556084,
            "y": 744.1045377368457
          },
          "selected": false
        }
      ],
      "viewport": {
        "x": 465.105220522385,
        "y": 320.52509061248657,
        "zoom": 0.1996910816548735
      }
    },
    "date_created": "2024-09-29T06:12:08.763Z",
    "date_updated": "2024-09-29T06:12:08.894Z",
    "status": "Public",
    "sort": null,
    "user_updated": "64bd3aa6-538a-4107-8754-c4a63e128385",
    "user_created": {
      "username": "huangxinghui",
      "first_name": "xinghui",
      "last_name": "huang",
      "id": "64bd3aa6-538a-4107-8754-c4a63e128385"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:54.415Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 132,
    "converter_version": "1.0.0"
  }
}