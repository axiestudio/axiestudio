{
  "id": "12413fd7-deae-4b29-b49b-da0cb49bb0ef",
  "name": "Vector Store RAG (2)",
  "description": "Visit https://docs.langflow.org/tutorials/rag-with-astradb for a detailed guide of this project.\nThis project give you both Ingestion and RAG in a single file. You'll need to visit https://astra.datastax.com/ to create an Astra DB instance, your Token and grab an API Endpoint.\nRunning this project requires you to add a file in the Files component, then define a Collection Name and click on the Play icon on the Astra DB component. \n\nAfter the ingestion ends you are ready to click on the Run button at the lower left corner and start asking questions about your data. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "1234",
    "first_name": "jack",
    "last_name": "zhu",
    "id": "4b9f6e29-04a3-417d-bd77-5087debade99",
    "full_name": "jack zhu"
  },
  "store_url": "https://www.langflow.store/store/component/12413fd7-deae-4b29-b49b-da0cb49bb0ef",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-08-01T10:19:50.674Z",
    "updated": "2024-08-01T10:19:50.733Z",
    "downloaded": "2025-08-19T17:50:05.919Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.7",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "data": {
          "id": "ChatInput-OWlie",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "pptx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "文件",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"文本\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"发送者角色\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"发送者姓名\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"进程号\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"文件\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"消息\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "给我介绍一下storm架构的内容",
                "name": "input_value",
                "display_name": "文本",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "发送者角色",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender_name",
                "display_name": "发送者姓名",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "进程号",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "从聊天框获取聊天输入。",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "聊天输入",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "消息",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": true
          },
          "type": "ChatInput",
          "description": "Get chat inputs from the Playground.",
          "display_name": "聊天输入"
        },
        "dragging": false,
        "height": 309,
        "id": "ChatInput-OWlie",
        "position": {
          "x": 611.4351861047734,
          "y": 200.00904515954315
        },
        "positionAbsolute": {
          "x": 611.4351861047734,
          "y": 200.00904515954315
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "ParseData-j2LzV",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "data",
                "display_name": "输入数据",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"输入数据\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"范式\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"分割器\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"文本\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        \n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "\n",
                "name": "sep",
                "display_name": "分割器",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "template",
                "display_name": "范式",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "将检索结果转换为格式化数据。",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "数据格式化",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "文本",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": true
          },
          "type": "ParseData",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "dragging": false,
        "height": 357,
        "id": "ParseData-j2LzV",
        "position": {
          "x": 1508.8317573148074,
          "y": 153.7368072611186
        },
        "positionAbsolute": {
          "x": 1508.8317573148074,
          "y": 153.7368072611186
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "提示词",
          "id": "Prompt-h6zCv",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(frontend_template=frontend_node, raw_template=current_build_config[\"template\"])\n        return frontend_node\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{上下文信息}\n\n---\n\n给定上述背景信息，请尽可能详细回答以下问题。\n\n在回答问题时，如果你引用了以上的背景信息, 请在回答的最后加以说明，并按照以下格式组织它们，例如：'答案': '你的答案', '文件路径': '你引用的文件路径', '页号': '文件中具体的页码' 。\n\n其中路径和页码信息使用背景信息中提供的内容表示，路径要精确到指定文件名，如第三章3.1.pptx。页码为一个数字。\n\n问题：{问题}\n\n答案：\n\n文件路径:\n\n页号:",
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt"
              },
              "上下文信息": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "上下文信息",
                "display_name": "上下文信息",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "问题": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "问题",
                "display_name": "问题",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "提示词",
            "documentation": "",
            "custom_fields": {
              "template": [
                "上下文信息",
                "问题"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": false,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 517,
        "id": "Prompt-h6zCv",
        "position": {
          "x": 2018.7404727448147,
          "y": 341.9151232146372
        },
        "positionAbsolute": {
          "x": 2018.7404727448147,
          "y": 341.9151232146372
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "ChatOutput-vmBD9",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\nfrom axiestudio.base.data.utils import  deal_with_video\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"文本\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"消息\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        print(self.input_value)\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        print(self.session_id)\n        print(\"1234544\")\n        deal_with_video(self.input_value)\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        print(message)\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "data_template",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "文本",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Machine",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "AI",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "聊天输出",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "消息",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": true
          },
          "type": "ChatOutput",
          "description": "Display a chat message in the Playground.",
          "display_name": "聊天输出"
        },
        "dragging": false,
        "height": 309,
        "id": "ChatOutput-vmBD9",
        "position": {
          "x": 3092.6556134037346,
          "y": 503.59650772032614
        },
        "positionAbsolute": {
          "x": 3092.6556134037346,
          "y": 503.59650772032614
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "data": {
          "id": "File-4OzQU",
          "node": {
            "template": {
              "_type": "Component",
              "path": {
                "trace_as_metadata": true,
                "file_path": "6c4b9a7b-e1c7-442a-b98a-2cd7287de034\\第三章3.1.pptx",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "pptx"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "path",
                "display_name": "文件路径",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx, pptx",
                "title_case": false,
                "type": "file"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data,  extract_text_from_ppt\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\nimport os\nfrom pptx import Presentation\nfrom cnocr import CnOcr\nfrom PIL import Image\nfrom io import BytesIO\nimport pandas as pd\n\n    \nclass FileComponent(Component):\n    display_name = \"文件\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n    if \"pptx\" not in TEXT_FILE_TYPES:\n        TEXT_FILE_TYPES.append(\"pptx\")\n    print(TEXT_FILE_TYPES)\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"文件路径\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"忽略报错\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"数据\", name=\"data\", method=\"load_file\"),\n    ]\n    \n\n        \n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        if extension == \"pptx\":\n            ocr = CnOcr()\n            data = extract_text_from_ppt(ocr, resolved_path)\n        else:\n            data = parse_text_file_to_data(resolved_path, silent_errors)\n            self.status = data if data else \"check\"\n        return data or Data()\n    \n    \n\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "silent_errors",
                "display_name": "忽略报错",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool"
              }
            },
            "description": "普通文件加载组件。",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "文件",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "数据",
                "method": "load_file",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "path",
              "silent_errors"
            ],
            "beta": false,
            "edited": true
          },
          "type": "File",
          "description": "A generic file loader.",
          "display_name": "文件"
        },
        "dragging": false,
        "height": 301,
        "id": "File-4OzQU",
        "position": {
          "x": 1825.9758551049765,
          "y": 1345.9763936100921
        },
        "positionAbsolute": {
          "x": 1825.9758551049765,
          "y": 1345.9763936100921
        },
        "selected": false,
        "type": "genericNode",
        "width": 384
      },
      {
        "id": "FAISS-fmnD5",
        "type": "genericNode",
        "position": {
          "x": 2732.0444134091613,
          "y": 1279.9226449468958
        },
        "data": {
          "type": "FAISS",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "嵌入模型",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "数据输入",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "allow_dangerous_deserialization": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "allow_dangerous_deserialization",
                "display_name": "Allow Dangerous Deserialization",
                "advanced": true,
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "title_case": false,
                "type": "bool"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"索引名\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"持久化地址\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"查询输入\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"数据输入\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"嵌入模型\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"结果数量\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n        print(self.ingest_data )\n        print(\"111\")\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "axiestudio_index",
                "name": "index_name",
                "display_name": "索引名",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4,
                "name": "number_of_results",
                "display_name": "结果数量",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "new",
                "name": "persist_directory",
                "display_name": "持久化地址",
                "advanced": false,
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "title_case": false,
                "type": "str"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_query",
                "display_name": "查询输入",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "FAISS 向量数据库。",
            "icon": "FAISS",
            "base_classes": [
              "Data",
              "Retriever"
            ],
            "display_name": "FAISS",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "index_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "edited": true
          },
          "id": "FAISS-fmnD5",
          "description": "FAISS Vector Store with search capabilities",
          "display_name": "FAISS"
        },
        "selected": false,
        "width": 384,
        "height": 625,
        "positionAbsolute": {
          "x": 2732.0444134091613,
          "y": 1279.9226449468958
        },
        "dragging": false
      },
      {
        "id": "FAISS-YhzNk",
        "type": "genericNode",
        "position": {
          "x": 1100.6458731644366,
          "y": 521.8613591556086
        },
        "data": {
          "type": "FAISS",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "嵌入模型",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "数据输入",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "allow_dangerous_deserialization": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "allow_dangerous_deserialization",
                "display_name": "Allow Dangerous Deserialization",
                "advanced": true,
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                "title_case": false,
                "type": "bool"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"索引名\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"持久化地址\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"查询输入\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"数据输入\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"嵌入模型\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"检索器\",\n            name=\"base_retriever\",\n            method=\"build_base_retriever\",\n        ),\n        Output(\n            display_name=\"检索结果\",\n            name=\"search_results\",\n            method=\"search_documents\",\n        ),\n    ]\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n        print(self.ingest_data )\n        print(\"111\")\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "axiestudio_index",
                "name": "index_name",
                "display_name": "索引名",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4,
                "name": "number_of_results",
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int"
              },
              "persist_directory": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "new",
                "name": "persist_directory",
                "display_name": "持久化地址",
                "advanced": false,
                "dynamic": false,
                "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                "title_case": false,
                "type": "str"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_query",
                "display_name": "查询输入",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "FAISS 向量数据库。",
            "icon": "FAISS",
            "base_classes": [
              "Data",
              "Retriever"
            ],
            "display_name": "FAISS",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "检索器",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "检索结果",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "index_name",
              "persist_directory",
              "search_query",
              "ingest_data",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "edited": true
          },
          "id": "FAISS-YhzNk",
          "description": "FAISS Vector Store with search capabilities",
          "display_name": "FAISS"
        },
        "selected": false,
        "width": 384,
        "height": 625,
        "positionAbsolute": {
          "x": 1100.6458731644366,
          "y": 521.8613591556086
        },
        "dragging": false
      },
      {
        "id": "TongyiQwenChatModel-UOAMC",
        "type": "genericNode",
        "position": {
          "x": 2569.2016317250905,
          "y": 494.1308947988908
        },
        "data": {
          "type": "TongyiQwenChatModel",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.chat_models.tongyi import ChatTongyi\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing.constants import LanguageModel\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, MessageTextInput, SecretStrInput\n\n\nclass TongyiQwenComponent(LCModelComponent):\n    display_name: str = \"Tongyi Qwen\"\n    description: str = \"Generate text using Tongyi Qwen.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/chat/tongyi\"\n    icon = \"TongyiQwen\"\n    name = \"TongyiQwenChatModel\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"输入\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"模型名称\",\n            options=[\n                \"qwen-turbo\",\n                \"qwen-turbo-0624\",\n                \"qwen-plus\",\n                \"qwen-plus-0624\",\n                \"qwen-max\",\n                \"qwen-max-0428\",\n                \"qwen-max-longcontext\",\n            ],\n            info=\"https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction\",\n            value=\"qwen-turbo\",\n        ),\n        SecretStrInput(\n            name=\"tongyi_api_key\",\n            display_name=\"通义 API key\",\n            info=\"which you could get from  https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top p\",\n            value=0.8,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"温度\",\n            value=0.95,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=STREAM_INFO_TEXT,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n#     outputs = [\n#     Output(display_name=\"文本\", name=\"text_output\", method=\"text_response\"),\n#     Output(display_name=\"大模型\", name=\"model_output\", method=\"build_model\"),\n# ]\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        tongyi_api_key = self.tongyi_api_key\n        top_p = self.top_p\n        temperature = self.temperature\n\n        try:\n            output = ChatTongyi(  # type: ignore\n                model=model,\n                api_key=SecretStr(tongyi_api_key),\n                top_p=top_p,\n                temperature=temperature,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Tongyi QWen API.\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "输入",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "qwen-turbo",
                  "qwen-turbo-0624",
                  "qwen-plus",
                  "qwen-plus-0624",
                  "qwen-max",
                  "qwen-max-0428",
                  "qwen-max-longcontext"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "qwen-turbo",
                "name": "model",
                "display_name": "模型名称",
                "advanced": false,
                "dynamic": false,
                "info": "https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction",
                "title_case": false,
                "type": "str"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.95,
                "name": "temperature",
                "display_name": "温度",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              },
              "tongyi_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "tongyi_api_key",
                "display_name": "通义 API key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "which you could get from  https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0.8,
                "name": "top_p",
                "display_name": "Top p",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "使用通义千问模型生成结果。",
            "icon": "TongyiQwen",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "通义千问",
            "documentation": "https://python.langchain.com/docs/integrations/chat/tongyi",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "model",
              "tongyi_api_key",
              "top_p",
              "temperature",
              "stream",
              "system_message"
            ],
            "beta": false,
            "edited": true
          },
          "id": "TongyiQwenChatModel-UOAMC",
          "description": "Generate text using Tongyi Qwen.",
          "display_name": "通义千问"
        },
        "selected": false,
        "width": 384,
        "height": 575,
        "positionAbsolute": {
          "x": 2569.2016317250905,
          "y": 494.1308947988908
        },
        "dragging": false
      },
      {
        "id": "BaichuanEmbeddings-96pml",
        "type": "genericNode",
        "position": {
          "x": 564.7364299468284,
          "y": 884.6486237845538
        },
        "data": {
          "type": "BaichuanEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "baichuan_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "baichuan_api_key",
                "display_name": "APIKey",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1.types import SecretStr\nfrom langchain_community.embeddings import BaichuanTextEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\n\n\nclass BaichuanEmbeddingsComponent(LCModelComponent):\n    display_name = \"百川嵌入模型\"\n    description = \"Baichuan Text Embeddings.\"\n    documentation = \"https://platform.baichuan-ai.com/docs/text-Embedding\"\n    icon = \"Baichuan\"\n    name = \"BaichuanEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"baichuan_api_key\", display_name=\"APIKey\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.baichuan_api_key:\n            raise ValueError(\"API Key is required\")\n        api_key = SecretStr(self.baichuan_api_key)\n\n        return BaichuanTextEmbeddings(baichuan_api_key=api_key)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Baichuan Text Embeddings.",
            "icon": "Baichuan",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "百川嵌入模型",
            "documentation": "https://platform.baichuan-ai.com/docs/text-Embedding",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "baichuan_api_key"
            ],
            "beta": false,
            "edited": false
          },
          "id": "BaichuanEmbeddings-96pml",
          "description": "Baichuan Text Embeddings.",
          "display_name": "百川嵌入模型"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "dragging": false,
        "positionAbsolute": {
          "x": 564.7364299468284,
          "y": 884.6486237845538
        }
      },
      {
        "id": "BaichuanEmbeddings-TKSpJ",
        "type": "genericNode",
        "position": {
          "x": 1860.886640442736,
          "y": 1873.785369175516
        },
        "data": {
          "type": "BaichuanEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "baichuan_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "baichuan_api_key",
                "display_name": "APIKey",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1.types import SecretStr\nfrom langchain_community.embeddings import BaichuanTextEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\n\n\nclass BaichuanEmbeddingsComponent(LCModelComponent):\n    display_name = \"百川嵌入模型\"\n    description = \"Baichuan Text Embeddings.\"\n    documentation = \"https://platform.baichuan-ai.com/docs/text-Embedding\"\n    icon = \"Baichuan\"\n    name = \"BaichuanEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"baichuan_api_key\", display_name=\"APIKey\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.baichuan_api_key:\n            raise ValueError(\"API Key is required\")\n        api_key = SecretStr(self.baichuan_api_key)\n\n        return BaichuanTextEmbeddings(baichuan_api_key=api_key)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Baichuan Text Embeddings.",
            "icon": "Baichuan",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "百川嵌入模型",
            "documentation": "https://platform.baichuan-ai.com/docs/text-Embedding",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "baichuan_api_key"
            ],
            "beta": false,
            "edited": true
          },
          "id": "BaichuanEmbeddings-TKSpJ",
          "description": "Baichuan Text Embeddings.",
          "display_name": "百川嵌入模型"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "FAISS-YhzNk",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-YhzNkœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-j2LzV",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-j2LzVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-j2LzV",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-YhzNk",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FAISS-YhzNk{œdataTypeœ:œFAISSœ,œidœ:œFAISS-YhzNkœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-j2LzV{œfieldNameœ:œdataœ,œidœ:œParseData-j2LzVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "Prompt-h6zCv",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-h6zCvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TongyiQwenChatModel-UOAMC",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TongyiQwenChatModel-UOAMC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-h6zCv",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-h6zCv{œdataTypeœ:œPromptœ,œidœ:œPrompt-h6zCvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-TongyiQwenChatModel-UOAMC{œfieldNameœ:œinput_valueœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "TongyiQwenChatModel-UOAMC",
        "sourceHandle": "{œdataTypeœ:œTongyiQwenChatModelœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-vmBD9",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-vmBD9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-vmBD9",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TongyiQwenChatModel",
            "id": "TongyiQwenChatModel-UOAMC",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TongyiQwenChatModel-UOAMC{œdataTypeœ:œTongyiQwenChatModelœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-vmBD9{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-vmBD9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ParseData-j2LzV",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-j2LzVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-h6zCv",
        "targetHandle": "{œfieldNameœ:œ上下文信息œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "上下文信息",
            "id": "Prompt-h6zCv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-j2LzV",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-j2LzV{œdataTypeœ:œParseDataœ,œidœ:œParseData-j2LzVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-h6zCv{œfieldNameœ:œ上下文信息œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ChatInput-OWlie",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-h6zCv",
        "targetHandle": "{œfieldNameœ:œ问题œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "问题",
            "id": "Prompt-h6zCv",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-OWlie",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-OWlie{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-h6zCv{œfieldNameœ:œ问题œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "File-4OzQU",
        "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-4OzQUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FAISS-fmnD5",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "FAISS-fmnD5",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "File",
            "id": "File-4OzQU",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-File-4OzQU{œdataTypeœ:œFileœ,œidœ:œFile-4OzQUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FAISS-fmnD5{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ChatInput-OWlie",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FAISS-YhzNk",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_query",
            "id": "FAISS-YhzNk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-OWlie",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-OWlie{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-FAISS-YhzNk{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "BaichuanEmbeddings-96pml",
        "sourceHandle": "{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-96pmlœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "FAISS-YhzNk",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-YhzNk",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "BaichuanEmbeddings",
            "id": "BaichuanEmbeddings-96pml",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-BaichuanEmbeddings-96pml{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-96pmlœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-YhzNk{œfieldNameœ:œembeddingœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "BaichuanEmbeddings-TKSpJ",
        "sourceHandle": "{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-TKSpJœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "FAISS-fmnD5",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-fmnD5",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "BaichuanEmbeddings",
            "id": "BaichuanEmbeddings-TKSpJ",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-BaichuanEmbeddings-TKSpJ{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-TKSpJœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-fmnD5{œfieldNameœ:œembeddingœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": -282.22009494310964,
      "y": -81.23992990353054,
      "zoom": 0.5000000000000007
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "File": {
      "count": 1
    },
    "FAISS": {
      "count": 2
    },
    "TongyiQwenChatModel": {
      "count": 1
    },
    "BaichuanEmbeddings": {
      "count": 2
    },
    "total": 10
  },
  "original": {
    "id": "12413fd7-deae-4b29-b49b-da0cb49bb0ef",
    "name": "Vector Store RAG (2)",
    "description": "Visit https://docs.langflow.org/tutorials/rag-with-astradb for a detailed guide of this project.\nThis project give you both Ingestion and RAG in a single file. You'll need to visit https://astra.datastax.com/ to create an Astra DB instance, your Token and grab an API Endpoint.\nRunning this project requires you to add a file in the Files component, then define a Collection Name and click on the Play icon on the Astra DB component. \n\nAfter the ingestion ends you are ready to click on the Run button at the lower left corner and start asking questions about your data.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "6",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "File": {
        "count": 1
      },
      "FAISS": {
        "count": 2
      },
      "TongyiQwenChatModel": {
        "count": 1
      },
      "BaichuanEmbeddings": {
        "count": 2
      },
      "total": 10
    },
    "last_tested_version": "1.0.7",
    "private": false,
    "data": {
      "nodes": [
        {
          "data": {
            "id": "ChatInput-OWlie",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "pptx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "文件",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"文本\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"发送者角色\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"发送者姓名\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"进程号\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"文件\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"消息\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "给我介绍一下storm架构的内容",
                  "name": "input_value",
                  "display_name": "文本",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "发送者角色",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender_name",
                  "display_name": "发送者姓名",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "进程号",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "从聊天框获取聊天输入。",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "聊天输入",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "消息",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": true
            },
            "type": "ChatInput",
            "description": "Get chat inputs from the Playground.",
            "display_name": "聊天输入"
          },
          "dragging": false,
          "height": 309,
          "id": "ChatInput-OWlie",
          "position": {
            "x": 611.4351861047734,
            "y": 200.00904515954315
          },
          "positionAbsolute": {
            "x": 611.4351861047734,
            "y": 200.00904515954315
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "ParseData-j2LzV",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "data",
                  "display_name": "输入数据",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"输入数据\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"范式\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"分割器\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"文本\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        \n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "\n",
                  "name": "sep",
                  "display_name": "分割器",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "template",
                  "display_name": "范式",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "将检索结果转换为格式化数据。",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "数据格式化",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "文本",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": true
            },
            "type": "ParseData",
            "description": "Convert Data into plain text following a specified template.",
            "display_name": "Parse Data"
          },
          "dragging": false,
          "height": 357,
          "id": "ParseData-j2LzV",
          "position": {
            "x": 1508.8317573148074,
            "y": 153.7368072611186
          },
          "positionAbsolute": {
            "x": 1508.8317573148074,
            "y": 153.7368072611186
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "提示词",
            "id": "Prompt-h6zCv",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(frontend_template=frontend_node, raw_template=current_build_config[\"template\"])\n        return frontend_node\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{上下文信息}\n\n---\n\n给定上述背景信息，请尽可能详细回答以下问题。\n\n在回答问题时，如果你引用了以上的背景信息, 请在回答的最后加以说明，并按照以下格式组织它们，例如：'答案': '你的答案', '文件路径': '你引用的文件路径', '页号': '文件中具体的页码' 。\n\n其中路径和页码信息使用背景信息中提供的内容表示，路径要精确到指定文件名，如第三章3.1.pptx。页码为一个数字。\n\n问题：{问题}\n\n答案：\n\n文件路径:\n\n页号:",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt"
                },
                "上下文信息": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "上下文信息",
                  "display_name": "上下文信息",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "问题": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "问题",
                  "display_name": "问题",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "提示词",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "上下文信息",
                  "问题"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": false,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "type": "Prompt"
          },
          "dragging": false,
          "height": 517,
          "id": "Prompt-h6zCv",
          "position": {
            "x": 2018.7404727448147,
            "y": 341.9151232146372
          },
          "positionAbsolute": {
            "x": 2018.7404727448147,
            "y": 341.9151232146372
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "ChatOutput-vmBD9",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.schema.message import Message\nfrom axiestudio.base.data.utils import  deal_with_video\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"文本\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"消息\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        print(self.input_value)\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        print(self.session_id)\n        print(\"1234544\")\n        deal_with_video(self.input_value)\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        print(message)\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "data_template",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "文本",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Machine",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "AI",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "聊天输出",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "消息",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": true
            },
            "type": "ChatOutput",
            "description": "Display a chat message in the Playground.",
            "display_name": "聊天输出"
          },
          "dragging": false,
          "height": 309,
          "id": "ChatOutput-vmBD9",
          "position": {
            "x": 3092.6556134037346,
            "y": 503.59650772032614
          },
          "positionAbsolute": {
            "x": 3092.6556134037346,
            "y": 503.59650772032614
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "data": {
            "id": "File-4OzQU",
            "node": {
              "template": {
                "_type": "Component",
                "path": {
                  "trace_as_metadata": true,
                  "file_path": "6c4b9a7b-e1c7-442a-b98a-2cd7287de034\\第三章3.1.pptx",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "pptx"
                  ],
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "path",
                  "display_name": "文件路径",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx, pptx",
                  "title_case": false,
                  "type": "file"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data,  extract_text_from_ppt\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\nimport os\nfrom pptx import Presentation\nfrom cnocr import CnOcr\nfrom PIL import Image\nfrom io import BytesIO\nimport pandas as pd\n\n    \nclass FileComponent(Component):\n    display_name = \"文件\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n    if \"pptx\" not in TEXT_FILE_TYPES:\n        TEXT_FILE_TYPES.append(\"pptx\")\n    print(TEXT_FILE_TYPES)\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"文件路径\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"忽略报错\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"数据\", name=\"data\", method=\"load_file\"),\n    ]\n    \n\n        \n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        if extension == \"pptx\":\n            ocr = CnOcr()\n            data = extract_text_from_ppt(ocr, resolved_path)\n        else:\n            data = parse_text_file_to_data(resolved_path, silent_errors)\n            self.status = data if data else \"check\"\n        return data or Data()\n    \n    \n\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "silent_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "silent_errors",
                  "display_name": "忽略报错",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, errors will not raise an exception.",
                  "title_case": false,
                  "type": "bool"
                }
              },
              "description": "普通文件加载组件。",
              "icon": "file-text",
              "base_classes": [
                "Data"
              ],
              "display_name": "文件",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "数据",
                  "method": "load_file",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "path",
                "silent_errors"
              ],
              "beta": false,
              "edited": true
            },
            "type": "File",
            "description": "A generic file loader.",
            "display_name": "文件"
          },
          "dragging": false,
          "height": 301,
          "id": "File-4OzQU",
          "position": {
            "x": 1825.9758551049765,
            "y": 1345.9763936100921
          },
          "positionAbsolute": {
            "x": 1825.9758551049765,
            "y": 1345.9763936100921
          },
          "selected": false,
          "type": "genericNode",
          "width": 384
        },
        {
          "id": "FAISS-fmnD5",
          "type": "genericNode",
          "position": {
            "x": 2732.0444134091613,
            "y": 1279.9226449468958
          },
          "data": {
            "type": "FAISS",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "嵌入模型",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "数据输入",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "allow_dangerous_deserialization": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "allow_dangerous_deserialization",
                  "display_name": "Allow Dangerous Deserialization",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                  "title_case": false,
                  "type": "bool"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"索引名\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"持久化地址\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"查询输入\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"数据输入\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"嵌入模型\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"结果数量\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n        print(self.ingest_data )\n        print(\"111\")\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "axiestudio_index",
                  "name": "index_name",
                  "display_name": "索引名",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4,
                  "name": "number_of_results",
                  "display_name": "结果数量",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "new",
                  "name": "persist_directory",
                  "display_name": "持久化地址",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                  "title_case": false,
                  "type": "str"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_query",
                  "display_name": "查询输入",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "FAISS 向量数据库。",
              "icon": "FAISS",
              "base_classes": [
                "Data",
                "Retriever"
              ],
              "display_name": "FAISS",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "index_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "allow_dangerous_deserialization",
                "embedding",
                "number_of_results"
              ],
              "beta": false,
              "edited": true
            },
            "id": "FAISS-fmnD5",
            "description": "FAISS Vector Store with search capabilities",
            "display_name": "FAISS"
          },
          "selected": false,
          "width": 384,
          "height": 625,
          "positionAbsolute": {
            "x": 2732.0444134091613,
            "y": 1279.9226449468958
          },
          "dragging": false
        },
        {
          "id": "FAISS-YhzNk",
          "type": "genericNode",
          "position": {
            "x": 1100.6458731644366,
            "y": 521.8613591556086
          },
          "data": {
            "type": "FAISS",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "嵌入模型",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "数据输入",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "allow_dangerous_deserialization": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "allow_dangerous_deserialization",
                  "display_name": "Allow Dangerous Deserialization",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.",
                  "title_case": false,
                  "type": "bool"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_community.vectorstores import FAISS\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\n    \"\"\"\n    FAISS Vector Store with search capabilities\n    \"\"\"\n\n    display_name: str = \"FAISS\"\n    description: str = \"FAISS Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\"\n    name = \"FAISS\"\n    icon = \"FAISS\"\n\n    inputs = [\n        StrInput(\n            name=\"index_name\",\n            display_name=\"索引名\",\n            value=\"axiestudio_index\",\n        ),\n        StrInput(\n            name=\"persist_directory\",\n            display_name=\"持久化地址\",\n            info=\"Path to save the FAISS index. It will be relative to where Langflow is running.\",\n        ),\n        MultilineInput(\n            name=\"search_query\",\n            display_name=\"查询输入\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"数据输入\",\n            is_list=True,\n        ),\n        BoolInput(\n            name=\"allow_dangerous_deserialization\",\n            display_name=\"Allow Dangerous Deserialization\",\n            info=\"Set to True to allow loading pickle files from untrusted sources. Only enable this if you trust the source of the data.\",\n            advanced=True,\n            value=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"嵌入模型\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"检索器\",\n            name=\"base_retriever\",\n            method=\"build_base_retriever\",\n        ),\n        Output(\n            display_name=\"检索结果\",\n            name=\"search_results\",\n            method=\"search_documents\",\n        ),\n    ]\n    def build_vector_store(self) -> FAISS:\n        \"\"\"\n        Builds the FAISS object.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to save the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        documents = []\n        print(self.ingest_data )\n        print(\"111\")\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        faiss = FAISS.from_documents(documents=documents, embedding=self.embedding)\n        faiss.save_local(str(path), self.index_name)\n\n        return faiss\n\n    def search_documents(self) -> List[Data]:\n        \"\"\"\n        Search for documents in the FAISS vector store.\n        \"\"\"\n        if not self.persist_directory:\n            raise ValueError(\"Folder path is required to load the FAISS index.\")\n        path = self.resolve_path(self.persist_directory)\n\n        vector_store = FAISS.load_local(\n            folder_path=path,\n            embeddings=self.embedding,\n            index_name=self.index_name,\n            allow_dangerous_deserialization=self.allow_dangerous_deserialization,\n        )\n\n        if not vector_store:\n            raise ValueError(\"Failed to load the FAISS index.\")\n\n        logger.debug(f\"Search input: {self.search_query}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            logger.debug(data)\n            return data  # Return the search results data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "axiestudio_index",
                  "name": "index_name",
                  "display_name": "索引名",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4,
                  "name": "number_of_results",
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int"
                },
                "persist_directory": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "new",
                  "name": "persist_directory",
                  "display_name": "持久化地址",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Path to save the FAISS index. It will be relative to where Langflow is running.",
                  "title_case": false,
                  "type": "str"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_query",
                  "display_name": "查询输入",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "FAISS 向量数据库。",
              "icon": "FAISS",
              "base_classes": [
                "Data",
                "Retriever"
              ],
              "display_name": "FAISS",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "检索器",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "检索结果",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "index_name",
                "persist_directory",
                "search_query",
                "ingest_data",
                "allow_dangerous_deserialization",
                "embedding",
                "number_of_results"
              ],
              "beta": false,
              "edited": true
            },
            "id": "FAISS-YhzNk",
            "description": "FAISS Vector Store with search capabilities",
            "display_name": "FAISS"
          },
          "selected": false,
          "width": 384,
          "height": 625,
          "positionAbsolute": {
            "x": 1100.6458731644366,
            "y": 521.8613591556086
          },
          "dragging": false
        },
        {
          "id": "TongyiQwenChatModel-UOAMC",
          "type": "genericNode",
          "position": {
            "x": 2569.2016317250905,
            "y": 494.1308947988908
          },
          "data": {
            "type": "TongyiQwenChatModel",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.chat_models.tongyi import ChatTongyi\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing.constants import LanguageModel\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, MessageTextInput, SecretStrInput\n\n\nclass TongyiQwenComponent(LCModelComponent):\n    display_name: str = \"Tongyi Qwen\"\n    description: str = \"Generate text using Tongyi Qwen.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/chat/tongyi\"\n    icon = \"TongyiQwen\"\n    name = \"TongyiQwenChatModel\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"输入\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"模型名称\",\n            options=[\n                \"qwen-turbo\",\n                \"qwen-turbo-0624\",\n                \"qwen-plus\",\n                \"qwen-plus-0624\",\n                \"qwen-max\",\n                \"qwen-max-0428\",\n                \"qwen-max-longcontext\",\n            ],\n            info=\"https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction\",\n            value=\"qwen-turbo\",\n        ),\n        SecretStrInput(\n            name=\"tongyi_api_key\",\n            display_name=\"通义 API key\",\n            info=\"which you could get from  https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top p\",\n            value=0.8,\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"温度\",\n            value=0.95,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=STREAM_INFO_TEXT,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n#     outputs = [\n#     Output(display_name=\"文本\", name=\"text_output\", method=\"text_response\"),\n#     Output(display_name=\"大模型\", name=\"model_output\", method=\"build_model\"),\n# ]\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        tongyi_api_key = self.tongyi_api_key\n        top_p = self.top_p\n        temperature = self.temperature\n\n        try:\n            output = ChatTongyi(  # type: ignore\n                model=model,\n                api_key=SecretStr(tongyi_api_key),\n                top_p=top_p,\n                temperature=temperature,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Tongyi QWen API.\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "输入",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "qwen-turbo",
                    "qwen-turbo-0624",
                    "qwen-plus",
                    "qwen-plus-0624",
                    "qwen-max",
                    "qwen-max-0428",
                    "qwen-max-longcontext"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "qwen-turbo",
                  "name": "model",
                  "display_name": "模型名称",
                  "advanced": false,
                  "dynamic": false,
                  "info": "https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction",
                  "title_case": false,
                  "type": "str"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.95,
                  "name": "temperature",
                  "display_name": "温度",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                },
                "tongyi_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "tongyi_api_key",
                  "display_name": "通义 API key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "which you could get from  https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "top_p": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0.8,
                  "name": "top_p",
                  "display_name": "Top p",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "使用通义千问模型生成结果。",
              "icon": "TongyiQwen",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "通义千问",
              "documentation": "https://python.langchain.com/docs/integrations/chat/tongyi",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": true
                }
              ],
              "field_order": [
                "input_value",
                "model",
                "tongyi_api_key",
                "top_p",
                "temperature",
                "stream",
                "system_message"
              ],
              "beta": false,
              "edited": true
            },
            "id": "TongyiQwenChatModel-UOAMC",
            "description": "Generate text using Tongyi Qwen.",
            "display_name": "通义千问"
          },
          "selected": false,
          "width": 384,
          "height": 575,
          "positionAbsolute": {
            "x": 2569.2016317250905,
            "y": 494.1308947988908
          },
          "dragging": false
        },
        {
          "id": "BaichuanEmbeddings-96pml",
          "type": "genericNode",
          "position": {
            "x": 564.7364299468284,
            "y": 884.6486237845538
          },
          "data": {
            "type": "BaichuanEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "baichuan_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "baichuan_api_key",
                  "display_name": "APIKey",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pydantic.v1.types import SecretStr\nfrom langchain_community.embeddings import BaichuanTextEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\n\n\nclass BaichuanEmbeddingsComponent(LCModelComponent):\n    display_name = \"百川嵌入模型\"\n    description = \"Baichuan Text Embeddings.\"\n    documentation = \"https://platform.baichuan-ai.com/docs/text-Embedding\"\n    icon = \"Baichuan\"\n    name = \"BaichuanEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"baichuan_api_key\", display_name=\"APIKey\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.baichuan_api_key:\n            raise ValueError(\"API Key is required\")\n        api_key = SecretStr(self.baichuan_api_key)\n\n        return BaichuanTextEmbeddings(baichuan_api_key=api_key)",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Baichuan Text Embeddings.",
              "icon": "Baichuan",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "百川嵌入模型",
              "documentation": "https://platform.baichuan-ai.com/docs/text-Embedding",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "baichuan_api_key"
              ],
              "beta": false,
              "edited": false
            },
            "id": "BaichuanEmbeddings-96pml",
            "description": "Baichuan Text Embeddings.",
            "display_name": "百川嵌入模型"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "dragging": false,
          "positionAbsolute": {
            "x": 564.7364299468284,
            "y": 884.6486237845538
          }
        },
        {
          "id": "BaichuanEmbeddings-TKSpJ",
          "type": "genericNode",
          "position": {
            "x": 1860.886640442736,
            "y": 1873.785369175516
          },
          "data": {
            "type": "BaichuanEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "baichuan_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "baichuan_api_key",
                  "display_name": "APIKey",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pydantic.v1.types import SecretStr\nfrom langchain_community.embeddings import BaichuanTextEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import MessageTextInput, Output, SecretStrInput\n\n\nclass BaichuanEmbeddingsComponent(LCModelComponent):\n    display_name = \"百川嵌入模型\"\n    description = \"Baichuan Text Embeddings.\"\n    documentation = \"https://platform.baichuan-ai.com/docs/text-Embedding\"\n    icon = \"Baichuan\"\n    name = \"BaichuanEmbeddings\"\n\n    inputs = [\n        SecretStrInput(name=\"baichuan_api_key\", display_name=\"APIKey\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        if not self.baichuan_api_key:\n            raise ValueError(\"API Key is required\")\n        api_key = SecretStr(self.baichuan_api_key)\n\n        return BaichuanTextEmbeddings(baichuan_api_key=api_key)",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Baichuan Text Embeddings.",
              "icon": "Baichuan",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "百川嵌入模型",
              "documentation": "https://platform.baichuan-ai.com/docs/text-Embedding",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "baichuan_api_key"
              ],
              "beta": false,
              "edited": true
            },
            "id": "BaichuanEmbeddings-TKSpJ",
            "description": "Baichuan Text Embeddings.",
            "display_name": "百川嵌入模型"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "FAISS-YhzNk",
          "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-YhzNkœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
          "target": "ParseData-j2LzV",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-j2LzVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-j2LzV",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "FAISS",
              "id": "FAISS-YhzNk",
              "name": "search_results",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-FAISS-YhzNk{œdataTypeœ:œFAISSœ,œidœ:œFAISS-YhzNkœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-j2LzV{œfieldNameœ:œdataœ,œidœ:œParseData-j2LzVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "Prompt-h6zCv",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-h6zCvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "TongyiQwenChatModel-UOAMC",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "TongyiQwenChatModel-UOAMC",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-h6zCv",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-h6zCv{œdataTypeœ:œPromptœ,œidœ:œPrompt-h6zCvœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-TongyiQwenChatModel-UOAMC{œfieldNameœ:œinput_valueœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "TongyiQwenChatModel-UOAMC",
          "sourceHandle": "{œdataTypeœ:œTongyiQwenChatModelœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-vmBD9",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-vmBD9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-vmBD9",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TongyiQwenChatModel",
              "id": "TongyiQwenChatModel-UOAMC",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-TongyiQwenChatModel-UOAMC{œdataTypeœ:œTongyiQwenChatModelœ,œidœ:œTongyiQwenChatModel-UOAMCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-vmBD9{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-vmBD9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ParseData-j2LzV",
          "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-j2LzVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-h6zCv",
          "targetHandle": "{œfieldNameœ:œ上下文信息œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "上下文信息",
              "id": "Prompt-h6zCv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParseData",
              "id": "ParseData-j2LzV",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ParseData-j2LzV{œdataTypeœ:œParseDataœ,œidœ:œParseData-j2LzVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-h6zCv{œfieldNameœ:œ上下文信息œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ChatInput-OWlie",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-h6zCv",
          "targetHandle": "{œfieldNameœ:œ问题œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "问题",
              "id": "Prompt-h6zCv",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-OWlie",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-OWlie{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-h6zCv{œfieldNameœ:œ问题œ,œidœ:œPrompt-h6zCvœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "File-4OzQU",
          "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-4OzQUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
          "target": "FAISS-fmnD5",
          "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "FAISS-fmnD5",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "File",
              "id": "File-4OzQU",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-File-4OzQU{œdataTypeœ:œFileœ,œidœ:œFile-4OzQUœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FAISS-fmnD5{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ChatInput-OWlie",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "FAISS-YhzNk",
          "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "search_query",
              "id": "FAISS-YhzNk",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-OWlie",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-OWlie{œdataTypeœ:œChatInputœ,œidœ:œChatInput-OWlieœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-FAISS-YhzNk{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "BaichuanEmbeddings-96pml",
          "sourceHandle": "{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-96pmlœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
          "target": "FAISS-YhzNk",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "FAISS-YhzNk",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "BaichuanEmbeddings",
              "id": "BaichuanEmbeddings-96pml",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-BaichuanEmbeddings-96pml{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-96pmlœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-YhzNk{œfieldNameœ:œembeddingœ,œidœ:œFAISS-YhzNkœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "BaichuanEmbeddings-TKSpJ",
          "sourceHandle": "{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-TKSpJœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
          "target": "FAISS-fmnD5",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "FAISS-fmnD5",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "BaichuanEmbeddings",
              "id": "BaichuanEmbeddings-TKSpJ",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-BaichuanEmbeddings-TKSpJ{œdataTypeœ:œBaichuanEmbeddingsœ,œidœ:œBaichuanEmbeddings-TKSpJœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-fmnD5{œfieldNameœ:œembeddingœ,œidœ:œFAISS-fmnD5œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": -282.22009494310964,
        "y": -81.23992990353054,
        "zoom": 0.5000000000000007
      }
    },
    "date_created": "2024-08-01T10:19:50.674Z",
    "date_updated": "2024-08-01T10:19:50.733Z",
    "status": "Public",
    "sort": null,
    "user_updated": "4b9f6e29-04a3-417d-bd77-5087debade99",
    "user_created": {
      "username": "1234",
      "first_name": "jack",
      "last_name": "zhu",
      "id": "4b9f6e29-04a3-417d-bd77-5087debade99"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:54.217Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 86,
    "converter_version": "1.0.0"
  }
}