{
  "id": "7685520d-2049-44e0-bd38-c2783923cf61",
  "name": "CharacterFinderComponent",
  "description": "",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "parlayg",
    "first_name": "Parlay",
    "last_name": "G",
    "id": "754c72ae-5bb3-4c94-b2a2-712c4607489d",
    "full_name": "Parlay G"
  },
  "store_url": "https://www.langflow.store/store/component/7685520d-2049-44e0-bd38-c2783923cf61",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-05-14T05:36:34.934Z",
    "updated": "2024-05-14T05:36:34.988Z",
    "downloaded": "2025-08-19T17:50:05.330Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.6.19",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatOpenAI-TnwTP",
        "type": "genericNode",
        "position": {
          "x": 465.0757031199179,
          "y": 336.2716775598046
        },
        "data": {
          "type": "ChatOpenAI",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom langchain.llms import BaseLLM\nfrom langchain_community.chat_models.openai import ChatOpenAI\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"field_type\": \"int\",\n                \"advanced\": False,\n                \"required\": False,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"field_type\": \"NestedDict\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"options\": [\n                    \"gpt-4-turbo-preview\",\n                    \"gpt-4-0125-preview\",\n                    \"gpt-4-1106-preview\",\n                    \"gpt-4-vision-preview\",\n                    \"gpt-3.5-turbo-0125\",\n                    \"gpt-3.5-turbo-1106\",\n                    \"meta-llama/llama-3-70b-instruct\",\n                    \"google/gemini-pro-1.5\",\n                    \"mistralai/mistral-7b-instruct:nitro\"\n                ],\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"meta-llama/llama-3-70b-instruct\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> Union[BaseLanguageModel, BaseLLM]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        return ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=openai_api_key,\n            temperature=temperature,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "2560",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": {},
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "meta-llama/llama-3-70b-instruct",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-4-turbo-preview",
                  "gpt-4-0125-preview",
                  "gpt-4-1106-preview",
                  "gpt-4-vision-preview",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-1106",
                  "meta-llama/llama-3-70b-instruct",
                  "google/gemini-pro-1.5",
                  "mistralai/mistral-7b-instruct:nitro"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "openai_api_base": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": true,
                "value": "https://openrouter.ai/api/v1"
              },
              "openai_api_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.7,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "`OpenAI` Chat large language models API.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "display_name": "ChatOpenAI",
            "documentation": "",
            "custom_fields": {
              "max_tokens": null,
              "model_kwargs": null,
              "model_name": null,
              "openai_api_base": null,
              "openai_api_key": null,
              "temperature": null
            },
            "output_types": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "ChatOpenAI-TnwTP",
          "description": "`OpenAI` Chat large language models API.",
          "display_name": "ChatOpenAI"
        },
        "selected": false,
        "width": 384,
        "height": 731,
        "dragging": false,
        "positionAbsolute": {
          "x": 465.0757031199179,
          "y": 336.2716775598046
        }
      },
      {
        "id": "ChatPromptTemplate-f5R9s",
        "type": "genericNode",
        "position": {
          "x": 1543.5740528914782,
          "y": 514.9744538978725
        },
        "data": {
          "type": "ChatPromptTemplate",
          "node": {
            "template": {
              "messages": {
                "type": "BaseMessagePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "messages",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "ChatPromptTemplate"
            },
            "description": "Prompt template for chat models.",
            "base_classes": [
              "BaseChatPromptTemplate",
              "ChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "display_name": "ChatPromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "ChatPromptTemplate-f5R9s"
        },
        "selected": false,
        "width": 384,
        "height": 243,
        "positionAbsolute": {
          "x": 1543.5740528914782,
          "y": 514.9744538978725
        },
        "dragging": false
      },
      {
        "id": "SystemMessagePromptTemplate-bLGqc",
        "type": "genericNode",
        "position": {
          "x": 1048.438598394175,
          "y": 235.17326996242065
        },
        "data": {
          "type": "SystemMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": true,
                "value": "You're a character identification specialist employed by a storytelling company. Your role is crucial in ensuring that the characters in a story are accurately identified and represented. Your expertise helps streamline the storytelling process. You've honed your skills through years of analyzing narratives across various genres and mediums.",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "SystemMessagePromptTemplate"
            },
            "description": "System message prompt template.",
            "icon": null,
            "base_classes": [
              "BaseMessagePromptTemplate",
              "SystemMessagePromptTemplate",
              "_StringImageMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "SystemMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {
              "": []
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "SystemMessagePromptTemplate-bLGqc",
          "description": "System message prompt template.",
          "display_name": "SystemMessagePromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 281,
        "positionAbsolute": {
          "x": 1048.438598394175,
          "y": 235.17326996242065
        },
        "dragging": false
      },
      {
        "id": "HumanMessagePromptTemplate-K3dBm",
        "type": "genericNode",
        "position": {
          "x": 1057.78645543636,
          "y": 591.6214960487391
        },
        "data": {
          "type": "HumanMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": true,
                "value": "**INPUT: **\n      * **Story Paragraph:** {story_paragaph}\n      * **characters list: ** {character_list}\n    **TASK: **\n      Identify the characters referenced in the paragraph and create a list of those involved. This list will serve as the basis for creating a character inventory during image generation for each scene in the Story Paragraph. Please include only the full names of characters who are ONLY involved in the paragraph. Exclude any additional notes or explanations in the output. The list should be accurate and contain all the characters mentioned in the paragraph. DO NOT INCLUDE characters not mentioned in the paragraph.\n\n**EXPECTED OUTPUT: **\n    * List all the characters mentioned in the paragraph.\n    * Make sure not to miss any characters referenced in the paragraph.\n    * DO NOT INCLUDE characters not mentioned in the paragraph.\n    * Make sure the list is accurate with only names that are mentioned in the 'character list'.\n    * Exclude any additional notes or explanations in the output.\n    * The output should ONLY CONTAIN THE FULL NAMES OF CHARACTERS WHO ARE MENTIONED IN JSON FORMAT",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "HumanMessagePromptTemplate",
              "story_paragaph": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "story_paragaph",
                "display_name": "story_paragaph",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "character_list": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "character_list",
                "display_name": "character_list",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "Human message prompt template. This is a message sent from the user.",
            "icon": null,
            "base_classes": [
              "BaseMessagePromptTemplate",
              "HumanMessagePromptTemplate",
              "_StringImageMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "HumanMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {
              "": [
                "story_paragaph",
                "character_list"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "HumanMessagePromptTemplate-K3dBm",
          "description": "Human message prompt template. This is a message sent from the user.",
          "display_name": "HumanMessagePromptTemplate"
        },
        "selected": true,
        "width": 384,
        "height": 489,
        "positionAbsolute": {
          "x": 1057.78645543636,
          "y": 591.6214960487391
        },
        "dragging": false
      },
      {
        "id": "LLMChain-9vRoM",
        "type": "genericNode",
        "position": {
          "x": 1987.2015707253486,
          "y": 502.61347253838403
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable",
              "LLMChain",
              "Chain"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "prompt": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable",
              "LLMChain"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "LLMChain-9vRoM"
        },
        "selected": false,
        "width": 384,
        "height": 425,
        "positionAbsolute": {
          "x": 1987.2015707253486,
          "y": 502.61347253838403
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "SystemMessagePromptTemplate-bLGqc",
        "sourceHandle": "{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-bLGqcœ}",
        "target": "ChatPromptTemplate-f5R9s",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-f5R9s",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseMessagePromptTemplate",
              "SystemMessagePromptTemplate",
              "_StringImageMessagePromptTemplate"
            ],
            "dataType": "SystemMessagePromptTemplate",
            "id": "SystemMessagePromptTemplate-bLGqc"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-SystemMessagePromptTemplate-bLGqc{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-bLGqcœ}-ChatPromptTemplate-f5R9s{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      },
      {
        "source": "HumanMessagePromptTemplate-K3dBm",
        "sourceHandle": "{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-K3dBmœ}",
        "target": "ChatPromptTemplate-f5R9s",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-f5R9s",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseMessagePromptTemplate",
              "HumanMessagePromptTemplate",
              "_StringImageMessagePromptTemplate"
            ],
            "dataType": "HumanMessagePromptTemplate",
            "id": "HumanMessagePromptTemplate-K3dBm"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-HumanMessagePromptTemplate-K3dBm{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-K3dBmœ}-ChatPromptTemplate-f5R9s{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      },
      {
        "source": "ChatPromptTemplate-f5R9s",
        "sourceHandle": "{œbaseClassesœ:[œBaseChatPromptTemplateœ,œChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-f5R9sœ}",
        "target": "LLMChain-9vRoM",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-9vRoM",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseChatPromptTemplate",
              "ChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "dataType": "ChatPromptTemplate",
            "id": "ChatPromptTemplate-f5R9s"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatPromptTemplate-f5R9s{œbaseClassesœ:[œBaseChatPromptTemplateœ,œChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-f5R9sœ}-LLMChain-9vRoM{œfieldNameœ:œpromptœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
      },
      {
        "source": "ChatOpenAI-TnwTP",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-TnwTPœ}",
        "target": "LLMChain-9vRoM",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-9vRoM",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "dataType": "ChatOpenAI",
            "id": "ChatOpenAI-TnwTP"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatOpenAI-TnwTP{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-TnwTPœ}-LLMChain-9vRoM{œfieldNameœ:œllmœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      }
    ],
    "viewport": {
      "x": 125.09937141711544,
      "y": 17.60704385247527,
      "zoom": 0.9501191163557534
    }
  },
  "metadata": {
    "ChatOpenAI": {
      "count": 1
    },
    "ChatPromptTemplate": {
      "count": 1
    },
    "SystemMessagePromptTemplate": {
      "count": 1
    },
    "HumanMessagePromptTemplate": {
      "count": 1
    },
    "LLMChain": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "7685520d-2049-44e0-bd38-c2783923cf61",
    "name": "CharacterFinderComponent",
    "description": "",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "ChatOpenAI": {
        "count": 1
      },
      "ChatPromptTemplate": {
        "count": 1
      },
      "SystemMessagePromptTemplate": {
        "count": 1
      },
      "HumanMessagePromptTemplate": {
        "count": 1
      },
      "LLMChain": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "0.6.19",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "ChatOpenAI-TnwTP",
          "type": "genericNode",
          "position": {
            "x": 465.0757031199179,
            "y": 336.2716775598046
          },
          "data": {
            "type": "ChatOpenAI",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, Union\n\nfrom langchain.llms import BaseLLM\nfrom langchain_community.chat_models.openai import ChatOpenAI\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"field_type\": \"int\",\n                \"advanced\": False,\n                \"required\": False,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"field_type\": \"NestedDict\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"options\": [\n                    \"gpt-4-turbo-preview\",\n                    \"gpt-4-0125-preview\",\n                    \"gpt-4-1106-preview\",\n                    \"gpt-4-vision-preview\",\n                    \"gpt-3.5-turbo-0125\",\n                    \"gpt-3.5-turbo-1106\",\n                    \"meta-llama/llama-3-70b-instruct\",\n                    \"google/gemini-pro-1.5\",\n                    \"mistralai/mistral-7b-instruct:nitro\"\n                ],\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"meta-llama/llama-3-70b-instruct\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> Union[BaseLanguageModel, BaseLLM]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        return ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=openai_api_key,\n            temperature=temperature,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "max_tokens": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "2560",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "model_kwargs": {
                  "type": "NestedDict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": {},
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "model_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "meta-llama/llama-3-70b-instruct",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "gpt-4-turbo-preview",
                    "gpt-4-0125-preview",
                    "gpt-4-1106-preview",
                    "gpt-4-vision-preview",
                    "gpt-3.5-turbo-0125",
                    "gpt-3.5-turbo-1106",
                    "meta-llama/llama-3-70b-instruct",
                    "google/gemini-pro-1.5",
                    "mistralai/mistral-7b-instruct:nitro"
                  ],
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "openai_api_base": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": true,
                  "value": "https://openrouter.ai/api/v1"
                },
                "openai_api_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "openai_api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": ""
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.7,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "`OpenAI` Chat large language models API.",
              "base_classes": [
                "BaseLanguageModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "display_name": "ChatOpenAI",
              "documentation": "",
              "custom_fields": {
                "max_tokens": null,
                "model_kwargs": null,
                "model_name": null,
                "openai_api_base": null,
                "openai_api_key": null,
                "temperature": null
              },
              "output_types": [
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "ChatOpenAI-TnwTP",
            "description": "`OpenAI` Chat large language models API.",
            "display_name": "ChatOpenAI"
          },
          "selected": false,
          "width": 384,
          "height": 731,
          "dragging": false,
          "positionAbsolute": {
            "x": 465.0757031199179,
            "y": 336.2716775598046
          }
        },
        {
          "id": "ChatPromptTemplate-f5R9s",
          "type": "genericNode",
          "position": {
            "x": 1543.5740528914782,
            "y": 514.9744538978725
          },
          "data": {
            "type": "ChatPromptTemplate",
            "node": {
              "template": {
                "messages": {
                  "type": "BaseMessagePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "messages",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "output_parser": {
                  "type": "BaseOutputParser",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_types": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_types",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_variables": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "name",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "partial_variables": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "tags": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "validate_template": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "ChatPromptTemplate"
              },
              "description": "Prompt template for chat models.",
              "base_classes": [
                "BaseChatPromptTemplate",
                "ChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "display_name": "ChatPromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "ChatPromptTemplate-f5R9s"
          },
          "selected": false,
          "width": 384,
          "height": 243,
          "positionAbsolute": {
            "x": 1543.5740528914782,
            "y": 514.9744538978725
          },
          "dragging": false
        },
        {
          "id": "SystemMessagePromptTemplate-bLGqc",
          "type": "genericNode",
          "position": {
            "x": 1048.438598394175,
            "y": 235.17326996242065
          },
          "data": {
            "type": "SystemMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": true,
                  "value": "You're a character identification specialist employed by a storytelling company. Your role is crucial in ensuring that the characters in a story are accurately identified and represented. Your expertise helps streamline the storytelling process. You've honed your skills through years of analyzing narratives across various genres and mediums.",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "SystemMessagePromptTemplate"
              },
              "description": "System message prompt template.",
              "icon": null,
              "base_classes": [
                "BaseMessagePromptTemplate",
                "SystemMessagePromptTemplate",
                "_StringImageMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "SystemMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {
                "": []
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "SystemMessagePromptTemplate-bLGqc",
            "description": "System message prompt template.",
            "display_name": "SystemMessagePromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 281,
          "positionAbsolute": {
            "x": 1048.438598394175,
            "y": 235.17326996242065
          },
          "dragging": false
        },
        {
          "id": "HumanMessagePromptTemplate-K3dBm",
          "type": "genericNode",
          "position": {
            "x": 1057.78645543636,
            "y": 591.6214960487391
          },
          "data": {
            "type": "HumanMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": true,
                  "value": "**INPUT: **\n      * **Story Paragraph:** {story_paragaph}\n      * **characters list: ** {character_list}\n    **TASK: **\n      Identify the characters referenced in the paragraph and create a list of those involved. This list will serve as the basis for creating a character inventory during image generation for each scene in the Story Paragraph. Please include only the full names of characters who are ONLY involved in the paragraph. Exclude any additional notes or explanations in the output. The list should be accurate and contain all the characters mentioned in the paragraph. DO NOT INCLUDE characters not mentioned in the paragraph.\n\n**EXPECTED OUTPUT: **\n    * List all the characters mentioned in the paragraph.\n    * Make sure not to miss any characters referenced in the paragraph.\n    * DO NOT INCLUDE characters not mentioned in the paragraph.\n    * Make sure the list is accurate with only names that are mentioned in the 'character list'.\n    * Exclude any additional notes or explanations in the output.\n    * The output should ONLY CONTAIN THE FULL NAMES OF CHARACTERS WHO ARE MENTIONED IN JSON FORMAT",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "HumanMessagePromptTemplate",
                "story_paragaph": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "story_paragaph",
                  "display_name": "story_paragaph",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "character_list": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "character_list",
                  "display_name": "character_list",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                }
              },
              "description": "Human message prompt template. This is a message sent from the user.",
              "icon": null,
              "base_classes": [
                "BaseMessagePromptTemplate",
                "HumanMessagePromptTemplate",
                "_StringImageMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "HumanMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {
                "": [
                  "story_paragaph",
                  "character_list"
                ]
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "HumanMessagePromptTemplate-K3dBm",
            "description": "Human message prompt template. This is a message sent from the user.",
            "display_name": "HumanMessagePromptTemplate"
          },
          "selected": true,
          "width": 384,
          "height": 489,
          "positionAbsolute": {
            "x": 1057.78645543636,
            "y": 591.6214960487391
          },
          "dragging": false
        },
        {
          "id": "LLMChain-9vRoM",
          "type": "genericNode",
          "position": {
            "x": 1987.2015707253486,
            "y": 502.61347253838403
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "BasePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt",
                  "display_name": "Prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "Chain",
                "Callable",
                "LLMChain",
                "Chain"
              ],
              "display_name": "LLMChain",
              "documentation": "",
              "custom_fields": {
                "prompt": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable",
                "LLMChain"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "LLMChain-9vRoM"
          },
          "selected": false,
          "width": 384,
          "height": 425,
          "positionAbsolute": {
            "x": 1987.2015707253486,
            "y": 502.61347253838403
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "SystemMessagePromptTemplate-bLGqc",
          "sourceHandle": "{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-bLGqcœ}",
          "target": "ChatPromptTemplate-f5R9s",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-f5R9s",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseMessagePromptTemplate",
                "SystemMessagePromptTemplate",
                "_StringImageMessagePromptTemplate"
              ],
              "dataType": "SystemMessagePromptTemplate",
              "id": "SystemMessagePromptTemplate-bLGqc"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-SystemMessagePromptTemplate-bLGqc{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-bLGqcœ}-ChatPromptTemplate-f5R9s{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        },
        {
          "source": "HumanMessagePromptTemplate-K3dBm",
          "sourceHandle": "{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-K3dBmœ}",
          "target": "ChatPromptTemplate-f5R9s",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-f5R9s",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseMessagePromptTemplate",
                "HumanMessagePromptTemplate",
                "_StringImageMessagePromptTemplate"
              ],
              "dataType": "HumanMessagePromptTemplate",
              "id": "HumanMessagePromptTemplate-K3dBm"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-HumanMessagePromptTemplate-K3dBm{œbaseClassesœ:[œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œ_StringImageMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-K3dBmœ}-ChatPromptTemplate-f5R9s{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-f5R9sœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        },
        {
          "source": "ChatPromptTemplate-f5R9s",
          "sourceHandle": "{œbaseClassesœ:[œBaseChatPromptTemplateœ,œChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-f5R9sœ}",
          "target": "LLMChain-9vRoM",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "LLMChain-9vRoM",
              "inputTypes": null,
              "type": "BasePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseChatPromptTemplate",
                "ChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "dataType": "ChatPromptTemplate",
              "id": "ChatPromptTemplate-f5R9s"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatPromptTemplate-f5R9s{œbaseClassesœ:[œBaseChatPromptTemplateœ,œChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-f5R9sœ}-LLMChain-9vRoM{œfieldNameœ:œpromptœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
        },
        {
          "source": "ChatOpenAI-TnwTP",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-TnwTPœ}",
          "target": "LLMChain-9vRoM",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-9vRoM",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "dataType": "ChatOpenAI",
              "id": "ChatOpenAI-TnwTP"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatOpenAI-TnwTP{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-TnwTPœ}-LLMChain-9vRoM{œfieldNameœ:œllmœ,œidœ:œLLMChain-9vRoMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        }
      ],
      "viewport": {
        "x": 125.09937141711544,
        "y": 17.60704385247527,
        "zoom": 0.9501191163557534
      }
    },
    "date_created": "2024-05-14T05:36:34.934Z",
    "date_updated": "2024-05-14T05:36:34.988Z",
    "status": "Public",
    "sort": null,
    "user_updated": "754c72ae-5bb3-4c94-b2a2-712c4607489d",
    "user_created": {
      "username": "parlayg",
      "first_name": "Parlay",
      "last_name": "G",
      "id": "754c72ae-5bb3-4c94-b2a2-712c4607489d"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:00.375Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 8,
    "converter_version": "1.0.0"
  }
}