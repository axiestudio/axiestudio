{
  "id": "96ce4b3f-0076-4cd3-bbee-e5498d1e6452",
  "name": "INV_IRS_CHAT",
  "description": "Transform Your Business with Smart Dialogues. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "eyalcats",
    "first_name": "Eyal",
    "last_name": "Katz",
    "id": "80067d70-c092-4332-b846-8121303bced1",
    "full_name": "Eyal Katz"
  },
  "store_url": "https://www.langflow.store/store/component/96ce4b3f-0076-4cd3-bbee-e5498d1e6452",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-07-17T07:21:49.317Z",
    "updated": "2024-07-17T07:22:55.954Z",
    "downloaded": "2025-08-19T17:50:06.029Z"
  },
  "tags": [
    {
      "tags_id": {
        "name": "Prompt",
        "id": "57f5c681-a1f5-4053-be33-e9525e7eb00a"
      }
    }
  ],
  "technical": {
    "last_tested_version": "1.0.9",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-6s5SE",
        "type": "genericNode",
        "position": {
          "x": -189.12988505404132,
          "y": 171.44798531632853
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "מה זו שגיאה 406",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              },
              "store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "store_message",
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatInput-6s5SE"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "positionAbsolute": {
          "x": -189.12988505404132,
          "y": 171.44798531632853
        },
        "dragging": true
      },
      {
        "id": "ChatOutput-SUnri",
        "type": "genericNode",
        "position": {
          "x": 1732.2447439378573,
          "y": 349.1843957258639
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "data_template",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Machine",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "AI",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Session ID for the message.",
                "title_case": false,
                "type": "str"
              },
              "store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "store_message",
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ChatOutput-SUnri"
        },
        "selected": false,
        "width": 384,
        "height": 309,
        "positionAbsolute": {
          "x": 1732.2447439378573,
          "y": 349.1843957258639
        },
        "dragging": false
      },
      {
        "id": "Prompt-uyPXP",
        "type": "genericNode",
        "position": {
          "x": 1245.7722089039519,
          "y": -167.98098967704766
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Answer in Hebrew. Use ONLY information from the context. Do not add external information.\nMax response length: [specify token limit, e.g., 300 tokens]\n\nContext: {data}\nQ: {question}\n\nFormat:\n1. Direct answer\n2. Elaboration (if context allows)",
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt"
              },
              "data": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "data",
                "display_name": "data",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "data",
                "question"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false
          },
          "id": "Prompt-uyPXP",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 517,
        "positionAbsolute": {
          "x": 1245.7722089039519,
          "y": -167.98098967704766
        },
        "dragging": false
      },
      {
        "id": "ParseData-5XQKq",
        "type": "genericNode",
        "position": {
          "x": 774.6069808876098,
          "y": -206.6611782480823
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "data",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "\n",
                "name": "sep",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "{text}",
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false
          },
          "id": "ParseData-5XQKq"
        },
        "selected": false,
        "width": 384,
        "height": 385,
        "positionAbsolute": {
          "x": 774.6069808876098,
          "y": -206.6611782480823
        },
        "dragging": false
      },
      {
        "id": "AnthropicModel-QLQ4R",
        "type": "genericNode",
        "position": {
          "x": 1735.4215080058402,
          "y": -407.55395375092456
        },
        "data": {
          "type": "AnthropicModel",
          "node": {
            "template": {
              "_type": "Component",
              "anthropic_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "anthropic_api_key",
                "display_name": "Anthropic API Key",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Your Anthropic API key.",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "anthropic_api_url": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "anthropic_api_url",
                "display_name": "Anthropic API URL",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.",
                "title_case": false,
                "type": "str"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4096,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "claude-3-5-sonnet-20240620",
                  "claude-3-opus-20240229",
                  "claude-3-sonnet-20240229",
                  "claude-3-haiku-20240307"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "claude-3-haiku-20240307",
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "https://python.langchain.com/docs/integrations/chat/anthropic",
                "title_case": false,
                "type": "str"
              },
              "prefill": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "prefill",
                "display_name": "Prefill",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Prefill text to guide the model's response.",
                "title_case": false,
                "type": "str"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "0.3",
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float"
              }
            },
            "description": "Generate text using Anthropic Chat&Completion LLMs with prefill support.",
            "icon": "Anthropic",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Anthropic",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "max_tokens",
              "model",
              "anthropic_api_key",
              "temperature",
              "anthropic_api_url",
              "stream",
              "system_message",
              "prefill"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AnthropicModel-QLQ4R"
        },
        "selected": false,
        "width": 384,
        "height": 651,
        "positionAbsolute": {
          "x": 1735.4215080058402,
          "y": -407.55395375092456
        },
        "dragging": false
      },
      {
        "id": "AstraDB-NxJ5p",
        "type": "genericNode",
        "position": {
          "x": 298.3570482254353,
          "y": -498.9276368963147
        },
        "data": {
          "type": "AstraDB",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "Embedding or Astra Vectorize",
                "advanced": false,
                "input_types": [
                  "Embeddings",
                  "dict"
                ],
                "dynamic": false,
                "info": "Allows either an embedding model or an Astra Vectorize configuration.",
                "title_case": false,
                "type": "other"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "api_endpoint": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "api_endpoint",
                "display_name": "API Endpoint",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "title_case": false,
                "password": true,
                "type": "str"
              },
              "batch_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "batch_size",
                "display_name": "Batch Size",
                "advanced": true,
                "dynamic": false,
                "info": "Optional number of data to process in a single batch.",
                "title_case": false,
                "type": "int"
              },
              "bulk_delete_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "bulk_delete_concurrency",
                "display_name": "Bulk Delete Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Optional concurrency level for bulk delete operations.",
                "title_case": false,
                "type": "int"
              },
              "bulk_insert_batch_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "bulk_insert_batch_concurrency",
                "display_name": "Bulk Insert Batch Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations.",
                "title_case": false,
                "type": "int"
              },
              "bulk_insert_overwrite_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "bulk_insert_overwrite_concurrency",
                "display_name": "Bulk Insert Overwrite Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                "title_case": false,
                "type": "int"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.vectorstores import VectorStore\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers import docs_to_data\nfrom axiestudio.inputs import DictInput, FloatInput\nfrom axiestudio.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom axiestudio.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vectorstore: VectorStore | None = None\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",  # TODO: This should be optional, but need to refactor langchain-astradb first.\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def _build_vector_store(self):\n        # cache the vector store to avoid re-initializing and ingest data again\n        if self._cached_vectorstore:\n            return self._cached_vectorstore\n\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {self.setup_mode}\")\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(dict_options)\n            }\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n        self._add_documents_to_vector_store(vector_store)\n\n        self._cached_vectorstore = vector_store\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                raise ValueError(f\"Error adding documents to AstraDBVectorStore: {str(e)}\") from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        elif self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        else:\n            return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self._build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                raise ValueError(f\"Error performing search in AstraDBVectorStore: {str(e)}\") from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n\n    def build_vector_store(self):\n        vector_store = self._build_vector_store()\n        return vector_store\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_indexing_policy": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "collection_indexing_policy",
                "display_name": "Collection Indexing Policy",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary defining the indexing policy for the collection.",
                "title_case": false,
                "type": "str"
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "invirs",
                "name": "collection_name",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "title_case": false,
                "type": "str"
              },
              "metadata_indexing_exclude": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "metadata_indexing_exclude",
                "display_name": "Metadata Indexing Exclude",
                "advanced": true,
                "dynamic": false,
                "info": "Optional list of metadata fields to exclude from the indexing.",
                "title_case": false,
                "type": "str"
              },
              "metadata_indexing_include": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "metadata_indexing_include",
                "display_name": "Metadata Indexing Include",
                "advanced": true,
                "dynamic": false,
                "info": "Optional list of metadata fields to include in the indexing.",
                "title_case": false,
                "type": "str"
              },
              "metric": {
                "trace_as_metadata": true,
                "options": [
                  "cosine",
                  "dot_product",
                  "euclidean"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "metric",
                "display_name": "Metric",
                "advanced": true,
                "dynamic": false,
                "info": "Optional distance metric for vector comparisons in the vector store.",
                "title_case": false,
                "type": "str"
              },
              "namespace": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "namespace",
                "display_name": "Namespace",
                "advanced": true,
                "dynamic": false,
                "info": "Optional namespace within Astra DB to use for the collection.",
                "title_case": false,
                "type": "str"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 4,
                "name": "number_of_results",
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int"
              },
              "pre_delete_collection": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": false,
                "name": "pre_delete_collection",
                "display_name": "Pre Delete Collection",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                "title_case": false,
                "type": "bool"
              },
              "search_filter": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "search_filter",
                "display_name": "Search Metadata Filter",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "title_case": false,
                "type": "dict"
              },
              "search_input": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "search_input",
                "display_name": "Search Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "search_score_threshold": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": 0,
                "name": "search_score_threshold",
                "display_name": "Search Score Threshold",
                "advanced": true,
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "title_case": false,
                "type": "float"
              },
              "search_type": {
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Similarity",
                "name": "search_type",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "Search type to use",
                "title_case": false,
                "type": "str"
              },
              "setup_mode": {
                "trace_as_metadata": true,
                "options": [
                  "Sync",
                  "Async",
                  "Off"
                ],
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "Sync",
                "name": "setup_mode",
                "display_name": "Setup Mode",
                "advanced": true,
                "dynamic": false,
                "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.",
                "title_case": false,
                "type": "str"
              },
              "token": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "token",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "title_case": false,
                "password": true,
                "type": "str"
              }
            },
            "description": "Implementation of Vector Store using Astra DB with search capabilities",
            "icon": "AstraDB",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Astra DB",
            "documentation": "https://python.langchain.com/docs/integrations/vectorstores/astradb",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "collection_name",
              "token",
              "api_endpoint",
              "search_input",
              "ingest_data",
              "namespace",
              "metric",
              "batch_size",
              "bulk_insert_batch_concurrency",
              "bulk_insert_overwrite_concurrency",
              "bulk_delete_concurrency",
              "setup_mode",
              "pre_delete_collection",
              "metadata_indexing_include",
              "embedding",
              "metadata_indexing_exclude",
              "collection_indexing_policy",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "search_filter"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AstraDB-NxJ5p"
        },
        "selected": false,
        "width": 384,
        "height": 803,
        "positionAbsolute": {
          "x": 298.3570482254353,
          "y": -498.9276368963147
        },
        "dragging": false
      },
      {
        "id": "AstraVectorize-JgMWU",
        "type": "genericNode",
        "position": {
          "x": -188.6407591740156,
          "y": -399.5688888349324
        },
        "data": {
          "type": "AstraVectorize",
          "node": {
            "template": {
              "_type": "Component",
              "api_key_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "pa-MzjCe11At98kqUuPN-p3SqtN1ilOisKe_ojXdp3_XF8",
                "name": "api_key_name",
                "display_name": "Provider API Key Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the embeddings provider API key stored on Astra.",
                "title_case": false,
                "type": "str"
              },
              "authentication": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "authentication",
                "display_name": "Authentication Parameters",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DictInput, SecretStrInput, MessageTextInput, DropdownInput\nfrom axiestudio.template.field.base import Output\n\n\nclass AstraVectorizeComponent(Component):\n    display_name: str = \"Astra Vectorize\"\n    description: str = \"Configuration options for Astra Vectorize server-side embeddings.\"\n    documentation: str = \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html\"\n    icon = \"AstraDB\"\n    name = \"AstraVectorize\"\n\n    VECTORIZE_PROVIDERS_MAPPING = {\n        \"Azure OpenAI\": [\"azureOpenAI\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Hugging Face - Dedicated\": [\"huggingfaceDedicated\", [\"endpoint-defined-model\"]],\n        \"Hugging Face - Serverless\": [\n            \"huggingface\",\n            [\n                \"sentence-transformers/all-MiniLM-L6-v2\",\n                \"intfloat/multilingual-e5-large\",\n                \"intfloat/multilingual-e5-large-instruct\",\n                \"BAAI/bge-small-en-v1.5\",\n                \"BAAI/bge-base-en-v1.5\",\n                \"BAAI/bge-large-en-v1.5\",\n            ],\n        ],\n        \"Jina AI\": [\n            \"jinaAI\",\n            [\n                \"jina-embeddings-v2-base-en\",\n                \"jina-embeddings-v2-base-de\",\n                \"jina-embeddings-v2-base-es\",\n                \"jina-embeddings-v2-base-code\",\n                \"jina-embeddings-v2-base-zh\",\n            ],\n        ],\n        \"Mistral AI\": [\"mistral\", [\"mistral-embed\"]],\n        \"NVIDIA\": [\"nvidia\", [\"NV-Embed-QA\"]],\n        \"OpenAI\": [\"openai\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Upstage\": [\"upstageAI\", [\"solar-embedding-1-large\"]],\n        \"Voyage AI\": [\n            \"voyageAI\",\n            [\"voyage-large-2-instruct\", \"voyage-law-2\", \"voyage-code-2\", \"voyage-large-2\", \"voyage-2\"],\n        ],\n    }\n    VECTORIZE_MODELS_STR = \"\\n\\n\".join(\n        [provider + \": \" + (\", \".join(models[1])) for provider, models in VECTORIZE_PROVIDERS_MAPPING.items()]\n    )\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Provider\",\n            options=VECTORIZE_PROVIDERS_MAPPING.keys(),\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=f\"The embedding model to use for the selected provider. Each provider has a different set of models \"\n            f\"available (https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\\n\\n{VECTORIZE_MODELS_STR}\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"api_key_name\",\n            display_name=\"Provider API Key Name\",\n            info=\"The name of the embeddings provider API key stored on Astra.\",\n        ),\n        SecretStrInput(\n            name=\"provider_api_key\",\n            display_name=\"Provider API Key\",\n            info=\"An alternative to the Astra Authentication that passes an API key for the provider with each request to Astra DB. This may be used when Vectorize is configured for the collection, but no corresponding provider secret is stored within Astra's key management system.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"authentication\",\n            display_name=\"Authentication Parameters\",\n            is_list=True,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_parameters\",\n            display_name=\"Model Parameters\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Vectorize\", name=\"config\", method=\"build_options\", types=[\"dict\"]),\n    ]\n\n    def build_options(self) -> dict[str, Any]:\n        provider_value = self.VECTORIZE_PROVIDERS_MAPPING[self.provider][0]\n        authentication = {**(self.authentication or {})}\n        api_key_name = self.api_key_name\n        if api_key_name:\n            authentication[\"providerKey\"] = api_key_name\n        return {\n            # must match astrapy.info.CollectionVectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": provider_value,\n                \"modelName\": self.model_name,\n                \"authentication\": authentication,\n                \"parameters\": self.model_parameters or {},\n            },\n            \"collection_embedding_api_key\": self.provider_api_key,\n        }\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "voyage-multilingual-2",
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The embedding model to use for the selected provider. Each provider has a different set of models available (https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\n\nAzure OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nHugging Face - Dedicated: endpoint-defined-model\n\nHugging Face - Serverless: sentence-transformers/all-MiniLM-L6-v2, intfloat/multilingual-e5-large, intfloat/multilingual-e5-large-instruct, BAAI/bge-small-en-v1.5, BAAI/bge-base-en-v1.5, BAAI/bge-large-en-v1.5\n\nJina AI: jina-embeddings-v2-base-en, jina-embeddings-v2-base-de, jina-embeddings-v2-base-es, jina-embeddings-v2-base-code, jina-embeddings-v2-base-zh\n\nMistral AI: mistral-embed\n\nNVIDIA: NV-Embed-QA\n\nOpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nUpstage: solar-embedding-1-large\n\nVoyage AI: voyage-large-2-instruct, voyage-law-2, voyage-code-2, voyage-large-2, voyage-2",
                "title_case": false,
                "type": "str"
              },
              "model_parameters": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": {},
                "name": "model_parameters",
                "display_name": "Model Parameters",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict"
              },
              "provider": {
                "trace_as_metadata": true,
                "options": [
                  "Azure OpenAI",
                  "Hugging Face - Dedicated",
                  "Hugging Face - Serverless",
                  "Jina AI",
                  "Mistral AI",
                  "NVIDIA",
                  "OpenAI",
                  "Upstage",
                  "Voyage AI"
                ],
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "Voyage AI",
                "name": "provider",
                "display_name": "Provider",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "provider_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "provider_api_key",
                "display_name": "Provider API Key",
                "advanced": true,
                "input_types": [],
                "dynamic": false,
                "info": "An alternative to the Astra Authentication that passes an API key for the provider with each request to Astra DB. This may be used when Vectorize is configured for the collection, but no corresponding provider secret is stored within Astra's key management system.",
                "title_case": false,
                "password": true,
                "type": "str"
              }
            },
            "description": "Configuration options for Astra Vectorize server-side embeddings.",
            "icon": "AstraDB",
            "base_classes": [
              "dict"
            ],
            "display_name": "Astra Vectorize",
            "documentation": "https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "dict"
                ],
                "name": "config",
                "display_name": "Vectorize",
                "method": "build_options",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "provider",
              "model_name",
              "api_key_name",
              "provider_api_key",
              "authentication",
              "model_parameters"
            ],
            "beta": false,
            "edited": false
          },
          "id": "AstraVectorize-JgMWU"
        },
        "selected": false,
        "width": 384,
        "height": 517,
        "positionAbsolute": {
          "x": -188.6407591740156,
          "y": -399.5688888349324
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ParseData-5XQKq",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5XQKqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-uyPXP",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "Prompt-uyPXP",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5XQKq",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5XQKq{œdataTypeœ:œParseDataœ,œidœ:œParseData-5XQKqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-uyPXP{œfieldNameœ:œdataœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ChatInput-6s5SE",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-uyPXP",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-uyPXP",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-6s5SE",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-6s5SE{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-uyPXP{œfieldNameœ:œquestionœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "AstraDB-NxJ5p",
        "sourceHandle": "{œdataTypeœ:œAstraDBœ,œidœ:œAstraDB-NxJ5pœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-5XQKq",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-5XQKqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-5XQKq",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraDB",
            "id": "AstraDB-NxJ5p",
            "name": "search_results",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-AstraDB-NxJ5p{œdataTypeœ:œAstraDBœ,œidœ:œAstraDB-NxJ5pœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-5XQKq{œfieldNameœ:œdataœ,œidœ:œParseData-5XQKqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "AstraVectorize-JgMWU",
        "sourceHandle": "{œdataTypeœ:œAstraVectorizeœ,œidœ:œAstraVectorize-JgMWUœ,œnameœ:œconfigœ,œoutput_typesœ:[œdictœ]}",
        "target": "AstraDB-NxJ5p",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œEmbeddingsœ,œdictœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "AstraDB-NxJ5p",
            "inputTypes": [
              "Embeddings",
              "dict"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraVectorize",
            "id": "AstraVectorize-JgMWU",
            "name": "config",
            "output_types": [
              "dict"
            ]
          }
        },
        "id": "reactflow__edge-AstraVectorize-JgMWU{œdataTypeœ:œAstraVectorizeœ,œidœ:œAstraVectorize-JgMWUœ,œnameœ:œconfigœ,œoutput_typesœ:[œdictœ]}-AstraDB-NxJ5p{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œEmbeddingsœ,œdictœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ChatInput-6s5SE",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "AstraDB-NxJ5p",
        "targetHandle": "{œfieldNameœ:œsearch_inputœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_input",
            "id": "AstraDB-NxJ5p",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-6s5SE",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-6s5SE{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-AstraDB-NxJ5p{œfieldNameœ:œsearch_inputœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-uyPXP",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-uyPXPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "AnthropicModel-QLQ4R",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-QLQ4Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "AnthropicModel-QLQ4R",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-uyPXP",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-uyPXP{œdataTypeœ:œPromptœ,œidœ:œPrompt-uyPXPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-QLQ4R{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-QLQ4Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "AnthropicModel-QLQ4R",
        "sourceHandle": "{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QLQ4Rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-SUnri",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SUnriœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-SUnri",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "AnthropicModel",
            "id": "AnthropicModel-QLQ4R",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-AnthropicModel-QLQ4R{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QLQ4Rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-SUnri{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SUnriœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 250.60968378114626,
      "y": 381.709199114537,
      "zoom": 0.5954852272304637
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "ParseData": {
      "count": 1
    },
    "AnthropicModel": {
      "count": 1
    },
    "AstraDB": {
      "count": 1
    },
    "AstraVectorize": {
      "count": 1
    },
    "total": 7
  },
  "original": {
    "id": "96ce4b3f-0076-4cd3-bbee-e5498d1e6452",
    "name": "INV_IRS_CHAT",
    "description": "Transform Your Business with Smart Dialogues.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "ParseData": {
        "count": 1
      },
      "AnthropicModel": {
        "count": 1
      },
      "AstraDB": {
        "count": 1
      },
      "AstraVectorize": {
        "count": 1
      },
      "total": 7
    },
    "last_tested_version": "1.0.9",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-6s5SE",
          "type": "genericNode",
          "position": {
            "x": -189.12988505404132,
            "y": 171.44798531632853
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "מה זו שגיאה 406",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                },
                "store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "store_message",
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatInput-6s5SE"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "positionAbsolute": {
            "x": -189.12988505404132,
            "y": 171.44798531632853
          },
          "dragging": true
        },
        {
          "id": "ChatOutput-SUnri",
          "type": "genericNode",
          "position": {
            "x": 1732.2447439378573,
            "y": 349.1843957258639
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "data_template",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Machine",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "AI",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Session ID for the message.",
                  "title_case": false,
                  "type": "str"
                },
                "store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "store_message",
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ChatOutput-SUnri"
          },
          "selected": false,
          "width": 384,
          "height": 309,
          "positionAbsolute": {
            "x": 1732.2447439378573,
            "y": 349.1843957258639
          },
          "dragging": false
        },
        {
          "id": "Prompt-uyPXP",
          "type": "genericNode",
          "position": {
            "x": 1245.7722089039519,
            "y": -167.98098967704766
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Answer in Hebrew. Use ONLY information from the context. Do not add external information.\nMax response length: [specify token limit, e.g., 300 tokens]\n\nContext: {data}\nQ: {question}\n\nFormat:\n1. Direct answer\n2. Elaboration (if context allows)",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt"
                },
                "data": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "data",
                  "display_name": "data",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "question",
                  "display_name": "question",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "data",
                  "question"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false
            },
            "id": "Prompt-uyPXP",
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 517,
          "positionAbsolute": {
            "x": 1245.7722089039519,
            "y": -167.98098967704766
          },
          "dragging": false
        },
        {
          "id": "ParseData-5XQKq",
          "type": "genericNode",
          "position": {
            "x": 774.6069808876098,
            "y": -206.6611782480823
          },
          "data": {
            "type": "ParseData",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "data",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.io import DataInput, MultilineInput, Output, StrInput\nfrom axiestudio.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sep": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "\n",
                  "name": "sep",
                  "display_name": "Separator",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "{text}",
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Convert Data into plain text following a specified template.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Parse Data",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "template",
                "sep"
              ],
              "beta": false,
              "edited": false
            },
            "id": "ParseData-5XQKq"
          },
          "selected": false,
          "width": 384,
          "height": 385,
          "positionAbsolute": {
            "x": 774.6069808876098,
            "y": -206.6611782480823
          },
          "dragging": false
        },
        {
          "id": "AnthropicModel-QLQ4R",
          "type": "genericNode",
          "position": {
            "x": 1735.4215080058402,
            "y": -407.55395375092456
          },
          "data": {
            "type": "AnthropicModel",
            "node": {
              "template": {
                "_type": "Component",
                "anthropic_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "anthropic_api_key",
                  "display_name": "Anthropic API Key",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "Your Anthropic API key.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "anthropic_api_url": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "anthropic_api_url",
                  "display_name": "Anthropic API URL",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.",
                  "title_case": false,
                  "type": "str"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4096,
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "claude-3-5-sonnet-20240620",
                    "claude-3-opus-20240229",
                    "claude-3-sonnet-20240229",
                    "claude-3-haiku-20240307"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "claude-3-haiku-20240307",
                  "name": "model",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "https://python.langchain.com/docs/integrations/chat/anthropic",
                  "title_case": false,
                  "type": "str"
                },
                "prefill": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "prefill",
                  "display_name": "Prefill",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Prefill text to guide the model's response.",
                  "title_case": false,
                  "type": "str"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "0.3",
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float"
                }
              },
              "description": "Generate text using Anthropic Chat&Completion LLMs with prefill support.",
              "icon": "Anthropic",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Anthropic",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "max_tokens",
                "model",
                "anthropic_api_key",
                "temperature",
                "anthropic_api_url",
                "stream",
                "system_message",
                "prefill"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AnthropicModel-QLQ4R"
          },
          "selected": false,
          "width": 384,
          "height": 651,
          "positionAbsolute": {
            "x": 1735.4215080058402,
            "y": -407.55395375092456
          },
          "dragging": false
        },
        {
          "id": "AstraDB-NxJ5p",
          "type": "genericNode",
          "position": {
            "x": 298.3570482254353,
            "y": -498.9276368963147
          },
          "data": {
            "type": "AstraDB",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "Embedding or Astra Vectorize",
                  "advanced": false,
                  "input_types": [
                    "Embeddings",
                    "dict"
                  ],
                  "dynamic": false,
                  "info": "Allows either an embedding model or an Astra Vectorize configuration.",
                  "title_case": false,
                  "type": "other"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "api_endpoint": {
                  "load_from_db": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "api_endpoint",
                  "display_name": "API Endpoint",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "API endpoint URL for the Astra DB service.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                },
                "batch_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "batch_size",
                  "display_name": "Batch Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional number of data to process in a single batch.",
                  "title_case": false,
                  "type": "int"
                },
                "bulk_delete_concurrency": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "bulk_delete_concurrency",
                  "display_name": "Bulk Delete Concurrency",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk delete operations.",
                  "title_case": false,
                  "type": "int"
                },
                "bulk_insert_batch_concurrency": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "bulk_insert_batch_concurrency",
                  "display_name": "Bulk Insert Batch Concurrency",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk insert operations.",
                  "title_case": false,
                  "type": "int"
                },
                "bulk_insert_overwrite_concurrency": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "bulk_insert_overwrite_concurrency",
                  "display_name": "Bulk Insert Overwrite Concurrency",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional concurrency level for bulk insert operations that overwrite existing data.",
                  "title_case": false,
                  "type": "int"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_core.vectorstores import VectorStore\nfrom loguru import logger\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent\nfrom axiestudio.helpers import docs_to_data\nfrom axiestudio.inputs import DictInput, FloatInput\nfrom axiestudio.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom axiestudio.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vectorstore: VectorStore | None = None\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",  # TODO: This should be optional, but need to refactor langchain-astradb first.\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    def _build_vector_store(self):\n        # cache the vector store to avoid re-initializing and ingest data again\n        if self._cached_vectorstore:\n            return self._cached_vectorstore\n\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {self.setup_mode}\")\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(dict_options)\n            }\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n        self._add_documents_to_vector_store(vector_store)\n\n        self._cached_vectorstore = vector_store\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                raise ValueError(f\"Error adding documents to AstraDBVectorStore: {str(e)}\") from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        elif self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        else:\n            return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self._build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                raise ValueError(f\"Error performing search in AstraDBVectorStore: {str(e)}\") from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n\n    def build_vector_store(self):\n        vector_store = self._build_vector_store()\n        return vector_store\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_indexing_policy": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "collection_indexing_policy",
                  "display_name": "Collection Indexing Policy",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional dictionary defining the indexing policy for the collection.",
                  "title_case": false,
                  "type": "str"
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "invirs",
                  "name": "collection_name",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The name of the collection within Astra DB where the vectors will be stored.",
                  "title_case": false,
                  "type": "str"
                },
                "metadata_indexing_exclude": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "metadata_indexing_exclude",
                  "display_name": "Metadata Indexing Exclude",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional list of metadata fields to exclude from the indexing.",
                  "title_case": false,
                  "type": "str"
                },
                "metadata_indexing_include": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "metadata_indexing_include",
                  "display_name": "Metadata Indexing Include",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional list of metadata fields to include in the indexing.",
                  "title_case": false,
                  "type": "str"
                },
                "metric": {
                  "trace_as_metadata": true,
                  "options": [
                    "cosine",
                    "dot_product",
                    "euclidean"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "metric",
                  "display_name": "Metric",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional distance metric for vector comparisons in the vector store.",
                  "title_case": false,
                  "type": "str"
                },
                "namespace": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "namespace",
                  "display_name": "Namespace",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional namespace within Astra DB to use for the collection.",
                  "title_case": false,
                  "type": "str"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 4,
                  "name": "number_of_results",
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int"
                },
                "pre_delete_collection": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": false,
                  "name": "pre_delete_collection",
                  "display_name": "Pre Delete Collection",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Boolean flag to determine whether to delete the collection before creating a new one.",
                  "title_case": false,
                  "type": "bool"
                },
                "search_filter": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "search_filter",
                  "display_name": "Search Metadata Filter",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional dictionary of filters to apply to the search query.",
                  "title_case": false,
                  "type": "dict"
                },
                "search_input": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "search_input",
                  "display_name": "Search Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "search_score_threshold": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": 0,
                  "name": "search_score_threshold",
                  "display_name": "Search Score Threshold",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                  "title_case": false,
                  "type": "float"
                },
                "search_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "Similarity",
                    "Similarity with score threshold",
                    "MMR (Max Marginal Relevance)"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Similarity",
                  "name": "search_type",
                  "display_name": "Search Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Search type to use",
                  "title_case": false,
                  "type": "str"
                },
                "setup_mode": {
                  "trace_as_metadata": true,
                  "options": [
                    "Sync",
                    "Async",
                    "Off"
                  ],
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "Sync",
                  "name": "setup_mode",
                  "display_name": "Setup Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.",
                  "title_case": false,
                  "type": "str"
                },
                "token": {
                  "load_from_db": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "token",
                  "display_name": "Astra DB Application Token",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "Authentication token for accessing Astra DB.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                }
              },
              "description": "Implementation of Vector Store using Astra DB with search capabilities",
              "icon": "AstraDB",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Astra DB",
              "documentation": "https://python.langchain.com/docs/integrations/vectorstores/astradb",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "collection_name",
                "token",
                "api_endpoint",
                "search_input",
                "ingest_data",
                "namespace",
                "metric",
                "batch_size",
                "bulk_insert_batch_concurrency",
                "bulk_insert_overwrite_concurrency",
                "bulk_delete_concurrency",
                "setup_mode",
                "pre_delete_collection",
                "metadata_indexing_include",
                "embedding",
                "metadata_indexing_exclude",
                "collection_indexing_policy",
                "number_of_results",
                "search_type",
                "search_score_threshold",
                "search_filter"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AstraDB-NxJ5p"
          },
          "selected": false,
          "width": 384,
          "height": 803,
          "positionAbsolute": {
            "x": 298.3570482254353,
            "y": -498.9276368963147
          },
          "dragging": false
        },
        {
          "id": "AstraVectorize-JgMWU",
          "type": "genericNode",
          "position": {
            "x": -188.6407591740156,
            "y": -399.5688888349324
          },
          "data": {
            "type": "AstraVectorize",
            "node": {
              "template": {
                "_type": "Component",
                "api_key_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "pa-MzjCe11At98kqUuPN-p3SqtN1ilOisKe_ojXdp3_XF8",
                  "name": "api_key_name",
                  "display_name": "Provider API Key Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The name of the embeddings provider API key stored on Astra.",
                  "title_case": false,
                  "type": "str"
                },
                "authentication": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "authentication",
                  "display_name": "Authentication Parameters",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DictInput, SecretStrInput, MessageTextInput, DropdownInput\nfrom axiestudio.template.field.base import Output\n\n\nclass AstraVectorizeComponent(Component):\n    display_name: str = \"Astra Vectorize\"\n    description: str = \"Configuration options for Astra Vectorize server-side embeddings.\"\n    documentation: str = \"https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html\"\n    icon = \"AstraDB\"\n    name = \"AstraVectorize\"\n\n    VECTORIZE_PROVIDERS_MAPPING = {\n        \"Azure OpenAI\": [\"azureOpenAI\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Hugging Face - Dedicated\": [\"huggingfaceDedicated\", [\"endpoint-defined-model\"]],\n        \"Hugging Face - Serverless\": [\n            \"huggingface\",\n            [\n                \"sentence-transformers/all-MiniLM-L6-v2\",\n                \"intfloat/multilingual-e5-large\",\n                \"intfloat/multilingual-e5-large-instruct\",\n                \"BAAI/bge-small-en-v1.5\",\n                \"BAAI/bge-base-en-v1.5\",\n                \"BAAI/bge-large-en-v1.5\",\n            ],\n        ],\n        \"Jina AI\": [\n            \"jinaAI\",\n            [\n                \"jina-embeddings-v2-base-en\",\n                \"jina-embeddings-v2-base-de\",\n                \"jina-embeddings-v2-base-es\",\n                \"jina-embeddings-v2-base-code\",\n                \"jina-embeddings-v2-base-zh\",\n            ],\n        ],\n        \"Mistral AI\": [\"mistral\", [\"mistral-embed\"]],\n        \"NVIDIA\": [\"nvidia\", [\"NV-Embed-QA\"]],\n        \"OpenAI\": [\"openai\", [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]],\n        \"Upstage\": [\"upstageAI\", [\"solar-embedding-1-large\"]],\n        \"Voyage AI\": [\n            \"voyageAI\",\n            [\"voyage-large-2-instruct\", \"voyage-law-2\", \"voyage-code-2\", \"voyage-large-2\", \"voyage-2\"],\n        ],\n    }\n    VECTORIZE_MODELS_STR = \"\\n\\n\".join(\n        [provider + \": \" + (\", \".join(models[1])) for provider, models in VECTORIZE_PROVIDERS_MAPPING.items()]\n    )\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Provider\",\n            options=VECTORIZE_PROVIDERS_MAPPING.keys(),\n            value=\"\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            info=f\"The embedding model to use for the selected provider. Each provider has a different set of models \"\n            f\"available (https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\\n\\n{VECTORIZE_MODELS_STR}\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"api_key_name\",\n            display_name=\"Provider API Key Name\",\n            info=\"The name of the embeddings provider API key stored on Astra.\",\n        ),\n        SecretStrInput(\n            name=\"provider_api_key\",\n            display_name=\"Provider API Key\",\n            info=\"An alternative to the Astra Authentication that passes an API key for the provider with each request to Astra DB. This may be used when Vectorize is configured for the collection, but no corresponding provider secret is stored within Astra's key management system.\",\n            advanced=True,\n        ),\n        DictInput(\n            name=\"authentication\",\n            display_name=\"Authentication Parameters\",\n            is_list=True,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"model_parameters\",\n            display_name=\"Model Parameters\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Vectorize\", name=\"config\", method=\"build_options\", types=[\"dict\"]),\n    ]\n\n    def build_options(self) -> dict[str, Any]:\n        provider_value = self.VECTORIZE_PROVIDERS_MAPPING[self.provider][0]\n        authentication = {**(self.authentication or {})}\n        api_key_name = self.api_key_name\n        if api_key_name:\n            authentication[\"providerKey\"] = api_key_name\n        return {\n            # must match astrapy.info.CollectionVectorServiceOptions\n            \"collection_vector_service_options\": {\n                \"provider\": provider_value,\n                \"modelName\": self.model_name,\n                \"authentication\": authentication,\n                \"parameters\": self.model_parameters or {},\n            },\n            \"collection_embedding_api_key\": self.provider_api_key,\n        }\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "voyage-multilingual-2",
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The embedding model to use for the selected provider. Each provider has a different set of models available (https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html):\n\nAzure OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nHugging Face - Dedicated: endpoint-defined-model\n\nHugging Face - Serverless: sentence-transformers/all-MiniLM-L6-v2, intfloat/multilingual-e5-large, intfloat/multilingual-e5-large-instruct, BAAI/bge-small-en-v1.5, BAAI/bge-base-en-v1.5, BAAI/bge-large-en-v1.5\n\nJina AI: jina-embeddings-v2-base-en, jina-embeddings-v2-base-de, jina-embeddings-v2-base-es, jina-embeddings-v2-base-code, jina-embeddings-v2-base-zh\n\nMistral AI: mistral-embed\n\nNVIDIA: NV-Embed-QA\n\nOpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002\n\nUpstage: solar-embedding-1-large\n\nVoyage AI: voyage-large-2-instruct, voyage-law-2, voyage-code-2, voyage-large-2, voyage-2",
                  "title_case": false,
                  "type": "str"
                },
                "model_parameters": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": {},
                  "name": "model_parameters",
                  "display_name": "Model Parameters",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict"
                },
                "provider": {
                  "trace_as_metadata": true,
                  "options": [
                    "Azure OpenAI",
                    "Hugging Face - Dedicated",
                    "Hugging Face - Serverless",
                    "Jina AI",
                    "Mistral AI",
                    "NVIDIA",
                    "OpenAI",
                    "Upstage",
                    "Voyage AI"
                  ],
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "Voyage AI",
                  "name": "provider",
                  "display_name": "Provider",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "provider_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "provider_api_key",
                  "display_name": "Provider API Key",
                  "advanced": true,
                  "input_types": [],
                  "dynamic": false,
                  "info": "An alternative to the Astra Authentication that passes an API key for the provider with each request to Astra DB. This may be used when Vectorize is configured for the collection, but no corresponding provider secret is stored within Astra's key management system.",
                  "title_case": false,
                  "password": true,
                  "type": "str"
                }
              },
              "description": "Configuration options for Astra Vectorize server-side embeddings.",
              "icon": "AstraDB",
              "base_classes": [
                "dict"
              ],
              "display_name": "Astra Vectorize",
              "documentation": "https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "dict"
                  ],
                  "name": "config",
                  "display_name": "Vectorize",
                  "method": "build_options",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "provider",
                "model_name",
                "api_key_name",
                "provider_api_key",
                "authentication",
                "model_parameters"
              ],
              "beta": false,
              "edited": false
            },
            "id": "AstraVectorize-JgMWU"
          },
          "selected": false,
          "width": 384,
          "height": 517,
          "positionAbsolute": {
            "x": -188.6407591740156,
            "y": -399.5688888349324
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ParseData-5XQKq",
          "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5XQKqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-uyPXP",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "Prompt-uyPXP",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ParseData",
              "id": "ParseData-5XQKq",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ParseData-5XQKq{œdataTypeœ:œParseDataœ,œidœ:œParseData-5XQKqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-uyPXP{œfieldNameœ:œdataœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ChatInput-6s5SE",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-uyPXP",
          "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "question",
              "id": "Prompt-uyPXP",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-6s5SE",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-6s5SE{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-uyPXP{œfieldNameœ:œquestionœ,œidœ:œPrompt-uyPXPœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "AstraDB-NxJ5p",
          "sourceHandle": "{œdataTypeœ:œAstraDBœ,œidœ:œAstraDB-NxJ5pœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}",
          "target": "ParseData-5XQKq",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-5XQKqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ParseData-5XQKq",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AstraDB",
              "id": "AstraDB-NxJ5p",
              "name": "search_results",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-AstraDB-NxJ5p{œdataTypeœ:œAstraDBœ,œidœ:œAstraDB-NxJ5pœ,œnameœ:œsearch_resultsœ,œoutput_typesœ:[œDataœ]}-ParseData-5XQKq{œfieldNameœ:œdataœ,œidœ:œParseData-5XQKqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "AstraVectorize-JgMWU",
          "sourceHandle": "{œdataTypeœ:œAstraVectorizeœ,œidœ:œAstraVectorize-JgMWUœ,œnameœ:œconfigœ,œoutput_typesœ:[œdictœ]}",
          "target": "AstraDB-NxJ5p",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œEmbeddingsœ,œdictœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "AstraDB-NxJ5p",
              "inputTypes": [
                "Embeddings",
                "dict"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AstraVectorize",
              "id": "AstraVectorize-JgMWU",
              "name": "config",
              "output_types": [
                "dict"
              ]
            }
          },
          "id": "reactflow__edge-AstraVectorize-JgMWU{œdataTypeœ:œAstraVectorizeœ,œidœ:œAstraVectorize-JgMWUœ,œnameœ:œconfigœ,œoutput_typesœ:[œdictœ]}-AstraDB-NxJ5p{œfieldNameœ:œembeddingœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œEmbeddingsœ,œdictœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ChatInput-6s5SE",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "AstraDB-NxJ5p",
          "targetHandle": "{œfieldNameœ:œsearch_inputœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "search_input",
              "id": "AstraDB-NxJ5p",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-6s5SE",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-6s5SE{œdataTypeœ:œChatInputœ,œidœ:œChatInput-6s5SEœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-AstraDB-NxJ5p{œfieldNameœ:œsearch_inputœ,œidœ:œAstraDB-NxJ5pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-uyPXP",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-uyPXPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "AnthropicModel-QLQ4R",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-QLQ4Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "AnthropicModel-QLQ4R",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-uyPXP",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-uyPXP{œdataTypeœ:œPromptœ,œidœ:œPrompt-uyPXPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-QLQ4R{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-QLQ4Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "AnthropicModel-QLQ4R",
          "sourceHandle": "{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QLQ4Rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-SUnri",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SUnriœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-SUnri",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "AnthropicModel",
              "id": "AnthropicModel-QLQ4R",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-AnthropicModel-QLQ4R{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QLQ4Rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-SUnri{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-SUnriœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 250.60968378114626,
        "y": 381.709199114537,
        "zoom": 0.5954852272304637
      }
    },
    "date_created": "2024-07-17T07:21:49.317Z",
    "date_updated": "2024-07-17T07:22:55.954Z",
    "status": "Public",
    "sort": null,
    "user_updated": "80067d70-c092-4332-b846-8121303bced1",
    "user_created": {
      "username": "eyalcats",
      "first_name": "Eyal",
      "last_name": "Katz",
      "id": "80067d70-c092-4332-b846-8121303bced1"
    },
    "tags": [
      {
        "tags_id": {
          "name": "Prompt",
          "id": "57f5c681-a1f5-4053-be33-e9525e7eb00a"
        }
      }
    ]
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:02.275Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 64,
    "converter_version": "1.0.0"
  }
}