{
  "id": "9e120d26-d4f6-4538-9f24-bf6fa0bcc0a5",
  "name": "Add data to Vector Index (1)",
  "description": "Design Dialogues with Langflow. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "ishita1196",
    "first_name": "Mayank",
    "last_name": "Mahajan",
    "id": "6cbcbad6-3ab4-41c5-a0c5-4ea9aa99bd54",
    "full_name": "Mayank Mahajan"
  },
  "store_url": "https://www.langflow.store/store/component/9e120d26-d4f6-4538-9f24-bf6fa0bcc0a5",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-09T17:19:58.774Z",
    "updated": "2024-09-09T17:19:58.803Z",
    "downloaded": "2025-08-19T17:50:05.649Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.15",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "SplitText-XEb86",
        "type": "genericNode",
        "position": {
          "x": 396.47746170476637,
          "y": 346.70012987626876
        },
        "data": {
          "type": "SplitText",
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": "200",
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> Message:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        status = str(data[0].text)\n        return status\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Message"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.15"
          },
          "id": "SplitText-XEb86"
        },
        "selected": false,
        "width": 384,
        "height": 542,
        "positionAbsolute": {
          "x": 396.47746170476637,
          "y": 346.70012987626876
        },
        "dragging": false
      },
      {
        "id": "File-8IFgS",
        "type": "genericNode",
        "position": {
          "x": -95.75120296391401,
          "y": 337.8468245108834
        },
        "data": {
          "type": "File",
          "node": {
            "template": {
              "_type": "Component",
              "path": {
                "trace_as_metadata": true,
                "file_path": "9c93a188-51ee-4b2e-9b9d-5be312c5bf18/check_offer.docx",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "",
                "display_name": "Path",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "A generic file loader.",
            "icon": "file-text",
            "base_classes": [
              "Data"
            ],
            "display_name": "File",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "silent_errors"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "File-8IFgS"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": -95.75120296391401,
          "y": 337.8468245108834
        },
        "dragging": false
      },
      {
        "id": "AzureOpenAIModel-3x3lC",
        "type": "genericNode",
        "position": {
          "x": 1460.0599010749177,
          "y": 18.344344287608095
        },
        "data": {
          "type": "AzureOpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_version": {
                "trace_as_metadata": true,
                "options": [
                  "2024-02-15-preview",
                  "2023-03-15-preview",
                  "2023-05-15",
                  "2023-06-01-preview",
                  "2023-07-01-preview",
                  "2023-08-01-preview",
                  "2023-09-01-preview",
                  "2023-12-01-preview",
                  "2024-04-09",
                  "2024-05-13"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_version",
                "value": "2024-02-15-preview",
                "display_name": "API Version",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "azure_deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_deployment",
                "value": "gpt-4",
                "display_name": "Deployment Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "azure_endpoint": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "azure_endpoint",
                "value": "https://bst-openai.openai.azure.com/",
                "display_name": "Azure Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-02-15-preview\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = LCModelComponent._base_inputs + [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.7,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Azure OpenAI LLMs.",
            "icon": "Azure",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Azure OpenAI",
            "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "azure_endpoint",
              "azure_deployment",
              "api_key",
              "api_version",
              "temperature",
              "max_tokens"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.15"
          },
          "id": "AzureOpenAIModel-3x3lC"
        },
        "selected": true,
        "width": 384,
        "height": 768,
        "positionAbsolute": {
          "x": 1460.0599010749177,
          "y": 18.344344287608095
        },
        "dragging": false
      },
      {
        "id": "Prompt-eyjmC",
        "type": "genericNode",
        "position": {
          "x": 932.0610684135406,
          "y": -145.76281611841424
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Compare the context with the average values and the ranges of the price fields. Check if the prices in the context are lower or higher than the average, and if the prices fall within the range for each price field, are less than the lower price range or higher than the higher price range. Try to analyse all the fields in the context to justify the prices in the context and its comparison. Provide a justification in detail for as many descriptive fields with their values as possible with the values mentioned in the context.\nHere is the: {context}\nHere are the average values for all the price fields: {average}\nHere are ranges for all the price fields: {range}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "average": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "average",
                "display_name": "average",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "range": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "range",
                "display_name": "range",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "context",
                "average",
                "range"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.15"
          },
          "id": "Prompt-eyjmC"
        },
        "selected": false,
        "width": 384,
        "height": 580,
        "positionAbsolute": {
          "x": 932.0610684135406,
          "y": -145.76281611841424
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-Wwdal",
        "type": "genericNode",
        "position": {
          "x": -100.39526195148073,
          "y": -174.5355859684044
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents.indexes import SearchIndexClient\nimport ast\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\n        MessageTextInput(name=\"input_text\", display_name=\"Input Data\", value=\"Hello, World!\"),\n\n    ]\n\n    outputs = [\n        Output(display_name=\"Price Range\", name=\"output_range\", method=\"build_output\"),\n        Output(display_name=\"Average Values\", name=\"output_aveg\", method=\"build_average\"),\n    ]\n    \n    def get_embeddings(self, text: str) -> Data:\n\n        embedding = AzureOpenAIEmbeddings(\n            azure_deployment=\"text-embedding-ada-002\",\n            openai_api_version=\"2024-02-15-preview\",\n            azure_endpoint=\"https://bst-openai.openai.azure.com/\",\n            openai_api_key=\"638cc37ffa90477991710dff30191ecd\",\n        )\n        embeddings = embedding.embed_documents([text])\n        return embeddings[0]\n    \n    def build_output(self) -> str:\n        key_value_pairs = {}\n        keys = []\n\n        search_service_name = \"gptkb-4bzmnubbcddwy\"\n        admin_api_key = \"lOTcnvgQmumTy27T8lzNtgpL9dPTUSfhDrioRZZD98AzSeC7WTaW\"\n        index_name = \"vector_search\"\n        search_key = \"HF8rWNDhDP0uGi54gmJrU3jjbFi3Pa0po7VNfZbssIAzSeDx64gs\"\n        # Construct the endpoint URL for your Azure Search service\n        endpoint = f\"https://{search_service_name}.search.windows.net\"\n        \n        # Create a client for the Search Index\n        client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_api_key))\n        \n        # Get the index schema\n        index_schema = client.get_index(index_name)\n        index_fields = []\n        string_fields = []\n        double_fields = []\n        result = []\n        fields_to_average = []\n        field_min = {field: float('inf') for field in fields_to_average}\n        field_max = {field: float('-inf') for field in fields_to_average}\n\n        \n        for field in index_schema.fields:\n            if field.type == \"Edm.String\":\n                string_fields.append(field)\n            elif field.type == \"Edm.Double\":\n                double_fields.append(field)\n        \n        for field in double_fields:\n            fields_to_average.append(field.name)\n            \n        field_sums = {field: 0 for field in fields_to_average}\n        total_documents = 0\n        \n        search_client = SearchClient(\n            endpoint=endpoint,\n            index_name=index_name,\n            credential=AzureKeyCredential(search_key)\n        )\n                \n        # Perform a search query to retrieve all documents (you can modify the query as needed)\n        results = search_client.search(search_text=\"*\", select=fields_to_average)\n        \n        # Loop through the documents and accumulate the sums\n        for result in results:\n            total_documents += 1\n            for field in fields_to_average:\n                field_sums[field] += result[field] if result[field] is not None else 0\n        \n        # Calculate the averages\n        if total_documents > 0:\n            field_averages = {field: field_sums[field] / total_documents for field in fields_to_average}\n        else:\n            field_averages = {field: 0 for field in fields_to_average}\n                    \n        range_values = []\n        for field in fields_to_average:\n            search_string_high = str(field) + \" desc\"\n            search_results_high = search_client.search(search_text=\"*\", order_by=search_string_high, top=1)\n            \n            search_string_low = str(field) + \" asc\"\n            search_results_low = search_client.search(search_text=\"*\", order_by=search_string_low, top=1)\n            \n            for result in search_results_high:\n                highest = result[str(field)]\n                \n            for result in search_results_low:\n                lowest = result[str(field)]\n            \n            res = [field, lowest, highest]\n            range_values.append(res)\n\n        return str(range_values)\n        \n    \n    def build_average(self) -> str:\n        key_value_pairs = {}\n        keys = []\n\n        search_service_name = \"gptkb-4bzmnubbcddwy\"\n        admin_api_key = \"lOTcnvgQmumTy27T8lzNtgpL9dPTUSfhDrioRZZD98AzSeC7WTaW\"\n        index_name = \"vector_search\"\n        search_key = \"HF8rWNDhDP0uGi54gmJrU3jjbFi3Pa0po7VNfZbssIAzSeDx64gs\"\n        # Construct the endpoint URL for your Azure Search service\n        endpoint = f\"https://{search_service_name}.search.windows.net\"\n        \n        # Create a client for the Search Index\n        client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_api_key))\n        \n        # Get the index schema\n        index_schema = client.get_index(index_name)\n        index_fields = []\n        string_fields = []\n        double_fields = []\n        result = []\n        fields_to_average = []\n        field_min = {field: float('inf') for field in fields_to_average}\n        field_max = {field: float('-inf') for field in fields_to_average}\n\n        \n        for field in index_schema.fields:\n            if field.type == \"Edm.String\":\n                string_fields.append(field)\n            elif field.type == \"Edm.Double\":\n                double_fields.append(field)\n        \n        for field in double_fields:\n            fields_to_average.append(field.name)\n            \n        field_sums = {field: 0 for field in fields_to_average}\n        total_documents = 0\n        \n        search_client = SearchClient(\n            endpoint=endpoint,\n            index_name=index_name,\n            credential=AzureKeyCredential(search_key)\n        )\n                \n        # Perform a search query to retrieve all documents (you can modify the query as needed)\n        results = search_client.search(search_text=\"*\", select=fields_to_average)\n        \n        # Loop through the documents and accumulate the sums\n        for result in results:\n            total_documents += 1\n            for field in fields_to_average:\n                field_sums[field] += result[field] if result[field] is not None else 0\n        \n        # Calculate the averages\n        if total_documents > 0:\n            field_averages = {field: field_sums[field] / total_documents for field in fields_to_average}\n        else:\n            field_averages = {field: 0 for field in fields_to_average}\n            \n        return str(field_averages)\n\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Input Data",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "custom_components",
            "base_classes": [
              "Text"
            ],
            "display_name": "Add Documents",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "output_range",
                "display_name": "Price Range",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "output_aveg",
                "display_name": "Average Values",
                "method": "build_average",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "input_text"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.15"
          },
          "id": "CustomComponent-Wwdal"
        },
        "selected": false,
        "width": 384,
        "height": 449,
        "positionAbsolute": {
          "x": -100.39526195148073,
          "y": -174.5355859684044
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "File-8IFgS",
        "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-8IFgSœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "SplitText-XEb86",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-XEb86œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-XEb86",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "File",
            "id": "File-8IFgS",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-File-8IFgS{œdataTypeœ:œFileœ,œidœ:œFile-8IFgSœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-XEb86{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-XEb86œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "SplitText-XEb86",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-XEb86œ,œnameœ:œchunksœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-eyjmC",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-eyjmC",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-XEb86",
            "name": "chunks",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-SplitText-XEb86{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-XEb86œ,œnameœ:œchunksœ,œoutput_typesœ:[œMessageœ]}-Prompt-eyjmC{œfieldNameœ:œcontextœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-eyjmC",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-eyjmCœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "AzureOpenAIModel-3x3lC",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-3x3lCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "AzureOpenAIModel-3x3lC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-eyjmC",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-eyjmC{œdataTypeœ:œPromptœ,œidœ:œPrompt-eyjmCœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AzureOpenAIModel-3x3lC{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-3x3lCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-Wwdal",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_rangeœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-eyjmC",
        "targetHandle": "{œfieldNameœ:œrangeœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "range",
            "id": "Prompt-eyjmC",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-Wwdal",
            "name": "output_range",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-Wwdal{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_rangeœ,œoutput_typesœ:[œTextœ]}-Prompt-eyjmC{œfieldNameœ:œrangeœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "CustomComponent-Wwdal",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_avegœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-eyjmC",
        "targetHandle": "{œfieldNameœ:œaverageœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "average",
            "id": "Prompt-eyjmC",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-Wwdal",
            "name": "output_aveg",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-Wwdal{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_avegœ,œoutput_typesœ:[œTextœ]}-Prompt-eyjmC{œfieldNameœ:œaverageœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": -177.03575838198526,
      "y": 152.2909859690912,
      "zoom": 0.5026790306373855
    }
  },
  "metadata": {
    "SplitText": {
      "count": 1
    },
    "File": {
      "count": 1
    },
    "AzureOpenAIModel": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "CustomComponent": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "9e120d26-d4f6-4538-9f24-bf6fa0bcc0a5",
    "name": "Add data to Vector Index (1)",
    "description": "Design Dialogues with Langflow.",
    "is_component": false,
    "liked_by_count": "4",
    "downloads_count": "8",
    "metadata": {
      "SplitText": {
        "count": 1
      },
      "File": {
        "count": 1
      },
      "AzureOpenAIModel": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "CustomComponent": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "1.0.15",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "SplitText-XEb86",
          "type": "genericNode",
          "position": {
            "x": 396.47746170476637,
            "y": 346.70012987626876
          },
          "data": {
            "type": "SplitText",
            "node": {
              "template": {
                "_type": "Component",
                "data_inputs": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_inputs",
                  "value": "",
                  "display_name": "Data Inputs",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_overlap",
                  "value": "200",
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Number of characters to overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput",
                  "load_from_db": false
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of characters in each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> Message:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        status = str(data[0].text)\n        return status\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separator": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "separator",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The character to split on. Defaults to newline.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text into chunks based on specified criteria.",
              "icon": "scissors-line-dashed",
              "base_classes": [
                "Message"
              ],
              "display_name": "Split Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "chunks",
                  "display_name": "Chunks",
                  "method": "split_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data_inputs",
                "chunk_overlap",
                "chunk_size",
                "separator"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.15"
            },
            "id": "SplitText-XEb86"
          },
          "selected": false,
          "width": 384,
          "height": 542,
          "positionAbsolute": {
            "x": 396.47746170476637,
            "y": 346.70012987626876
          },
          "dragging": false
        },
        {
          "id": "File-8IFgS",
          "type": "genericNode",
          "position": {
            "x": -95.75120296391401,
            "y": 337.8468245108834
          },
          "data": {
            "type": "File",
            "node": {
              "template": {
                "_type": "Component",
                "path": {
                  "trace_as_metadata": true,
                  "file_path": "9c93a188-51ee-4b2e-9b9d-5be312c5bf18/check_offer.docx",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx"
                  ],
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "path",
                  "value": "",
                  "display_name": "Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pathlib import Path\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, FileInput, Output\nfrom axiestudio.schema import Data\n\n\nclass FileComponent(Component):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    inputs = [\n        FileInput(\n            name=\"path\",\n            display_name=\"Path\",\n            file_types=TEXT_FILE_TYPES,\n            info=f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_file\"),\n    ]\n\n    def load_file(self) -> Data:\n        if not self.path:\n            raise ValueError(\"Please, upload a file to use this component.\")\n        resolved_path = self.resolve_path(self.path)\n        silent_errors = self.silent_errors\n\n        extension = Path(resolved_path).suffix[1:].lower()\n\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n\n        data = parse_text_file_to_data(resolved_path, silent_errors)\n        self.status = data if data else \"No data\"\n        return data or Data()\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "silent_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "silent_errors",
                  "value": false,
                  "display_name": "Silent Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, errors will not raise an exception.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "A generic file loader.",
              "icon": "file-text",
              "base_classes": [
                "Data"
              ],
              "display_name": "File",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "load_file",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "path",
                "silent_errors"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "File-8IFgS"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": -95.75120296391401,
            "y": 337.8468245108834
          },
          "dragging": false
        },
        {
          "id": "AzureOpenAIModel-3x3lC",
          "type": "genericNode",
          "position": {
            "x": 1460.0599010749177,
            "y": 18.344344287608095
          },
          "data": {
            "type": "AzureOpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "api_version": {
                  "trace_as_metadata": true,
                  "options": [
                    "2024-02-15-preview",
                    "2023-03-15-preview",
                    "2023-05-15",
                    "2023-06-01-preview",
                    "2023-07-01-preview",
                    "2023-08-01-preview",
                    "2023-09-01-preview",
                    "2023-12-01-preview",
                    "2024-04-09",
                    "2024-05-13"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_version",
                  "value": "2024-02-15-preview",
                  "display_name": "API Version",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "azure_deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "azure_deployment",
                  "value": "gpt-4",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "azure_endpoint": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "azure_endpoint",
                  "value": "https://bst-openai.openai.azure.com/",
                  "display_name": "Azure Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai import AzureChatOpenAI\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, SecretStrInput\n\n\nclass AzureChatOpenAIComponent(LCModelComponent):\n    display_name: str = \"Azure OpenAI\"\n    description: str = \"Generate text using Azure OpenAI LLMs.\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/llms/azure_openai\"\n    beta = False\n    icon = \"Azure\"\n    name = \"AzureOpenAIModel\"\n\n    AZURE_OPENAI_API_VERSIONS = [\n        \"2024-02-15-preview\",\n        \"2023-03-15-preview\",\n        \"2023-05-15\",\n        \"2023-06-01-preview\",\n        \"2023-07-01-preview\",\n        \"2023-08-01-preview\",\n        \"2023-09-01-preview\",\n        \"2023-12-01-preview\",\n        \"2024-04-09\",\n        \"2024-05-13\",\n    ]\n\n    inputs = LCModelComponent._base_inputs + [\n        MessageTextInput(\n            name=\"azure_endpoint\",\n            display_name=\"Azure Endpoint\",\n            info=\"Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`\",\n            required=True,\n        ),\n        MessageTextInput(name=\"azure_deployment\", display_name=\"Deployment Name\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\"),\n        DropdownInput(\n            name=\"api_version\",\n            display_name=\"API Version\",\n            options=AZURE_OPENAI_API_VERSIONS,\n            value=AZURE_OPENAI_API_VERSIONS[-1],\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.7),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        azure_endpoint = self.azure_endpoint\n        azure_deployment = self.azure_deployment\n        api_version = self.api_version\n        api_key = self.api_key\n        temperature = self.temperature\n        max_tokens = self.max_tokens\n        stream = self.stream\n\n        try:\n            output = AzureChatOpenAI(\n                azure_endpoint=azure_endpoint,\n                azure_deployment=azure_deployment,\n                api_version=api_version,\n                api_key=api_key,\n                temperature=temperature,\n                max_tokens=max_tokens or None,\n                streaming=stream,\n            )\n        except Exception as e:\n            raise ValueError(f\"Could not connect to AzureOpenAI API: {str(e)}\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.7,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Azure OpenAI LLMs.",
              "icon": "Azure",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Azure OpenAI",
              "documentation": "https://python.langchain.com/docs/integrations/llms/azure_openai",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "azure_endpoint",
                "azure_deployment",
                "api_key",
                "api_version",
                "temperature",
                "max_tokens"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.15"
            },
            "id": "AzureOpenAIModel-3x3lC"
          },
          "selected": true,
          "width": 384,
          "height": 768,
          "positionAbsolute": {
            "x": 1460.0599010749177,
            "y": 18.344344287608095
          },
          "dragging": false
        },
        {
          "id": "Prompt-eyjmC",
          "type": "genericNode",
          "position": {
            "x": 932.0610684135406,
            "y": -145.76281611841424
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Compare the context with the average values and the ranges of the price fields. Check if the prices in the context are lower or higher than the average, and if the prices fall within the range for each price field, are less than the lower price range or higher than the higher price range. Try to analyse all the fields in the context to justify the prices in the context and its comparison. Provide a justification in detail for as many descriptive fields with their values as possible with the values mentioned in the context.\nHere is the: {context}\nHere are the average values for all the price fields: {average}\nHere are ranges for all the price fields: {range}",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput",
                  "load_from_db": false
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "average": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "average",
                  "display_name": "average",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "range": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "range",
                  "display_name": "range",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "context",
                  "average",
                  "range"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.15"
            },
            "id": "Prompt-eyjmC"
          },
          "selected": false,
          "width": 384,
          "height": 580,
          "positionAbsolute": {
            "x": 932.0610684135406,
            "y": -145.76281611841424
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-Wwdal",
          "type": "genericNode",
          "position": {
            "x": -100.39526195148073,
            "y": -174.5355859684044
          },
          "data": {
            "type": "CustomComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents.indexes import SearchIndexClient\nimport ast\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\n        MessageTextInput(name=\"input_text\", display_name=\"Input Data\", value=\"Hello, World!\"),\n\n    ]\n\n    outputs = [\n        Output(display_name=\"Price Range\", name=\"output_range\", method=\"build_output\"),\n        Output(display_name=\"Average Values\", name=\"output_aveg\", method=\"build_average\"),\n    ]\n    \n    def get_embeddings(self, text: str) -> Data:\n\n        embedding = AzureOpenAIEmbeddings(\n            azure_deployment=\"text-embedding-ada-002\",\n            openai_api_version=\"2024-02-15-preview\",\n            azure_endpoint=\"https://bst-openai.openai.azure.com/\",\n            openai_api_key=\"638cc37ffa90477991710dff30191ecd\",\n        )\n        embeddings = embedding.embed_documents([text])\n        return embeddings[0]\n    \n    def build_output(self) -> str:\n        key_value_pairs = {}\n        keys = []\n\n        search_service_name = \"gptkb-4bzmnubbcddwy\"\n        admin_api_key = \"lOTcnvgQmumTy27T8lzNtgpL9dPTUSfhDrioRZZD98AzSeC7WTaW\"\n        index_name = \"vector_search\"\n        search_key = \"HF8rWNDhDP0uGi54gmJrU3jjbFi3Pa0po7VNfZbssIAzSeDx64gs\"\n        # Construct the endpoint URL for your Azure Search service\n        endpoint = f\"https://{search_service_name}.search.windows.net\"\n        \n        # Create a client for the Search Index\n        client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_api_key))\n        \n        # Get the index schema\n        index_schema = client.get_index(index_name)\n        index_fields = []\n        string_fields = []\n        double_fields = []\n        result = []\n        fields_to_average = []\n        field_min = {field: float('inf') for field in fields_to_average}\n        field_max = {field: float('-inf') for field in fields_to_average}\n\n        \n        for field in index_schema.fields:\n            if field.type == \"Edm.String\":\n                string_fields.append(field)\n            elif field.type == \"Edm.Double\":\n                double_fields.append(field)\n        \n        for field in double_fields:\n            fields_to_average.append(field.name)\n            \n        field_sums = {field: 0 for field in fields_to_average}\n        total_documents = 0\n        \n        search_client = SearchClient(\n            endpoint=endpoint,\n            index_name=index_name,\n            credential=AzureKeyCredential(search_key)\n        )\n                \n        # Perform a search query to retrieve all documents (you can modify the query as needed)\n        results = search_client.search(search_text=\"*\", select=fields_to_average)\n        \n        # Loop through the documents and accumulate the sums\n        for result in results:\n            total_documents += 1\n            for field in fields_to_average:\n                field_sums[field] += result[field] if result[field] is not None else 0\n        \n        # Calculate the averages\n        if total_documents > 0:\n            field_averages = {field: field_sums[field] / total_documents for field in fields_to_average}\n        else:\n            field_averages = {field: 0 for field in fields_to_average}\n                    \n        range_values = []\n        for field in fields_to_average:\n            search_string_high = str(field) + \" desc\"\n            search_results_high = search_client.search(search_text=\"*\", order_by=search_string_high, top=1)\n            \n            search_string_low = str(field) + \" asc\"\n            search_results_low = search_client.search(search_text=\"*\", order_by=search_string_low, top=1)\n            \n            for result in search_results_high:\n                highest = result[str(field)]\n                \n            for result in search_results_low:\n                lowest = result[str(field)]\n            \n            res = [field, lowest, highest]\n            range_values.append(res)\n\n        return str(range_values)\n        \n    \n    def build_average(self) -> str:\n        key_value_pairs = {}\n        keys = []\n\n        search_service_name = \"gptkb-4bzmnubbcddwy\"\n        admin_api_key = \"lOTcnvgQmumTy27T8lzNtgpL9dPTUSfhDrioRZZD98AzSeC7WTaW\"\n        index_name = \"vector_search\"\n        search_key = \"HF8rWNDhDP0uGi54gmJrU3jjbFi3Pa0po7VNfZbssIAzSeDx64gs\"\n        # Construct the endpoint URL for your Azure Search service\n        endpoint = f\"https://{search_service_name}.search.windows.net\"\n        \n        # Create a client for the Search Index\n        client = SearchIndexClient(endpoint=endpoint, credential=AzureKeyCredential(admin_api_key))\n        \n        # Get the index schema\n        index_schema = client.get_index(index_name)\n        index_fields = []\n        string_fields = []\n        double_fields = []\n        result = []\n        fields_to_average = []\n        field_min = {field: float('inf') for field in fields_to_average}\n        field_max = {field: float('-inf') for field in fields_to_average}\n\n        \n        for field in index_schema.fields:\n            if field.type == \"Edm.String\":\n                string_fields.append(field)\n            elif field.type == \"Edm.Double\":\n                double_fields.append(field)\n        \n        for field in double_fields:\n            fields_to_average.append(field.name)\n            \n        field_sums = {field: 0 for field in fields_to_average}\n        total_documents = 0\n        \n        search_client = SearchClient(\n            endpoint=endpoint,\n            index_name=index_name,\n            credential=AzureKeyCredential(search_key)\n        )\n                \n        # Perform a search query to retrieve all documents (you can modify the query as needed)\n        results = search_client.search(search_text=\"*\", select=fields_to_average)\n        \n        # Loop through the documents and accumulate the sums\n        for result in results:\n            total_documents += 1\n            for field in fields_to_average:\n                field_sums[field] += result[field] if result[field] is not None else 0\n        \n        # Calculate the averages\n        if total_documents > 0:\n            field_averages = {field: field_sums[field] / total_documents for field in fields_to_average}\n        else:\n            field_averages = {field: 0 for field in fields_to_average}\n            \n        return str(field_averages)\n\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_text",
                  "value": "",
                  "display_name": "Input Data",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input Value",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Use as a template to create your own component.",
              "icon": "custom_components",
              "base_classes": [
                "Text"
              ],
              "display_name": "Add Documents",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Text"
                  ],
                  "selected": "Text",
                  "name": "output_range",
                  "display_name": "Price Range",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Text"
                  ],
                  "selected": "Text",
                  "name": "output_aveg",
                  "display_name": "Average Values",
                  "method": "build_average",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "input_text"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.15"
            },
            "id": "CustomComponent-Wwdal"
          },
          "selected": false,
          "width": 384,
          "height": 449,
          "positionAbsolute": {
            "x": -100.39526195148073,
            "y": -174.5355859684044
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "File-8IFgS",
          "sourceHandle": "{œdataTypeœ:œFileœ,œidœ:œFile-8IFgSœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
          "target": "SplitText-XEb86",
          "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-XEb86œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data_inputs",
              "id": "SplitText-XEb86",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "File",
              "id": "File-8IFgS",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-File-8IFgS{œdataTypeœ:œFileœ,œidœ:œFile-8IFgSœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-XEb86{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-XEb86œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "SplitText-XEb86",
          "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-XEb86œ,œnameœ:œchunksœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-eyjmC",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-eyjmC",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "SplitText",
              "id": "SplitText-XEb86",
              "name": "chunks",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-SplitText-XEb86{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-XEb86œ,œnameœ:œchunksœ,œoutput_typesœ:[œMessageœ]}-Prompt-eyjmC{œfieldNameœ:œcontextœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-eyjmC",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-eyjmCœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "AzureOpenAIModel-3x3lC",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-3x3lCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "AzureOpenAIModel-3x3lC",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-eyjmC",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-eyjmC{œdataTypeœ:œPromptœ,œidœ:œPrompt-eyjmCœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AzureOpenAIModel-3x3lC{œfieldNameœ:œinput_valueœ,œidœ:œAzureOpenAIModel-3x3lCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-Wwdal",
          "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_rangeœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-eyjmC",
          "targetHandle": "{œfieldNameœ:œrangeœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "range",
              "id": "Prompt-eyjmC",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CustomComponent",
              "id": "CustomComponent-Wwdal",
              "name": "output_range",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-Wwdal{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_rangeœ,œoutput_typesœ:[œTextœ]}-Prompt-eyjmC{œfieldNameœ:œrangeœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "CustomComponent-Wwdal",
          "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_avegœ,œoutput_typesœ:[œTextœ]}",
          "target": "Prompt-eyjmC",
          "targetHandle": "{œfieldNameœ:œaverageœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "average",
              "id": "Prompt-eyjmC",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CustomComponent",
              "id": "CustomComponent-Wwdal",
              "name": "output_aveg",
              "output_types": [
                "Text"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-Wwdal{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Wwdalœ,œnameœ:œoutput_avegœ,œoutput_typesœ:[œTextœ]}-Prompt-eyjmC{œfieldNameœ:œaverageœ,œidœ:œPrompt-eyjmCœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": -177.03575838198526,
        "y": 152.2909859690912,
        "zoom": 0.5026790306373855
      }
    },
    "date_created": "2024-09-09T17:19:58.774Z",
    "date_updated": "2024-09-09T17:19:58.803Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6cbcbad6-3ab4-41c5-a0c5-4ea9aa99bd54",
    "user_created": {
      "username": "ishita1196",
      "first_name": "Mayank",
      "last_name": "Mahajan",
      "id": "6cbcbad6-3ab4-41c5-a0c5-4ea9aa99bd54"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:02.691Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 48,
    "converter_version": "1.0.0"
  }
}