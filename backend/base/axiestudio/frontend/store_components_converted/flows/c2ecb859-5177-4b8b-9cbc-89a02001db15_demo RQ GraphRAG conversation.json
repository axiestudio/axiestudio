{
  "id": "c2ecb859-5177-4b8b-9cbc-89a02001db15",
  "name": "[demo] RQ GraphRAG conversation",
  "description": "RQ assisted graphrag conversation (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "jingconsult",
    "first_name": "Jing",
    "last_name": "Consulting",
    "id": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "full_name": "Jing Consulting"
  },
  "store_url": "https://www.langflow.store/store/component/c2ecb859-5177-4b8b-9cbc-89a02001db15",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-21T09:13:38.069Z",
    "updated": "2024-10-21T09:13:38.211Z",
    "downloaded": "2025-08-19T17:50:07.001Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
        "type": "genericNode",
        "position": {
          "x": -1553.7468478695346,
          "y": -139.46983356297787
        },
        "data": {
          "type": "KnowledgeGraphIndexKRetrieverComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n\r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=\"Document\",\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "k",
                "value": 4,
                "display_name": "Number of results to return",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_embedding_model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_embedding_model",
                "value": "text-embedding-3-small",
                "display_name": "Embedding Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "user_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "User query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Neo4J K Retriever (Vector Search)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "user_query",
              "k",
              "openai_embedding_model",
              "openai_api_key",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX"
        },
        "selected": false,
        "width": 384,
        "height": 691,
        "positionAbsolute": {
          "x": -1553.7468478695346,
          "y": -139.46983356297787
        },
        "dragging": false
      },
      {
        "id": "Prompt-mPmaJ",
        "type": "genericNode",
        "position": {
          "x": 803.803042166736,
          "y": 183.19102418146838
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Conversation Memory: {memory}\nContext: {context}\nLabeled Documents: {labeled_documents}\nUser File: {user_file}\nQuestion: {question}\nSubdomains: {subdomains}\nSubdomain Context: {subdomain_context}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "memory": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "memory",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "user_file": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_file",
                "display_name": "user_file",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "labeled_documents": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "labeled_documents",
                "display_name": "labeled_documents",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "subdomain_context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "subdomain_context",
                "display_name": "subdomain_context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "subdomains": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "subdomains",
                "display_name": "subdomains",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Generate a prompt for LLM to process query",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "memory",
                "context",
                "labeled_documents",
                "user_file",
                "question",
                "subdomains",
                "subdomain_context"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Prompt-mPmaJ"
        },
        "selected": false,
        "width": 384,
        "height": 891,
        "positionAbsolute": {
          "x": 803.803042166736,
          "y": 183.19102418146838
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-pHCSV",
        "type": "genericNode",
        "position": {
          "x": 1403.3436178353643,
          "y": 1275.1313254043337
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": false
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-pHCSV"
        },
        "selected": false,
        "width": 384,
        "height": 679,
        "positionAbsolute": {
          "x": 1403.3436178353643,
          "y": 1275.1313254043337
        },
        "dragging": false
      },
      {
        "id": "Neo4jCredentialLoader-OdDSF",
        "type": "genericNode",
        "position": {
          "x": -2597.1327148085256,
          "y": -205.3840003152996
        },
        "data": {
          "type": "Neo4jCredentialLoader",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_password": {
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_password",
                "value": "Neo4j Password",
                "display_name": "Neo4j Password",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_url",
                "value": "neo4j://jingconsult.tech:7687",
                "display_name": "Neo4j URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_username": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_username",
                "value": "neo4j",
                "display_name": "Neo4j Username",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "A handy component to load neo4j credentials",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Neo4j Credential Loader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "credentials",
                "display_name": "Credentials",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "neo4j_url",
              "neo4j_username",
              "neo4j_password"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "Neo4jCredentialLoader-OdDSF"
        },
        "selected": false,
        "width": 384,
        "height": 465,
        "positionAbsolute": {
          "x": -2597.1327148085256,
          "y": -205.3840003152996
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-1JJGM",
        "type": "genericNode",
        "position": {
          "x": 1917.1052240661318,
          "y": 986.3484963560147
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatOutput-1JJGM"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": 1917.1052240661318,
          "y": 986.3484963560147
        },
        "dragging": false
      },
      {
        "id": "VectorRetrieverParserComponent-arvf7",
        "type": "genericNode",
        "position": {
          "x": -690.318341057922,
          "y": 504.67586328169546
        },
        "data": {
          "type": "VectorRetrieverParserComponent",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Parse retrieved Documents",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Vector Retriever Parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parsed_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "VectorRetrieverParserComponent-arvf7"
        },
        "selected": false,
        "width": 384,
        "height": 257,
        "positionAbsolute": {
          "x": -690.318341057922,
          "y": 504.67586328169546
        },
        "dragging": false
      },
      {
        "id": "CombineText-3sFLj",
        "type": "genericNode",
        "position": {
          "x": -33.43760090079604,
          "y": 485.7503649564312
        },
        "data": {
          "type": "CombineText",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "delimiter": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "delimiter",
                "value": "",
                "display_name": "Delimiter",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text1": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text1",
                "value": "",
                "display_name": "First Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text2": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text2",
                "value": "",
                "display_name": "Second Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "icon": "merge",
            "base_classes": [
              "Message"
            ],
            "display_name": "Combine Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "combined_text",
                "display_name": "Combined Text",
                "method": "combine_texts",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "CombineText-3sFLj"
        },
        "selected": false,
        "width": 384,
        "height": 493,
        "positionAbsolute": {
          "x": -33.43760090079604,
          "y": 485.7503649564312
        },
        "dragging": false
      },
      {
        "id": "ChatInput-CozXU",
        "type": "genericNode",
        "position": {
          "x": -3682.906807200662,
          "y": 708.277545087129
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Most total goals in a premier league season?",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatInput-CozXU"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": -3682.906807200662,
          "y": 708.277545087129
        },
        "dragging": false
      },
      {
        "id": "Memory-7czUw",
        "type": "genericNode",
        "position": {
          "x": -443.3263533525806,
          "y": 1681.6828277169948
        },
        "data": {
          "type": "Memory",
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "BaseChatMemory"
                ],
                "selected": "BaseChatMemory",
                "name": "lc_memory",
                "display_name": "Memory",
                "method": "build_lc_memory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Memory-7czUw"
        },
        "selected": false,
        "width": 384,
        "height": 373,
        "positionAbsolute": {
          "x": -443.3263533525806,
          "y": 1681.6828277169948
        },
        "dragging": false
      },
      {
        "id": "OpenAIEmbeddings-C2xV6",
        "type": "genericNode",
        "position": {
          "x": -666.425503055166,
          "y": 2498.9751055970846
        },
        "data": {
          "type": "OpenAIEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-small",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_version": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_base",
              "openai_api_key",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIEmbeddings-C2xV6"
        },
        "selected": false,
        "width": 384,
        "height": 379,
        "positionAbsolute": {
          "x": -666.425503055166,
          "y": 2498.9751055970846
        },
        "dragging": false
      },
      {
        "id": "VectorRetriever-LuqmZ",
        "type": "genericNode",
        "position": {
          "x": 220.15983853713158,
          "y": 2360.9990646753527
        },
        "data": {
          "type": "VectorRetriever",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chat_session_id": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_session_id",
                "value": "",
                "display_name": "Chat Session ID",
                "advanced": false,
                "dynamic": false,
                "info": "Chat Session ID",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass VectorRetriever(Component):\r\n    display_name = \"Vector Retriever\"\r\n    description = \"Retrieve vector from postgres database.\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetriever\"\r\n    inputs = [\r\n        StrInput(\r\n            name=\"chat_session_id\",\r\n            display_name=\"Chat Session ID\",\r\n            value=\"\",\r\n            info=\"Chat Session ID\",\r\n        ),\r\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of results to return.\",\r\n            value=4,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        if self.chat_session_id and self.search_query:\r\n            conn = psycopg2.connect(\r\n                host=\"localhost\", \r\n                database=\"ai_tutor\", \r\n                user=\"postgres\", \r\n                password=\"Jing_consult\"\r\n            )\r\n            cursor = conn.cursor()\r\n            chat_session_id = self.chat_session_id\r\n            search_vector = self.embedding.embed_query(str(self.search_query))\r\n            query = \"\"\"\r\n                SELECT file_content\r\n                FROM embedding\r\n                WHERE session_id = %s\r\n                ORDER BY vector <-> %s::vector\r\n                LIMIT 5;\r\n            \"\"\"\r\n            \r\n            cursor.execute(query, (chat_session_id, search_vector))\r\n            # Fetch the top results\r\n            results = cursor.fetchall()\r\n            cursor.close()\r\n            conn.close()\r\n            self.status = results\r\n            return Message(text=str(results))\r\n        else:\r\n            return None",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieve vector from postgres database.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Vector store retriever",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "chat_session_id",
              "search_query",
              "embedding",
              "number_of_results",
              "embedding"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "VectorRetriever-LuqmZ"
        },
        "selected": false,
        "width": 384,
        "height": 427,
        "positionAbsolute": {
          "x": 220.15983853713158,
          "y": 2360.9990646753527
        },
        "dragging": false
      },
      {
        "id": "TextInput-iuMVX",
        "type": "genericNode",
        "position": {
          "x": 796.2395035343704,
          "y": 1908.3855012942813
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n        MultilineInput(display_name=\"System prompt\", name=\"sys_prompt\"),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n        \r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = self.sys_prompt\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sys_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sys_prompt",
                "value": "Assume that you are using the ChatGPT-4o-mini model. You are an answer generation component to answer the user's question based on the context information of some stored documents that is associated with user's question. Also suggest project structure if user askes project-related questions.\n\n**Guidelines for Answering Questions:**\n1. **Question Analysis:**\n   - First, analyze the user's question. Determine if the user is asking about a specific \"label\" and its associated document(s). The context describes the documents related to the asked label. Deem these information as the documents labeled with the asked label.\n   - If the question pertains to a \"label\" or document, look up the 'source' value in the 'metadata' from the provided context, extract meaningful name(s) and that will be the user's expected document name(s) (excluding the preceding path) in the source value.\n   - For example: if text like '{\"metadata\": {\"source\": \"/tmp/tmpp37u0kdd/Creating-Online-Learning-Experiences-1612365388.pdf\"' appears in the context, then the related document name is 'Creating-Online-Learning-Experiences', as indicated by the 'source' in the 'metadata', excluding .pdf and tmp numbers.\n   - The context does not contain the label explicitly. Never respond something like 'The document related to that label is not explicitly mentioned in the provided context.'. Always assume the documents are retrieved in the context already.\n   \n2. **Use Conversation Memory:**\n   - If the question does not clearly reference a label or document, review the conversation memory. Use it to guide your response, interpreting the user's intent based on prior interactions. \n   \n3. **Context and User File Priority:**\n   - Always prioritize the context and the user file for answers. If the answer is found in the user file, respond using it as the highest priority source. If the context contains the necessary data, generate a response based on the documents retrieved from the context.\n   \n4. **Response Generation:**\n   - If the answer cannot be derived from conversation memory, context, or the user file, generate an appropriate answer based on your general knowledge. However, if no valid answer can be generated, provide a clear, reasonable explanation or politely decline if it involves sharing raw data or if the information is unavailable.\n\n5. **Data Handling:**\n   - Never provide raw data directly to the user, even if the question asks for it. Instead, summarize or analyze the data from the context and user file to deliver a comprehensive answer.\n\n6. **Format:**\n   - Responses should be concise, accurate, and relevant to the user's question. Do not mention conversation memory, context, or the user file unless the question directly involves them.\n\n7. **Subdomain relationships**\nThe provided context are paths between the provided subdomains in the context. The graph consists of nodes representing items and directed edges representing verbs (relationships) between these items. Your objective is to explore and provide insights into how these two subdomains are interconnected based on the provided data.\nWhen performing your analysis, focus solely on meaningful and context-rich properties. Do not consider node properties that are overly specific, such as real person names, discrete numbers, dates, or special characters. Instead, emphasize solid, context-complete properties like descriptions or definitions that add depth to the concepts—for example, \"description: great responsibility associated with AI deployment\".\nUsing the sample data, identify key patterns, relationships, and themes that illustrate the interplay between the subdomains. Use a comprehensive analysis that highlights significant connections, underlying concepts, and potential implications of these interrelated domains within the context of the knowledge graph to assist the generation of response.\n\n\n\n**Contextual Breakdown for Answering Questions:**\n- **Context:** This includes database documents, their names, and contents.\n- **User File:** Any uploaded or associated files provided by the user.\n- **Conversation Memory:** Previous exchanges during the ongoing chat session.\n- **Question:** user's question.\n- **Labeled Documents**: Document names and their related labels.\n- **Subdomains**: The subdomains related to the user's question.\n- **Subdomain Context**: how the two subdomains connect to each other related to projects via nodes in the source graph database.",
                "display_name": "System prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Inject systemprompt",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "System Prompt",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "System Prompt",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "sys_prompt"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "TextInput-iuMVX"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": 796.2395035343704,
          "y": 1908.3855012942813
        },
        "dragging": false
      },
      {
        "id": "DocumentNameParser-q4HWm",
        "type": "genericNode",
        "position": {
          "x": -436.17032446723624,
          "y": 10.188767497399795
        },
        "data": {
          "type": "DocumentNameParser",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to parse.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nfrom neo4j import GraphDatabase\r\nclass DocumentNameParser(Component):\r\n    display_name = \"Document Name parser\"\r\n    description = \"Parse the retrieved document, extract document names and find their related labels.\"\r\n    icon = \"custom_components\"\r\n    name = \"DocumentNameParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to parse.\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Parsed document names with labels\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n    def get_node_labels(self, driver ,source, page):\r\n        \"\"\"Query Neo4j to retrieve the labels of nodes matching the source and page.\"\"\"\r\n        query = \"\"\"\r\n        MATCH (n:Document) WHERE n.source =$source\r\n        RETURN n.source AS source, labels(n) AS labels\r\n        \"\"\"\r\n        with driver.session() as session:\r\n            result = session.run(query, source=source, page=page)\r\n            return [{\"source\": source, \"labels\": record[\"labels\"]} for record in result]\r\n\r\n    def parsed_data(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        url=credentials[\"url\"]\r\n        username=credentials[\"username\"]\r\n        password=credentials[\"password\"]\r\n        driver = GraphDatabase.driver(url, auth=(username, password))\r\n        \r\n        result = []\r\n        seen = set()\r\n        for document in self.data:\r\n            source = document.metadata.get(\"source\")\r\n            page = document.metadata.get(\"page\")\r\n            labels = self.get_node_labels(driver, source, page)\r\n            if labels:\r\n                labels_list = self.get_node_labels(driver, source, page)\r\n\r\n                # Check for uniqueness using a tuple (source, tuple(labels))\r\n                for labels_dict in labels_list:\r\n                    source = labels_dict[\"source\"]\r\n                    labels = tuple(labels_dict[\"labels\"])  # Convert labels to tuple to use in a set\r\n\r\n                    identifier = (source, labels)\r\n                    if identifier not in seen:\r\n                        seen.add(identifier)\r\n                        result.append({\r\n                            \"source\": source,\r\n                            \"labels\": list(labels)  # Convert back to list for JSON output\r\n                        })\r\n        driver.close()\r\n        if result:\r\n            return Message(text=json.dumps(result))\r\n        else:\r\n            return Message(text=\"No nodes found for the given documents.\")\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Parse the retrieved document, extract document names and find their related labels.",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Document Name parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Parsed document names with labels",
                "method": "parsed_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "DocumentNameParser-q4HWm"
        },
        "selected": false,
        "width": 384,
        "height": 370,
        "dragging": false,
        "positionAbsolute": {
          "x": -436.17032446723624,
          "y": 10.188767497399795
        }
      },
      {
        "id": "OpenAIModel-7sqhi",
        "type": "genericNode",
        "position": {
          "x": -3028.597497711401,
          "y": 3472.1578876580616
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": "0.1",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-7sqhi"
        },
        "selected": false,
        "width": 384,
        "height": 679,
        "positionAbsolute": {
          "x": -3028.597497711401,
          "y": 3472.1578876580616
        },
        "dragging": false
      },
      {
        "id": "TextInput-gLVPJ",
        "type": "genericNode",
        "position": {
          "x": -3952.4730676336967,
          "y": 3308.7379204474264
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n        MultilineInput(display_name=\"System prompt\", name=\"sys_prompt\"),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n        \r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = self.sys_prompt\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sys_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sys_prompt",
                "value": "Task: Generate a Cypher statement to query a graph database based on the user's question\n\nInstructions:\n\n1. Determine which subdomain(s) best align with the user's question. The list of available subdomains are:\n\n- Physics\n- Chemistry\n- Biology\n- Earth Sciences\n- Psychology\n- Sociology & Anthropology\n- Economics\n- Political Science\n- Communication & Media\n- Philosophy\n- Linguistics\n- Pure Math\n- Applied Math\n- Statistics\n- General Education\n- Literacy & Writing\n- Computer Science\n- Food Science\n- Environmental Science\n- Marine Science\n- Strategy\n- Marketing\n- Cultural Studies\n- Ethics & Social Justice\n\nIf nothing matches, do not match a subdomain. Maximum match is 2 subdomains.\n\n2. If there are 2 subdomains that can match, generate a Cypher query to find all possible connection paths from the starting Subdomain node to the ending Subdomain node. Only return doc1.source, n, and doc2.source.\n\nThe path should be:\n\n(start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\n\nAt least 2 in the 3 nodes must be one of the following terms:\n\"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n\nUse only the provided relationship types and properties in the schema.\n\nDo not use any other relationship types or properties that are not provided.\n\n\nNote: Do not include any explanations or apologies in your responses.\n\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n\nDo not include any text except the generated Cypher statement.\n\n\nThe question is:\n{question}\n\nExample:\n\n```\nWITH [\n    \"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n] AS terms\nMATCH (start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\nWHERE NOT (\"Document\" IN labels(n1) OR \"Subdomain\" IN labels(n1))\n  AND NOT (\"Document\" IN labels(n2) OR \"Subdomain\" IN labels(n2))\n  AND NOT (\"Document\" IN labels(n3) OR \"Subdomain\" IN labels(n3))\n  AND (\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n2.id = term)) OR\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n3.id = term)) OR\n    (any(term IN terms WHERE n2.id = term) AND any(term IN terms WHERE n3.id = term))\n  )\n  AND start <> end\nRETURN DISTINCT\n  properties(n1) AS n1_properties,\n  type(r1) AS r1_type,\n  CASE\n    WHEN startNode(r1) = n1 THEN 'n1 -> n2'\n    ELSE 'n1 <- n2'\n  END AS r1_direction,\n  properties(n2) AS n2_properties,\n  type(r2) AS r2_type,\n  CASE\n    WHEN startNode(r2) = n2 THEN 'n2 -> n3'\n    ELSE 'n2 <- n3'\n  END AS r2_direction,\n  properties(n3) AS n3_properties\n```\n\n\n\n3.Return the subdomains you think that are relevant and the cypher query you generate in the following format:\nNumber_of_subdomains: subdomain1, subdomain2, subdomain3...\nCypher query:\n(start of cypher query in the third line)\n\nExample output:\n2: Computer Science, Economics\nCypher query:\n```\nWITH [\n    \"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n] AS terms\nMATCH (start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\nWHERE NOT (\"Document\" IN labels(n1) OR \"Subdomain\" IN labels(n1))\n  AND NOT (\"Document\" IN labels(n2) OR \"Subdomain\" IN labels(n2))\n  AND NOT (\"Document\" IN labels(n3) OR \"Subdomain\" IN labels(n3))\n  AND (\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n2.id = term)) OR\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n3.id = term)) OR\n    (any(term IN terms WHERE n2.id = term) AND any(term IN terms WHERE n3.id = term))\n  )\n  AND start <> end\nRETURN DISTINCT\n  properties(n1) AS n1_properties,\n  type(r1) AS r1_type,\n  CASE\n    WHEN startNode(r1) = n1 THEN 'n1 -> n2'\n    ELSE 'n1 <- n2'\n  END AS r1_direction,\n  properties(n2) AS n2_properties,\n  type(r2) AS r2_type,\n  CASE\n    WHEN startNode(r2) = n2 THEN 'n2 -> n3'\n    ELSE 'n2 <- n3'\n  END AS r2_direction,\n  properties(n3) AS n3_properties\n```\n\n",
                "display_name": "System prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Inject systemprompt",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "System Prompt",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "System Prompt",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "sys_prompt"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "TextInput-gLVPJ"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": -3952.4730676336967,
          "y": 3308.7379204474264
        },
        "dragging": false
      },
      {
        "id": "Prompt-cKxbM",
        "type": "genericNode",
        "position": {
          "x": -3566.4424230652553,
          "y": 1823.969960142119
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "User question: {user_question}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "user_question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "user_question",
                "display_name": "user_question",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "user_question"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Prompt-cKxbM"
        },
        "selected": false,
        "width": 384,
        "height": 407,
        "positionAbsolute": {
          "x": -3566.4424230652553,
          "y": 1823.969960142119
        },
        "dragging": false
      },
      {
        "id": "CustomComExtractVerifyCypherponent-StbzE",
        "type": "genericNode",
        "position": {
          "x": -2120.4842430553567,
          "y": 4002.695387440143
        },
        "data": {
          "type": "CustomComExtractVerifyCypherponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\r\n# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nclass ExtractVerifyCypher(Component):\r\n    display_name = \"Extract cypher query\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComExtractVerifyCypherponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Extract the Cypher query from the text\r\n        lines = self.input_value.strip().split('\\n')\r\n        try:\r\n            idx = lines.index(\"Cypher query:\")\r\n            cypher_query = '\\n'.join(lines[idx + 1:]).replace(\"```\",\"\").strip()\r\n        except ValueError:\r\n            return None\r\n\r\n        self.status = cypher_query\r\n        return Message(text= cypher_query)\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Extract Cypher Query",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CustomComExtractVerifyCypherponent-StbzE"
        },
        "selected": false,
        "width": 384,
        "height": 286,
        "dragging": false,
        "positionAbsolute": {
          "x": -2120.4842430553567,
          "y": 4002.695387440143
        }
      },
      {
        "id": "ExtractSubdomains-nTLbt",
        "type": "genericNode",
        "position": {
          "x": -775.4196762919416,
          "y": 1115.4813817066977
        },
        "data": {
          "type": "ExtractSubdomains",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\r\n# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport re\r\nclass ExtractSubdomains(Component):\r\n    display_name = \"Extract subdomains\"\r\n    description = \"Extract 2 subdomains\"\r\n    icon = \"custom_component\"\r\n    name = \"ExtractSubdomains\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Extract the Cypher query from the text\r\n\r\n        text = self.input_value.splitlines()[0]\r\n        pattern = r\"\\d+:\\s*(.*)\"\r\n\r\n        match = re.search(pattern, text)\r\n\r\n        if match:\r\n\r\n            subdomains = match.group(1)\r\n        else:\r\n            subdomains = None\r\n        self.status = subdomains\r\n        return Message(text= subdomains)\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Extract 2 subdomains",
            "icon": "custom_component",
            "base_classes": [
              "Message"
            ],
            "display_name": "Extract Subdomains",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "ExtractSubdomains-nTLbt"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "positionAbsolute": {
          "x": -775.4196762919416,
          "y": 1115.4813817066977
        },
        "dragging": false
      },
      {
        "id": "GraphRetriever-OaJr8",
        "type": "genericNode",
        "position": {
          "x": -1607.0071624815937,
          "y": 3934.8523551571548
        },
        "data": {
          "type": "GraphRetriever",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.io import Output, MessageTextInput, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom neo4j import GraphDatabase, exceptions\r\nimport json\r\n\r\nclass GraphRetriever(Component):\r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"cypher_query\", \r\n                       display_name=\"Cypher Query\",\r\n                       info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Load Neo4j credentials\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        try:\r\n            with driver.session() as session:\r\n                results = session.run(self.cypher_query)\r\n\r\n                result_dic_list = []\r\n                for record in results:\r\n                    result_dic = {\r\n                        \"n1_properties\": record[\"n1_properties\"],\r\n                        \"r1_type\": record[\"r1_type\"],\r\n                        \"r1_direction\": record[\"r1_direction\"],\r\n                        \"n2_properties\": record[\"n2_properties\"],\r\n                        \"r2_type\": record[\"r2_type\"],\r\n                        \"r2_direction\": record[\"r2_direction\"],\r\n                        \"n3_properties\": record[\"n3_properties\"]\r\n                    }\r\n                    result_dic_list.append(result_dic)\r\n        \r\n\r\n                results_str = json.dumps(result_dic_list)\r\n        except exceptions.CypherSyntaxError as e:\r\n            # Handle invalid Cypher query\r\n            self.status = f\"Invalid Cypher query: {str(e)}\"\r\n            return Message(text=\"\")\r\n        except Exception as e:\r\n            # Handle any other exceptions\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return Message(text=\"\")\r\n        finally:\r\n            # Ensure driver is closed even if an error occurs\r\n            driver.close()\r\n\r\n        # If no exceptions occur, update status and return the result\r\n        self.status = results_str\r\n        return Message(text=results_str)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cypher_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cypher_query",
                "value": "",
                "display_name": "Cypher Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Cypher query",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Execute cypher query to retrieve from knowledge graph",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Retriever Consumed",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cypher_query",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true
          },
          "id": "GraphRetriever-OaJr8"
        },
        "selected": false,
        "width": 384,
        "height": 407,
        "positionAbsolute": {
          "x": -1607.0071624815937,
          "y": 3934.8523551571548
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-NrS5e",
        "type": "genericNode",
        "position": {
          "x": -758.5845144672244,
          "y": 4086.2578766931674
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nimport pandas as pd\r\n\r\n\r\n\r\nclass GraphRetrievalParser(Component):\r\n    display_name = \"GraphRetrievalParser\"\r\n    description = \"Parse fetched data\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        try:\r\n            data = json.loads(self.input_value)\r\n            rows = []\r\n            for item in data:\r\n                row = {\r\n                    'n1': item['n1_properties'],\r\n                    'r1': item['r1_type'],\r\n                    'r1_direction': item['r1_direction'],\r\n                    'n2': item['n2_properties'],\r\n                    'r2': item['r2_type'],\r\n                    'r2_direction': item['r2_direction'],\r\n                    'n3': item['n3_properties']\r\n                }\r\n            \r\n                rows.append(row)\r\n            \r\n            \r\n            df = pd.DataFrame(rows)\r\n            processed = df.to_string()\r\n            self.status = processed\r\n            return Message(text=processed)\r\n        except:\r\n            return Message(text=\"\")\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Parse fetched data",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Retrieval result parsed",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "CustomComponent-NrS5e"
        },
        "selected": false,
        "width": 384,
        "height": 294,
        "dragging": false,
        "positionAbsolute": {
          "x": -758.5845144672244,
          "y": 4086.2578766931674
        }
      }
    ],
    "edges": [
      {
        "source": "Neo4jCredentialLoader-OdDSF",
        "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
        "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-OdDSF",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
        "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "VectorRetrieverParserComponent-arvf7",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "VectorRetrieverParserComponent-arvf7",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KnowledgeGraphIndexKRetrieverComponent",
            "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-VectorRetrieverParserComponent-arvf7{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "VectorRetrieverParserComponent-arvf7",
        "sourceHandle": "{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-3sFLj",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-3sFLjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-3sFLj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "VectorRetrieverParserComponent",
            "id": "VectorRetrieverParserComponent-arvf7",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-VectorRetrieverParserComponent-arvf7{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-3sFLj{œfieldNameœ:œtext1œ,œidœ:œCombineText-3sFLjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ChatInput-CozXU",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CozXU",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ChatInput-CozXU",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CozXU",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œquestionœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-C2xV6",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-C2xV6œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "VectorRetriever-LuqmZ",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "VectorRetriever-LuqmZ",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-C2xV6",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-C2xV6{��dataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-C2xV6œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-VectorRetriever-LuqmZ{œfieldNameœ:œembeddingœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ChatInput-CozXU",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "VectorRetriever-LuqmZ",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_query",
            "id": "VectorRetriever-LuqmZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CozXU",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-VectorRetriever-LuqmZ{œfieldNameœ:œsearch_queryœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false
      },
      {
        "source": "VectorRetriever-LuqmZ",
        "sourceHandle": "{œdataTypeœ:œVectorRetrieverœ,œidœ:œVectorRetriever-LuqmZœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œuser_fileœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_file",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "VectorRetriever",
            "id": "VectorRetriever-LuqmZ",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-VectorRetriever-LuqmZ{œdataTypeœ:œVectorRetrieverœ,œidœ:œVectorRetriever-LuqmZœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œuser_fileœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "TextInput-iuMVX",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-iuMVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-pHCSV",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-pHCSV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-iuMVX",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-iuMVX{œdataTypeœ:œTextInputœ,œidœ:œTextInput-iuMVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pHCSV{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CombineText-3sFLj",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-3sFLjœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-3sFLj",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CombineText-3sFLj{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-3sFLjœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œcontextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-mPmaJ",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-mPmaJœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-pHCSV",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-pHCSV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-mPmaJ",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-mPmaJ{œdataTypeœ:œPromptœ,œidœ:œPrompt-mPmaJœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pHCSV{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-pHCSV",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pHCSVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-1JJGM",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1JJGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-1JJGM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-pHCSV",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-pHCSV{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pHCSVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-1JJGM{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1JJGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-OdDSF",
        "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
        "target": "DocumentNameParser-q4HWm",
        "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "DocumentNameParser-q4HWm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-OdDSF",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-DocumentNameParser-q4HWm{œfieldNameœ:œneo4j_credentialsœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
        "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "DocumentNameParser-q4HWm",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "DocumentNameParser-q4HWm",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KnowledgeGraphIndexKRetrieverComponent",
            "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-DocumentNameParser-q4HWm{œfieldNameœ:œdataœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "DocumentNameParser-q4HWm",
        "sourceHandle": "{œdataTypeœ:œDocumentNameParserœ,œidœ:œDocumentNameParser-q4HWmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œlabeled_documentsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "labeled_documents",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "DocumentNameParser",
            "id": "DocumentNameParser-q4HWm",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-DocumentNameParser-q4HWm{œdataTypeœ:œDocumentNameParserœ,œidœ:œDocumentNameParser-q4HWmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œlabeled_documentsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "TextInput-gLVPJ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-gLVPJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-7sqhi",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-7sqhi",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-gLVPJ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-gLVPJ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-gLVPJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-7sqhi{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ChatInput-CozXU",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-cKxbM",
        "targetHandle": "{œfieldNameœ:œuser_questionœ,œidœ:œPrompt-cKxbMœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_question",
            "id": "Prompt-cKxbM",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-CozXU",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-cKxbM{œfieldNameœ:œuser_questionœ,œidœ:œPrompt-cKxbMœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Prompt-cKxbM",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-cKxbMœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-7sqhi",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-7sqhi",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-cKxbM",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-cKxbM{œdataTypeœ:œPromptœ,œidœ:œPrompt-cKxbMœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-7sqhi{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-7sqhi",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComExtractVerifyCypherponent-StbzE",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComExtractVerifyCypherponent-StbzE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-7sqhi",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-7sqhi{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComExtractVerifyCypherponent-StbzE{œfieldNameœ:œinput_valueœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-7sqhi",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExtractSubdomains-nTLbt",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œExtractSubdomains-nTLbtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ExtractSubdomains-nTLbt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-7sqhi",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-7sqhi{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExtractSubdomains-nTLbt{œfieldNameœ:œinput_valueœ,œidœ:œExtractSubdomains-nTLbtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "ExtractSubdomains-nTLbt",
        "sourceHandle": "{œdataTypeœ:œExtractSubdomainsœ,œidœ:œExtractSubdomains-nTLbtœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œsubdomainsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "subdomains",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ExtractSubdomains",
            "id": "ExtractSubdomains-nTLbt",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ExtractSubdomains-nTLbt{œdataTypeœ:œExtractSubdomainsœ,œidœ:œExtractSubdomains-nTLbtœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œsubdomainsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-OdDSF",
        "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GraphRetriever-OaJr8",
        "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "GraphRetriever-OaJr8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-OdDSF",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-OaJr8{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphRetriever-OaJr8",
        "sourceHandle": "{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-OaJr8œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-NrS5e",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-NrS5eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-NrS5e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRetriever",
            "id": "GraphRetriever-OaJr8",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRetriever-OaJr8{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-OaJr8œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-NrS5e{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-NrS5eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComExtractVerifyCypherponent-StbzE",
        "sourceHandle": "{œdataTypeœ:œCustomComExtractVerifyCypherponentœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GraphRetriever-OaJr8",
        "targetHandle": "{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "cypher_query",
            "id": "GraphRetriever-OaJr8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComExtractVerifyCypherponent",
            "id": "CustomComExtractVerifyCypherponent-StbzE",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComExtractVerifyCypherponent-StbzE{œdataTypeœ:œCustomComExtractVerifyCypherponentœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-OaJr8{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CustomComponent-NrS5e",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NrS5eœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-mPmaJ",
        "targetHandle": "{œfieldNameœ:œsubdomain_contextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "subdomain_context",
            "id": "Prompt-mPmaJ",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-NrS5e",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-NrS5e{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NrS5eœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œsubdomain_contextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 0,
      "y": 0,
      "zoom": 1
    }
  },
  "metadata": {
    "KnowledgeGraphIndexKRetrieverComponent": {
      "count": 1
    },
    "Prompt": {
      "count": 2
    },
    "OpenAIModel": {
      "count": 2
    },
    "Neo4jCredentialLoader": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "VectorRetrieverParserComponent": {
      "count": 1
    },
    "CombineText": {
      "count": 1
    },
    "ChatInput": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "OpenAIEmbeddings": {
      "count": 1
    },
    "VectorRetriever": {
      "count": 1
    },
    "TextInput": {
      "count": 2
    },
    "DocumentNameParser": {
      "count": 1
    },
    "CustomComExtractVerifyCypherponent": {
      "count": 1
    },
    "ExtractSubdomains": {
      "count": 1
    },
    "GraphRetriever": {
      "count": 1
    },
    "CustomComponent": {
      "count": 1
    },
    "total": 20
  },
  "original": {
    "id": "c2ecb859-5177-4b8b-9cbc-89a02001db15",
    "name": "[demo] RQ GraphRAG conversation",
    "description": "RQ assisted graphrag conversation",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "KnowledgeGraphIndexKRetrieverComponent": {
        "count": 1
      },
      "Prompt": {
        "count": 2
      },
      "OpenAIModel": {
        "count": 2
      },
      "Neo4jCredentialLoader": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "VectorRetrieverParserComponent": {
        "count": 1
      },
      "CombineText": {
        "count": 1
      },
      "ChatInput": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "OpenAIEmbeddings": {
        "count": 1
      },
      "VectorRetriever": {
        "count": 1
      },
      "TextInput": {
        "count": 2
      },
      "DocumentNameParser": {
        "count": 1
      },
      "CustomComExtractVerifyCypherponent": {
        "count": 1
      },
      "ExtractSubdomains": {
        "count": 1
      },
      "GraphRetriever": {
        "count": 1
      },
      "CustomComponent": {
        "count": 1
      },
      "total": 20
    },
    "last_tested_version": "1.0.17",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
          "type": "genericNode",
          "position": {
            "x": -1553.7468478695346,
            "y": -139.46983356297787
          },
          "data": {
            "type": "KnowledgeGraphIndexKRetrieverComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n\r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=\"Document\",\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "k",
                  "value": 4,
                  "display_name": "Number of results to return",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_embedding_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_embedding_model",
                  "value": "text-embedding-3-small",
                  "display_name": "Embedding Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "user_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_query",
                  "value": "",
                  "display_name": "Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "User query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Neo4J K Retriever (Vector Search)",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "user_query",
                "k",
                "openai_embedding_model",
                "openai_api_key",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX"
          },
          "selected": false,
          "width": 384,
          "height": 691,
          "positionAbsolute": {
            "x": -1553.7468478695346,
            "y": -139.46983356297787
          },
          "dragging": false
        },
        {
          "id": "Prompt-mPmaJ",
          "type": "genericNode",
          "position": {
            "x": 803.803042166736,
            "y": 183.19102418146838
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Conversation Memory: {memory}\nContext: {context}\nLabeled Documents: {labeled_documents}\nUser File: {user_file}\nQuestion: {question}\nSubdomains: {subdomains}\nSubdomain Context: {subdomain_context}",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "question",
                  "display_name": "question",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "memory": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "memory",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "user_file": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_file",
                  "display_name": "user_file",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "labeled_documents": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "labeled_documents",
                  "display_name": "labeled_documents",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "subdomain_context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "subdomain_context",
                  "display_name": "subdomain_context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "subdomains": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "subdomains",
                  "display_name": "subdomains",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Generate a prompt for LLM to process query",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "memory",
                  "context",
                  "labeled_documents",
                  "user_file",
                  "question",
                  "subdomains",
                  "subdomain_context"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Prompt-mPmaJ"
          },
          "selected": false,
          "width": 384,
          "height": 891,
          "positionAbsolute": {
            "x": 803.803042166736,
            "y": 183.19102418146838
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-pHCSV",
          "type": "genericNode",
          "position": {
            "x": 1403.3436178353643,
            "y": 1275.1313254043337
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "hidden": false
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-pHCSV"
          },
          "selected": false,
          "width": 384,
          "height": 679,
          "positionAbsolute": {
            "x": 1403.3436178353643,
            "y": 1275.1313254043337
          },
          "dragging": false
        },
        {
          "id": "Neo4jCredentialLoader-OdDSF",
          "type": "genericNode",
          "position": {
            "x": -2597.1327148085256,
            "y": -205.3840003152996
          },
          "data": {
            "type": "Neo4jCredentialLoader",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_password": {
                  "trace_as_metadata": true,
                  "load_from_db": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_password",
                  "value": "Neo4j Password",
                  "display_name": "Neo4j Password",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_url",
                  "value": "neo4j://jingconsult.tech:7687",
                  "display_name": "Neo4j URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_username": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_username",
                  "value": "neo4j",
                  "display_name": "Neo4j Username",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "A handy component to load neo4j credentials",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Neo4j Credential Loader",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "credentials",
                  "display_name": "Credentials",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "neo4j_url",
                "neo4j_username",
                "neo4j_password"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "Neo4jCredentialLoader-OdDSF"
          },
          "selected": false,
          "width": 384,
          "height": 465,
          "positionAbsolute": {
            "x": -2597.1327148085256,
            "y": -205.3840003152996
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-1JJGM",
          "type": "genericNode",
          "position": {
            "x": 1917.1052240661318,
            "y": 986.3484963560147
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatOutput-1JJGM"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": 1917.1052240661318,
            "y": 986.3484963560147
          },
          "dragging": false
        },
        {
          "id": "VectorRetrieverParserComponent-arvf7",
          "type": "genericNode",
          "position": {
            "x": -690.318341057922,
            "y": 504.67586328169546
          },
          "data": {
            "type": "VectorRetrieverParserComponent",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Parse retrieved Documents",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Vector Retriever Parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parsed_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "VectorRetrieverParserComponent-arvf7"
          },
          "selected": false,
          "width": 384,
          "height": 257,
          "positionAbsolute": {
            "x": -690.318341057922,
            "y": 504.67586328169546
          },
          "dragging": false
        },
        {
          "id": "CombineText-3sFLj",
          "type": "genericNode",
          "position": {
            "x": -33.43760090079604,
            "y": 485.7503649564312
          },
          "data": {
            "type": "CombineText",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "delimiter": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "delimiter",
                  "value": "",
                  "display_name": "Delimiter",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text1": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text1",
                  "value": "",
                  "display_name": "First Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The first text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text2": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text2",
                  "value": "",
                  "display_name": "Second Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The second text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
              "icon": "merge",
              "base_classes": [
                "Message"
              ],
              "display_name": "Combine Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "combined_text",
                  "display_name": "Combined Text",
                  "method": "combine_texts",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text1",
                "text2",
                "delimiter"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "CombineText-3sFLj"
          },
          "selected": false,
          "width": 384,
          "height": 493,
          "positionAbsolute": {
            "x": -33.43760090079604,
            "y": 485.7503649564312
          },
          "dragging": false
        },
        {
          "id": "ChatInput-CozXU",
          "type": "genericNode",
          "position": {
            "x": -3682.906807200662,
            "y": 708.277545087129
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "Most total goals in a premier league season?",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatInput-CozXU"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": -3682.906807200662,
            "y": 708.277545087129
          },
          "dragging": false
        },
        {
          "id": "Memory-7czUw",
          "type": "genericNode",
          "position": {
            "x": -443.3263533525806,
            "y": 1681.6828277169948
          },
          "data": {
            "type": "Memory",
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "icon": "message-square-more",
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "BaseChatMemory"
                  ],
                  "selected": "BaseChatMemory",
                  "name": "lc_memory",
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Memory-7czUw"
          },
          "selected": false,
          "width": 384,
          "height": 373,
          "positionAbsolute": {
            "x": -443.3263533525806,
            "y": 1681.6828277169948
          },
          "dragging": false
        },
        {
          "id": "OpenAIEmbeddings-C2xV6",
          "type": "genericNode",
          "position": {
            "x": -666.425503055166,
            "y": 2498.9751055970846
          },
          "data": {
            "type": "OpenAIEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "client": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "client",
                  "value": "",
                  "display_name": "Client",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom axiestudio.base.embeddings.model import LCEmbeddingsModel\nfrom axiestudio.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "default_headers": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_headers",
                  "value": {},
                  "display_name": "Default Headers",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default headers to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "default_query": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "default_query",
                  "value": {},
                  "display_name": "Default Query",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Default query parameters to use for the API request.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "deployment": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "deployment",
                  "value": "",
                  "display_name": "Deployment",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "dimensions": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "dimensions",
                  "value": "",
                  "display_name": "Dimensions",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "embedding_ctx_length": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding_ctx_length",
                  "value": 1536,
                  "display_name": "Embedding Context Length",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "text-embedding-3-small",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "openai_api_base": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_type": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_type",
                  "value": "",
                  "display_name": "OpenAI API Type",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_api_version": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_version",
                  "value": "",
                  "display_name": "OpenAI API Version",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_organization": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_organization",
                  "value": "",
                  "display_name": "OpenAI Organization",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_proxy": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_proxy",
                  "value": "",
                  "display_name": "OpenAI Proxy",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "show_progress_bar": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "show_progress_bar",
                  "value": false,
                  "display_name": "Show Progress Bar",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "skip_empty": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "skip_empty",
                  "value": false,
                  "display_name": "Skip Empty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_enable": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_enable",
                  "value": true,
                  "display_name": "TikToken Enable",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If False, you must have transformers installed.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "tiktoken_model_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tiktoken_model_name",
                  "value": "",
                  "display_name": "TikToken Model Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using OpenAI models.",
              "icon": "OpenAI",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "OpenAI Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "default_headers",
                "default_query",
                "chunk_size",
                "client",
                "deployment",
                "embedding_ctx_length",
                "max_retries",
                "model",
                "model_kwargs",
                "openai_api_base",
                "openai_api_key",
                "openai_api_type",
                "openai_api_version",
                "openai_organization",
                "openai_proxy",
                "request_timeout",
                "show_progress_bar",
                "skip_empty",
                "tiktoken_model_name",
                "tiktoken_enable",
                "dimensions"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIEmbeddings-C2xV6"
          },
          "selected": false,
          "width": 384,
          "height": 379,
          "positionAbsolute": {
            "x": -666.425503055166,
            "y": 2498.9751055970846
          },
          "dragging": false
        },
        {
          "id": "VectorRetriever-LuqmZ",
          "type": "genericNode",
          "position": {
            "x": 220.15983853713158,
            "y": 2360.9990646753527
          },
          "data": {
            "type": "VectorRetriever",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chat_session_id": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_session_id",
                  "value": "",
                  "display_name": "Chat Session ID",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Chat Session ID",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom typing import List\r\nfrom langchain_community.vectorstores import PGVector\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom axiestudio.helpers.data import docs_to_data\r\nfrom axiestudio.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.utils.connection_string_parser import transform_connection_string\r\nfrom langchain_openai.embeddings.base import OpenAIEmbeddings\r\nimport psycopg2\r\nimport numpy as np\r\n\r\nclass VectorRetriever(Component):\r\n    display_name = \"Vector Retriever\"\r\n    description = \"Retrieve vector from postgres database.\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetriever\"\r\n    inputs = [\r\n        StrInput(\r\n            name=\"chat_session_id\",\r\n            display_name=\"Chat Session ID\",\r\n            value=\"\",\r\n            info=\"Chat Session ID\",\r\n        ),\r\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(\r\n            name=\"number_of_results\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of results to return.\",\r\n            value=4,\r\n            advanced=True,\r\n        ),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        if self.chat_session_id and self.search_query:\r\n            conn = psycopg2.connect(\r\n                host=\"localhost\", \r\n                database=\"ai_tutor\", \r\n                user=\"postgres\", \r\n                password=\"Jing_consult\"\r\n            )\r\n            cursor = conn.cursor()\r\n            chat_session_id = self.chat_session_id\r\n            search_vector = self.embedding.embed_query(str(self.search_query))\r\n            query = \"\"\"\r\n                SELECT file_content\r\n                FROM embedding\r\n                WHERE session_id = %s\r\n                ORDER BY vector <-> %s::vector\r\n                LIMIT 5;\r\n            \"\"\"\r\n            \r\n            cursor.execute(query, (chat_session_id, search_vector))\r\n            # Fetch the top results\r\n            results = cursor.fetchall()\r\n            cursor.close()\r\n            conn.close()\r\n            self.status = results\r\n            return Message(text=str(results))\r\n        else:\r\n            return None",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 4,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieve vector from postgres database.",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Vector store retriever",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "chat_session_id",
                "search_query",
                "embedding",
                "number_of_results",
                "embedding"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "VectorRetriever-LuqmZ"
          },
          "selected": false,
          "width": 384,
          "height": 427,
          "positionAbsolute": {
            "x": 220.15983853713158,
            "y": 2360.9990646753527
          },
          "dragging": false
        },
        {
          "id": "TextInput-iuMVX",
          "type": "genericNode",
          "position": {
            "x": 796.2395035343704,
            "y": 1908.3855012942813
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n        MultilineInput(display_name=\"System prompt\", name=\"sys_prompt\"),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n        \r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = self.sys_prompt\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sys_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sys_prompt",
                  "value": "Assume that you are using the ChatGPT-4o-mini model. You are an answer generation component to answer the user's question based on the context information of some stored documents that is associated with user's question. Also suggest project structure if user askes project-related questions.\n\n**Guidelines for Answering Questions:**\n1. **Question Analysis:**\n   - First, analyze the user's question. Determine if the user is asking about a specific \"label\" and its associated document(s). The context describes the documents related to the asked label. Deem these information as the documents labeled with the asked label.\n   - If the question pertains to a \"label\" or document, look up the 'source' value in the 'metadata' from the provided context, extract meaningful name(s) and that will be the user's expected document name(s) (excluding the preceding path) in the source value.\n   - For example: if text like '{\"metadata\": {\"source\": \"/tmp/tmpp37u0kdd/Creating-Online-Learning-Experiences-1612365388.pdf\"' appears in the context, then the related document name is 'Creating-Online-Learning-Experiences', as indicated by the 'source' in the 'metadata', excluding .pdf and tmp numbers.\n   - The context does not contain the label explicitly. Never respond something like 'The document related to that label is not explicitly mentioned in the provided context.'. Always assume the documents are retrieved in the context already.\n   \n2. **Use Conversation Memory:**\n   - If the question does not clearly reference a label or document, review the conversation memory. Use it to guide your response, interpreting the user's intent based on prior interactions. \n   \n3. **Context and User File Priority:**\n   - Always prioritize the context and the user file for answers. If the answer is found in the user file, respond using it as the highest priority source. If the context contains the necessary data, generate a response based on the documents retrieved from the context.\n   \n4. **Response Generation:**\n   - If the answer cannot be derived from conversation memory, context, or the user file, generate an appropriate answer based on your general knowledge. However, if no valid answer can be generated, provide a clear, reasonable explanation or politely decline if it involves sharing raw data or if the information is unavailable.\n\n5. **Data Handling:**\n   - Never provide raw data directly to the user, even if the question asks for it. Instead, summarize or analyze the data from the context and user file to deliver a comprehensive answer.\n\n6. **Format:**\n   - Responses should be concise, accurate, and relevant to the user's question. Do not mention conversation memory, context, or the user file unless the question directly involves them.\n\n7. **Subdomain relationships**\nThe provided context are paths between the provided subdomains in the context. The graph consists of nodes representing items and directed edges representing verbs (relationships) between these items. Your objective is to explore and provide insights into how these two subdomains are interconnected based on the provided data.\nWhen performing your analysis, focus solely on meaningful and context-rich properties. Do not consider node properties that are overly specific, such as real person names, discrete numbers, dates, or special characters. Instead, emphasize solid, context-complete properties like descriptions or definitions that add depth to the concepts—for example, \"description: great responsibility associated with AI deployment\".\nUsing the sample data, identify key patterns, relationships, and themes that illustrate the interplay between the subdomains. Use a comprehensive analysis that highlights significant connections, underlying concepts, and potential implications of these interrelated domains within the context of the knowledge graph to assist the generation of response.\n\n\n\n**Contextual Breakdown for Answering Questions:**\n- **Context:** This includes database documents, their names, and contents.\n- **User File:** Any uploaded or associated files provided by the user.\n- **Conversation Memory:** Previous exchanges during the ongoing chat session.\n- **Question:** user's question.\n- **Labeled Documents**: Document names and their related labels.\n- **Subdomains**: The subdomains related to the user's question.\n- **Subdomain Context**: how the two subdomains connect to each other related to projects via nodes in the source graph database.",
                  "display_name": "System prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Inject systemprompt",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "System Prompt",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "System Prompt",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "sys_prompt"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "TextInput-iuMVX"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": 796.2395035343704,
            "y": 1908.3855012942813
          },
          "dragging": false
        },
        {
          "id": "DocumentNameParser-q4HWm",
          "type": "genericNode",
          "position": {
            "x": -436.17032446723624,
            "y": 10.188767497399795
          },
          "data": {
            "type": "DocumentNameParser",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to parse.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nfrom neo4j import GraphDatabase\r\nclass DocumentNameParser(Component):\r\n    display_name = \"Document Name parser\"\r\n    description = \"Parse the retrieved document, extract document names and find their related labels.\"\r\n    icon = \"custom_components\"\r\n    name = \"DocumentNameParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to parse.\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Parsed document names with labels\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n    def get_node_labels(self, driver ,source, page):\r\n        \"\"\"Query Neo4j to retrieve the labels of nodes matching the source and page.\"\"\"\r\n        query = \"\"\"\r\n        MATCH (n:Document) WHERE n.source =$source\r\n        RETURN n.source AS source, labels(n) AS labels\r\n        \"\"\"\r\n        with driver.session() as session:\r\n            result = session.run(query, source=source, page=page)\r\n            return [{\"source\": source, \"labels\": record[\"labels\"]} for record in result]\r\n\r\n    def parsed_data(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        url=credentials[\"url\"]\r\n        username=credentials[\"username\"]\r\n        password=credentials[\"password\"]\r\n        driver = GraphDatabase.driver(url, auth=(username, password))\r\n        \r\n        result = []\r\n        seen = set()\r\n        for document in self.data:\r\n            source = document.metadata.get(\"source\")\r\n            page = document.metadata.get(\"page\")\r\n            labels = self.get_node_labels(driver, source, page)\r\n            if labels:\r\n                labels_list = self.get_node_labels(driver, source, page)\r\n\r\n                # Check for uniqueness using a tuple (source, tuple(labels))\r\n                for labels_dict in labels_list:\r\n                    source = labels_dict[\"source\"]\r\n                    labels = tuple(labels_dict[\"labels\"])  # Convert labels to tuple to use in a set\r\n\r\n                    identifier = (source, labels)\r\n                    if identifier not in seen:\r\n                        seen.add(identifier)\r\n                        result.append({\r\n                            \"source\": source,\r\n                            \"labels\": list(labels)  # Convert back to list for JSON output\r\n                        })\r\n        driver.close()\r\n        if result:\r\n            return Message(text=json.dumps(result))\r\n        else:\r\n            return Message(text=\"No nodes found for the given documents.\")\r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Parse the retrieved document, extract document names and find their related labels.",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Document Name parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Parsed document names with labels",
                  "method": "parsed_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "DocumentNameParser-q4HWm"
          },
          "selected": false,
          "width": 384,
          "height": 370,
          "dragging": false,
          "positionAbsolute": {
            "x": -436.17032446723624,
            "y": 10.188767497399795
          }
        },
        {
          "id": "OpenAIModel-7sqhi",
          "type": "genericNode",
          "position": {
            "x": -3028.597497711401,
            "y": 3472.1578876580616
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": "0.1",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-7sqhi"
          },
          "selected": false,
          "width": 384,
          "height": 679,
          "positionAbsolute": {
            "x": -3028.597497711401,
            "y": 3472.1578876580616
          },
          "dragging": false
        },
        {
          "id": "TextInput-gLVPJ",
          "type": "genericNode",
          "position": {
            "x": -3952.4730676336967,
            "y": 3308.7379204474264
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.text import TextComponent\r\nfrom axiestudio.io import MessageTextInput, Output, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\n\r\n\r\nclass SystemPromptComponent(TextComponent):\r\n    display_name = \"System prompt\"\r\n    description = \"Inject systemprompt\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    inputs = [\r\n        MultilineInput(display_name=\"System prompt\", name=\"sys_prompt\"),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"System Prompt\", name=\"text\", method=\"text_response\"),\r\n        \r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        sys_prompt = self.sys_prompt\r\n        message = Message(\r\n            text=sys_prompt,\r\n        )\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "sys_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sys_prompt",
                  "value": "Task: Generate a Cypher statement to query a graph database based on the user's question\n\nInstructions:\n\n1. Determine which subdomain(s) best align with the user's question. The list of available subdomains are:\n\n- Physics\n- Chemistry\n- Biology\n- Earth Sciences\n- Psychology\n- Sociology & Anthropology\n- Economics\n- Political Science\n- Communication & Media\n- Philosophy\n- Linguistics\n- Pure Math\n- Applied Math\n- Statistics\n- General Education\n- Literacy & Writing\n- Computer Science\n- Food Science\n- Environmental Science\n- Marine Science\n- Strategy\n- Marketing\n- Cultural Studies\n- Ethics & Social Justice\n\nIf nothing matches, do not match a subdomain. Maximum match is 2 subdomains.\n\n2. If there are 2 subdomains that can match, generate a Cypher query to find all possible connection paths from the starting Subdomain node to the ending Subdomain node. Only return doc1.source, n, and doc2.source.\n\nThe path should be:\n\n(start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\n\nAt least 2 in the 3 nodes must be one of the following terms:\n\"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n\nUse only the provided relationship types and properties in the schema.\n\nDo not use any other relationship types or properties that are not provided.\n\n\nNote: Do not include any explanations or apologies in your responses.\n\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n\nDo not include any text except the generated Cypher statement.\n\n\nThe question is:\n{question}\n\nExample:\n\n```\nWITH [\n    \"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n] AS terms\nMATCH (start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\nWHERE NOT (\"Document\" IN labels(n1) OR \"Subdomain\" IN labels(n1))\n  AND NOT (\"Document\" IN labels(n2) OR \"Subdomain\" IN labels(n2))\n  AND NOT (\"Document\" IN labels(n3) OR \"Subdomain\" IN labels(n3))\n  AND (\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n2.id = term)) OR\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n3.id = term)) OR\n    (any(term IN terms WHERE n2.id = term) AND any(term IN terms WHERE n3.id = term))\n  )\n  AND start <> end\nRETURN DISTINCT\n  properties(n1) AS n1_properties,\n  type(r1) AS r1_type,\n  CASE\n    WHEN startNode(r1) = n1 THEN 'n1 -> n2'\n    ELSE 'n1 <- n2'\n  END AS r1_direction,\n  properties(n2) AS n2_properties,\n  type(r2) AS r2_type,\n  CASE\n    WHEN startNode(r2) = n2 THEN 'n2 -> n3'\n    ELSE 'n2 <- n3'\n  END AS r2_direction,\n  properties(n3) AS n3_properties\n```\n\n\n\n3.Return the subdomains you think that are relevant and the cypher query you generate in the following format:\nNumber_of_subdomains: subdomain1, subdomain2, subdomain3...\nCypher query:\n(start of cypher query in the third line)\n\nExample output:\n2: Computer Science, Economics\nCypher query:\n```\nWITH [\n    \"Task\", \"Milestone\", \"Prototyping\", \"Resource\", \"Risk\", \"Schedule\", \"Project Scope\", \"Timeline\",\n    \"Stakeholder\", \"Budget\", \"Deliverable\", \"Dependency\", \"Project Plan\", \"Work Breakdown Structure\",\n    \"Critical Path\", \"Change Request\", \"Change Management\", \"Issue\", \"Team Member\", \"Gantt\",\n    \"Domain Knowledge\", \"Subject Matter Expert\", \"Technical Champion\", \"Trainer\", \"Coach\",\n    \"Team Lead\", \"Project Manager\"\n] AS terms\nMATCH (start:Subdomain {name:\"Computer Science\"})--(doc1:Document)--(n1)-[r1]-(n2)-[r2]-(n3)--(doc2:Document)--(end:Subdomain {name:\"Economics\"})\nWHERE NOT (\"Document\" IN labels(n1) OR \"Subdomain\" IN labels(n1))\n  AND NOT (\"Document\" IN labels(n2) OR \"Subdomain\" IN labels(n2))\n  AND NOT (\"Document\" IN labels(n3) OR \"Subdomain\" IN labels(n3))\n  AND (\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n2.id = term)) OR\n    (any(term IN terms WHERE n1.id = term) AND any(term IN terms WHERE n3.id = term)) OR\n    (any(term IN terms WHERE n2.id = term) AND any(term IN terms WHERE n3.id = term))\n  )\n  AND start <> end\nRETURN DISTINCT\n  properties(n1) AS n1_properties,\n  type(r1) AS r1_type,\n  CASE\n    WHEN startNode(r1) = n1 THEN 'n1 -> n2'\n    ELSE 'n1 <- n2'\n  END AS r1_direction,\n  properties(n2) AS n2_properties,\n  type(r2) AS r2_type,\n  CASE\n    WHEN startNode(r2) = n2 THEN 'n2 -> n3'\n    ELSE 'n2 <- n3'\n  END AS r2_direction,\n  properties(n3) AS n3_properties\n```\n\n",
                  "display_name": "System prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Inject systemprompt",
              "icon": "type",
              "base_classes": [
                "Message"
              ],
              "display_name": "System Prompt",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "System Prompt",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "sys_prompt"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "TextInput-gLVPJ"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": -3952.4730676336967,
            "y": 3308.7379204474264
          },
          "dragging": false
        },
        {
          "id": "Prompt-cKxbM",
          "type": "genericNode",
          "position": {
            "x": -3566.4424230652553,
            "y": 1823.969960142119
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "User question: {user_question}",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "user_question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "user_question",
                  "display_name": "user_question",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "user_question"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Prompt-cKxbM"
          },
          "selected": false,
          "width": 384,
          "height": 407,
          "positionAbsolute": {
            "x": -3566.4424230652553,
            "y": 1823.969960142119
          },
          "dragging": false
        },
        {
          "id": "CustomComExtractVerifyCypherponent-StbzE",
          "type": "genericNode",
          "position": {
            "x": -2120.4842430553567,
            "y": 4002.695387440143
          },
          "data": {
            "type": "CustomComExtractVerifyCypherponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "\r\n# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nclass ExtractVerifyCypher(Component):\r\n    display_name = \"Extract cypher query\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComExtractVerifyCypherponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Extract the Cypher query from the text\r\n        lines = self.input_value.strip().split('\\n')\r\n        try:\r\n            idx = lines.index(\"Cypher query:\")\r\n            cypher_query = '\\n'.join(lines[idx + 1:]).replace(\"```\",\"\").strip()\r\n        except ValueError:\r\n            return None\r\n\r\n        self.status = cypher_query\r\n        return Message(text= cypher_query)\r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input Value",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Extract Cypher Query",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CustomComExtractVerifyCypherponent-StbzE"
          },
          "selected": false,
          "width": 384,
          "height": 286,
          "dragging": false,
          "positionAbsolute": {
            "x": -2120.4842430553567,
            "y": 4002.695387440143
          }
        },
        {
          "id": "ExtractSubdomains-nTLbt",
          "type": "genericNode",
          "position": {
            "x": -775.4196762919416,
            "y": 1115.4813817066977
          },
          "data": {
            "type": "ExtractSubdomains",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "\r\n# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport re\r\nclass ExtractSubdomains(Component):\r\n    display_name = \"Extract subdomains\"\r\n    description = \"Extract 2 subdomains\"\r\n    icon = \"custom_component\"\r\n    name = \"ExtractSubdomains\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Extract the Cypher query from the text\r\n\r\n        text = self.input_value.splitlines()[0]\r\n        pattern = r\"\\d+:\\s*(.*)\"\r\n\r\n        match = re.search(pattern, text)\r\n\r\n        if match:\r\n\r\n            subdomains = match.group(1)\r\n        else:\r\n            subdomains = None\r\n        self.status = subdomains\r\n        return Message(text= subdomains)\r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input Value",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Extract 2 subdomains",
              "icon": "custom_component",
              "base_classes": [
                "Message"
              ],
              "display_name": "Extract Subdomains",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "ExtractSubdomains-nTLbt"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "positionAbsolute": {
            "x": -775.4196762919416,
            "y": 1115.4813817066977
          },
          "dragging": false
        },
        {
          "id": "GraphRetriever-OaJr8",
          "type": "genericNode",
          "position": {
            "x": -1607.0071624815937,
            "y": 3934.8523551571548
          },
          "data": {
            "type": "GraphRetriever",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.io import Output, MessageTextInput, MultilineInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom neo4j import GraphDatabase, exceptions\r\nimport json\r\n\r\nclass GraphRetriever(Component):\r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MultilineInput(name=\"cypher_query\", \r\n                       display_name=\"Cypher Query\",\r\n                       info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # Load Neo4j credentials\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        try:\r\n            with driver.session() as session:\r\n                results = session.run(self.cypher_query)\r\n\r\n                result_dic_list = []\r\n                for record in results:\r\n                    result_dic = {\r\n                        \"n1_properties\": record[\"n1_properties\"],\r\n                        \"r1_type\": record[\"r1_type\"],\r\n                        \"r1_direction\": record[\"r1_direction\"],\r\n                        \"n2_properties\": record[\"n2_properties\"],\r\n                        \"r2_type\": record[\"r2_type\"],\r\n                        \"r2_direction\": record[\"r2_direction\"],\r\n                        \"n3_properties\": record[\"n3_properties\"]\r\n                    }\r\n                    result_dic_list.append(result_dic)\r\n        \r\n\r\n                results_str = json.dumps(result_dic_list)\r\n        except exceptions.CypherSyntaxError as e:\r\n            # Handle invalid Cypher query\r\n            self.status = f\"Invalid Cypher query: {str(e)}\"\r\n            return Message(text=\"\")\r\n        except Exception as e:\r\n            # Handle any other exceptions\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return Message(text=\"\")\r\n        finally:\r\n            # Ensure driver is closed even if an error occurs\r\n            driver.close()\r\n\r\n        # If no exceptions occur, update status and return the result\r\n        self.status = results_str\r\n        return Message(text=results_str)\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cypher_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cypher_query",
                  "value": "",
                  "display_name": "Cypher Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Cypher query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Execute cypher query to retrieve from knowledge graph",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Retriever Consumed",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cypher_query",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true
            },
            "id": "GraphRetriever-OaJr8"
          },
          "selected": false,
          "width": 384,
          "height": 407,
          "positionAbsolute": {
            "x": -1607.0071624815937,
            "y": 3934.8523551571548
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-NrS5e",
          "type": "genericNode",
          "position": {
            "x": -758.5845144672244,
            "y": 4086.2578766931674
          },
          "data": {
            "type": "CustomComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nimport pandas as pd\r\n\r\n\r\n\r\nclass GraphRetrievalParser(Component):\r\n    display_name = \"GraphRetrievalParser\"\r\n    description = \"Parse fetched data\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"CustomComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        try:\r\n            data = json.loads(self.input_value)\r\n            rows = []\r\n            for item in data:\r\n                row = {\r\n                    'n1': item['n1_properties'],\r\n                    'r1': item['r1_type'],\r\n                    'r1_direction': item['r1_direction'],\r\n                    'n2': item['n2_properties'],\r\n                    'r2': item['r2_type'],\r\n                    'r2_direction': item['r2_direction'],\r\n                    'n3': item['n3_properties']\r\n                }\r\n            \r\n                rows.append(row)\r\n            \r\n            \r\n            df = pd.DataFrame(rows)\r\n            processed = df.to_string()\r\n            self.status = processed\r\n            return Message(text=processed)\r\n        except:\r\n            return Message(text=\"\")\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input Value",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Parse fetched data",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Retrieval result parsed",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "CustomComponent-NrS5e"
          },
          "selected": false,
          "width": 384,
          "height": 294,
          "dragging": false,
          "positionAbsolute": {
            "x": -758.5845144672244,
            "y": 4086.2578766931674
          }
        }
      ],
      "edges": [
        {
          "source": "Neo4jCredentialLoader-OdDSF",
          "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
          "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-OdDSF",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
          "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
          "target": "VectorRetrieverParserComponent-arvf7",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "VectorRetrieverParserComponent-arvf7",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeGraphIndexKRetrieverComponent",
              "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-VectorRetrieverParserComponent-arvf7{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "VectorRetrieverParserComponent-arvf7",
          "sourceHandle": "{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CombineText-3sFLj",
          "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-3sFLjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "text1",
              "id": "CombineText-3sFLj",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "VectorRetrieverParserComponent",
              "id": "VectorRetrieverParserComponent-arvf7",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-VectorRetrieverParserComponent-arvf7{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-arvf7œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-3sFLj{œfieldNameœ:œtext1œ,œidœ:œCombineText-3sFLjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ChatInput-CozXU",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
          "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "user_query",
              "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-CozXU",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ChatInput-CozXU",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "question",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-CozXU",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œquestionœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "OpenAIEmbeddings-C2xV6",
          "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-C2xV6œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
          "target": "VectorRetriever-LuqmZ",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "VectorRetriever-LuqmZ",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "OpenAIEmbeddings",
              "id": "OpenAIEmbeddings-C2xV6",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIEmbeddings-C2xV6{��dataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-C2xV6œ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-VectorRetriever-LuqmZ{œfieldNameœ:œembeddingœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ChatInput-CozXU",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "VectorRetriever-LuqmZ",
          "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "search_query",
              "id": "VectorRetriever-LuqmZ",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-CozXU",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-VectorRetriever-LuqmZ{œfieldNameœ:œsearch_queryœ,œidœ:œVectorRetriever-LuqmZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": "",
          "selected": false
        },
        {
          "source": "VectorRetriever-LuqmZ",
          "sourceHandle": "{œdataTypeœ:œVectorRetrieverœ,œidœ:œVectorRetriever-LuqmZœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œuser_fileœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "user_file",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "VectorRetriever",
              "id": "VectorRetriever-LuqmZ",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-VectorRetriever-LuqmZ{œdataTypeœ:œVectorRetrieverœ,œidœ:œVectorRetriever-LuqmZœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œuser_fileœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "TextInput-iuMVX",
          "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-iuMVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-pHCSV",
          "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "system_message",
              "id": "OpenAIModel-pHCSV",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-iuMVX",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-TextInput-iuMVX{œdataTypeœ:œTextInputœ,œidœ:œTextInput-iuMVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pHCSV{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CombineText-3sFLj",
          "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-3sFLjœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CombineText",
              "id": "CombineText-3sFLj",
              "name": "combined_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CombineText-3sFLj{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-3sFLjœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œcontextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-mPmaJ",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-mPmaJœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-pHCSV",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-pHCSV",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-mPmaJ",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-mPmaJ{œdataTypeœ:œPromptœ,œidœ:œPrompt-mPmaJœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pHCSV{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pHCSVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-pHCSV",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pHCSVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-1JJGM",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1JJGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-1JJGM",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-pHCSV",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-pHCSV{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pHCSVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-1JJGM{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1JJGMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-OdDSF",
          "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
          "target": "DocumentNameParser-q4HWm",
          "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "DocumentNameParser-q4HWm",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-OdDSF",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-DocumentNameParser-q4HWm{œfieldNameœ:œneo4j_credentialsœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
          "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
          "target": "DocumentNameParser-q4HWm",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "DocumentNameParser-q4HWm",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeGraphIndexKRetrieverComponent",
              "id": "KnowledgeGraphIndexKRetrieverComponent-xNKcX",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-xNKcX{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-xNKcXœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-DocumentNameParser-q4HWm{œfieldNameœ:œdataœ,œidœ:œDocumentNameParser-q4HWmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "DocumentNameParser-q4HWm",
          "sourceHandle": "{œdataTypeœ:œDocumentNameParserœ,œidœ:œDocumentNameParser-q4HWmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œlabeled_documentsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "labeled_documents",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "DocumentNameParser",
              "id": "DocumentNameParser-q4HWm",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-DocumentNameParser-q4HWm{œdataTypeœ:œDocumentNameParserœ,œidœ:œDocumentNameParser-q4HWmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œlabeled_documentsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "TextInput-gLVPJ",
          "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-gLVPJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-7sqhi",
          "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "system_message",
              "id": "OpenAIModel-7sqhi",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "TextInput",
              "id": "TextInput-gLVPJ",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-TextInput-gLVPJ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-gLVPJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-7sqhi{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ChatInput-CozXU",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-cKxbM",
          "targetHandle": "{œfieldNameœ:œuser_questionœ,œidœ:œPrompt-cKxbMœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "user_question",
              "id": "Prompt-cKxbM",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-CozXU",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-CozXU{œdataTypeœ:œChatInputœ,œidœ:œChatInput-CozXUœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-cKxbM{œfieldNameœ:œuser_questionœ,œidœ:œPrompt-cKxbMœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Prompt-cKxbM",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-cKxbMœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-7sqhi",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-7sqhi",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-cKxbM",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-cKxbM{œdataTypeœ:œPromptœ,œidœ:œPrompt-cKxbMœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-7sqhi{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-7sqhiœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-7sqhi",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CustomComExtractVerifyCypherponent-StbzE",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "CustomComExtractVerifyCypherponent-StbzE",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-7sqhi",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-7sqhi{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComExtractVerifyCypherponent-StbzE{œfieldNameœ:œinput_valueœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-7sqhi",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ExtractSubdomains-nTLbt",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œExtractSubdomains-nTLbtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ExtractSubdomains-nTLbt",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-7sqhi",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-7sqhi{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-7sqhiœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExtractSubdomains-nTLbt{œfieldNameœ:œinput_valueœ,œidœ:œExtractSubdomains-nTLbtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "ExtractSubdomains-nTLbt",
          "sourceHandle": "{œdataTypeœ:œExtractSubdomainsœ,œidœ:œExtractSubdomains-nTLbtœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œsubdomainsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "subdomains",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ExtractSubdomains",
              "id": "ExtractSubdomains-nTLbt",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ExtractSubdomains-nTLbt{œdataTypeœ:œExtractSubdomainsœ,œidœ:œExtractSubdomains-nTLbtœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œsubdomainsœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-OdDSF",
          "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
          "target": "GraphRetriever-OaJr8",
          "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "GraphRetriever-OaJr8",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-OdDSF",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-OdDSF{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-OdDSFœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-OaJr8{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphRetriever-OaJr8",
          "sourceHandle": "{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-OaJr8œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CustomComponent-NrS5e",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-NrS5eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "CustomComponent-NrS5e",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRetriever",
              "id": "GraphRetriever-OaJr8",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRetriever-OaJr8{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-OaJr8œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-NrS5e{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-NrS5eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComExtractVerifyCypherponent-StbzE",
          "sourceHandle": "{œdataTypeœ:œCustomComExtractVerifyCypherponentœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "GraphRetriever-OaJr8",
          "targetHandle": "{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "cypher_query",
              "id": "GraphRetriever-OaJr8",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CustomComExtractVerifyCypherponent",
              "id": "CustomComExtractVerifyCypherponent-StbzE",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CustomComExtractVerifyCypherponent-StbzE{œdataTypeœ:œCustomComExtractVerifyCypherponentœ,œidœ:œCustomComExtractVerifyCypherponent-StbzEœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-OaJr8{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-OaJr8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CustomComponent-NrS5e",
          "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NrS5eœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-mPmaJ",
          "targetHandle": "{œfieldNameœ:œsubdomain_contextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "subdomain_context",
              "id": "Prompt-mPmaJ",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CustomComponent",
              "id": "CustomComponent-NrS5e",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-NrS5e{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NrS5eœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt-mPmaJ{œfieldNameœ:œsubdomain_contextœ,œidœ:œPrompt-mPmaJœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 0,
        "y": 0,
        "zoom": 1
      }
    },
    "date_created": "2024-10-21T09:13:38.069Z",
    "date_updated": "2024-10-21T09:13:38.211Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "user_created": {
      "username": "jingconsult",
      "first_name": "Jing",
      "last_name": "Consulting",
      "id": "6decf44a-a4d8-438a-92d3-df07d49ad213"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:05.097Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 214,
    "converter_version": "1.0.0"
  }
}