"""Create webhook_events table for Stripe webhook idempotency - FIXED SCHEMA

Revision ID: 67f73f05b2ef
Revises: 66f72f04a1de
Create Date: 2025-01-11 15:00:00.000000

CRITICAL FIX: This migration now uses consistent schema that matches SQLModel definitions
to prevent AutogenerateDiffsDetected errors.
"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel
from axiestudio.utils import migration

# revision identifiers, used by Alembic.
revision: str = '67f73f05b2ef'
down_revision: Union[str, None] = '66f72f04a1de'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Create webhook_events table with FIXED SCHEMA that matches SQLModel definitions."""
    conn = op.get_bind()

    # Create webhook_events table if it doesn't exist
    if not migration.table_exists("webhook_events", conn):
        print("🔧 Creating webhook_events table with FIXED SCHEMA...")

        op.create_table(
            "webhook_events",
            # Use UUID with proper default
            sa.Column("id", sa.UUID(), nullable=False, server_default=sa.text('gen_random_uuid()')),
            # Use AutoString for consistency with SQLModel
            sa.Column("stripe_event_id", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
            sa.Column("event_type", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
            sa.Column("status", sqlmodel.sql.sqltypes.AutoString(), nullable=False, server_default='processing'),
            sa.Column("error_message", sa.Text(), nullable=True),
            # CRITICAL FIX: created_at should be nullable=False with proper default
            sa.Column("created_at", sa.DateTime(timezone=True), nullable=False, server_default=sa.text('NOW()')),
            sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
            sa.PrimaryKeyConstraint("id"),
        )

        # Create UNIQUE INDEX instead of constraint to match SQLModel expectations
        op.create_index("ix_webhook_events_stripe_event_id", "webhook_events", ["stripe_event_id"], unique=True)
        op.create_index("ix_webhook_events_status", "webhook_events", ["status"])
        op.create_index("ix_webhook_events_created_at", "webhook_events", ["created_at"])

        print("✅ webhook_events table created with FIXED SCHEMA")
    else:
        print("✅ webhook_events table already exists - checking schema compatibility...")

        # Check and fix schema if needed
        try:
            inspector = sa.inspect(conn)
            columns = {col['name']: col for col in inspector.get_columns('webhook_events')}

            # Fix created_at nullable issue if it exists
            if 'created_at' in columns and columns['created_at']['nullable']:
                print("🔧 FIXING created_at nullable mismatch...")
                op.alter_column('webhook_events', 'created_at', nullable=False, server_default=sa.text('NOW()'))
                print("✅ created_at column fixed")

        except Exception as e:
            print(f"⚠️ Could not check/fix schema: {e}")
            # Continue anyway - the database service will handle it


def downgrade() -> None:
    """Drop webhook_events table."""
    conn = op.get_bind()
    
    if migration.table_exists("webhook_events", conn):
        # Drop indexes first
        op.drop_index("ix_webhook_events_created_at", "webhook_events")
        op.drop_index("ix_webhook_events_status", "webhook_events")
        op.drop_index("ix_webhook_events_stripe_event_id", "webhook_events")
        
        # Drop table
        op.drop_table("webhook_events")
