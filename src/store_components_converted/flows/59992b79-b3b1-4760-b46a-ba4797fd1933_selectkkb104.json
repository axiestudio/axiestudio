{
  "id": "59992b79-b3b1-4760-b46a-ba4797fd1933",
  "name": "selectkkb104",
  "description": "Crafting Dialogues that Drive Business Success. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "lz",
    "first_name": "liu",
    "last_name": "zheng",
    "id": "b116f436-52c6-445a-91d2-7174073c5cd1",
    "full_name": "liu zheng"
  },
  "store_url": "https://www.langflow.store/store/component/59992b79-b3b1-4760-b46a-ba4797fd1933",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-03-24T15:00:27.631Z",
    "updated": "2024-03-24T15:00:27.702Z",
    "downloaded": "2025-08-19T17:50:04.940Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.6.10",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "BaseChatModel-SkAoU",
        "type": "genericNode",
        "position": {
          "x": -39.782069543189834,
          "y": 59.00874449763252
        },
        "data": {
          "type": "BaseChatModel",
          "node": {
            "template": {
              "metadata": {
                "type": "Dict[str, Any]",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "metadata",
                "display_name": "Metadata",
                "advanced": true,
                "dynamic": false,
                "info": "Metadata to add to the run trace.",
                "title_case": true
              },
              "stop": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stop",
                "display_name": "Stop Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "List of tokens to signal the model to stop generating text.",
                "title_case": true
              },
              "tags": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tags",
                "display_name": "Tags",
                "advanced": true,
                "dynamic": false,
                "info": "Tags to add to the run trace.",
                "title_case": true
              },
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                "title_case": true,
                "value": "http://localhost:11434"
              },
              "cache": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "cache",
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "Enable or disable caching.",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\nfrom langchain_core.language_models.chat_models import BaseChatModel\n\n# from langchain.chat_models import ChatOllama\nfrom axiestudio import CustomComponent\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(CustomComponent):\n    display_name = \"ChatOllama\"\n    description = \"Local LLM for chat with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseChatModel:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return output  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "format": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "format",
                "display_name": "Format",
                "advanced": true,
                "dynamic": false,
                "info": "Specify the format of the output (e.g., json).",
                "title_case": true
              },
              "mirostat": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Disabled",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "name": "mirostat",
                "display_name": "Mirostat",
                "advanced": true,
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "title_case": true
              },
              "mirostat_eta": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_eta",
                "display_name": "Mirostat Eta",
                "advanced": true,
                "dynamic": false,
                "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "mirostat_tau": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_tau",
                "display_name": "Mirostat Tau",
                "advanced": true,
                "dynamic": false,
                "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "model": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "llama2",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "Refer to https://ollama.ai/library for more models.",
                "title_case": true
              },
              "num_ctx": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_ctx",
                "display_name": "Context Window Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the context window for generating tokens. (Default: 2048)",
                "title_case": true
              },
              "num_gpu": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_gpu",
                "display_name": "Number of GPUs",
                "advanced": true,
                "dynamic": false,
                "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                "title_case": true
              },
              "num_thread": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_thread",
                "display_name": "Number of Threads",
                "advanced": true,
                "dynamic": false,
                "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                "title_case": true
              },
              "repeat_last_n": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_last_n",
                "display_name": "Repeat Last N",
                "advanced": true,
                "dynamic": false,
                "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                "title_case": true
              },
              "repeat_penalty": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_penalty",
                "display_name": "Repeat Penalty",
                "advanced": true,
                "dynamic": false,
                "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "system": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system",
                "display_name": "System",
                "advanced": true,
                "dynamic": false,
                "info": "System to use for generating text.",
                "title_case": true
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.8,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Controls the creativity of model responses.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to use for generating text.",
                "title_case": true
              },
              "tfs_z": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tfs_z",
                "display_name": "TFS Z",
                "advanced": true,
                "dynamic": false,
                "info": "Tail free sampling value. (Default: 1)",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "timeout": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "Timeout for the request stream.",
                "title_case": true
              },
              "top_k": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_k",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Limits token selection to top K. (Default: 40)",
                "title_case": true
              },
              "top_p": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_p",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "Works together with top-k. (Default: 0.9)",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "verbose": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "verbose",
                "display_name": "Verbose",
                "advanced": false,
                "dynamic": false,
                "info": "Whether to print out response text.",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Local LLM for chat with Ollama.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseChatModel"
            ],
            "display_name": "ChatOllama",
            "documentation": "",
            "custom_fields": {
              "base_url": null,
              "model": null,
              "mirostat": null,
              "mirostat_eta": null,
              "mirostat_tau": null,
              "repeat_last_n": null,
              "verbose": null,
              "cache": null,
              "num_ctx": null,
              "num_gpu": null,
              "format": null,
              "metadata": null,
              "num_thread": null,
              "repeat_penalty": null,
              "stop": null,
              "system": null,
              "tags": null,
              "temperature": null,
              "template": null,
              "tfs_z": null,
              "timeout": null,
              "top_k": null,
              "top_p": null
            },
            "output_types": [
              "BaseChatModel"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "BaseChatModel-SkAoU"
        },
        "selected": false,
        "width": 384,
        "height": 631,
        "dragging": false,
        "positionAbsolute": {
          "x": -39.782069543189834,
          "y": 59.00874449763252
        }
      },
      {
        "id": "ChatPromptTemplate-fQVIO",
        "type": "genericNode",
        "position": {
          "x": 438.47849043573876,
          "y": 740.5227633036815
        },
        "data": {
          "type": "ChatPromptTemplate",
          "node": {
            "template": {
              "messages": {
                "type": "BaseMessagePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "messages",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "ChatPromptTemplate"
            },
            "description": "Prompt template for chat models.",
            "base_classes": [
              "ChatPromptTemplate",
              "BaseChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "display_name": "ChatPromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "ChatPromptTemplate-fQVIO"
        },
        "selected": false,
        "width": 384,
        "height": 243,
        "dragging": false,
        "positionAbsolute": {
          "x": 438.47849043573876,
          "y": 740.5227633036815
        }
      },
      {
        "id": "SQLDatabaseChain-r3rfJ",
        "type": "genericNode",
        "position": {
          "x": 874.2302463081979,
          "y": 366.9749669941597
        },
        "data": {
          "type": "SQLDatabaseChain",
          "node": {
            "template": {
              "db": {
                "type": "SQLDatabase",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "db",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "llm",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "_type": "SQLDatabaseChain"
            },
            "description": "Create a SQLDatabaseChain from an LLM and a database connection.",
            "base_classes": [
              "Chain",
              "SQLDatabaseChain",
              "Callable"
            ],
            "display_name": "SQLDatabaseChain",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "SQLDatabaseChain-r3rfJ"
        },
        "selected": false,
        "width": 384,
        "height": 359,
        "positionAbsolute": {
          "x": 874.2302463081979,
          "y": 366.9749669941597
        },
        "dragging": true
      },
      {
        "id": "SQLDatabase-xvjnb",
        "type": "genericNode",
        "position": {
          "x": 477.5835749147011,
          "y": 44.7964513380214
        },
        "data": {
          "type": "SQLDatabase",
          "node": {
            "template": {
              "database_uri": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "database_uri",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": "mysql+pymysql://qyyluser:quN8Qos2BRzUF0zt@172.20.3.21:3311/neuqpay_auth_v2?charset=utf8mb4"
              },
              "engine_args": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "engine_args",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "_type": "SQLDatabase"
            },
            "description": "Construct a SQLAlchemy engine from URI.",
            "base_classes": [
              "SQLDatabase",
              "Callable"
            ],
            "display_name": "SQLDatabase",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "SQLDatabase-xvjnb"
        },
        "selected": false,
        "width": 384,
        "height": 289,
        "positionAbsolute": {
          "x": 477.5835749147011,
          "y": 44.7964513380214
        },
        "dragging": false
      },
      {
        "id": "ChatMessagePromptTemplate-2R7NK",
        "type": "genericNode",
        "position": {
          "x": -65.25633310445909,
          "y": 702.9666989262669
        },
        "data": {
          "type": "ChatMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\nYou are a helpful assistant that talks casually about life in general.\nYou are a good listener and you can talk about anything.\n医疗机构编码为{input}，\n根据提供的医疗机构编码，查询对应的医疗机构名称。使用的数据库表是kb01，医疗机构编码字段是kkb101，需要检索的医疗机构名称字段是kkb104。请构造并执行相应的MYSQL查询命令。",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "role": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "role",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true,
                "value": "123"
              },
              "_type": "ChatMessagePromptTemplate",
              "input": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input",
                "display_name": "input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "Chat message prompt template.",
            "icon": null,
            "base_classes": [
              "BaseStringMessagePromptTemplate",
              "ChatMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "ChatMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates",
            "custom_fields": {
              "": [
                "input"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "ChatMessagePromptTemplate-2R7NK",
          "description": "Chat message prompt template.",
          "display_name": "ChatMessagePromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 469,
        "positionAbsolute": {
          "x": -65.25633310445909,
          "y": 702.9666989262669
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "SQLDatabase-xvjnb",
        "sourceHandle": "{œbaseClassesœ:[œSQLDatabaseœ,œCallableœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-xvjnbœ}",
        "target": "SQLDatabaseChain-r3rfJ",
        "targetHandle": "{œfieldNameœ:œdbœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}",
        "data": {
          "targetHandle": {
            "fieldName": "db",
            "id": "SQLDatabaseChain-r3rfJ",
            "inputTypes": null,
            "type": "SQLDatabase"
          },
          "sourceHandle": {
            "baseClasses": [
              "SQLDatabase",
              "Callable"
            ],
            "dataType": "SQLDatabase",
            "id": "SQLDatabase-xvjnb"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-SQLDatabase-xvjnb{œbaseClassesœ:[œSQLDatabaseœ,œCallableœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-xvjnbœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œdbœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}"
      },
      {
        "source": "ChatPromptTemplate-fQVIO",
        "sourceHandle": "{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-fQVIOœ}",
        "target": "SQLDatabaseChain-r3rfJ",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "SQLDatabaseChain-r3rfJ",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "ChatPromptTemplate",
              "BaseChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "dataType": "ChatPromptTemplate",
            "id": "ChatPromptTemplate-fQVIO"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatPromptTemplate-fQVIO{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-fQVIOœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œpromptœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
      },
      {
        "source": "BaseChatModel-SkAoU",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseChatModelœ],œdataTypeœ:œBaseChatModelœ,œidœ:œBaseChatModel-SkAoUœ}",
        "target": "SQLDatabaseChain-r3rfJ",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "SQLDatabaseChain-r3rfJ",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseChatModel"
            ],
            "dataType": "BaseChatModel",
            "id": "BaseChatModel-SkAoU"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-BaseChatModel-SkAoU{œbaseClassesœ:[œBaseLanguageModelœ,œBaseChatModelœ],œdataTypeœ:œBaseChatModelœ,œidœ:œBaseChatModel-SkAoUœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œllmœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "ChatMessagePromptTemplate-2R7NK",
        "sourceHandle": "{œbaseClassesœ:[œBaseStringMessagePromptTemplateœ,œChatMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œChatMessagePromptTemplateœ,œidœ:œChatMessagePromptTemplate-2R7NKœ}",
        "target": "ChatPromptTemplate-fQVIO",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-fQVIOœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-fQVIO",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseStringMessagePromptTemplate",
              "ChatMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "dataType": "ChatMessagePromptTemplate",
            "id": "ChatMessagePromptTemplate-2R7NK"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatMessagePromptTemplate-2R7NK{œbaseClassesœ:[œBaseStringMessagePromptTemplateœ,œChatMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œChatMessagePromptTemplateœ,œidœ:œChatMessagePromptTemplate-2R7NKœ}-ChatPromptTemplate-fQVIO{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-fQVIOœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      }
    ],
    "viewport": {
      "x": 215.4480887709076,
      "y": 26.571773868787204,
      "zoom": 0.9263175832167161
    }
  },
  "metadata": {
    "BaseChatModel": {
      "count": 1
    },
    "ChatPromptTemplate": {
      "count": 1
    },
    "SQLDatabaseChain": {
      "count": 1
    },
    "SQLDatabase": {
      "count": 1
    },
    "ChatMessagePromptTemplate": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "59992b79-b3b1-4760-b46a-ba4797fd1933",
    "name": "selectkkb104",
    "description": "Crafting Dialogues that Drive Business Success.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "1",
    "metadata": {
      "BaseChatModel": {
        "count": 1
      },
      "ChatPromptTemplate": {
        "count": 1
      },
      "SQLDatabaseChain": {
        "count": 1
      },
      "SQLDatabase": {
        "count": 1
      },
      "ChatMessagePromptTemplate": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "0.6.10",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "BaseChatModel-SkAoU",
          "type": "genericNode",
          "position": {
            "x": -39.782069543189834,
            "y": 59.00874449763252
          },
          "data": {
            "type": "BaseChatModel",
            "node": {
              "template": {
                "metadata": {
                  "type": "Dict[str, Any]",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "metadata",
                  "display_name": "Metadata",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Metadata to add to the run trace.",
                  "title_case": true
                },
                "stop": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stop",
                  "display_name": "Stop Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "List of tokens to signal the model to stop generating text.",
                  "title_case": true
                },
                "tags": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tags",
                  "display_name": "Tags",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tags to add to the run trace.",
                  "title_case": true
                },
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                  "title_case": true,
                  "value": "http://localhost:11434"
                },
                "cache": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "cache",
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Enable or disable caching.",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\nfrom langchain_core.language_models.chat_models import BaseChatModel\n\n# from langchain.chat_models import ChatOllama\nfrom axiestudio import CustomComponent\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(CustomComponent):\n    display_name = \"ChatOllama\"\n    description = \"Local LLM for chat with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseChatModel:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return output  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "format": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "format",
                  "display_name": "Format",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Specify the format of the output (e.g., json).",
                  "title_case": true
                },
                "mirostat": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Disabled",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Disabled",
                    "Mirostat",
                    "Mirostat 2.0"
                  ],
                  "name": "mirostat",
                  "display_name": "Mirostat",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                  "title_case": true
                },
                "mirostat_eta": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_eta",
                  "display_name": "Mirostat Eta",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "mirostat_tau": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_tau",
                  "display_name": "Mirostat Tau",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "model": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "llama2",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Refer to https://ollama.ai/library for more models.",
                  "title_case": true
                },
                "num_ctx": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_ctx",
                  "display_name": "Context Window Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Size of the context window for generating tokens. (Default: 2048)",
                  "title_case": true
                },
                "num_gpu": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_gpu",
                  "display_name": "Number of GPUs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                  "title_case": true
                },
                "num_thread": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_thread",
                  "display_name": "Number of Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                  "title_case": true
                },
                "repeat_last_n": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_last_n",
                  "display_name": "Repeat Last N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                  "title_case": true
                },
                "repeat_penalty": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_penalty",
                  "display_name": "Repeat Penalty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "system": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "system",
                  "display_name": "System",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System to use for generating text.",
                  "title_case": true
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.8,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Controls the creativity of model responses.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to use for generating text.",
                  "title_case": true
                },
                "tfs_z": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tfs_z",
                  "display_name": "TFS Z",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tail free sampling value. (Default: 1)",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "timeout": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Timeout for the request stream.",
                  "title_case": true
                },
                "top_k": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_k",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limits token selection to top K. (Default: 40)",
                  "title_case": true
                },
                "top_p": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_p",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Works together with top-k. (Default: 0.9)",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "verbose": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "verbose",
                  "display_name": "Verbose",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether to print out response text.",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Local LLM for chat with Ollama.",
              "base_classes": [
                "BaseLanguageModel",
                "BaseChatModel"
              ],
              "display_name": "ChatOllama",
              "documentation": "",
              "custom_fields": {
                "base_url": null,
                "model": null,
                "mirostat": null,
                "mirostat_eta": null,
                "mirostat_tau": null,
                "repeat_last_n": null,
                "verbose": null,
                "cache": null,
                "num_ctx": null,
                "num_gpu": null,
                "format": null,
                "metadata": null,
                "num_thread": null,
                "repeat_penalty": null,
                "stop": null,
                "system": null,
                "tags": null,
                "temperature": null,
                "template": null,
                "tfs_z": null,
                "timeout": null,
                "top_k": null,
                "top_p": null
              },
              "output_types": [
                "BaseChatModel"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "BaseChatModel-SkAoU"
          },
          "selected": false,
          "width": 384,
          "height": 631,
          "dragging": false,
          "positionAbsolute": {
            "x": -39.782069543189834,
            "y": 59.00874449763252
          }
        },
        {
          "id": "ChatPromptTemplate-fQVIO",
          "type": "genericNode",
          "position": {
            "x": 438.47849043573876,
            "y": 740.5227633036815
          },
          "data": {
            "type": "ChatPromptTemplate",
            "node": {
              "template": {
                "messages": {
                  "type": "BaseMessagePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "messages",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "output_parser": {
                  "type": "BaseOutputParser",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_types": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_types",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_variables": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "name",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "partial_variables": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "tags": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "validate_template": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "ChatPromptTemplate"
              },
              "description": "Prompt template for chat models.",
              "base_classes": [
                "ChatPromptTemplate",
                "BaseChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "display_name": "ChatPromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "ChatPromptTemplate-fQVIO"
          },
          "selected": false,
          "width": 384,
          "height": 243,
          "dragging": false,
          "positionAbsolute": {
            "x": 438.47849043573876,
            "y": 740.5227633036815
          }
        },
        {
          "id": "SQLDatabaseChain-r3rfJ",
          "type": "genericNode",
          "position": {
            "x": 874.2302463081979,
            "y": 366.9749669941597
          },
          "data": {
            "type": "SQLDatabaseChain",
            "node": {
              "template": {
                "db": {
                  "type": "SQLDatabase",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "db",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "llm",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "BasePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "_type": "SQLDatabaseChain"
              },
              "description": "Create a SQLDatabaseChain from an LLM and a database connection.",
              "base_classes": [
                "Chain",
                "SQLDatabaseChain",
                "Callable"
              ],
              "display_name": "SQLDatabaseChain",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "SQLDatabaseChain-r3rfJ"
          },
          "selected": false,
          "width": 384,
          "height": 359,
          "positionAbsolute": {
            "x": 874.2302463081979,
            "y": 366.9749669941597
          },
          "dragging": true
        },
        {
          "id": "SQLDatabase-xvjnb",
          "type": "genericNode",
          "position": {
            "x": 477.5835749147011,
            "y": 44.7964513380214
          },
          "data": {
            "type": "SQLDatabase",
            "node": {
              "template": {
                "database_uri": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "database_uri",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": "mysql+pymysql://qyyluser:quN8Qos2BRzUF0zt@172.20.3.21:3311/neuqpay_auth_v2?charset=utf8mb4"
                },
                "engine_args": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "engine_args",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "_type": "SQLDatabase"
              },
              "description": "Construct a SQLAlchemy engine from URI.",
              "base_classes": [
                "SQLDatabase",
                "Callable"
              ],
              "display_name": "SQLDatabase",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "SQLDatabase-xvjnb"
          },
          "selected": false,
          "width": 384,
          "height": 289,
          "positionAbsolute": {
            "x": 477.5835749147011,
            "y": 44.7964513380214
          },
          "dragging": false
        },
        {
          "id": "ChatMessagePromptTemplate-2R7NK",
          "type": "genericNode",
          "position": {
            "x": -65.25633310445909,
            "y": 702.9666989262669
          },
          "data": {
            "type": "ChatMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "\nYou are a helpful assistant that talks casually about life in general.\nYou are a good listener and you can talk about anything.\n医疗机构编码为{input}，\n根据提供的医疗机构编码，查询对应的医疗机构名称。使用的数据库表是kb01，医疗机构编码字段是kkb101，需要检索的医疗机构名称字段是kkb104。请构造并执行相应的MYSQL查询命令。",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "role": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "role",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true,
                  "value": "123"
                },
                "_type": "ChatMessagePromptTemplate",
                "input": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input",
                  "display_name": "input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                }
              },
              "description": "Chat message prompt template.",
              "icon": null,
              "base_classes": [
                "BaseStringMessagePromptTemplate",
                "ChatMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "ChatMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates",
              "custom_fields": {
                "": [
                  "input"
                ]
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "ChatMessagePromptTemplate-2R7NK",
            "description": "Chat message prompt template.",
            "display_name": "ChatMessagePromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 469,
          "positionAbsolute": {
            "x": -65.25633310445909,
            "y": 702.9666989262669
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "SQLDatabase-xvjnb",
          "sourceHandle": "{œbaseClassesœ:[œSQLDatabaseœ,œCallableœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-xvjnbœ}",
          "target": "SQLDatabaseChain-r3rfJ",
          "targetHandle": "{œfieldNameœ:œdbœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}",
          "data": {
            "targetHandle": {
              "fieldName": "db",
              "id": "SQLDatabaseChain-r3rfJ",
              "inputTypes": null,
              "type": "SQLDatabase"
            },
            "sourceHandle": {
              "baseClasses": [
                "SQLDatabase",
                "Callable"
              ],
              "dataType": "SQLDatabase",
              "id": "SQLDatabase-xvjnb"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-SQLDatabase-xvjnb{œbaseClassesœ:[œSQLDatabaseœ,œCallableœ],œdataTypeœ:œSQLDatabaseœ,œidœ:œSQLDatabase-xvjnbœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œdbœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œSQLDatabaseœ}"
        },
        {
          "source": "ChatPromptTemplate-fQVIO",
          "sourceHandle": "{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-fQVIOœ}",
          "target": "SQLDatabaseChain-r3rfJ",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "SQLDatabaseChain-r3rfJ",
              "inputTypes": null,
              "type": "BasePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "ChatPromptTemplate",
                "BaseChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "dataType": "ChatPromptTemplate",
              "id": "ChatPromptTemplate-fQVIO"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatPromptTemplate-fQVIO{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-fQVIOœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œpromptœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
        },
        {
          "source": "BaseChatModel-SkAoU",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseChatModelœ],œdataTypeœ:œBaseChatModelœ,œidœ:œBaseChatModel-SkAoUœ}",
          "target": "SQLDatabaseChain-r3rfJ",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "SQLDatabaseChain-r3rfJ",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseChatModel"
              ],
              "dataType": "BaseChatModel",
              "id": "BaseChatModel-SkAoU"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-BaseChatModel-SkAoU{œbaseClassesœ:[œBaseLanguageModelœ,œBaseChatModelœ],œdataTypeœ:œBaseChatModelœ,œidœ:œBaseChatModel-SkAoUœ}-SQLDatabaseChain-r3rfJ{œfieldNameœ:œllmœ,œidœ:œSQLDatabaseChain-r3rfJœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "ChatMessagePromptTemplate-2R7NK",
          "sourceHandle": "{œbaseClassesœ:[œBaseStringMessagePromptTemplateœ,œChatMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œChatMessagePromptTemplateœ,œidœ:œChatMessagePromptTemplate-2R7NKœ}",
          "target": "ChatPromptTemplate-fQVIO",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-fQVIOœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-fQVIO",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseStringMessagePromptTemplate",
                "ChatMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "dataType": "ChatMessagePromptTemplate",
              "id": "ChatMessagePromptTemplate-2R7NK"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatMessagePromptTemplate-2R7NK{œbaseClassesœ:[œBaseStringMessagePromptTemplateœ,œChatMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œChatMessagePromptTemplateœ,œidœ:œChatMessagePromptTemplate-2R7NKœ}-ChatPromptTemplate-fQVIO{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-fQVIOœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        }
      ],
      "viewport": {
        "x": 215.4480887709076,
        "y": 26.571773868787204,
        "zoom": 0.9263175832167161
      }
    },
    "date_created": "2024-03-24T15:00:27.631Z",
    "date_updated": "2024-03-24T15:00:27.702Z",
    "status": "Public",
    "sort": null,
    "user_updated": "b116f436-52c6-445a-91d2-7174073c5cd1",
    "user_created": {
      "username": "lz",
      "first_name": "liu",
      "last_name": "zheng",
      "id": "b116f436-52c6-445a-91d2-7174073c5cd1"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:58.440Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 2,
    "converter_version": "1.0.0"
  }
}