{
  "id": "4a689676-6036-4b5b-bd3a-7b6db2a89ebd",
  "name": "Untitled document (17) (3)",
  "description": "Unleashing Business Potential through Language Engineering. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "prat210688",
    "first_name": "PRATIK",
    "last_name": "GHODKE",
    "id": "61218f6e-08b1-4f25-8d76-5723614cd60f",
    "full_name": "PRATIK GHODKE"
  },
  "store_url": "https://www.langflow.store/store/component/4a689676-6036-4b5b-bd3a-7b6db2a89ebd",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-05T19:19:23.731Z",
    "updated": "2024-10-05T19:19:24.015Z",
    "downloaded": "2025-08-19T17:50:07.431Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-ed3Pl",
        "type": "genericNode",
        "position": {
          "x": 314.93914971534537,
          "y": -2851.2309113631127
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "files",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "what is axiestudio",
                "name": "input_value",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "User",
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": true,
                "name": "should_store_message",
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatInput-ed3Pl"
        },
        "selected": false,
        "width": 384,
        "height": 298,
        "positionAbsolute": {
          "x": 314.93914971534537,
          "y": -2851.2309113631127
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-t8IwZ",
        "type": "genericNode",
        "position": {
          "x": 1923.3342526887081,
          "y": -2685.254812830411
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatOutput-t8IwZ",
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output"
        },
        "selected": false,
        "width": 384,
        "height": 298,
        "positionAbsolute": {
          "x": 1923.3342526887081,
          "y": -2685.254812830411
        },
        "dragging": false
      },
      {
        "id": "LangWatchEvaluatorComponent-v6Wt0",
        "type": "genericNode",
        "position": {
          "x": 2393.325028867806,
          "y": -1988.3593318279497
        },
        "data": {
          "type": "LangWatchEvaluatorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "context_data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "context_data",
                "value": "",
                "display_name": "RAG Search Results (optional)",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to be used as context for evaluation.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "answer": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "answer",
                "value": "",
                "display_name": "Answer",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The generated answer to be evaluated.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import MessageTextInput, DataInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.template import Output\r\nfrom axiestudio.schema import Data\r\nimport langwatch\r\n\r\nclass LangWatchEvaluatorComponent(Component):\r\n    display_name = \"LangWatch Evaluator\"\r\n    description = \"Evaluates a question-answer pair using LangWatch and provides a trace URL.\"\r\n    icon = \"view\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"question\",\r\n            display_name=\"Question\",\r\n            info=\"The question to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"answer\",\r\n            display_name=\"Answer\",\r\n            info=\"The generated answer to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"ground_truth\",\r\n            display_name=\"Correct Answer\",\r\n            info=\"The expected correct answer.\",\r\n        ),\r\n        DataInput(\r\n            name=\"context_data\",\r\n            display_name=\"RAG Search Results (optional)\",\r\n            info=\"The data to be used as context for evaluation.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_email\",\r\n            display_name=\"User Email\",\r\n            info=\"The user email for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_name\",\r\n            display_name=\"Participant Name\",\r\n            info=\"Full name for identification in the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"question_id\",\r\n            display_name=\"Question ID\",\r\n            info=\"The question ID for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Trace URL\", name=\"trace_url\", method=\"evaluate\"),\r\n    ]\r\n\r\n    async def evaluate(self) -> Data:\r\n        question = self.question\r\n        answer = self.answer\r\n        ground_truth = self.ground_truth\r\n        context_data = self.context_data\r\n        user_email = self.user_email if self.user_email else \"\"\r\n        question_id = self.question_id if self.question_id else \"\"\r\n        user_name = self.user_name if self.user_name else \"\"\r\n\r\n        # Validate email if provided\r\n        if user_email and not self.validate_email(user_email):\r\n            raise ValueError(f\"Invalid email address: {user_email}\")\r\n\r\n        langwatch.api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOjE3MjY2Njk3NTkyMjcsInJhbmQiOjAuMjg5OTc4Mjk4NzU2MzIzOTcsImlhdCI6MTcyNjY2OTc1OX0._ow7WQ5RSTlYE-HjdcouHUCoXf9nRnWHk4u9nfq4LIw'\r\n\r\n        trace = langwatch.trace(\r\n            metadata={\r\n                \"user_email\": user_email,\r\n                \"question_id\": question_id,\r\n                \"user_name\": user_name,\r\n            },\r\n            expected_output=ground_truth\r\n        )\r\n        \r\n        contexts = [item.text.replace(\"\\t\", \" \").replace(\"\\n\", \" \") for item in context_data[:5]] if context_data else []\r\n        rag_span = trace.span(type=\"rag\", name=\"LangWatch Evaluator\", input=question, contexts=contexts, output=answer)\r\n        rag_span.end()\r\n\r\n        trace.send_spans()\r\n\r\n        public_url = trace.share()\r\n        self.log(f\"See the trace at: {public_url}\")\r\n\r\n        self.status = Data(data={\"trace_url\": public_url})\r\n        return Data(data={\"trace_url\": public_url})\r\n        \r\n    def validate_email(self, email):\r\n        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\r\n        return re.match(pattern, email) is not None",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "ground_truth": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ground_truth",
                "value": "",
                "display_name": "Correct Answer",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The expected correct answer.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "question": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "question",
                "value": "",
                "display_name": "Question",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The question to be evaluated.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "question_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "question_id",
                "value": "",
                "display_name": "Question ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The question ID for the trace metadata.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_email": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_email",
                "value": "",
                "display_name": "User Email",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The user email for the trace metadata.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_name",
                "value": "",
                "display_name": "Participant Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Full name for identification in the trace metadata.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.",
            "icon": "view",
            "base_classes": [
              "Data"
            ],
            "display_name": "Langwatch Evaluator",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "trace_url",
                "display_name": "Trace URL",
                "method": "evaluate",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "question",
              "answer",
              "ground_truth",
              "context_data",
              "user_email",
              "user_name",
              "question_id"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "LangWatchEvaluatorComponent-v6Wt0",
          "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.",
          "display_name": "Langwatch Evaluator"
        },
        "selected": false,
        "width": 384,
        "height": 546,
        "dragging": false,
        "positionAbsolute": {
          "x": 2393.325028867806,
          "y": -1988.3593318279497
        }
      },
      {
        "id": "APIRequest-NvyuE",
        "type": "genericNode",
        "position": {
          "x": 787.4397924723891,
          "y": -2933.4371664910223
        },
        "data": {
          "type": "APIRequest",
          "node": {
            "template": {
              "_type": "Component",
              "query_params": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "query_params",
                "value": "",
                "display_name": "Query Parameters",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "body": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "body",
                "value": {},
                "display_name": "Body",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "chat_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_message",
                "value": "",
                "display_name": "Chat Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Input message from ChatInput component",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import asyncio\r\nimport json\r\nfrom typing import Any, List, Optional\r\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\r\n\r\nimport httpx\r\nfrom loguru import logger\r\n\r\nfrom axiestudio.base.curl.parse import parse_context\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output, MessageInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.dotdict import dotdict\r\nfrom axiestudio.schema.message import Message\r\n\r\nclass APIRequestComponent(Component):\r\n    display_name = \"API Request\"\r\n    description = (\r\n        \"This component allows you to make HTTP requests to one or more URLs. \"\r\n        \"You can provide headers and body as either dictionaries or Data objects. \"\r\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\r\n        \"**Note:** Check advanced options for more settings.\"\r\n    )\r\n    icon = \"Globe\"\r\n    name = \"APIRequest\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"urls\",\r\n            display_name=\"URLs\",\r\n            is_list=True,\r\n            info=\"Enter one or more URLs, separated by commas.\",\r\n            value=[\"https://api.dify.ai/v1/chat-messages\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"curl\",\r\n            display_name=\"Curl\",\r\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\r\n            advanced=False,\r\n            refresh_button=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\r\n            value=\"POST\",\r\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\r\n        ),\r\n        NestedDictInput(\r\n            name=\"headers\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\r\n            input_types=[\"Data\"],\r\n        ),\r\n        NestedDictInput(\r\n            name=\"body\",\r\n            display_name=\"Body\",\r\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\r\n            input_types=[\"Data\"],\r\n        ),\r\n        DataInput(\r\n            name=\"query_params\",\r\n            display_name=\"Query Parameters\",\r\n            info=\"The query parameters to append to the URL.\",\r\n        ),\r\n        IntInput(\r\n            name=\"timeout\",\r\n            display_name=\"Timeout\",\r\n            value=5,\r\n            info=\"The timeout to use for the request.\",\r\n        ),\r\n        MessageInput(\r\n            name=\"chat_message\",\r\n            display_name=\"Chat Message\",\r\n            info=\"Input message from ChatInput component\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"API Response\", name=\"api_response\", method=\"make_requests\"),\r\n    ]\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._build_config = dotdict()\r\n        self.set_default_config()\r\n\r\n    def set_default_config(self):\r\n        default_curl = \"\"\"curl -X POST 'https://api.dify.ai/v1/chat-messages' \\\r\n--header 'Authorization: Bearer app-NKw5JuFE05yAw9GtQs0MyM4I' \\\r\n--header 'Content-Type: application/json' \\\r\n--data-raw '{\r\n    \"inputs\": {},\r\n    \"query\": \"What are the specs of the iPhone 13 Pro Max?\",\r\n    \"response_mode\": \"streaming\",\r\n    \"conversation_id\": \"\",\r\n    \"user\": \"abc-123\",\r\n    \"files\": []\r\n}'\"\"\"\r\n        self._build_config = self.parse_curl(default_curl, dotdict())\r\n\r\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\r\n        try:\r\n            parsed = parse_context(curl)\r\n            build_config[\"urls\"] = {\"value\": [parsed.url]}\r\n            build_config[\"method\"] = {\"value\": parsed.method.upper()}\r\n            build_config[\"headers\"] = {\"value\": dict(parsed.headers)}\r\n\r\n            if parsed.data:\r\n                try:\r\n                    json_data = json.loads(parsed.data)\r\n                    build_config[\"body\"] = {\"value\": json_data}\r\n                except json.JSONDecodeError as e:\r\n                    logger.error(f\"Error decoding JSON data: {e}\")\r\n            else:\r\n                build_config[\"body\"] = {\"value\": {}}\r\n        except Exception as exc:\r\n            logger.error(f\"Error parsing curl: {exc}\")\r\n            raise ValueError(f\"Error parsing curl: {exc}\")\r\n        return build_config\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\r\n        if field_name == \"curl\" and field_value:\r\n            build_config = self.parse_curl(field_value, build_config)\r\n        return build_config\r\n\r\n    async def make_request(\r\n        self,\r\n        client: httpx.AsyncClient,\r\n        method: str,\r\n        url: str,\r\n        headers: Optional[dict] = None,\r\n        body: Optional[dict] = None,\r\n        timeout: int = 5,\r\n    ) -> Data:\r\n        method = method.upper()\r\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\r\n            raise ValueError(f\"Unsupported method: {method}\")\r\n\r\n        if isinstance(body, str) and body:\r\n            try:\r\n                body = json.loads(body)\r\n            except Exception as e:\r\n                logger.error(f\"Error decoding JSON data: {e}\")\r\n                body = None\r\n                raise ValueError(f\"Error decoding JSON data: {e}\")\r\n\r\n        data = body if body else None\r\n\r\n        try:\r\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\r\n            try:\r\n                result = response.json()\r\n            except Exception:\r\n                result = response.text\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": response.status_code,\r\n                    \"result\": result,\r\n                },\r\n            )\r\n        except httpx.TimeoutException:\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": 408,\r\n                    \"error\": \"Request timed out\",\r\n                },\r\n            )\r\n        except Exception as exc:\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": 500,\r\n                    \"error\": str(exc),\r\n                },\r\n            )\r\n\r\n    def add_query_params(self, url: str, params: dict) -> str:\r\n        url_parts = list(urlparse(url))\r\n        query = dict(parse_qsl(url_parts[4]))\r\n        query.update(params)\r\n        url_parts[4] = urlencode(query)\r\n        return urlunparse(url_parts)\r\n\r\n    async def make_requests(self) -> Data:\r\n        method = self.method or self._build_config.get(\"method\", {}).get(\"value\", \"POST\")\r\n        urls = self.urls or self._build_config.get(\"urls\", {}).get(\"value\", [])\r\n        urls = [url.strip() for url in urls if url.strip()]\r\n        curl = self.curl\r\n        headers = self.headers or self._build_config.get(\"headers\", {}).get(\"value\", {})\r\n        body = self.body or self._build_config.get(\"body\", {}).get(\"value\", {})\r\n        timeout = self.timeout\r\n        query_params = self.query_params.data if self.query_params else {}\r\n\r\n        if curl:\r\n            self._build_config = self.parse_curl(curl, dotdict())\r\n\r\n        if isinstance(headers, Data):\r\n            headers = headers.data\r\n\r\n        if isinstance(body, Data):\r\n            body = body.data\r\n\r\n        # Process chat_message if available\r\n        if isinstance(self.chat_message, Message):\r\n            # Update the body with the chat message text\r\n            body[\"query\"] = self.chat_message.text\r\n            \r\n            # If there are files in the message, add them to the body\r\n            if self.chat_message.files:\r\n                body[\"files\"] = [\r\n                    {\r\n                        \"type\": \"file\",\r\n                        \"transfer_method\": \"local_file\",\r\n                        \"name\": file.name,\r\n                        \"content\": file.content,\r\n                    }\r\n                    for file in self.chat_message.files\r\n                ]\r\n\r\n        bodies = [body] * len(urls)\r\n\r\n        urls = [self.add_query_params(url, query_params) for url in urls]\r\n\r\n        async with httpx.AsyncClient() as client:\r\n            results = await asyncio.gather(\r\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\r\n            )\r\n        \r\n        # Process the results into a single Data object\r\n        processed_results = []\r\n        for result in results:\r\n            if isinstance(result, Data) and isinstance(result.data, dict):\r\n                processed_results.append(result.data)\r\n\r\n        self.status = processed_results\r\n        return Data(data={\"api_response\": processed_results})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "curl": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "curl",
                "value": "",
                "display_name": "Curl",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "headers": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "headers",
                "value": {},
                "display_name": "Headers",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "method": {
                "trace_as_metadata": true,
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "method",
                "value": "POST",
                "display_name": "Method",
                "advanced": false,
                "dynamic": false,
                "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": 5,
                "display_name": "Timeout",
                "advanced": false,
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "urls": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "urls",
                "value": [
                  "https://api.dify.ai/v1/chat-messages"
                ],
                "display_name": "URLs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter one or more URLs, separated by commas.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
            "icon": "Globe",
            "base_classes": [
              "Data"
            ],
            "display_name": "API Request",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_response",
                "display_name": "API Response",
                "method": "make_requests",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "urls",
              "curl",
              "method",
              "headers",
              "body",
              "query_params",
              "timeout",
              "chat_message"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "APIRequest-NvyuE"
        },
        "selected": false,
        "width": 384,
        "height": 1070,
        "dragging": false,
        "positionAbsolute": {
          "x": 787.4397924723891,
          "y": -2933.4371664910223
        }
      },
      {
        "id": "ToolCallingAgent-hgTUU",
        "type": "genericNode",
        "position": {
          "x": 1491.699367223321,
          "y": -2652.8667148174773
        },
        "data": {
          "type": "ToolCallingAgent",
          "node": {
            "template": {
              "_type": "Component",
              "api_response": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_response",
                "value": "",
                "display_name": "API Response",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chat_history": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_history",
                "value": "",
                "display_name": "Chat History",
                "advanced": true,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, List\r\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\r\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\r\nfrom langchain.agents.tools import Tool\r\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\r\nfrom axiestudio.inputs import MultilineInput\r\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\r\nfrom axiestudio.schema import Data\r\n\r\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\r\n    display_name: str = \"Tool Calling Agent\"\r\n    description: str = \"Agent that processes API responses and uses tools to answer queries\"\r\n    icon = \"LangChain\"\r\n    beta = True\r\n    name = \"ToolCallingAgent\"\r\n\r\n    inputs = LCToolsAgentComponent._base_inputs + [\r\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\r\n        MultilineInput(\r\n            name=\"system_prompt\",\r\n            display_name=\"System Prompt\",\r\n            info=\"System prompt for the agent.\",\r\n            value=\"You are a helpful assistant that processes API responses and answers user queries.\",\r\n        ),\r\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\r\n        DataInput(name=\"api_response\", display_name=\"API Response\", required=True),\r\n    ]\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        if not hasattr(self, 'tools') or self.tools is None:\r\n            self.tools = []\r\n\r\n    def get_chat_history_data(self) -> Optional[List[Data]]:\r\n        return self.chat_history\r\n\r\n    def process_api_response(self) -> str:\r\n        if not self.api_response or not isinstance(self.api_response, Data):\r\n            return \"No API response available.\"\r\n        \r\n        api_data = self.api_response.data\r\n        if not isinstance(api_data, dict) or \"api_response\" not in api_data:\r\n            return \"Invalid API response format.\"\r\n        \r\n        processed_response = \"\"\r\n        for response in api_data[\"api_response\"]:\r\n            result = response.get(\"result\", \"\")\r\n            if isinstance(result, dict):\r\n                # Extract relevant information from the result\r\n                answer = result.get(\"answer\", \"\")\r\n                processed_response += f\"Answer: {answer}\\n\"\r\n            else:\r\n                processed_response += f\"Result: {result}\\n\"\r\n        return processed_response.strip()\r\n\r\n    def create_agent_runnable(self):\r\n        if not self.llm:\r\n            raise ValueError(\"Language model (llm) is required but not provided.\")\r\n\r\n        messages = [\r\n            (\"system\", self.system_prompt),\r\n            (\"placeholder\", \"{chat_history}\"),\r\n            HumanMessagePromptTemplate(\r\n                prompt=PromptTemplate(\r\n                    input_variables=[\"api_response\"], \r\n                    template=\"API Response: {api_response}\\nPlease analyze this API response and provide a helpful answer.\"\r\n                )\r\n            ),\r\n            (\"placeholder\", \"{agent_scratchpad}\"),\r\n        ]\r\n        prompt = ChatPromptTemplate.from_messages(messages)\r\n        \r\n        # Ensure tools is a list, even if empty\r\n        tools = self.tools if isinstance(self.tools, list) else []\r\n\r\n        # Create the agent\r\n        agent = create_openai_tools_agent(self.llm, tools, prompt)\r\n        \r\n        # Create an AgentExecutor\r\n        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\r\n\r\n        # Wrap the agent executor to include API response processing\r\n        def wrapped_agent():\r\n            processed_api_response = self.process_api_response()\r\n            return agent_executor.invoke({\r\n                \"api_response\": processed_api_response,\r\n                \"chat_history\": self.get_chat_history_data()\r\n            })\r\n\r\n        return wrapped_agent",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "system_prompt": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant just take the input and output the same text as response",
                "display_name": "System Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System prompt for the agent.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Agent that processes API responses and uses tools to answer queries",
            "icon": "LangChain",
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "AgentExecutor"
                ],
                "selected": "AgentExecutor",
                "name": "agent",
                "display_name": "Agent",
                "method": "build_agent",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "tools",
              "llm",
              "system_prompt",
              "chat_history",
              "api_response"
            ],
            "beta": true,
            "edited": true
          },
          "id": "ToolCallingAgent-hgTUU"
        },
        "selected": true,
        "width": 384,
        "height": 599,
        "positionAbsolute": {
          "x": 1491.699367223321,
          "y": -2652.8667148174773
        },
        "dragging": false
      },
      {
        "id": "AnthropicModel-QorsX",
        "type": "genericNode",
        "position": {
          "x": 334.8787208196154,
          "y": -2430.7058981921127
        },
        "data": {
          "type": "AnthropicModel",
          "node": {
            "template": {
              "_type": "Component",
              "anthropic_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "anthropic_api_key",
                "value": "",
                "display_name": "Anthropic API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Anthropic API key.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "anthropic_api_url": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "anthropic_api_url",
                "value": "",
                "display_name": "Anthropic API URL",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_anthropic.chat_models import ChatAnthropic\n        except ImportError:\n            raise ImportError(\n                \"langchain_anthropic is not installed. Please install it with `pip install langchain_anthropic`.\"\n            )\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": {
                  "text_key": "text",
                  "data": {
                    "template": "Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer:",
                    "variables": {
                      "user_input": {
                        "text_key": "text",
                        "data": {
                          "text": "oi",
                          "sender": "User",
                          "sender_name": "User",
                          "session_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                          "files": [],
                          "timestamp": "2024-10-03 23:42:47",
                          "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                        },
                        "default_value": "",
                        "text": "oi",
                        "sender": "User",
                        "sender_name": "User",
                        "files": [],
                        "session_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                        "timestamp": "2024-10-03 23:42:47",
                        "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                      }
                    },
                    "files": [],
                    "timestamp": "2024-10-03 23:42:47",
                    "text": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                    "prompt": {
                      "lc": 1,
                      "type": "constructor",
                      "id": [
                        "langchain",
                        "prompts",
                        "chat",
                        "ChatPromptTemplate"
                      ],
                      "kwargs": {
                        "input_variables": [],
                        "messages": [
                          {
                            "content": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                            "additional_kwargs": {},
                            "response_metadata": {},
                            "type": "human",
                            "name": null,
                            "id": null,
                            "example": false
                          }
                        ]
                      },
                      "name": "ChatPromptTemplate",
                      "graph": {
                        "nodes": [
                          {
                            "id": 0,
                            "type": "schema",
                            "data": "PromptInput"
                          },
                          {
                            "id": 1,
                            "type": "runnable",
                            "data": {
                              "id": [
                                "langchain",
                                "prompts",
                                "chat",
                                "ChatPromptTemplate"
                              ],
                              "name": "ChatPromptTemplate"
                            }
                          },
                          {
                            "id": 2,
                            "type": "schema",
                            "data": "ChatPromptTemplateOutput"
                          }
                        ],
                        "edges": [
                          {
                            "source": 0,
                            "target": 1
                          },
                          {
                            "source": 1,
                            "target": 2
                          }
                        ]
                      }
                    },
                    "messages": [
                      {
                        "content": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                        "additional_kwargs": {},
                        "response_metadata": {},
                        "type": "human",
                        "name": null,
                        "id": null,
                        "example": false
                      }
                    ],
                    "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                    "session_id": ""
                  },
                  "default_value": "",
                  "text": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                  "files": [],
                  "session_id": "",
                  "timestamp": "2024-10-03 23:42:47",
                  "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                },
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": 4096,
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "claude-3-5-sonnet-20240620",
                  "claude-3-opus-20240229",
                  "claude-3-sonnet-20240229",
                  "claude-3-haiku-20240307"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "claude-3-5-sonnet-20240620",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "https://python.langchain.com/docs/integrations/chat/anthropic",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prefill": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "prefill",
                "value": "",
                "display_name": "Prefill",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Prefill text to guide the model's response.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Anthropic Chat&Completion LLMs with prefill support.",
            "icon": "Anthropic",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Anthropic",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model",
              "anthropic_api_key",
              "temperature",
              "anthropic_api_url",
              "prefill"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "AnthropicModel-QorsX"
        },
        "selected": false,
        "width": 384,
        "height": 629,
        "positionAbsolute": {
          "x": 334.8787208196154,
          "y": -2430.7058981921127
        },
        "dragging": false
      },
      {
        "id": "Memory-sKTYv",
        "type": "genericNode",
        "position": {
          "x": 990.0672084328285,
          "y": -2671.6995185570977
        },
        "data": {
          "type": "Memory",
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "BaseChatMemory",
              "Data",
              "Message"
            ],
            "display_name": "Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Messages (Data)",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Messages (Text)",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "BaseChatMemory"
                ],
                "selected": "BaseChatMemory",
                "name": "lc_memory",
                "display_name": "Memory",
                "method": "build_lc_memory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Memory-sKTYv"
        },
        "selected": false,
        "width": 384,
        "height": 378,
        "positionAbsolute": {
          "x": 990.0672084328285,
          "y": -2671.6995185570977
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatOutput-t8IwZ",
        "target": "LangWatchEvaluatorComponent-v6Wt0",
        "sourceHandle": "{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-t8IwZœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œanswerœ,œidœ:œLangWatchEvaluatorComponent-v6Wt0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ChatOutput-t8IwZ{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-t8IwZœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-LangWatchEvaluatorComponent-v6Wt0{œfieldNameœ:œanswerœ,œidœ:œLangWatchEvaluatorComponent-v6Wt0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "answer",
            "id": "LangWatchEvaluatorComponent-v6Wt0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatOutput",
            "id": "ChatOutput-t8IwZ",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false
      },
      {
        "source": "ChatInput-ed3Pl",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ed3Plœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "APIRequest-NvyuE",
        "targetHandle": "{œfieldNameœ:œchat_messageœ,œidœ:œAPIRequest-NvyuEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "chat_message",
            "id": "APIRequest-NvyuE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-ed3Pl",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-ed3Pl{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ed3Plœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-APIRequest-NvyuE{œfieldNameœ:œchat_messageœ,œidœ:œAPIRequest-NvyuEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "ToolCallingAgent-hgTUU",
        "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-hgTUUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-t8IwZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t8IwZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-t8IwZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-hgTUU",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ToolCallingAgent-hgTUU{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-hgTUUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-t8IwZ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t8IwZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "Memory-sKTYv",
        "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-sKTYvœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ToolCallingAgent-hgTUU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ToolCallingAgent-hgTUU",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Memory",
            "id": "Memory-sKTYv",
            "name": "messages_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Memory-sKTYv{œdataTypeœ:œMemoryœ,œidœ:œMemory-sKTYvœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "source": "APIRequest-NvyuE",
        "sourceHandle": "{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-NvyuEœ,œnameœ:œapi_responseœ,œoutput_typesœ:[œDataœ]}",
        "target": "ToolCallingAgent-hgTUU",
        "targetHandle": "{œfieldNameœ:œapi_responseœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "api_response",
            "id": "ToolCallingAgent-hgTUU",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "APIRequest",
            "id": "APIRequest-NvyuE",
            "name": "api_response",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-APIRequest-NvyuE{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-NvyuEœ,œnameœ:œapi_responseœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œapi_responseœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "source": "AnthropicModel-QorsX",
        "sourceHandle": "{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QorsXœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ToolCallingAgent-hgTUU",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-hgTUU",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AnthropicModel",
            "id": "AnthropicModel-QorsX",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-AnthropicModel-QorsX{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QorsXœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      }
    ],
    "viewport": {
      "x": -6.545344702226657,
      "y": 1189.2905257231873,
      "zoom": 0.4011631367667991
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "LangWatchEvaluatorComponent": {
      "count": 1
    },
    "APIRequest": {
      "count": 1
    },
    "ToolCallingAgent": {
      "count": 1
    },
    "AnthropicModel": {
      "count": 1
    },
    "Memory": {
      "count": 1
    },
    "total": 7
  },
  "original": {
    "id": "4a689676-6036-4b5b-bd3a-7b6db2a89ebd",
    "name": "Untitled document (17) (3)",
    "description": "Unleashing Business Potential through Language Engineering.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "3",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "LangWatchEvaluatorComponent": {
        "count": 1
      },
      "APIRequest": {
        "count": 1
      },
      "ToolCallingAgent": {
        "count": 1
      },
      "AnthropicModel": {
        "count": 1
      },
      "Memory": {
        "count": 1
      },
      "total": 7
    },
    "last_tested_version": "1.0.17",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-ed3Pl",
          "type": "genericNode",
          "position": {
            "x": 314.93914971534537,
            "y": -2851.2309113631127
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "files",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "what is axiestudio",
                  "name": "input_value",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "User",
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": true,
                  "name": "should_store_message",
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatInput-ed3Pl"
          },
          "selected": false,
          "width": 384,
          "height": 298,
          "positionAbsolute": {
            "x": 314.93914971534537,
            "y": -2851.2309113631127
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-t8IwZ",
          "type": "genericNode",
          "position": {
            "x": 1923.3342526887081,
            "y": -2685.254812830411
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatOutput-t8IwZ",
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output"
          },
          "selected": false,
          "width": 384,
          "height": 298,
          "positionAbsolute": {
            "x": 1923.3342526887081,
            "y": -2685.254812830411
          },
          "dragging": false
        },
        {
          "id": "LangWatchEvaluatorComponent-v6Wt0",
          "type": "genericNode",
          "position": {
            "x": 2393.325028867806,
            "y": -1988.3593318279497
          },
          "data": {
            "type": "LangWatchEvaluatorComponent",
            "node": {
              "template": {
                "_type": "Component",
                "context_data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "context_data",
                  "value": "",
                  "display_name": "RAG Search Results (optional)",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to be used as context for evaluation.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "answer": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "answer",
                  "value": "",
                  "display_name": "Answer",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The generated answer to be evaluated.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import re\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.inputs import MessageTextInput, DataInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.template import Output\r\nfrom axiestudio.schema import Data\r\nimport langwatch\r\n\r\nclass LangWatchEvaluatorComponent(Component):\r\n    display_name = \"LangWatch Evaluator\"\r\n    description = \"Evaluates a question-answer pair using LangWatch and provides a trace URL.\"\r\n    icon = \"view\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"question\",\r\n            display_name=\"Question\",\r\n            info=\"The question to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"answer\",\r\n            display_name=\"Answer\",\r\n            info=\"The generated answer to be evaluated.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"ground_truth\",\r\n            display_name=\"Correct Answer\",\r\n            info=\"The expected correct answer.\",\r\n        ),\r\n        DataInput(\r\n            name=\"context_data\",\r\n            display_name=\"RAG Search Results (optional)\",\r\n            info=\"The data to be used as context for evaluation.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_email\",\r\n            display_name=\"User Email\",\r\n            info=\"The user email for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_name\",\r\n            display_name=\"Participant Name\",\r\n            info=\"Full name for identification in the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"question_id\",\r\n            display_name=\"Question ID\",\r\n            info=\"The question ID for the trace metadata.\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Trace URL\", name=\"trace_url\", method=\"evaluate\"),\r\n    ]\r\n\r\n    async def evaluate(self) -> Data:\r\n        question = self.question\r\n        answer = self.answer\r\n        ground_truth = self.ground_truth\r\n        context_data = self.context_data\r\n        user_email = self.user_email if self.user_email else \"\"\r\n        question_id = self.question_id if self.question_id else \"\"\r\n        user_name = self.user_name if self.user_name else \"\"\r\n\r\n        # Validate email if provided\r\n        if user_email and not self.validate_email(user_email):\r\n            raise ValueError(f\"Invalid email address: {user_email}\")\r\n\r\n        langwatch.api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOjE3MjY2Njk3NTkyMjcsInJhbmQiOjAuMjg5OTc4Mjk4NzU2MzIzOTcsImlhdCI6MTcyNjY2OTc1OX0._ow7WQ5RSTlYE-HjdcouHUCoXf9nRnWHk4u9nfq4LIw'\r\n\r\n        trace = langwatch.trace(\r\n            metadata={\r\n                \"user_email\": user_email,\r\n                \"question_id\": question_id,\r\n                \"user_name\": user_name,\r\n            },\r\n            expected_output=ground_truth\r\n        )\r\n        \r\n        contexts = [item.text.replace(\"\\t\", \" \").replace(\"\\n\", \" \") for item in context_data[:5]] if context_data else []\r\n        rag_span = trace.span(type=\"rag\", name=\"LangWatch Evaluator\", input=question, contexts=contexts, output=answer)\r\n        rag_span.end()\r\n\r\n        trace.send_spans()\r\n\r\n        public_url = trace.share()\r\n        self.log(f\"See the trace at: {public_url}\")\r\n\r\n        self.status = Data(data={\"trace_url\": public_url})\r\n        return Data(data={\"trace_url\": public_url})\r\n        \r\n    def validate_email(self, email):\r\n        pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\r\n        return re.match(pattern, email) is not None",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "ground_truth": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ground_truth",
                  "value": "",
                  "display_name": "Correct Answer",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The expected correct answer.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "question": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "question",
                  "value": "",
                  "display_name": "Question",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The question to be evaluated.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "question_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "question_id",
                  "value": "",
                  "display_name": "Question ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The question ID for the trace metadata.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_email": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_email",
                  "value": "",
                  "display_name": "User Email",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The user email for the trace metadata.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_name",
                  "value": "",
                  "display_name": "Participant Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Full name for identification in the trace metadata.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.",
              "icon": "view",
              "base_classes": [
                "Data"
              ],
              "display_name": "Langwatch Evaluator",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "trace_url",
                  "display_name": "Trace URL",
                  "method": "evaluate",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "question",
                "answer",
                "ground_truth",
                "context_data",
                "user_email",
                "user_name",
                "question_id"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "LangWatchEvaluatorComponent-v6Wt0",
            "description": "Evaluates a question-answer pair using LangWatch and provides a trace URL.",
            "display_name": "Langwatch Evaluator"
          },
          "selected": false,
          "width": 384,
          "height": 546,
          "dragging": false,
          "positionAbsolute": {
            "x": 2393.325028867806,
            "y": -1988.3593318279497
          }
        },
        {
          "id": "APIRequest-NvyuE",
          "type": "genericNode",
          "position": {
            "x": 787.4397924723891,
            "y": -2933.4371664910223
          },
          "data": {
            "type": "APIRequest",
            "node": {
              "template": {
                "_type": "Component",
                "query_params": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "query_params",
                  "value": "",
                  "display_name": "Query Parameters",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The query parameters to append to the URL.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "body": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "body",
                  "value": {},
                  "display_name": "Body",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "chat_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_message",
                  "value": "",
                  "display_name": "Chat Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Input message from ChatInput component",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import asyncio\r\nimport json\r\nfrom typing import Any, List, Optional\r\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\r\n\r\nimport httpx\r\nfrom loguru import logger\r\n\r\nfrom axiestudio.base.curl.parse import parse_context\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, DropdownInput, IntInput, MessageTextInput, NestedDictInput, Output, MessageInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.dotdict import dotdict\r\nfrom axiestudio.schema.message import Message\r\n\r\nclass APIRequestComponent(Component):\r\n    display_name = \"API Request\"\r\n    description = (\r\n        \"This component allows you to make HTTP requests to one or more URLs. \"\r\n        \"You can provide headers and body as either dictionaries or Data objects. \"\r\n        \"Additionally, you can append query parameters to the URLs.\\n\\n\"\r\n        \"**Note:** Check advanced options for more settings.\"\r\n    )\r\n    icon = \"Globe\"\r\n    name = \"APIRequest\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"urls\",\r\n            display_name=\"URLs\",\r\n            is_list=True,\r\n            info=\"Enter one or more URLs, separated by commas.\",\r\n            value=[\"https://api.dify.ai/v1/chat-messages\"],\r\n        ),\r\n        MessageTextInput(\r\n            name=\"curl\",\r\n            display_name=\"Curl\",\r\n            info=\"Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.\",\r\n            advanced=False,\r\n            refresh_button=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\"],\r\n            value=\"POST\",\r\n            info=\"The HTTP method to use (GET, POST, PATCH, PUT).\",\r\n        ),\r\n        NestedDictInput(\r\n            name=\"headers\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request as a dictionary. This is populated when using the CURL field.\",\r\n            input_types=[\"Data\"],\r\n        ),\r\n        NestedDictInput(\r\n            name=\"body\",\r\n            display_name=\"Body\",\r\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT). This is populated when using the CURL field.\",\r\n            input_types=[\"Data\"],\r\n        ),\r\n        DataInput(\r\n            name=\"query_params\",\r\n            display_name=\"Query Parameters\",\r\n            info=\"The query parameters to append to the URL.\",\r\n        ),\r\n        IntInput(\r\n            name=\"timeout\",\r\n            display_name=\"Timeout\",\r\n            value=5,\r\n            info=\"The timeout to use for the request.\",\r\n        ),\r\n        MessageInput(\r\n            name=\"chat_message\",\r\n            display_name=\"Chat Message\",\r\n            info=\"Input message from ChatInput component\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"API Response\", name=\"api_response\", method=\"make_requests\"),\r\n    ]\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self._build_config = dotdict()\r\n        self.set_default_config()\r\n\r\n    def set_default_config(self):\r\n        default_curl = \"\"\"curl -X POST 'https://api.dify.ai/v1/chat-messages' \\\r\n--header 'Authorization: Bearer app-NKw5JuFE05yAw9GtQs0MyM4I' \\\r\n--header 'Content-Type: application/json' \\\r\n--data-raw '{\r\n    \"inputs\": {},\r\n    \"query\": \"What are the specs of the iPhone 13 Pro Max?\",\r\n    \"response_mode\": \"streaming\",\r\n    \"conversation_id\": \"\",\r\n    \"user\": \"abc-123\",\r\n    \"files\": []\r\n}'\"\"\"\r\n        self._build_config = self.parse_curl(default_curl, dotdict())\r\n\r\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\r\n        try:\r\n            parsed = parse_context(curl)\r\n            build_config[\"urls\"] = {\"value\": [parsed.url]}\r\n            build_config[\"method\"] = {\"value\": parsed.method.upper()}\r\n            build_config[\"headers\"] = {\"value\": dict(parsed.headers)}\r\n\r\n            if parsed.data:\r\n                try:\r\n                    json_data = json.loads(parsed.data)\r\n                    build_config[\"body\"] = {\"value\": json_data}\r\n                except json.JSONDecodeError as e:\r\n                    logger.error(f\"Error decoding JSON data: {e}\")\r\n            else:\r\n                build_config[\"body\"] = {\"value\": {}}\r\n        except Exception as exc:\r\n            logger.error(f\"Error parsing curl: {exc}\")\r\n            raise ValueError(f\"Error parsing curl: {exc}\")\r\n        return build_config\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\r\n        if field_name == \"curl\" and field_value:\r\n            build_config = self.parse_curl(field_value, build_config)\r\n        return build_config\r\n\r\n    async def make_request(\r\n        self,\r\n        client: httpx.AsyncClient,\r\n        method: str,\r\n        url: str,\r\n        headers: Optional[dict] = None,\r\n        body: Optional[dict] = None,\r\n        timeout: int = 5,\r\n    ) -> Data:\r\n        method = method.upper()\r\n        if method not in [\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"]:\r\n            raise ValueError(f\"Unsupported method: {method}\")\r\n\r\n        if isinstance(body, str) and body:\r\n            try:\r\n                body = json.loads(body)\r\n            except Exception as e:\r\n                logger.error(f\"Error decoding JSON data: {e}\")\r\n                body = None\r\n                raise ValueError(f\"Error decoding JSON data: {e}\")\r\n\r\n        data = body if body else None\r\n\r\n        try:\r\n            response = await client.request(method, url, headers=headers, json=data, timeout=timeout)\r\n            try:\r\n                result = response.json()\r\n            except Exception:\r\n                result = response.text\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": response.status_code,\r\n                    \"result\": result,\r\n                },\r\n            )\r\n        except httpx.TimeoutException:\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": 408,\r\n                    \"error\": \"Request timed out\",\r\n                },\r\n            )\r\n        except Exception as exc:\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": 500,\r\n                    \"error\": str(exc),\r\n                },\r\n            )\r\n\r\n    def add_query_params(self, url: str, params: dict) -> str:\r\n        url_parts = list(urlparse(url))\r\n        query = dict(parse_qsl(url_parts[4]))\r\n        query.update(params)\r\n        url_parts[4] = urlencode(query)\r\n        return urlunparse(url_parts)\r\n\r\n    async def make_requests(self) -> Data:\r\n        method = self.method or self._build_config.get(\"method\", {}).get(\"value\", \"POST\")\r\n        urls = self.urls or self._build_config.get(\"urls\", {}).get(\"value\", [])\r\n        urls = [url.strip() for url in urls if url.strip()]\r\n        curl = self.curl\r\n        headers = self.headers or self._build_config.get(\"headers\", {}).get(\"value\", {})\r\n        body = self.body or self._build_config.get(\"body\", {}).get(\"value\", {})\r\n        timeout = self.timeout\r\n        query_params = self.query_params.data if self.query_params else {}\r\n\r\n        if curl:\r\n            self._build_config = self.parse_curl(curl, dotdict())\r\n\r\n        if isinstance(headers, Data):\r\n            headers = headers.data\r\n\r\n        if isinstance(body, Data):\r\n            body = body.data\r\n\r\n        # Process chat_message if available\r\n        if isinstance(self.chat_message, Message):\r\n            # Update the body with the chat message text\r\n            body[\"query\"] = self.chat_message.text\r\n            \r\n            # If there are files in the message, add them to the body\r\n            if self.chat_message.files:\r\n                body[\"files\"] = [\r\n                    {\r\n                        \"type\": \"file\",\r\n                        \"transfer_method\": \"local_file\",\r\n                        \"name\": file.name,\r\n                        \"content\": file.content,\r\n                    }\r\n                    for file in self.chat_message.files\r\n                ]\r\n\r\n        bodies = [body] * len(urls)\r\n\r\n        urls = [self.add_query_params(url, query_params) for url in urls]\r\n\r\n        async with httpx.AsyncClient() as client:\r\n            results = await asyncio.gather(\r\n                *[self.make_request(client, method, u, headers, rec, timeout) for u, rec in zip(urls, bodies)]\r\n            )\r\n        \r\n        # Process the results into a single Data object\r\n        processed_results = []\r\n        for result in results:\r\n            if isinstance(result, Data) and isinstance(result.data, dict):\r\n                processed_results.append(result.data)\r\n\r\n        self.status = processed_results\r\n        return Data(data={\"api_response\": processed_results})",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "curl": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "curl",
                  "value": "",
                  "display_name": "Curl",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                  "refresh_button": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "headers": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "headers",
                  "value": {},
                  "display_name": "Headers",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The headers to send with the request as a dictionary. This is populated when using the CURL field.",
                  "title_case": false,
                  "type": "NestedDict",
                  "_input_type": "NestedDictInput"
                },
                "method": {
                  "trace_as_metadata": true,
                  "options": [
                    "GET",
                    "POST",
                    "PATCH",
                    "PUT"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "method",
                  "value": "POST",
                  "display_name": "Method",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The HTTP method to use (GET, POST, PATCH, PUT).",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "timeout",
                  "value": 5,
                  "display_name": "Timeout",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The timeout to use for the request.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "urls": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "urls",
                  "value": [
                    "https://api.dify.ai/v1/chat-messages"
                  ],
                  "display_name": "URLs",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Enter one or more URLs, separated by commas.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "This component allows you to make HTTP requests to one or more URLs. You can provide headers and body as either dictionaries or Data objects. Additionally, you can append query parameters to the URLs.\n\n**Note:** Check advanced options for more settings.",
              "icon": "Globe",
              "base_classes": [
                "Data"
              ],
              "display_name": "API Request",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_response",
                  "display_name": "API Response",
                  "method": "make_requests",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "urls",
                "curl",
                "method",
                "headers",
                "body",
                "query_params",
                "timeout",
                "chat_message"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "APIRequest-NvyuE"
          },
          "selected": false,
          "width": 384,
          "height": 1070,
          "dragging": false,
          "positionAbsolute": {
            "x": 787.4397924723891,
            "y": -2933.4371664910223
          }
        },
        {
          "id": "ToolCallingAgent-hgTUU",
          "type": "genericNode",
          "position": {
            "x": 1491.699367223321,
            "y": -2652.8667148174773
          },
          "data": {
            "type": "ToolCallingAgent",
            "node": {
              "template": {
                "_type": "Component",
                "api_response": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_response",
                  "value": "",
                  "display_name": "API Response",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "chat_history": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chat_history",
                  "value": "",
                  "display_name": "Chat History",
                  "advanced": true,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "llm",
                  "value": "",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool",
                    "BaseTool"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, List\r\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\r\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\r\nfrom langchain.agents.tools import Tool\r\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\r\nfrom axiestudio.inputs import MultilineInput\r\nfrom axiestudio.inputs.inputs import HandleInput, DataInput\r\nfrom axiestudio.schema import Data\r\n\r\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\r\n    display_name: str = \"Tool Calling Agent\"\r\n    description: str = \"Agent that processes API responses and uses tools to answer queries\"\r\n    icon = \"LangChain\"\r\n    beta = True\r\n    name = \"ToolCallingAgent\"\r\n\r\n    inputs = LCToolsAgentComponent._base_inputs + [\r\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\r\n        MultilineInput(\r\n            name=\"system_prompt\",\r\n            display_name=\"System Prompt\",\r\n            info=\"System prompt for the agent.\",\r\n            value=\"You are a helpful assistant that processes API responses and answers user queries.\",\r\n        ),\r\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\r\n        DataInput(name=\"api_response\", display_name=\"API Response\", required=True),\r\n    ]\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        if not hasattr(self, 'tools') or self.tools is None:\r\n            self.tools = []\r\n\r\n    def get_chat_history_data(self) -> Optional[List[Data]]:\r\n        return self.chat_history\r\n\r\n    def process_api_response(self) -> str:\r\n        if not self.api_response or not isinstance(self.api_response, Data):\r\n            return \"No API response available.\"\r\n        \r\n        api_data = self.api_response.data\r\n        if not isinstance(api_data, dict) or \"api_response\" not in api_data:\r\n            return \"Invalid API response format.\"\r\n        \r\n        processed_response = \"\"\r\n        for response in api_data[\"api_response\"]:\r\n            result = response.get(\"result\", \"\")\r\n            if isinstance(result, dict):\r\n                # Extract relevant information from the result\r\n                answer = result.get(\"answer\", \"\")\r\n                processed_response += f\"Answer: {answer}\\n\"\r\n            else:\r\n                processed_response += f\"Result: {result}\\n\"\r\n        return processed_response.strip()\r\n\r\n    def create_agent_runnable(self):\r\n        if not self.llm:\r\n            raise ValueError(\"Language model (llm) is required but not provided.\")\r\n\r\n        messages = [\r\n            (\"system\", self.system_prompt),\r\n            (\"placeholder\", \"{chat_history}\"),\r\n            HumanMessagePromptTemplate(\r\n                prompt=PromptTemplate(\r\n                    input_variables=[\"api_response\"], \r\n                    template=\"API Response: {api_response}\\nPlease analyze this API response and provide a helpful answer.\"\r\n                )\r\n            ),\r\n            (\"placeholder\", \"{agent_scratchpad}\"),\r\n        ]\r\n        prompt = ChatPromptTemplate.from_messages(messages)\r\n        \r\n        # Ensure tools is a list, even if empty\r\n        tools = self.tools if isinstance(self.tools, list) else []\r\n\r\n        # Create the agent\r\n        agent = create_openai_tools_agent(self.llm, tools, prompt)\r\n        \r\n        # Create an AgentExecutor\r\n        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\r\n\r\n        # Wrap the agent executor to include API response processing\r\n        def wrapped_agent():\r\n            processed_api_response = self.process_api_response()\r\n            return agent_executor.invoke({\r\n                \"api_response\": processed_api_response,\r\n                \"chat_history\": self.get_chat_history_data()\r\n            })\r\n\r\n        return wrapped_agent",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "handle_parsing_errors",
                  "value": true,
                  "display_name": "Handle Parse Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "max_iterations": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_iterations",
                  "value": 15,
                  "display_name": "Max Iterations",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "system_prompt": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_prompt",
                  "value": "You are a helpful assistant just take the input and output the same text as response",
                  "display_name": "System Prompt",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System prompt for the agent.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": true,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Agent that processes API responses and uses tools to answer queries",
              "icon": "LangChain",
              "base_classes": [
                "AgentExecutor",
                "Message"
              ],
              "display_name": "Tool Calling Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "AgentExecutor"
                  ],
                  "selected": "AgentExecutor",
                  "name": "agent",
                  "display_name": "Agent",
                  "method": "build_agent",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "response",
                  "display_name": "Response",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "handle_parsing_errors",
                "verbose",
                "max_iterations",
                "tools",
                "llm",
                "system_prompt",
                "chat_history",
                "api_response"
              ],
              "beta": true,
              "edited": true
            },
            "id": "ToolCallingAgent-hgTUU"
          },
          "selected": true,
          "width": 384,
          "height": 599,
          "positionAbsolute": {
            "x": 1491.699367223321,
            "y": -2652.8667148174773
          },
          "dragging": false
        },
        {
          "id": "AnthropicModel-QorsX",
          "type": "genericNode",
          "position": {
            "x": 334.8787208196154,
            "y": -2430.7058981921127
          },
          "data": {
            "type": "AnthropicModel",
            "node": {
              "template": {
                "_type": "Component",
                "anthropic_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "anthropic_api_key",
                  "value": "",
                  "display_name": "Anthropic API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Anthropic API key.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "anthropic_api_url": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "anthropic_api_url",
                  "value": "",
                  "display_name": "Anthropic API URL",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_anthropic.chat_models import ChatAnthropic\n        except ImportError:\n            raise ImportError(\n                \"langchain_anthropic is not installed. Please install it with `pip install langchain_anthropic`.\"\n            )\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": {
                    "text_key": "text",
                    "data": {
                      "template": "Answer the user as if you were a pirate.\n\nUser: {user_input}\n\nAnswer:",
                      "variables": {
                        "user_input": {
                          "text_key": "text",
                          "data": {
                            "text": "oi",
                            "sender": "User",
                            "sender_name": "User",
                            "session_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                            "files": [],
                            "timestamp": "2024-10-03 23:42:47",
                            "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                          },
                          "default_value": "",
                          "text": "oi",
                          "sender": "User",
                          "sender_name": "User",
                          "files": [],
                          "session_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                          "timestamp": "2024-10-03 23:42:47",
                          "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                        }
                      },
                      "files": [],
                      "timestamp": "2024-10-03 23:42:47",
                      "text": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                      "prompt": {
                        "lc": 1,
                        "type": "constructor",
                        "id": [
                          "langchain",
                          "prompts",
                          "chat",
                          "ChatPromptTemplate"
                        ],
                        "kwargs": {
                          "input_variables": [],
                          "messages": [
                            {
                              "content": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                              "additional_kwargs": {},
                              "response_metadata": {},
                              "type": "human",
                              "name": null,
                              "id": null,
                              "example": false
                            }
                          ]
                        },
                        "name": "ChatPromptTemplate",
                        "graph": {
                          "nodes": [
                            {
                              "id": 0,
                              "type": "schema",
                              "data": "PromptInput"
                            },
                            {
                              "id": 1,
                              "type": "runnable",
                              "data": {
                                "id": [
                                  "langchain",
                                  "prompts",
                                  "chat",
                                  "ChatPromptTemplate"
                                ],
                                "name": "ChatPromptTemplate"
                              }
                            },
                            {
                              "id": 2,
                              "type": "schema",
                              "data": "ChatPromptTemplateOutput"
                            }
                          ],
                          "edges": [
                            {
                              "source": 0,
                              "target": 1
                            },
                            {
                              "source": 1,
                              "target": 2
                            }
                          ]
                        }
                      },
                      "messages": [
                        {
                          "content": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                          "additional_kwargs": {},
                          "response_metadata": {},
                          "type": "human",
                          "name": null,
                          "id": null,
                          "example": false
                        }
                      ],
                      "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d",
                      "session_id": ""
                    },
                    "default_value": "",
                    "text": "Answer the user as if you were a pirate.\n\nUser: oi\n\nAnswer:",
                    "files": [],
                    "session_id": "",
                    "timestamp": "2024-10-03 23:42:47",
                    "flow_id": "69d4e2ed-3096-46a6-b203-8e6e51f5bc1d"
                  },
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": 4096,
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "claude-3-5-sonnet-20240620",
                    "claude-3-opus-20240229",
                    "claude-3-sonnet-20240229",
                    "claude-3-haiku-20240307"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "claude-3-5-sonnet-20240620",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "https://python.langchain.com/docs/integrations/chat/anthropic",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "prefill": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "prefill",
                  "value": "",
                  "display_name": "Prefill",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Prefill text to guide the model's response.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generate text using Anthropic Chat&Completion LLMs with prefill support.",
              "icon": "Anthropic",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "Anthropic",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model",
                "anthropic_api_key",
                "temperature",
                "anthropic_api_url",
                "prefill"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "AnthropicModel-QorsX"
          },
          "selected": false,
          "width": 384,
          "height": 629,
          "positionAbsolute": {
            "x": 334.8787208196154,
            "y": -2430.7058981921127
          },
          "dragging": false
        },
        {
          "id": "Memory-sKTYv",
          "type": "genericNode",
          "position": {
            "x": 990.0672084328285,
            "y": -2671.6995185570977
          },
          "data": {
            "type": "Memory",
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain.memory import ConversationBufferMemory\n\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import BaseChatMemory\nfrom axiestudio.helpers.data import data_to_text\nfrom axiestudio.inputs import HandleInput\nfrom axiestudio.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import LCBuiltinChatMemory, get_messages\nfrom axiestudio.schema import Data\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        if self.memory:\n            chat_memory = self.memory\n        else:\n            chat_memory = LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "order": {
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "template": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                }
              },
              "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
              "icon": "message-square-more",
              "base_classes": [
                "BaseChatMemory",
                "Data",
                "Message"
              ],
              "display_name": "Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "messages",
                  "display_name": "Messages (Data)",
                  "method": "retrieve_messages",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "messages_text",
                  "display_name": "Messages (Text)",
                  "method": "retrieve_messages_as_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "BaseChatMemory"
                  ],
                  "selected": "BaseChatMemory",
                  "name": "lc_memory",
                  "display_name": "Memory",
                  "method": "build_lc_memory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Memory-sKTYv"
          },
          "selected": false,
          "width": 384,
          "height": 378,
          "positionAbsolute": {
            "x": 990.0672084328285,
            "y": -2671.6995185570977
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ChatOutput-t8IwZ",
          "target": "LangWatchEvaluatorComponent-v6Wt0",
          "sourceHandle": "{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-t8IwZœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "targetHandle": "{œfieldNameœ:œanswerœ,œidœ:œLangWatchEvaluatorComponent-v6Wt0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "id": "reactflow__edge-ChatOutput-t8IwZ{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-t8IwZœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-LangWatchEvaluatorComponent-v6Wt0{œfieldNameœ:œanswerœ,œidœ:œLangWatchEvaluatorComponent-v6Wt0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "answer",
              "id": "LangWatchEvaluatorComponent-v6Wt0",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatOutput",
              "id": "ChatOutput-t8IwZ",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "selected": false
        },
        {
          "source": "ChatInput-ed3Pl",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ed3Plœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "APIRequest-NvyuE",
          "targetHandle": "{œfieldNameœ:œchat_messageœ,œidœ:œAPIRequest-NvyuEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "chat_message",
              "id": "APIRequest-NvyuE",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-ed3Pl",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-ed3Pl{œdataTypeœ:œChatInputœ,œidœ:œChatInput-ed3Plœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-APIRequest-NvyuE{œfieldNameœ:œchat_messageœ,œidœ:œAPIRequest-NvyuEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "ToolCallingAgent-hgTUU",
          "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-hgTUUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-t8IwZ",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t8IwZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-t8IwZ",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ToolCallingAgent",
              "id": "ToolCallingAgent-hgTUU",
              "name": "response",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ToolCallingAgent-hgTUU{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-hgTUUœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-t8IwZ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-t8IwZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Memory-sKTYv",
          "sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-sKTYvœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ToolCallingAgent-hgTUU",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ToolCallingAgent-hgTUU",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Memory",
              "id": "Memory-sKTYv",
              "name": "messages_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Memory-sKTYv{œdataTypeœ:œMemoryœ,œidœ:œMemory-sKTYvœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
        },
        {
          "source": "APIRequest-NvyuE",
          "sourceHandle": "{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-NvyuEœ,œnameœ:œapi_responseœ,œoutput_typesœ:[œDataœ]}",
          "target": "ToolCallingAgent-hgTUU",
          "targetHandle": "{œfieldNameœ:œapi_responseœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "api_response",
              "id": "ToolCallingAgent-hgTUU",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "APIRequest",
              "id": "APIRequest-NvyuE",
              "name": "api_response",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-APIRequest-NvyuE{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-NvyuEœ,œnameœ:œapi_responseœ,œoutput_typesœ:[œDataœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œapi_responseœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
        },
        {
          "source": "AnthropicModel-QorsX",
          "sourceHandle": "{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QorsXœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
          "target": "ToolCallingAgent-hgTUU",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ToolCallingAgent-hgTUU",
              "inputTypes": [
                "LanguageModel"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AnthropicModel",
              "id": "AnthropicModel-QorsX",
              "name": "model_output",
              "output_types": [
                "LanguageModel"
              ]
            }
          },
          "id": "reactflow__edge-AnthropicModel-QorsX{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-QorsXœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-hgTUU{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-hgTUUœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
        }
      ],
      "viewport": {
        "x": -6.545344702226657,
        "y": 1189.2905257231873,
        "zoom": 0.4011631367667991
      }
    },
    "date_created": "2024-10-05T19:19:23.731Z",
    "date_updated": "2024-10-05T19:19:24.015Z",
    "status": "Public",
    "sort": null,
    "user_updated": "61218f6e-08b1-4f25-8d76-5723614cd60f",
    "user_created": {
      "username": "prat210688",
      "first_name": "PRATIK",
      "last_name": "GHODKE",
      "id": "61218f6e-08b1-4f25-8d76-5723614cd60f"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:57.563Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 82,
    "converter_version": "1.0.0"
  }
}