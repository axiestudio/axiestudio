{
  "id": "65bd4a96-318f-4b32-9acd-9c1fbf432079",
  "name": "RAG TXT",
  "description": "Smart Chains, Smarter Conversations. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "wweezy0007",
    "first_name": "Olawale",
    "last_name": "Adu",
    "id": "ddefa9cc-2e19-41ca-98cf-b4e0bc8cd7bc",
    "full_name": "Olawale Adu"
  },
  "store_url": "https://www.langflow.store/store/component/65bd4a96-318f-4b32-9acd-9c1fbf432079",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-05-26T03:45:33.980Z",
    "updated": "2024-05-26T03:45:34.018Z",
    "downloaded": "2025-08-19T17:50:05.451Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.0a37",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-nVdVb",
        "type": "genericNode",
        "position": {
          "x": -57.74602439133173,
          "y": -198.32596164127042
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Message",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "value": "What is the primary function of the Orchestrator in a UiPath automation workflow?\n\n"
              },
              "return_record": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_record",
                "display_name": "Return Record",
                "advanced": true,
                "dynamic": false,
                "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                "load_from_db": false,
                "title_case": false
              },
              "sender": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "User",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "sender_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "User",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "session_id": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "If provided, the message will be stored in the memory.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "object",
              "Record",
              "str",
              "Text"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {
              "sender": null,
              "sender_name": null,
              "input_value": null,
              "session_id": null,
              "return_record": null
            },
            "output_types": [
              "Text",
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "ChatInput-nVdVb"
        },
        "selected": false,
        "width": 384,
        "height": 375,
        "dragging": false,
        "positionAbsolute": {
          "x": -57.74602439133173,
          "y": -198.32596164127042
        }
      },
      {
        "id": "OllamaModel-5gJx6",
        "type": "genericNode",
        "position": {
          "x": 1302.4122413190705,
          "y": -135.61798546636712
        },
        "data": {
          "type": "OllamaModel",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "metadata": {
                "type": "Dict[str, Any]",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "metadata",
                "display_name": "Metadata",
                "advanced": true,
                "dynamic": false,
                "info": "Metadata to add to the run trace.",
                "load_from_db": false,
                "title_case": false
              },
              "stop": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stop",
                "display_name": "Stop Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "List of tokens to signal the model to stop generating text.",
                "load_from_db": false,
                "title_case": false
              },
              "tags": {
                "type": "list",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tags",
                "display_name": "Tags",
                "advanced": true,
                "dynamic": false,
                "info": "Tags to add to the run trace.",
                "load_from_db": false,
                "title_case": false
              },
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Base URL",
                "advanced": true,
                "dynamic": false,
                "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "http://localhost:11434/"
              },
              "cache": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "cache",
                "display_name": "Cache",
                "advanced": true,
                "dynamic": false,
                "info": "Enable or disable caching.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\n\n# from langchain.chat_models import ChatOllama\nfrom axiestudio.field_typing import Text\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"callback_manager\",\n        \"callbacks\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n                \"advanced\": True,\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "format": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "format",
                "display_name": "Format",
                "advanced": true,
                "dynamic": false,
                "info": "Specify the format of the output (e.g., json).",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "mirostat": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Disabled",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "name": "mirostat",
                "display_name": "Mirostat",
                "advanced": true,
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "mirostat_eta": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_eta",
                "display_name": "Mirostat Eta",
                "advanced": true,
                "dynamic": false,
                "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "mirostat_tau": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_tau",
                "display_name": "Mirostat Tau",
                "advanced": true,
                "dynamic": false,
                "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "llama3:8b-instruct-q8_0",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "Refer to https://ollama.ai/library for more models.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "num_ctx": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_ctx",
                "display_name": "Context Window Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the context window for generating tokens. (Default: 2048)",
                "load_from_db": false,
                "title_case": false
              },
              "num_gpu": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_gpu",
                "display_name": "Number of GPUs",
                "advanced": true,
                "dynamic": false,
                "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                "load_from_db": false,
                "title_case": false
              },
              "num_thread": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_thread",
                "display_name": "Number of Threads",
                "advanced": true,
                "dynamic": false,
                "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                "load_from_db": false,
                "title_case": false
              },
              "repeat_last_n": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_last_n",
                "display_name": "Repeat Last N",
                "advanced": true,
                "dynamic": false,
                "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                "load_from_db": false,
                "title_case": false
              },
              "repeat_penalty": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_penalty",
                "display_name": "Repeat Penalty",
                "advanced": true,
                "dynamic": false,
                "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "stream": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stream",
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "load_from_db": false,
                "title_case": false
              },
              "system": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system",
                "display_name": "System",
                "advanced": true,
                "dynamic": false,
                "info": "System to use for generating text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "system_message": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "system_message",
                "display_name": "System Message",
                "advanced": true,
                "dynamic": false,
                "info": "System message to pass to the model.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.8,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Controls the creativity of model responses.",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to use for generating text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "tfs_z": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tfs_z",
                "display_name": "TFS Z",
                "advanced": true,
                "dynamic": false,
                "info": "Tail free sampling value. (Default: 1)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "timeout": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "timeout",
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "Timeout for the request stream.",
                "load_from_db": false,
                "title_case": false
              },
              "top_k": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_k",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Limits token selection to top K. (Default: 40)",
                "load_from_db": false,
                "title_case": false
              },
              "top_p": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_p",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "Works together with top-k. (Default: 0.9)",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "verbose": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "verbose",
                "display_name": "Verbose",
                "advanced": false,
                "dynamic": false,
                "info": "Whether to print out response text.",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Generate text using Ollama Local LLMs.",
            "icon": "Ollama",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "Ollama",
            "documentation": "",
            "custom_fields": {
              "base_url": null,
              "model": null,
              "input_value": null,
              "mirostat": null,
              "mirostat_eta": null,
              "mirostat_tau": null,
              "repeat_last_n": null,
              "verbose": null,
              "cache": null,
              "num_ctx": null,
              "num_gpu": null,
              "format": null,
              "metadata": null,
              "num_thread": null,
              "repeat_penalty": null,
              "stop": null,
              "system": null,
              "tags": null,
              "temperature": null,
              "template": null,
              "tfs_z": null,
              "timeout": null,
              "top_k": null,
              "top_p": null,
              "stream": null,
              "system_message": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "base_url",
              "model",
              "temperature",
              "cache",
              "callback_manager",
              "callbacks",
              "format",
              "metadata",
              "mirostat",
              "mirostat_eta",
              "mirostat_tau",
              "num_ctx",
              "num_gpu",
              "num_thread",
              "repeat_last_n",
              "repeat_penalty",
              "tfs_z",
              "timeout",
              "top_k",
              "top_p",
              "verbose",
              "tags",
              "stop",
              "system",
              "template",
              "input_value",
              "system_message",
              "stream"
            ],
            "beta": false
          },
          "id": "OllamaModel-5gJx6"
        },
        "selected": false,
        "width": 384,
        "height": 621,
        "positionAbsolute": {
          "x": 1302.4122413190705,
          "y": -135.61798546636712
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-eWjtm",
        "type": "genericNode",
        "position": {
          "x": 1948.0318323775798,
          "y": 139.58850113595645
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{text}",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "In case of Message being a Record, this template will be used to convert it to text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "return_record": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_record",
                "display_name": "Return Record",
                "advanced": true,
                "dynamic": false,
                "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                "load_from_db": false,
                "title_case": false
              },
              "sender": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Machine",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "sender_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "AI",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "session_id": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "If provided, the message will be stored in the memory.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "object",
              "Record",
              "str",
              "Text"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {
              "sender": null,
              "sender_name": null,
              "input_value": null,
              "session_id": null,
              "return_record": null,
              "record_template": null
            },
            "output_types": [
              "Text",
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "ChatOutput-eWjtm"
        },
        "selected": false,
        "width": 384,
        "height": 383,
        "dragging": false,
        "positionAbsolute": {
          "x": 1948.0318323775798,
          "y": 139.58850113595645
        }
      },
      {
        "id": "File-nkAzv",
        "type": "genericNode",
        "position": {
          "x": -1136.4871731029673,
          "y": -135.55616282534143
        },
        "data": {
          "type": "File",
          "node": {
            "template": {
              "path": {
                "type": "file",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [
                  ".txt",
                  ".md",
                  ".mdx",
                  ".csv",
                  ".json",
                  ".yaml",
                  ".yml",
                  ".xml",
                  ".html",
                  ".htm",
                  ".pdf",
                  ".docx",
                  ".py",
                  ".sh",
                  ".sql",
                  ".js",
                  ".ts",
                  ".tsx"
                ],
                "file_path": "74e5856a-9a44-4d8a-a30a-4fa5e932e08c/output.txt",
                "password": false,
                "name": "path",
                "display_name": "Path",
                "advanced": false,
                "dynamic": false,
                "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                "load_from_db": false,
                "title_case": false,
                "value": ""
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pathlib import Path\nfrom typing import Any, Dict\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "silent_errors": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "silent_errors",
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "A generic file loader.",
            "icon": "file-text",
            "base_classes": [
              "Record"
            ],
            "display_name": "File",
            "documentation": "",
            "custom_fields": {
              "path": null,
              "silent_errors": null
            },
            "output_types": [
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "File-nkAzv"
        },
        "selected": false,
        "width": 384,
        "height": 281,
        "positionAbsolute": {
          "x": -1136.4871731029673,
          "y": -135.55616282534143
        },
        "dragging": false
      },
      {
        "id": "RecursiveCharacterTextSplitter-pg0R5",
        "type": "genericNode",
        "position": {
          "x": -518.3233325912678,
          "y": -31.362509204501556
        },
        "data": {
          "type": "RecursiveCharacterTextSplitter",
          "node": {
            "template": {
              "inputs": {
                "type": "Document",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "inputs",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "load_from_db": false,
                "title_case": false
              },
              "chunk_overlap": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 200,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chunk_overlap",
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "load_from_db": false,
                "title_case": false
              },
              "chunk_size": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 1000,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "chunk_size",
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\nfrom langchain_core.documents import Document\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema import Record\nfrom axiestudio.utils.util import build_loader_repr_from_records, unescape_string\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Input\",\n                \"info\": \"The texts to split.\",\n                \"input_types\": [\"Document\", \"Record\"],\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: list[Document],\n        separators: Optional[list[str]] = None,\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n    ) -> list[Record]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n\n        if separators == \"\":\n            separators = None\n        elif separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        records = self.to_records(docs)\n        self.repr_value = build_loader_repr_from_records(records)\n        return records\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separators": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "separators",
                "display_name": "Separators",
                "advanced": false,
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": [
                  "/n"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Split text into chunks of a specified length.",
            "base_classes": [
              "Record"
            ],
            "display_name": "Recursive Character Text Splitter",
            "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
            "custom_fields": {
              "inputs": null,
              "separators": null,
              "chunk_size": null,
              "chunk_overlap": null
            },
            "output_types": [
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "RecursiveCharacterTextSplitter-pg0R5"
        },
        "selected": false,
        "width": 384,
        "height": 501,
        "positionAbsolute": {
          "x": -518.3233325912678,
          "y": -31.362509204501556
        },
        "dragging": false
      },
      {
        "id": "OllamaEmbeddings-ecr2M",
        "type": "genericNode",
        "position": {
          "x": -1166.2938153079344,
          "y": 433.3619209998918
        },
        "data": {
          "type": "OllamaEmbeddings",
          "node": {
            "template": {
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "http://localhost:11434",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Ollama Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom langchain_core.embeddings import Embeddings\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "mxbai-embed-large:335m",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model",
                "display_name": "Ollama Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Model Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false,
                "value": "0.6"
              },
              "_type": "CustomComponent"
            },
            "description": "Generate embeddings using Ollama models.",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Ollama Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
            "custom_fields": {
              "model": null,
              "base_url": null,
              "temperature": null
            },
            "output_types": [
              "Embeddings"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "OllamaEmbeddings-ecr2M"
        },
        "selected": false,
        "width": 384,
        "height": 469,
        "positionAbsolute": {
          "x": -1166.2938153079344,
          "y": 433.3619209998918
        },
        "dragging": false
      },
      {
        "id": "Pinecone-pERLu",
        "type": "genericNode",
        "position": {
          "x": -28.457647657468044,
          "y": 815.6645058027251
        },
        "data": {
          "type": "Pinecone",
          "node": {
            "template": {
              "embedding": {
                "type": "Embeddings",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "inputs": {
                "type": "Record",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "inputs",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Optional, Union\nfrom langchain_core.documents import Document\nfrom langchain_pinecone._utilities import DistanceStrategy\nfrom langchain_pinecone.vectorstores import PineconeVectorStore\n\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema.schema import Record\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\n\nclass PineconeComponent(CustomComponent):\n    display_name = \"Pinecone\"\n    description = \"Construct Pinecone wrapper from raw documents.\"\n    icon = \"Pinecone\"\n    field_order = [\"index_name\", \"namespace\", \"distance_strategy\", \"pinecone_api_key\", \"documents\", \"embedding\"]\n\n    def build_config(self):\n        distance_options = [e.value.title().replace(\"_\", \" \") for e in DistanceStrategy]\n        distance_value = distance_options[0]\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"namespace\": {\"display_name\": \"Namespace\"},\n            \"text_key\": {\"display_name\": \"Text Key\"},\n            \"distance_strategy\": {\n                \"display_name\": \"Distance Strategy\",\n                # get values from enum\n                # and make them title case for display\n                \"options\": distance_options,\n                \"advanced\": True,\n                \"value\": distance_value,\n            },\n            \"pinecone_api_key\": {\n                \"display_name\": \"Pinecone API Key\",\n                \"default\": \"\",\n                \"password\": True,\n                \"required\": True,\n            },\n            \"pool_threads\": {\n                \"display_name\": \"Pool Threads\",\n                \"default\": 1,\n                \"advanced\": True,\n            },\n        }\n\n    def from_existing_index(\n        self,\n        index_name: str,\n        embedding: Embeddings,\n        pinecone_api_key: str | None,\n        text_key: str = \"text\",\n        namespace: Optional[str] = None,\n        distance_strategy: DistanceStrategy = DistanceStrategy.COSINE,\n        pool_threads: int = 4,\n    ) -> PineconeVectorStore:\n        \"\"\"Load pinecone vectorstore from index name.\"\"\"\n        pinecone_index = PineconeVectorStore.get_pinecone_index(\n            index_name, pool_threads, pinecone_api_key=pinecone_api_key\n        )\n        return PineconeVectorStore(\n            index=pinecone_index,\n            embedding=embedding,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=distance_strategy,\n        )\n\n    def from_documents(\n        self,\n        documents: List[Document],\n        embedding: Embeddings,\n        index_name: str,\n        pinecone_api_key: str | None,\n        text_key: str = \"text\",\n        namespace: Optional[str] = None,\n        pool_threads: int = 4,\n        distance_strategy: DistanceStrategy = DistanceStrategy.COSINE,\n        batch_size: int = 32,\n        upsert_kwargs: Optional[dict] = None,\n        embeddings_chunk_size: int = 1000,\n    ) -> PineconeVectorStore:\n        \"\"\"Create a new pinecone vectorstore from documents.\"\"\"\n        texts = [d.page_content for d in documents]\n        metadatas = [d.metadata for d in documents]\n        pinecone = self.from_existing_index(\n            index_name=index_name,\n            embedding=embedding,\n            pinecone_api_key=pinecone_api_key,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=distance_strategy,\n            pool_threads=pool_threads,\n        )\n        pinecone.add_texts(\n            texts,\n            metadatas=metadatas,\n            ids=None,\n            namespace=namespace,\n            batch_size=batch_size,\n            embedding_chunk_size=embeddings_chunk_size,\n            **(upsert_kwargs or {}),\n        )\n        return pinecone\n\n    def build(\n        self,\n        embedding: Embeddings,\n        distance_strategy: str,\n        inputs: Optional[List[Record]] = None,\n        text_key: str = \"text\",\n        pool_threads: int = 4,\n        index_name: Optional[str] = None,\n        pinecone_api_key: Optional[str] = None,\n        namespace: Optional[str] = \"default\",\n    ) -> Union[VectorStore, BaseRetriever]:\n        # get distance strategy from string\n        distance_strategy = distance_strategy.replace(\" \", \"_\").upper()\n        _distance_strategy = DistanceStrategy[distance_strategy]\n        if not index_name:\n            raise ValueError(\"Index Name is required.\")\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        if documents:\n            return self.from_documents(\n                documents=documents,\n                embedding=embedding,\n                index_name=index_name,\n                pinecone_api_key=pinecone_api_key,\n                text_key=text_key,\n                namespace=namespace,\n                distance_strategy=_distance_strategy,\n                pool_threads=pool_threads,\n            )\n\n        return self.from_existing_index(\n            index_name=index_name,\n            embedding=embedding,\n            pinecone_api_key=pinecone_api_key,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=_distance_strategy,\n            pool_threads=pool_threads,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "distance_strategy": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Euclidean Distance",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Euclidean Distance",
                  "Max Inner Product",
                  "Cosine"
                ],
                "name": "distance_strategy",
                "display_name": "Distance Strategy",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "index_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "index_name",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "youtube-rag-index"
              },
              "namespace": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "default",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "namespace",
                "display_name": "Namespace",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "pinecone_api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "pinecone_api_key",
                "display_name": "Pinecone API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": ""
              },
              "pool_threads": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 4,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "pool_threads",
                "display_name": "Pool Threads",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "text_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "text",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "text_key",
                "display_name": "Text Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Construct Pinecone wrapper from raw documents.",
            "icon": "Pinecone",
            "base_classes": [
              "BaseRetriever",
              "Generic",
              "object",
              "Runnable",
              "RunnableSerializable",
              "Serializable",
              "VectorStore"
            ],
            "display_name": "Pinecone",
            "documentation": "",
            "custom_fields": {
              "embedding": null,
              "distance_strategy": null,
              "inputs": null,
              "text_key": null,
              "pool_threads": null,
              "index_name": null,
              "pinecone_api_key": null,
              "namespace": null
            },
            "output_types": [
              "VectorStore",
              "BaseRetriever"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "index_name",
              "namespace",
              "distance_strategy",
              "pinecone_api_key",
              "documents",
              "embedding"
            ],
            "beta": false
          },
          "id": "Pinecone-pERLu"
        },
        "selected": false,
        "width": 384,
        "height": 667,
        "positionAbsolute": {
          "x": -28.457647657468044,
          "y": 815.6645058027251
        },
        "dragging": false
      },
      {
        "id": "PineconeSearch-X4rs5",
        "type": "genericNode",
        "position": {
          "x": 447.1526866565655,
          "y": 381.58907943083005
        },
        "data": {
          "type": "PineconeSearch",
          "node": {
            "template": {
              "embedding": {
                "type": "Embeddings",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Optional\n\nfrom langchain_pinecone._utilities import DistanceStrategy\n\nfrom axiestudio.components.vectorstores.base.model import LCVectorStoreComponent\nfrom axiestudio.components.vectorstores.Pinecone import PineconeComponent\nfrom axiestudio.field_typing import Embeddings, Text\nfrom axiestudio.field_typing.constants import NestedDict\nfrom axiestudio.schema import Record\n\n\nclass PineconeSearchComponent(PineconeComponent, LCVectorStoreComponent):\n    display_name = \"Pinecone Search\"\n    description = \"Search a Pinecone Vector Store for similar documents.\"\n    icon = \"Pinecone\"\n    field_order = [\"index_name\", \"namespace\", \"distance_strategy\", \"pinecone_api_key\", \"input_value\", \"embedding\"]\n\n    def build_config(self):\n        distance_options = [e.value.title().replace(\"_\", \" \") for e in DistanceStrategy]\n        distance_value = distance_options[0]\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"namespace\": {\"display_name\": \"Namespace\", \"advanced\": True},\n            \"distance_strategy\": {\n                \"display_name\": \"Distance Strategy\",\n                # get values from enum\n                # and make them title case for display\n                \"options\": distance_options,\n                \"advanced\": True,\n                \"value\": distance_value,\n            },\n            \"pinecone_api_key\": {\n                \"display_name\": \"Pinecone API Key\",\n                \"default\": \"\",\n                \"password\": True,\n            },\n            \"pool_threads\": {\n                \"display_name\": \"Pool Threads\",\n                \"default\": 1,\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n            \"text_key\": {\n                \"display_name\": \"Text Key\",\n                \"info\": \"Key in the record to use as text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(  # type: ignore[override]\n        self,\n        input_value: Text,\n        embedding: Embeddings,\n        distance_strategy: str,\n        text_key: str = \"text\",\n        number_of_results: int = 4,\n        pool_threads: int = 4,\n        index_name: Optional[str] = None,\n        pinecone_api_key: Optional[str] = None,\n        namespace: Optional[str] = \"default\",\n        search_type: str = \"similarity\",\n        search_kwargs: Optional[NestedDict] = None,\n    ) -> List[Record]:  # type: ignore[override]\n        vector_store = super().build(\n            embedding=embedding,\n            distance_strategy=distance_strategy,\n            inputs=[],\n            text_key=text_key,\n            pool_threads=pool_threads,\n            index_name=index_name,\n            pinecone_api_key=pinecone_api_key,\n            namespace=namespace,\n        )\n        if not vector_store:\n            raise ValueError(\"Failed to load the Pinecone index.\")\n        if search_kwargs is None:\n            search_kwargs = {}\n\n        return self.search_with_vector_store(\n            vector_store=vector_store,\n            input_value=input_value,\n            search_type=search_type,\n            k=number_of_results,\n            **search_kwargs,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "distance_strategy": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Euclidean Distance",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Euclidean Distance",
                  "Max Inner Product",
                  "Cosine"
                ],
                "name": "distance_strategy",
                "display_name": "Distance Strategy",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "index_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "index_name",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "youtube-rag-index"
              },
              "namespace": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "default",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "namespace",
                "display_name": "Namespace",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "number_of_results": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 4,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "number_of_results",
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "load_from_db": false,
                "title_case": false
              },
              "pinecone_api_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "pinecone_api_key",
                "display_name": "Pinecone API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": ""
              },
              "pool_threads": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 4,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "pool_threads",
                "display_name": "Pool Threads",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "search_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "search_kwargs",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "value": {}
              },
              "search_type": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Similarity",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Similarity",
                  "MMR"
                ],
                "name": "search_type",
                "display_name": "Search Type",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "text_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "text",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "text_key",
                "display_name": "Text Key",
                "advanced": true,
                "dynamic": false,
                "info": "Key in the record to use as text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Search a Pinecone Vector Store for similar documents.",
            "icon": "Pinecone",
            "base_classes": [
              "Record"
            ],
            "display_name": "Pinecone Search",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "embedding": null,
              "distance_strategy": null,
              "text_key": null,
              "number_of_results": null,
              "pool_threads": null,
              "index_name": null,
              "pinecone_api_key": null,
              "namespace": null,
              "search_type": null,
              "search_kwargs": null
            },
            "output_types": [
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [
              "index_name",
              "namespace",
              "distance_strategy",
              "pinecone_api_key",
              "input_value",
              "embedding"
            ],
            "beta": false
          },
          "id": "PineconeSearch-X4rs5"
        },
        "selected": false,
        "width": 384,
        "height": 725,
        "positionAbsolute": {
          "x": 447.1526866565655,
          "y": 381.58907943083005
        },
        "dragging": false
      },
      {
        "id": "OllamaEmbeddings-UpAf8",
        "type": "genericNode",
        "position": {
          "x": -42.51372223665737,
          "y": 253.948785134003
        },
        "data": {
          "type": "OllamaEmbeddings",
          "node": {
            "template": {
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "http://localhost:11434",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Ollama Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom langchain_core.embeddings import Embeddings\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "mxbai-embed-large:335m",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model",
                "display_name": "Ollama Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Model Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false,
                "value": "0.6"
              },
              "_type": "CustomComponent"
            },
            "description": "Generate embeddings using Ollama models.",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Ollama Embeddings",
            "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
            "custom_fields": {
              "model": null,
              "base_url": null,
              "temperature": null
            },
            "output_types": [
              "Embeddings"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "OllamaEmbeddings-UpAf8"
        },
        "selected": false,
        "width": 384,
        "height": 469,
        "positionAbsolute": {
          "x": -42.51372223665737,
          "y": 253.948785134003
        },
        "dragging": false
      },
      {
        "id": "Prompt-opl9z",
        "type": "genericNode",
        "position": {
          "x": 709.6596523965989,
          "y": -162.8985026253091
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\nfrom axiestudio.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Answer the question using the below provided context. Your answer should be in your own words and be no longer than 50 words. If the answer is not within the context, reply with \"I don't know\"\n\n{Context}\n\n{Question}",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "Context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "Context",
                "display_name": "Context",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "Question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "Question",
                "display_name": "Question",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "Context",
                "Question"
              ]
            },
            "output_types": [
              "Text"
            ],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-opl9z",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 384,
        "height": 477,
        "dragging": false,
        "positionAbsolute": {
          "x": 709.6596523965989,
          "y": -162.8985026253091
        }
      },
      {
        "id": "RetrievalQAWithSourcesChain-UGiM0",
        "type": "genericNode",
        "position": {
          "x": 1077.3124842893967,
          "y": 557.363034941791
        },
        "data": {
          "type": "RetrievalQAWithSourcesChain",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input Value",
                "advanced": false,
                "dynamic": false,
                "info": "The input value to pass to the chain.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "retriever": {
                "type": "BaseRetriever",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "retriever",
                "display_name": "Retriever",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "chain_type": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Stuff",
                  "Map Reduce",
                  "Refine",
                  "Map Rerank"
                ],
                "name": "chain_type",
                "display_name": "Chain Type",
                "advanced": false,
                "dynamic": false,
                "info": "The type of chain to use to combined Documents.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ],
                "value": "Stuff"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain_core.documents import Document\n\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, BaseRetriever, Text\nfrom axiestudio.interface.custom.custom_component import CustomComponent\n\n\nclass RetrievalQAWithSourcesChainComponent(CustomComponent):\n    display_name = \"RetrievalQAWithSourcesChain\"\n    description = \"Question-answering with sources over an index.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"chain_type\": {\n                \"display_name\": \"Chain Type\",\n                \"options\": [\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n                \"info\": \"The type of chain to use to combined Documents.\",\n            },\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"return_source_documents\": {\"display_name\": \"Return Source Documents\"},\n            \"retriever\": {\"display_name\": \"Retriever\"},\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        retriever: BaseRetriever,\n        llm: BaseLanguageModel,\n        chain_type: str,\n        memory: Optional[BaseMemory] = None,\n        return_source_documents: Optional[bool] = True,\n    ) -> Text:\n        chain_type = chain_type.lower().replace(\" \", \"_\")\n        runnable = RetrievalQAWithSourcesChain.from_chain_type(\n            llm=llm,\n            chain_type=chain_type,\n            memory=memory,\n            return_source_documents=return_source_documents,\n            retriever=retriever,\n        )\n        if isinstance(input_value, Document):\n            input_value = input_value.page_content\n        self.status = runnable\n        input_key = runnable.input_keys[0]\n        result = runnable.invoke({input_key: input_value})\n        result = result.content if hasattr(result, \"content\") else result\n        # Result is a dict with keys \"query\",  \"result\" and \"source_documents\"\n        # for now we just return the result\n        records = self.to_records(result.get(\"source_documents\"))\n        references_str = \"\"\n        if return_source_documents:\n            references_str = self.create_references_from_records(records)\n        result_str = Text(result.get(\"answer\", \"\"))\n        final_result = \"\\n\".join([result_str, references_str])\n        self.status = final_result\n        return final_result\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "return_source_documents": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_source_documents",
                "display_name": "Return Source Documents",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Question-answering with sources over an index.",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "RetrievalQAWithSourcesChain",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "retriever": null,
              "llm": null,
              "chain_type": null,
              "memory": null,
              "return_source_documents": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "RetrievalQAWithSourcesChain-UGiM0"
        },
        "selected": true,
        "width": 384,
        "height": 603,
        "positionAbsolute": {
          "x": 1077.3124842893967,
          "y": 557.363034941791
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "File-nkAzv",
        "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-nkAzvœ}",
        "target": "RecursiveCharacterTextSplitter-pg0R5",
        "targetHandle": "{œfieldNameœ:œinputsœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œDocumentœ}",
        "data": {
          "targetHandle": {
            "fieldName": "inputs",
            "id": "RecursiveCharacterTextSplitter-pg0R5",
            "inputTypes": [
              "Document",
              "Record"
            ],
            "type": "Document"
          },
          "sourceHandle": {
            "baseClasses": [
              "Record"
            ],
            "dataType": "File",
            "id": "File-nkAzv"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-File-nkAzv{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-nkAzvœ}-RecursiveCharacterTextSplitter-pg0R5{œfieldNameœ:œinputsœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œDocumentœ}"
      },
      {
        "source": "OllamaEmbeddings-ecr2M",
        "sourceHandle": "{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-ecr2Mœ}",
        "target": "Pinecone-pERLu",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Pinecone-pERLu",
            "inputTypes": null,
            "type": "Embeddings"
          },
          "sourceHandle": {
            "baseClasses": [
              "Embeddings"
            ],
            "dataType": "OllamaEmbeddings",
            "id": "OllamaEmbeddings-ecr2M"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OllamaEmbeddings-ecr2M{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-ecr2Mœ}-Pinecone-pERLu{œfieldNameœ:œembeddingœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"
      },
      {
        "source": "RecursiveCharacterTextSplitter-pg0R5",
        "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ}",
        "target": "Pinecone-pERLu",
        "targetHandle": "{œfieldNameœ:œinputsœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}",
        "data": {
          "targetHandle": {
            "fieldName": "inputs",
            "id": "Pinecone-pERLu",
            "inputTypes": [
              "Document",
              "Record"
            ],
            "type": "Record"
          },
          "sourceHandle": {
            "baseClasses": [
              "Record"
            ],
            "dataType": "RecursiveCharacterTextSplitter",
            "id": "RecursiveCharacterTextSplitter-pg0R5"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-RecursiveCharacterTextSplitter-pg0R5{œbaseClassesœ:[œRecordœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ}-Pinecone-pERLu{œfieldNameœ:œinputsœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}"
      },
      {
        "source": "ChatInput-nVdVb",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}",
        "target": "PineconeSearch-X4rs5",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "PineconeSearch-X4rs5",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "Record",
              "str",
              "Text"
            ],
            "dataType": "ChatInput",
            "id": "ChatInput-nVdVb"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-ChatInput-nVdVb{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}-PineconeSearch-X4rs5{œfieldNameœ:œinput_valueœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "OllamaEmbeddings-UpAf8",
        "sourceHandle": "{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-UpAf8œ}",
        "target": "PineconeSearch-X4rs5",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "PineconeSearch-X4rs5",
            "inputTypes": null,
            "type": "Embeddings"
          },
          "sourceHandle": {
            "baseClasses": [
              "Embeddings"
            ],
            "dataType": "OllamaEmbeddings",
            "id": "OllamaEmbeddings-UpAf8"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OllamaEmbeddings-UpAf8{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-UpAf8œ}-PineconeSearch-X4rs5{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"
      },
      {
        "source": "ChatInput-nVdVb",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}",
        "target": "Prompt-opl9z",
        "targetHandle": "{œfieldNameœ:œQuestionœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Question",
            "id": "Prompt-opl9z",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "Record",
              "str",
              "Text"
            ],
            "dataType": "ChatInput",
            "id": "ChatInput-nVdVb"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-ChatInput-nVdVb{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}-Prompt-opl9z{œfieldNameœ:œQuestionœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "PineconeSearch-X4rs5",
        "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-X4rs5œ}",
        "target": "Prompt-opl9z",
        "targetHandle": "{œfieldNameœ:œContextœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Context",
            "id": "Prompt-opl9z",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "Record"
            ],
            "dataType": "PineconeSearch",
            "id": "PineconeSearch-X4rs5"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-PineconeSearch-X4rs5{œbaseClassesœ:[œRecordœ],œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-X4rs5œ}-Prompt-opl9z{œfieldNameœ:œContextœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "Prompt-opl9z",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-opl9zœ}",
        "target": "OllamaModel-5gJx6",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-5gJx6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OllamaModel-5gJx6",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "Prompt",
            "id": "Prompt-opl9z"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-Prompt-opl9z{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-opl9zœ}-OllamaModel-5gJx6{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-5gJx6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "OllamaModel-5gJx6",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-5gJx6œ}",
        "target": "ChatOutput-eWjtm",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eWjtmœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-eWjtm",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "OllamaModel",
            "id": "OllamaModel-5gJx6"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900 stroke-connection",
        "id": "reactflow__edge-OllamaModel-5gJx6{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-5gJx6œ}-ChatOutput-eWjtm{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eWjtmœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": 1071.3123612389816,
      "y": 202.98916242936957,
      "zoom": 0.6671115848388874
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "OllamaModel": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "File": {
      "count": 1
    },
    "RecursiveCharacterTextSplitter": {
      "count": 1
    },
    "OllamaEmbeddings": {
      "count": 2
    },
    "Pinecone": {
      "count": 1
    },
    "PineconeSearch": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "RetrievalQAWithSourcesChain": {
      "count": 1
    },
    "total": 11
  },
  "original": {
    "id": "65bd4a96-318f-4b32-9acd-9c1fbf432079",
    "name": "RAG TXT",
    "description": "Smart Chains, Smarter Conversations.",
    "is_component": false,
    "liked_by_count": "3",
    "downloads_count": "88",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "OllamaModel": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "File": {
        "count": 1
      },
      "RecursiveCharacterTextSplitter": {
        "count": 1
      },
      "OllamaEmbeddings": {
        "count": 2
      },
      "Pinecone": {
        "count": 1
      },
      "PineconeSearch": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "RetrievalQAWithSourcesChain": {
        "count": 1
      },
      "total": 11
    },
    "last_tested_version": "1.0.0a37",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-nVdVb",
          "type": "genericNode",
          "position": {
            "x": -57.74602439133173,
            "y": -198.32596164127042
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "value": "What is the primary function of the Orchestrator in a UiPath automation workflow?\n\n"
                },
                "return_record": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_record",
                  "display_name": "Return Record",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                  "load_from_db": false,
                  "title_case": false
                },
                "sender": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "User",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "sender_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "User",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "session_id": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If provided, the message will be stored in the memory.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "object",
                "Record",
                "str",
                "Text"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {
                "sender": null,
                "sender_name": null,
                "input_value": null,
                "session_id": null,
                "return_record": null
              },
              "output_types": [
                "Text",
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "ChatInput-nVdVb"
          },
          "selected": false,
          "width": 384,
          "height": 375,
          "dragging": false,
          "positionAbsolute": {
            "x": -57.74602439133173,
            "y": -198.32596164127042
          }
        },
        {
          "id": "OllamaModel-5gJx6",
          "type": "genericNode",
          "position": {
            "x": 1302.4122413190705,
            "y": -135.61798546636712
          },
          "data": {
            "type": "OllamaModel",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "metadata": {
                  "type": "Dict[str, Any]",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "metadata",
                  "display_name": "Metadata",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Metadata to add to the run trace.",
                  "load_from_db": false,
                  "title_case": false
                },
                "stop": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stop",
                  "display_name": "Stop Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "List of tokens to signal the model to stop generating text.",
                  "load_from_db": false,
                  "title_case": false
                },
                "tags": {
                  "type": "list",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tags",
                  "display_name": "Tags",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tags to add to the run trace.",
                  "load_from_db": false,
                  "title_case": false
                },
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Base URL",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "http://localhost:11434/"
                },
                "cache": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "cache",
                  "display_name": "Cache",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Enable or disable caching.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, Dict, List, Optional\n\n# from langchain_community.chat_models import ChatOllama\nfrom langchain_community.chat_models import ChatOllama\n\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.base.models.model import LCModelComponent\n\n# from langchain.chat_models import ChatOllama\nfrom axiestudio.field_typing import Text\n\n# whe When a callback component is added to Langflow, the comment must be uncommented.\n# from langchain.callbacks.manager import CallbackManager\n\n\nclass ChatOllamaComponent(LCModelComponent):\n    display_name = \"Ollama\"\n    description = \"Generate text using Ollama Local LLMs.\"\n    icon = \"Ollama\"\n\n    field_order = [\n        \"base_url\",\n        \"model\",\n        \"temperature\",\n        \"cache\",\n        \"callback_manager\",\n        \"callbacks\",\n        \"format\",\n        \"metadata\",\n        \"mirostat\",\n        \"mirostat_eta\",\n        \"mirostat_tau\",\n        \"num_ctx\",\n        \"num_gpu\",\n        \"num_thread\",\n        \"repeat_last_n\",\n        \"repeat_penalty\",\n        \"tfs_z\",\n        \"timeout\",\n        \"top_k\",\n        \"top_p\",\n        \"verbose\",\n        \"tags\",\n        \"stop\",\n        \"system\",\n        \"template\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n                \"advanced\": True,\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"cache\": {\n                \"display_name\": \"Cache\",\n                \"field_type\": \"bool\",\n                \"info\": \"Enable or disable caching.\",\n                \"advanced\": True,\n                \"value\": False,\n            },\n            ### When a callback component is added to Langflow, the comment must be uncommented. ###\n            # \"callback_manager\": {\n            #     \"display_name\": \"Callback Manager\",\n            #     \"info\": \"Optional callback manager for additional functionality.\",\n            #     \"advanced\": True,\n            # },\n            # \"callbacks\": {\n            #     \"display_name\": \"Callbacks\",\n            #     \"info\": \"Callbacks to execute during model runtime.\",\n            #     \"advanced\": True,\n            # },\n            ########################################################################################\n            \"format\": {\n                \"display_name\": \"Format\",\n                \"field_type\": \"str\",\n                \"info\": \"Specify the format of the output (e.g., json).\",\n                \"advanced\": True,\n            },\n            \"metadata\": {\n                \"display_name\": \"Metadata\",\n                \"info\": \"Metadata to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate for Mirostat algorithm. (Default: 0.1)\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls the balance between coherence and diversity of the output. (Default: 5.0)\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating tokens. (Default: 2048)\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation. (Default: detected for optimal performance)\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text. (Default: 1.1)\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling value. (Default: 1)\",\n                \"advanced\": True,\n            },\n            \"timeout\": {\n                \"display_name\": \"Timeout\",\n                \"field_type\": \"int\",\n                \"info\": \"Timeout for the request stream.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K. (Default: 40)\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"float\",\n                \"info\": \"Works together with top-k. (Default: 0.9)\",\n                \"advanced\": True,\n            },\n            \"verbose\": {\n                \"display_name\": \"Verbose\",\n                \"field_type\": \"bool\",\n                \"info\": \"Whether to print out response text.\",\n            },\n            \"tags\": {\n                \"display_name\": \"Tags\",\n                \"field_type\": \"list\",\n                \"info\": \"Tags to add to the run trace.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"field_type\": \"list\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"system\": {\n                \"display_name\": \"System\",\n                \"field_type\": \"str\",\n                \"info\": \"System to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"template\": {\n                \"display_name\": \"Template\",\n                \"field_type\": \"str\",\n                \"info\": \"Template to use for generating text.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        input_value: Text,\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        ### When a callback component is added to Langflow, the comment must be uncommented.###\n        # callback_manager: Optional[CallbackManager] = None,\n        # callbacks: Optional[List[Callbacks]] = None,\n        #######################################################################################\n        repeat_last_n: Optional[int] = None,\n        verbose: Optional[bool] = None,\n        cache: Optional[bool] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        format: Optional[str] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        num_thread: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        system: Optional[str] = None,\n        tags: Optional[List[str]] = None,\n        temperature: Optional[float] = None,\n        template: Optional[str] = None,\n        tfs_z: Optional[float] = None,\n        timeout: Optional[int] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        # Mapping system settings to their corresponding values\n        llm_params = {\n            \"base_url\": base_url,\n            \"cache\": cache,\n            \"model\": model,\n            \"mirostat\": mirostat_value,\n            \"format\": format,\n            \"metadata\": metadata,\n            \"tags\": tags,\n            ## When a callback component is added to Langflow, the comment must be uncommented.##\n            # \"callback_manager\": callback_manager,\n            # \"callbacks\": callbacks,\n            #####################################################################################\n            \"mirostat_eta\": mirostat_eta,\n            \"mirostat_tau\": mirostat_tau,\n            \"num_ctx\": num_ctx,\n            \"num_gpu\": num_gpu,\n            \"num_thread\": num_thread,\n            \"repeat_last_n\": repeat_last_n,\n            \"repeat_penalty\": repeat_penalty,\n            \"temperature\": temperature,\n            \"stop\": stop,\n            \"system\": system,\n            \"template\": template,\n            \"tfs_z\": tfs_z,\n            \"timeout\": timeout,\n            \"top_k\": top_k,\n            \"top_p\": top_p,\n            \"verbose\": verbose,\n        }\n\n        # None Value remove\n        llm_params = {k: v for k, v in llm_params.items() if v is not None}\n\n        try:\n            output = ChatOllama(**llm_params)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not initialize Ollama LLM.\") from e\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "format": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "format",
                  "display_name": "Format",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Specify the format of the output (e.g., json).",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "mirostat": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Disabled",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Disabled",
                    "Mirostat",
                    "Mirostat 2.0"
                  ],
                  "name": "mirostat",
                  "display_name": "Mirostat",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "mirostat_eta": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_eta",
                  "display_name": "Mirostat Eta",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Learning rate for Mirostat algorithm. (Default: 0.1)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "mirostat_tau": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_tau",
                  "display_name": "Mirostat Tau",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "model": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "llama3:8b-instruct-q8_0",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Refer to https://ollama.ai/library for more models.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "num_ctx": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_ctx",
                  "display_name": "Context Window Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Size of the context window for generating tokens. (Default: 2048)",
                  "load_from_db": false,
                  "title_case": false
                },
                "num_gpu": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_gpu",
                  "display_name": "Number of GPUs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)",
                  "load_from_db": false,
                  "title_case": false
                },
                "num_thread": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_thread",
                  "display_name": "Number of Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of threads to use during computation. (Default: detected for optimal performance)",
                  "load_from_db": false,
                  "title_case": false
                },
                "repeat_last_n": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_last_n",
                  "display_name": "Repeat Last N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)",
                  "load_from_db": false,
                  "title_case": false
                },
                "repeat_penalty": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_penalty",
                  "display_name": "Repeat Penalty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Penalty for repetitions in generated text. (Default: 1.1)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "stream": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stream",
                  "display_name": "Stream",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "load_from_db": false,
                  "title_case": false
                },
                "system": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "system",
                  "display_name": "System",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System to use for generating text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "system_message": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "system_message",
                  "display_name": "System Message",
                  "advanced": true,
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.8,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Controls the creativity of model responses.",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to use for generating text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "tfs_z": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tfs_z",
                  "display_name": "TFS Z",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tail free sampling value. (Default: 1)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "timeout": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "timeout",
                  "display_name": "Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Timeout for the request stream.",
                  "load_from_db": false,
                  "title_case": false
                },
                "top_k": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_k",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limits token selection to top K. (Default: 40)",
                  "load_from_db": false,
                  "title_case": false
                },
                "top_p": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_p",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Works together with top-k. (Default: 0.9)",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "verbose": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "verbose",
                  "display_name": "Verbose",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Whether to print out response text.",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "Generate text using Ollama Local LLMs.",
              "icon": "Ollama",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "Ollama",
              "documentation": "",
              "custom_fields": {
                "base_url": null,
                "model": null,
                "input_value": null,
                "mirostat": null,
                "mirostat_eta": null,
                "mirostat_tau": null,
                "repeat_last_n": null,
                "verbose": null,
                "cache": null,
                "num_ctx": null,
                "num_gpu": null,
                "format": null,
                "metadata": null,
                "num_thread": null,
                "repeat_penalty": null,
                "stop": null,
                "system": null,
                "tags": null,
                "temperature": null,
                "template": null,
                "tfs_z": null,
                "timeout": null,
                "top_k": null,
                "top_p": null,
                "stream": null,
                "system_message": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [
                "base_url",
                "model",
                "temperature",
                "cache",
                "callback_manager",
                "callbacks",
                "format",
                "metadata",
                "mirostat",
                "mirostat_eta",
                "mirostat_tau",
                "num_ctx",
                "num_gpu",
                "num_thread",
                "repeat_last_n",
                "repeat_penalty",
                "tfs_z",
                "timeout",
                "top_k",
                "top_p",
                "verbose",
                "tags",
                "stop",
                "system",
                "template",
                "input_value",
                "system_message",
                "stream"
              ],
              "beta": false
            },
            "id": "OllamaModel-5gJx6"
          },
          "selected": false,
          "width": 384,
          "height": 621,
          "positionAbsolute": {
            "x": 1302.4122413190705,
            "y": -135.61798546636712
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-eWjtm",
          "type": "genericNode",
          "position": {
            "x": 1948.0318323775798,
            "y": 139.58850113595645
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "{text}",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "In case of Message being a Record, this template will be used to convert it to text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "return_record": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_record",
                  "display_name": "Return Record",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                  "load_from_db": false,
                  "title_case": false
                },
                "sender": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Machine",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "sender_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "AI",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "session_id": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If provided, the message will be stored in the memory.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "object",
                "Record",
                "str",
                "Text"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {
                "sender": null,
                "sender_name": null,
                "input_value": null,
                "session_id": null,
                "return_record": null,
                "record_template": null
              },
              "output_types": [
                "Text",
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "ChatOutput-eWjtm"
          },
          "selected": false,
          "width": 384,
          "height": 383,
          "dragging": false,
          "positionAbsolute": {
            "x": 1948.0318323775798,
            "y": 139.58850113595645
          }
        },
        {
          "id": "File-nkAzv",
          "type": "genericNode",
          "position": {
            "x": -1136.4871731029673,
            "y": -135.55616282534143
          },
          "data": {
            "type": "File",
            "node": {
              "template": {
                "path": {
                  "type": "file",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [
                    ".txt",
                    ".md",
                    ".mdx",
                    ".csv",
                    ".json",
                    ".yaml",
                    ".yml",
                    ".xml",
                    ".html",
                    ".htm",
                    ".pdf",
                    ".docx",
                    ".py",
                    ".sh",
                    ".sql",
                    ".js",
                    ".ts",
                    ".tsx"
                  ],
                  "file_path": "74e5856a-9a44-4d8a-a30a-4fa5e932e08c/output.txt",
                  "password": false,
                  "name": "path",
                  "display_name": "Path",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Supported file types: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx",
                  "load_from_db": false,
                  "title_case": false,
                  "value": ""
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from pathlib import Path\nfrom typing import Any, Dict\n\nfrom axiestudio.base.data.utils import TEXT_FILE_TYPES, parse_text_file_to_record\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema import Record\n\n\nclass FileComponent(CustomComponent):\n    display_name = \"File\"\n    description = \"A generic file loader.\"\n    icon = \"file-text\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n                \"field_type\": \"file\",\n                \"file_types\": TEXT_FILE_TYPES,\n                \"info\": f\"Supported file types: {', '.join(TEXT_FILE_TYPES)}\",\n            },\n            \"silent_errors\": {\n                \"display_name\": \"Silent Errors\",\n                \"advanced\": True,\n                \"info\": \"If true, errors will not raise an exception.\",\n            },\n        }\n\n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(\n        self,\n        path: str,\n        silent_errors: bool = False,\n    ) -> Record:\n        record = self.load_file(path, silent_errors)\n        self.status = record\n        return record\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "silent_errors": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "silent_errors",
                  "display_name": "Silent Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, errors will not raise an exception.",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "A generic file loader.",
              "icon": "file-text",
              "base_classes": [
                "Record"
              ],
              "display_name": "File",
              "documentation": "",
              "custom_fields": {
                "path": null,
                "silent_errors": null
              },
              "output_types": [
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "File-nkAzv"
          },
          "selected": false,
          "width": 384,
          "height": 281,
          "positionAbsolute": {
            "x": -1136.4871731029673,
            "y": -135.55616282534143
          },
          "dragging": false
        },
        {
          "id": "RecursiveCharacterTextSplitter-pg0R5",
          "type": "genericNode",
          "position": {
            "x": -518.3233325912678,
            "y": -31.362509204501556
          },
          "data": {
            "type": "RecursiveCharacterTextSplitter",
            "node": {
              "template": {
                "inputs": {
                  "type": "Document",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "inputs",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record"
                  ],
                  "dynamic": false,
                  "info": "The texts to split.",
                  "load_from_db": false,
                  "title_case": false
                },
                "chunk_overlap": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 200,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chunk_overlap",
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The amount of overlap between chunks.",
                  "load_from_db": false,
                  "title_case": false
                },
                "chunk_size": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 1000,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "chunk_size",
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum length of each chunk.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\nfrom langchain_core.documents import Document\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema import Record\nfrom axiestudio.utils.util import build_loader_repr_from_records, unescape_string\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter\"\n\n    def build_config(self):\n        return {\n            \"inputs\": {\n                \"display_name\": \"Input\",\n                \"info\": \"The texts to split.\",\n                \"input_types\": [\"Document\", \"Record\"],\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        inputs: list[Document],\n        separators: Optional[list[str]] = None,\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n    ) -> list[Record]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n\n        if separators == \"\":\n            separators = None\n        elif separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n        documents = []\n        for _input in inputs:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        docs = splitter.split_documents(documents)\n        records = self.to_records(docs)\n        self.repr_value = build_loader_repr_from_records(records)\n        return records\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separators": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "separators",
                  "display_name": "Separators",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": [
                    "/n"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Split text into chunks of a specified length.",
              "base_classes": [
                "Record"
              ],
              "display_name": "Recursive Character Text Splitter",
              "documentation": "https://docs.axiestudio.org/components/text-splitters#recursivecharactertextsplitter",
              "custom_fields": {
                "inputs": null,
                "separators": null,
                "chunk_size": null,
                "chunk_overlap": null
              },
              "output_types": [
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "RecursiveCharacterTextSplitter-pg0R5"
          },
          "selected": false,
          "width": 384,
          "height": 501,
          "positionAbsolute": {
            "x": -518.3233325912678,
            "y": -31.362509204501556
          },
          "dragging": false
        },
        {
          "id": "OllamaEmbeddings-ecr2M",
          "type": "genericNode",
          "position": {
            "x": -1166.2938153079344,
            "y": 433.3619209998918
          },
          "data": {
            "type": "OllamaEmbeddings",
            "node": {
              "template": {
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "http://localhost:11434",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Ollama Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom langchain_core.embeddings import Embeddings\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "model": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "mxbai-embed-large:335m",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model",
                  "display_name": "Ollama Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Model Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false,
                  "value": "0.6"
                },
                "_type": "CustomComponent"
              },
              "description": "Generate embeddings using Ollama models.",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Ollama Embeddings",
              "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
              "custom_fields": {
                "model": null,
                "base_url": null,
                "temperature": null
              },
              "output_types": [
                "Embeddings"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "OllamaEmbeddings-ecr2M"
          },
          "selected": false,
          "width": 384,
          "height": 469,
          "positionAbsolute": {
            "x": -1166.2938153079344,
            "y": 433.3619209998918
          },
          "dragging": false
        },
        {
          "id": "Pinecone-pERLu",
          "type": "genericNode",
          "position": {
            "x": -28.457647657468044,
            "y": 815.6645058027251
          },
          "data": {
            "type": "Pinecone",
            "node": {
              "template": {
                "embedding": {
                  "type": "Embeddings",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "inputs": {
                  "type": "Record",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "inputs",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, Optional, Union\nfrom langchain_core.documents import Document\nfrom langchain_pinecone._utilities import DistanceStrategy\nfrom langchain_pinecone.vectorstores import PineconeVectorStore\n\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom axiestudio.schema.schema import Record\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.vectorstores import VectorStore\n\n\nclass PineconeComponent(CustomComponent):\n    display_name = \"Pinecone\"\n    description = \"Construct Pinecone wrapper from raw documents.\"\n    icon = \"Pinecone\"\n    field_order = [\"index_name\", \"namespace\", \"distance_strategy\", \"pinecone_api_key\", \"documents\", \"embedding\"]\n\n    def build_config(self):\n        distance_options = [e.value.title().replace(\"_\", \" \") for e in DistanceStrategy]\n        distance_value = distance_options[0]\n        return {\n            \"inputs\": {\"display_name\": \"Input\", \"input_types\": [\"Document\", \"Record\"]},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"namespace\": {\"display_name\": \"Namespace\"},\n            \"text_key\": {\"display_name\": \"Text Key\"},\n            \"distance_strategy\": {\n                \"display_name\": \"Distance Strategy\",\n                # get values from enum\n                # and make them title case for display\n                \"options\": distance_options,\n                \"advanced\": True,\n                \"value\": distance_value,\n            },\n            \"pinecone_api_key\": {\n                \"display_name\": \"Pinecone API Key\",\n                \"default\": \"\",\n                \"password\": True,\n                \"required\": True,\n            },\n            \"pool_threads\": {\n                \"display_name\": \"Pool Threads\",\n                \"default\": 1,\n                \"advanced\": True,\n            },\n        }\n\n    def from_existing_index(\n        self,\n        index_name: str,\n        embedding: Embeddings,\n        pinecone_api_key: str | None,\n        text_key: str = \"text\",\n        namespace: Optional[str] = None,\n        distance_strategy: DistanceStrategy = DistanceStrategy.COSINE,\n        pool_threads: int = 4,\n    ) -> PineconeVectorStore:\n        \"\"\"Load pinecone vectorstore from index name.\"\"\"\n        pinecone_index = PineconeVectorStore.get_pinecone_index(\n            index_name, pool_threads, pinecone_api_key=pinecone_api_key\n        )\n        return PineconeVectorStore(\n            index=pinecone_index,\n            embedding=embedding,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=distance_strategy,\n        )\n\n    def from_documents(\n        self,\n        documents: List[Document],\n        embedding: Embeddings,\n        index_name: str,\n        pinecone_api_key: str | None,\n        text_key: str = \"text\",\n        namespace: Optional[str] = None,\n        pool_threads: int = 4,\n        distance_strategy: DistanceStrategy = DistanceStrategy.COSINE,\n        batch_size: int = 32,\n        upsert_kwargs: Optional[dict] = None,\n        embeddings_chunk_size: int = 1000,\n    ) -> PineconeVectorStore:\n        \"\"\"Create a new pinecone vectorstore from documents.\"\"\"\n        texts = [d.page_content for d in documents]\n        metadatas = [d.metadata for d in documents]\n        pinecone = self.from_existing_index(\n            index_name=index_name,\n            embedding=embedding,\n            pinecone_api_key=pinecone_api_key,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=distance_strategy,\n            pool_threads=pool_threads,\n        )\n        pinecone.add_texts(\n            texts,\n            metadatas=metadatas,\n            ids=None,\n            namespace=namespace,\n            batch_size=batch_size,\n            embedding_chunk_size=embeddings_chunk_size,\n            **(upsert_kwargs or {}),\n        )\n        return pinecone\n\n    def build(\n        self,\n        embedding: Embeddings,\n        distance_strategy: str,\n        inputs: Optional[List[Record]] = None,\n        text_key: str = \"text\",\n        pool_threads: int = 4,\n        index_name: Optional[str] = None,\n        pinecone_api_key: Optional[str] = None,\n        namespace: Optional[str] = \"default\",\n    ) -> Union[VectorStore, BaseRetriever]:\n        # get distance strategy from string\n        distance_strategy = distance_strategy.replace(\" \", \"_\").upper()\n        _distance_strategy = DistanceStrategy[distance_strategy]\n        if not index_name:\n            raise ValueError(\"Index Name is required.\")\n        documents = []\n        for _input in inputs or []:\n            if isinstance(_input, Record):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n        if documents:\n            return self.from_documents(\n                documents=documents,\n                embedding=embedding,\n                index_name=index_name,\n                pinecone_api_key=pinecone_api_key,\n                text_key=text_key,\n                namespace=namespace,\n                distance_strategy=_distance_strategy,\n                pool_threads=pool_threads,\n            )\n\n        return self.from_existing_index(\n            index_name=index_name,\n            embedding=embedding,\n            pinecone_api_key=pinecone_api_key,\n            text_key=text_key,\n            namespace=namespace,\n            distance_strategy=_distance_strategy,\n            pool_threads=pool_threads,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "distance_strategy": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Euclidean Distance",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Euclidean Distance",
                    "Max Inner Product",
                    "Cosine"
                  ],
                  "name": "distance_strategy",
                  "display_name": "Distance Strategy",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "index_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "index_name",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "youtube-rag-index"
                },
                "namespace": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "default",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "namespace",
                  "display_name": "Namespace",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "pinecone_api_key": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "pinecone_api_key",
                  "display_name": "Pinecone API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": ""
                },
                "pool_threads": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 4,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "pool_threads",
                  "display_name": "Pool Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "text_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "text",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "text_key",
                  "display_name": "Text Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Construct Pinecone wrapper from raw documents.",
              "icon": "Pinecone",
              "base_classes": [
                "BaseRetriever",
                "Generic",
                "object",
                "Runnable",
                "RunnableSerializable",
                "Serializable",
                "VectorStore"
              ],
              "display_name": "Pinecone",
              "documentation": "",
              "custom_fields": {
                "embedding": null,
                "distance_strategy": null,
                "inputs": null,
                "text_key": null,
                "pool_threads": null,
                "index_name": null,
                "pinecone_api_key": null,
                "namespace": null
              },
              "output_types": [
                "VectorStore",
                "BaseRetriever"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [
                "index_name",
                "namespace",
                "distance_strategy",
                "pinecone_api_key",
                "documents",
                "embedding"
              ],
              "beta": false
            },
            "id": "Pinecone-pERLu"
          },
          "selected": false,
          "width": 384,
          "height": 667,
          "positionAbsolute": {
            "x": -28.457647657468044,
            "y": 815.6645058027251
          },
          "dragging": false
        },
        {
          "id": "PineconeSearch-X4rs5",
          "type": "genericNode",
          "position": {
            "x": 447.1526866565655,
            "y": 381.58907943083005
          },
          "data": {
            "type": "PineconeSearch",
            "node": {
              "template": {
                "embedding": {
                  "type": "Embeddings",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Input",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, Optional\n\nfrom langchain_pinecone._utilities import DistanceStrategy\n\nfrom axiestudio.components.vectorstores.base.model import LCVectorStoreComponent\nfrom axiestudio.components.vectorstores.Pinecone import PineconeComponent\nfrom axiestudio.field_typing import Embeddings, Text\nfrom axiestudio.field_typing.constants import NestedDict\nfrom axiestudio.schema import Record\n\n\nclass PineconeSearchComponent(PineconeComponent, LCVectorStoreComponent):\n    display_name = \"Pinecone Search\"\n    description = \"Search a Pinecone Vector Store for similar documents.\"\n    icon = \"Pinecone\"\n    field_order = [\"index_name\", \"namespace\", \"distance_strategy\", \"pinecone_api_key\", \"input_value\", \"embedding\"]\n\n    def build_config(self):\n        distance_options = [e.value.title().replace(\"_\", \" \") for e in DistanceStrategy]\n        distance_value = distance_options[0]\n        return {\n            \"search_type\": {\n                \"display_name\": \"Search Type\",\n                \"options\": [\"Similarity\", \"MMR\"],\n            },\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"index_name\": {\"display_name\": \"Index Name\"},\n            \"namespace\": {\"display_name\": \"Namespace\", \"advanced\": True},\n            \"distance_strategy\": {\n                \"display_name\": \"Distance Strategy\",\n                # get values from enum\n                # and make them title case for display\n                \"options\": distance_options,\n                \"advanced\": True,\n                \"value\": distance_value,\n            },\n            \"pinecone_api_key\": {\n                \"display_name\": \"Pinecone API Key\",\n                \"default\": \"\",\n                \"password\": True,\n            },\n            \"pool_threads\": {\n                \"display_name\": \"Pool Threads\",\n                \"default\": 1,\n                \"advanced\": True,\n            },\n            \"number_of_results\": {\n                \"display_name\": \"Number of Results\",\n                \"info\": \"Number of results to return.\",\n                \"advanced\": True,\n            },\n            \"text_key\": {\n                \"display_name\": \"Text Key\",\n                \"info\": \"Key in the record to use as text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(  # type: ignore[override]\n        self,\n        input_value: Text,\n        embedding: Embeddings,\n        distance_strategy: str,\n        text_key: str = \"text\",\n        number_of_results: int = 4,\n        pool_threads: int = 4,\n        index_name: Optional[str] = None,\n        pinecone_api_key: Optional[str] = None,\n        namespace: Optional[str] = \"default\",\n        search_type: str = \"similarity\",\n        search_kwargs: Optional[NestedDict] = None,\n    ) -> List[Record]:  # type: ignore[override]\n        vector_store = super().build(\n            embedding=embedding,\n            distance_strategy=distance_strategy,\n            inputs=[],\n            text_key=text_key,\n            pool_threads=pool_threads,\n            index_name=index_name,\n            pinecone_api_key=pinecone_api_key,\n            namespace=namespace,\n        )\n        if not vector_store:\n            raise ValueError(\"Failed to load the Pinecone index.\")\n        if search_kwargs is None:\n            search_kwargs = {}\n\n        return self.search_with_vector_store(\n            vector_store=vector_store,\n            input_value=input_value,\n            search_type=search_type,\n            k=number_of_results,\n            **search_kwargs,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "distance_strategy": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Euclidean Distance",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Euclidean Distance",
                    "Max Inner Product",
                    "Cosine"
                  ],
                  "name": "distance_strategy",
                  "display_name": "Distance Strategy",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "index_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "index_name",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "youtube-rag-index"
                },
                "namespace": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "default",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "namespace",
                  "display_name": "Namespace",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "number_of_results": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 4,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "number_of_results",
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "load_from_db": false,
                  "title_case": false
                },
                "pinecone_api_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "pinecone_api_key",
                  "display_name": "Pinecone API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": ""
                },
                "pool_threads": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 4,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "pool_threads",
                  "display_name": "Pool Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "search_kwargs": {
                  "type": "NestedDict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "search_kwargs",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "value": {}
                },
                "search_type": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Similarity",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Similarity",
                    "MMR"
                  ],
                  "name": "search_type",
                  "display_name": "Search Type",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "text_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "text",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "text_key",
                  "display_name": "Text Key",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Key in the record to use as text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Search a Pinecone Vector Store for similar documents.",
              "icon": "Pinecone",
              "base_classes": [
                "Record"
              ],
              "display_name": "Pinecone Search",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "embedding": null,
                "distance_strategy": null,
                "text_key": null,
                "number_of_results": null,
                "pool_threads": null,
                "index_name": null,
                "pinecone_api_key": null,
                "namespace": null,
                "search_type": null,
                "search_kwargs": null
              },
              "output_types": [
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [
                "index_name",
                "namespace",
                "distance_strategy",
                "pinecone_api_key",
                "input_value",
                "embedding"
              ],
              "beta": false
            },
            "id": "PineconeSearch-X4rs5"
          },
          "selected": false,
          "width": 384,
          "height": 725,
          "positionAbsolute": {
            "x": 447.1526866565655,
            "y": 381.58907943083005
          },
          "dragging": false
        },
        {
          "id": "OllamaEmbeddings-UpAf8",
          "type": "genericNode",
          "position": {
            "x": -42.51372223665737,
            "y": 253.948785134003
          },
          "data": {
            "type": "OllamaEmbeddings",
            "node": {
              "template": {
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "http://localhost:11434",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Ollama Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\nfrom langchain_community.embeddings import OllamaEmbeddings\n\nfrom axiestudio.interface.custom.custom_component import CustomComponent\nfrom langchain_core.embeddings import Embeddings\n\n\nclass OllamaEmbeddingsComponent(CustomComponent):\n    display_name: str = \"Ollama Embeddings\"\n    description: str = \"Generate embeddings using Ollama models.\"\n    documentation = \"https://python.langchain.com/docs/integrations/text_embedding/ollama\"\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Ollama Model\",\n            },\n            \"base_url\": {\"display_name\": \"Ollama Base URL\"},\n            \"temperature\": {\"display_name\": \"Model Temperature\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str = \"llama2\",\n        base_url: str = \"http://localhost:11434\",\n        temperature: Optional[float] = None,\n    ) -> Embeddings:\n        try:\n            output = OllamaEmbeddings(model=model, base_url=base_url, temperature=temperature)  # type: ignore\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama API.\") from e\n        return output\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "model": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "mxbai-embed-large:335m",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model",
                  "display_name": "Ollama Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Model Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false,
                  "value": "0.6"
                },
                "_type": "CustomComponent"
              },
              "description": "Generate embeddings using Ollama models.",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Ollama Embeddings",
              "documentation": "https://python.langchain.com/docs/integrations/text_embedding/ollama",
              "custom_fields": {
                "model": null,
                "base_url": null,
                "temperature": null
              },
              "output_types": [
                "Embeddings"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "OllamaEmbeddings-UpAf8"
          },
          "selected": false,
          "width": 384,
          "height": 469,
          "positionAbsolute": {
            "x": -42.51372223665737,
            "y": 253.948785134003
          },
          "dragging": false
        },
        {
          "id": "Prompt-opl9z",
          "type": "genericNode",
          "position": {
            "x": 709.6596523965989,
            "y": -162.8985026253091
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\nfrom axiestudio.interface.custom.custom_component import CustomComponent\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "prompt",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "Answer the question using the below provided context. Your answer should be in your own words and be no longer than 50 words. If the answer is not within the context, reply with \"I don't know\"\n\n{Context}\n\n{Question}",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent",
                "Context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "Context",
                  "display_name": "Context",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "Question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "Question",
                  "display_name": "Question",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "Context",
                  "Question"
                ]
              },
              "output_types": [
                "Text"
              ],
              "full_path": null,
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false,
              "error": null
            },
            "id": "Prompt-opl9z",
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt"
          },
          "selected": false,
          "width": 384,
          "height": 477,
          "dragging": false,
          "positionAbsolute": {
            "x": 709.6596523965989,
            "y": -162.8985026253091
          }
        },
        {
          "id": "RetrievalQAWithSourcesChain-UGiM0",
          "type": "genericNode",
          "position": {
            "x": 1077.3124842893967,
            "y": 557.363034941791
          },
          "data": {
            "type": "RetrievalQAWithSourcesChain",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Input Value",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The input value to pass to the chain.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "retriever": {
                  "type": "BaseRetriever",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "retriever",
                  "display_name": "Retriever",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "chain_type": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Stuff",
                    "Map Reduce",
                    "Refine",
                    "Map Rerank"
                  ],
                  "name": "chain_type",
                  "display_name": "Chain Type",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The type of chain to use to combined Documents.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ],
                  "value": "Stuff"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain_core.documents import Document\n\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, BaseRetriever, Text\nfrom axiestudio.interface.custom.custom_component import CustomComponent\n\n\nclass RetrievalQAWithSourcesChainComponent(CustomComponent):\n    display_name = \"RetrievalQAWithSourcesChain\"\n    description = \"Question-answering with sources over an index.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"chain_type\": {\n                \"display_name\": \"Chain Type\",\n                \"options\": [\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n                \"info\": \"The type of chain to use to combined Documents.\",\n            },\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"return_source_documents\": {\"display_name\": \"Return Source Documents\"},\n            \"retriever\": {\"display_name\": \"Retriever\"},\n            \"input_value\": {\n                \"display_name\": \"Input Value\",\n                \"info\": \"The input value to pass to the chain.\",\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        retriever: BaseRetriever,\n        llm: BaseLanguageModel,\n        chain_type: str,\n        memory: Optional[BaseMemory] = None,\n        return_source_documents: Optional[bool] = True,\n    ) -> Text:\n        chain_type = chain_type.lower().replace(\" \", \"_\")\n        runnable = RetrievalQAWithSourcesChain.from_chain_type(\n            llm=llm,\n            chain_type=chain_type,\n            memory=memory,\n            return_source_documents=return_source_documents,\n            retriever=retriever,\n        )\n        if isinstance(input_value, Document):\n            input_value = input_value.page_content\n        self.status = runnable\n        input_key = runnable.input_keys[0]\n        result = runnable.invoke({input_key: input_value})\n        result = result.content if hasattr(result, \"content\") else result\n        # Result is a dict with keys \"query\",  \"result\" and \"source_documents\"\n        # for now we just return the result\n        records = self.to_records(result.get(\"source_documents\"))\n        references_str = \"\"\n        if return_source_documents:\n            references_str = self.create_references_from_records(records)\n        result_str = Text(result.get(\"answer\", \"\"))\n        final_result = \"\\n\".join([result_str, references_str])\n        self.status = final_result\n        return final_result\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "return_source_documents": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_source_documents",
                  "display_name": "Return Source Documents",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "Question-answering with sources over an index.",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "RetrievalQAWithSourcesChain",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "retriever": null,
                "llm": null,
                "chain_type": null,
                "memory": null,
                "return_source_documents": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "RetrievalQAWithSourcesChain-UGiM0"
          },
          "selected": true,
          "width": 384,
          "height": 603,
          "positionAbsolute": {
            "x": 1077.3124842893967,
            "y": 557.363034941791
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "File-nkAzv",
          "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-nkAzvœ}",
          "target": "RecursiveCharacterTextSplitter-pg0R5",
          "targetHandle": "{œfieldNameœ:œinputsœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œDocumentœ}",
          "data": {
            "targetHandle": {
              "fieldName": "inputs",
              "id": "RecursiveCharacterTextSplitter-pg0R5",
              "inputTypes": [
                "Document",
                "Record"
              ],
              "type": "Document"
            },
            "sourceHandle": {
              "baseClasses": [
                "Record"
              ],
              "dataType": "File",
              "id": "File-nkAzv"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-File-nkAzv{œbaseClassesœ:[œRecordœ],œdataTypeœ:œFileœ,œidœ:œFile-nkAzvœ}-RecursiveCharacterTextSplitter-pg0R5{œfieldNameœ:œinputsœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œDocumentœ}"
        },
        {
          "source": "OllamaEmbeddings-ecr2M",
          "sourceHandle": "{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-ecr2Mœ}",
          "target": "Pinecone-pERLu",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "Pinecone-pERLu",
              "inputTypes": null,
              "type": "Embeddings"
            },
            "sourceHandle": {
              "baseClasses": [
                "Embeddings"
              ],
              "dataType": "OllamaEmbeddings",
              "id": "OllamaEmbeddings-ecr2M"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-OllamaEmbeddings-ecr2M{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-ecr2Mœ}-Pinecone-pERLu{œfieldNameœ:œembeddingœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"
        },
        {
          "source": "RecursiveCharacterTextSplitter-pg0R5",
          "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ}",
          "target": "Pinecone-pERLu",
          "targetHandle": "{œfieldNameœ:œinputsœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}",
          "data": {
            "targetHandle": {
              "fieldName": "inputs",
              "id": "Pinecone-pERLu",
              "inputTypes": [
                "Document",
                "Record"
              ],
              "type": "Record"
            },
            "sourceHandle": {
              "baseClasses": [
                "Record"
              ],
              "dataType": "RecursiveCharacterTextSplitter",
              "id": "RecursiveCharacterTextSplitter-pg0R5"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-RecursiveCharacterTextSplitter-pg0R5{œbaseClassesœ:[œRecordœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-pg0R5œ}-Pinecone-pERLu{œfieldNameœ:œinputsœ,œidœ:œPinecone-pERLuœ,œinputTypesœ:[œDocumentœ,œRecordœ],œtypeœ:œRecordœ}"
        },
        {
          "source": "ChatInput-nVdVb",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}",
          "target": "PineconeSearch-X4rs5",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "PineconeSearch-X4rs5",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "Record",
                "str",
                "Text"
              ],
              "dataType": "ChatInput",
              "id": "ChatInput-nVdVb"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-ChatInput-nVdVb{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}-PineconeSearch-X4rs5{œfieldNameœ:œinput_valueœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "OllamaEmbeddings-UpAf8",
          "sourceHandle": "{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-UpAf8œ}",
          "target": "PineconeSearch-X4rs5",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "PineconeSearch-X4rs5",
              "inputTypes": null,
              "type": "Embeddings"
            },
            "sourceHandle": {
              "baseClasses": [
                "Embeddings"
              ],
              "dataType": "OllamaEmbeddings",
              "id": "OllamaEmbeddings-UpAf8"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-OllamaEmbeddings-UpAf8{œbaseClassesœ:[œEmbeddingsœ],œdataTypeœ:œOllamaEmbeddingsœ,œidœ:œOllamaEmbeddings-UpAf8œ}-PineconeSearch-X4rs5{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-X4rs5œ,œinputTypesœ:null,œtypeœ:œEmbeddingsœ}"
        },
        {
          "source": "ChatInput-nVdVb",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}",
          "target": "Prompt-opl9z",
          "targetHandle": "{œfieldNameœ:œQuestionœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Question",
              "id": "Prompt-opl9z",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "Record",
                "str",
                "Text"
              ],
              "dataType": "ChatInput",
              "id": "ChatInput-nVdVb"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-ChatInput-nVdVb{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-nVdVbœ}-Prompt-opl9z{œfieldNameœ:œQuestionœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "PineconeSearch-X4rs5",
          "sourceHandle": "{œbaseClassesœ:[œRecordœ],œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-X4rs5œ}",
          "target": "Prompt-opl9z",
          "targetHandle": "{œfieldNameœ:œContextœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Context",
              "id": "Prompt-opl9z",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "Record"
              ],
              "dataType": "PineconeSearch",
              "id": "PineconeSearch-X4rs5"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-PineconeSearch-X4rs5{œbaseClassesœ:[œRecordœ],œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-X4rs5œ}-Prompt-opl9z{œfieldNameœ:œContextœ,œidœ:œPrompt-opl9zœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Prompt-opl9z",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-opl9zœ}",
          "target": "OllamaModel-5gJx6",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-5gJx6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OllamaModel-5gJx6",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "Prompt",
              "id": "Prompt-opl9z"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-Prompt-opl9z{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-opl9zœ}-OllamaModel-5gJx6{œfieldNameœ:œinput_valueœ,œidœ:œOllamaModel-5gJx6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "OllamaModel-5gJx6",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-5gJx6œ}",
          "target": "ChatOutput-eWjtm",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eWjtmœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-eWjtm",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "OllamaModel",
              "id": "OllamaModel-5gJx6"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900 stroke-connection",
          "id": "reactflow__edge-OllamaModel-5gJx6{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOllamaModelœ,œidœ:œOllamaModel-5gJx6œ}-ChatOutput-eWjtm{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-eWjtmœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": 1071.3123612389816,
        "y": 202.98916242936957,
        "zoom": 0.6671115848388874
      }
    },
    "date_created": "2024-05-26T03:45:33.980Z",
    "date_updated": "2024-05-26T03:45:34.018Z",
    "status": "Public",
    "sort": null,
    "user_updated": "ddefa9cc-2e19-41ca-98cf-b4e0bc8cd7bc",
    "user_created": {
      "username": "wweezy0007",
      "first_name": "Olawale",
      "last_name": "Adu",
      "id": "ddefa9cc-2e19-41ca-98cf-b4e0bc8cd7bc"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:59.264Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 64,
    "converter_version": "1.0.0"
  }
}