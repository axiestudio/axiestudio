{
  "id": "d7054d56-5010-4efe-a492-052eb375a270",
  "name": "Simple Travel Agent v.1.1",
  "description": "Here's a beginner-friendly example of a simple agent flow, perfect for anyone just getting started with agents. This walkthrough is designed to help you grasp the basics of how agents operate, providing a solid foundation for understanding the core steps and logic they use to complete tasks or solve problems.   (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "boreilly",
    "first_name": "Betul",
    "last_name": "O'Reilly",
    "id": "76f05705-dfce-454b-8d27-4f5f02d94090",
    "full_name": "Betul O'Reilly"
  },
  "store_url": "https://www.langflow.store/store/component/d7054d56-5010-4efe-a492-052eb375a270",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-11-18T10:49:55.878Z",
    "updated": "2024-11-18T10:49:55.939Z",
    "downloaded": "2025-08-19T17:50:07.336Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.1.0",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ChatInput-Tdj5J",
        "type": "genericNode",
        "position": {
          "x": 609.4960180759202,
          "y": 577.3977387113978
        },
        "data": {
          "type": "ChatInput",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "what is my name?",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "ChatInput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.1.0"
          },
          "id": "ChatInput-Tdj5J"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 609.4960180759202,
          "y": 577.3977387113978
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-ASkuo",
        "type": "genericNode",
        "position": {
          "x": 1705.9387678769672,
          "y": 633.4973168994502
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.1.0"
          },
          "id": "ChatOutput-ASkuo"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1705.9387678769672,
          "y": 633.4973168994502
        },
        "dragging": false
      },
      {
        "id": "Agent-VOGPG",
        "type": "genericNode",
        "position": {
          "x": 1177.2843447786609,
          "y": 425.0000000000001
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool",
                  "StructuredTool"
                ],
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "add_current_date_tool": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "add_current_date_tool",
                "value": true,
                "display_name": "Add tool Current Date",
                "advanced": true,
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "agent_description": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_description",
                "value": "A helpful assistant with access to the following tools:",
                "display_name": "Agent Description",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "Custom"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "Model Provider",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.base.models.model_input_constants import ALL_PROVIDER_FIELDS, MODEL_PROVIDERS_DICT\nfrom axiestudio.base.models.model_utils import get_model_name\nfrom axiestudio.components.helpers import CurrentDateComponent\nfrom axiestudio.components.helpers.memory import MemoryComponent\nfrom axiestudio.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom axiestudio.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom axiestudio.schema.dotdict import dotdict\nfrom axiestudio.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Add tool Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        llm_model, display_name = self.get_llm()\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n        if llm_model is None:\n            msg = \"No language model selected\"\n            raise ValueError(msg)\n        self.chat_history = self.get_memory_data()\n\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            # Convert CurrentDateComponent to a StructuredTool\n            current_date_tool = CurrentDateComponent().to_toolkit()[0]\n            if isinstance(current_date_tool, StructuredTool):\n                self.tools.append(current_date_tool)\n            else:\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise ValueError(msg)\n\n        if not self.tools:\n            msg = \"Tools are required to run the agent.\"\n            raise ValueError(msg)\n        self.set(\n            llm=llm_model,\n            tools=self.tools,\n            chat_history=self.chat_history,\n            input_value=self.input_value,\n            system_prompt=self.system_prompt,\n        )\n        agent = self.create_agent_runnable()\n        return await self.run_agent(agent)\n\n    def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n\n        return MemoryComponent().set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if isinstance(self.agent_llm, str):\n            try:\n                provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n                if provider_info:\n                    component_class = provider_info.get(\"component_class\")\n                    display_name = component_class.display_name\n                    inputs = provider_info.get(\"inputs\")\n                    prefix = provider_info.get(\"prefix\", \"\")\n                    return self._build_llm_model(component_class, inputs, prefix), display_name\n            except Exception as e:\n                msg = f\"Error building {self.agent_llm} language model\"\n                raise ValueError(msg) from e\n        return self.agent_llm, None\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: str, field_name: str | None = None) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name == \"agent_llm\":\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if isinstance(self.agent_llm, str) and self.agent_llm in MODEL_PROVIDERS_DICT:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "order": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "system_prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                "display_name": "Agent Instructions",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "icon": "bot",
            "base_classes": [
              "Message"
            ],
            "display_name": "Agent",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "agents",
            "key": "Agent",
            "lf_version": "1.1.0"
          },
          "type": "Agent",
          "id": "Agent-VOGPG"
        },
        "selected": false,
        "width": 320,
        "height": 695,
        "dragging": false
      },
      {
        "id": "CalculatorTool-wBGpz",
        "type": "genericNode",
        "position": {
          "x": 602.9236617730055,
          "y": 222.94388312138466
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import ast\nimport operator\n\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom loguru import logger\nfrom pydantic import BaseModel, Field\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.schema import Data\n\n\nclass CalculatorToolComponent(LCToolComponent):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n    name = \"CalculatorTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n            tool_mode=True,\n        ),\n    ]\n\n    class CalculatorToolSchema(BaseModel):\n        expression: str = Field(..., description=\"The arithmetic expression to evaluate.\")\n\n    def run_model(self) -> list[Data]:\n        return self._evaluate_expression(self.expression)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"calculator\",\n            description=\"Evaluate basic arithmetic expressions. Input should be a string containing the expression.\",\n            func=self._eval_expr_with_error,\n            args_schema=self.CalculatorToolSchema,\n        )\n\n    def _eval_expr(self, node):\n        # Define the allowed operators\n        operators = {\n            ast.Add: operator.add,\n            ast.Sub: operator.sub,\n            ast.Mult: operator.mul,\n            ast.Div: operator.truediv,\n            ast.Pow: operator.pow,\n        }\n        if isinstance(node, ast.Num):\n            return node.n\n        if isinstance(node, ast.BinOp):\n            return operators[type(node.op)](self._eval_expr(node.left), self._eval_expr(node.right))\n        if isinstance(node, ast.UnaryOp):\n            return operators[type(node.op)](self._eval_expr(node.operand))\n        if isinstance(node, ast.Call):\n            msg = (\n                \"Function calls like sqrt(), sin(), cos() etc. are not supported. \"\n                \"Only basic arithmetic operations (+, -, *, /, **) are allowed.\"\n            )\n            raise TypeError(msg)\n        msg = f\"Unsupported operation or expression type: {type(node).__name__}\"\n        raise TypeError(msg)\n\n    def _eval_expr_with_error(self, expression: str) -> list[Data]:\n        try:\n            return self._evaluate_expression(expression)\n        except Exception as e:\n            raise ToolException(str(e)) from e\n\n    def _evaluate_expression(self, expression: str) -> list[Data]:\n        try:\n            # Parse the expression and evaluate it\n            tree = ast.parse(expression, mode=\"eval\")\n            result = self._eval_expr(tree.body)\n\n            # Format the result to a reasonable number of decimal places\n            formatted_result = f\"{result:.6f}\".rstrip(\"0\").rstrip(\".\")\n\n            self.status = formatted_result\n            return [Data(data={\"result\": formatted_result})]\n\n        except (SyntaxError, TypeError, KeyError) as e:\n            error_message = f\"Invalid expression: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except Exception as e:  # noqa: BLE001\n            logger.opt(exception=True).debug(\"Error evaluating expression\")\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "expression": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "expression",
                "value": "",
                "display_name": "Expression",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Perform basic arithmetic operations on a given expression.",
            "icon": "calculator",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "Calculator",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "expression"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "tools",
            "key": "CalculatorTool",
            "lf_version": "1.1.0"
          },
          "type": "CalculatorTool",
          "id": "CalculatorTool-wBGpz"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 602.9236617730055,
          "y": 222.94388312138466
        },
        "dragging": false
      },
      {
        "id": "AstraDBChatMemory-cgiAN",
        "type": "genericNode",
        "position": {
          "x": 1163.457295299928,
          "y": 1187.2077281198465
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_endpoint": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_endpoint",
                "value": "",
                "display_name": "API Endpoint",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API endpoint URL for the Astra DB service.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\n\nfrom astrapy.admin import parse_api_endpoint\n\nfrom axiestudio.base.memory.model import LCChatMemoryComponent\nfrom axiestudio.field_typing import BaseChatMessageHistory\nfrom axiestudio.inputs import MessageTextInput, SecretStrInput, StrInput\n\n\nclass AstraDBChatMemory(LCChatMemoryComponent):\n    display_name = \"Astra DB Chat Memory\"\n    description = \"Retrieves and store chat messages from Astra DB.\"\n    name = \"AstraDBChatMemory\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_message_history(self) -> BaseChatMessageHistory:\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        return AstraDBChatMessageHistory(\n            session_id=self.session_id,\n            collection_name=self.collection_name,\n            token=self.token,\n            api_endpoint=self.api_endpoint,\n            namespace=self.namespace or None,\n            environment=parse_api_endpoint(self.api_endpoint).environment,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "chathistory",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "namespace": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "namespace",
                "value": "",
                "display_name": "Namespace",
                "advanced": true,
                "dynamic": false,
                "info": "Optional namespace within Astra DB to use for the collection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "token": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "token",
                "value": "",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Retrieves and store chat messages from Astra DB.",
            "icon": "AstraDB",
            "base_classes": [
              "BaseChatMessageHistory"
            ],
            "display_name": "Astra DB Chat Memory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "BaseChatMessageHistory"
                ],
                "selected": "BaseChatMessageHistory",
                "name": "memory",
                "display_name": "Memory",
                "method": "build_message_history",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_endpoint",
                  "collection_name",
                  "token"
                ]
              }
            ],
            "field_order": [
              "token",
              "api_endpoint",
              "collection_name",
              "namespace",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "memories",
            "key": "AstraDBChatMemory",
            "lf_version": "1.1.0"
          },
          "type": "AstraDBChatMemory",
          "id": "AstraDBChatMemory-cgiAN"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 1163.457295299928,
          "y": 1187.2077281198465
        }
      },
      {
        "id": "StoreMessage-kS9bC",
        "type": "genericNode",
        "position": {
          "x": 618.0262867769094,
          "y": 900.1558502214912
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "The external memory to store the message. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import HandleInput, MessageInput\nfrom axiestudio.inputs.inputs import MessageTextInput\nfrom axiestudio.memory import get_messages, store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template import Output\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n\nclass StoreMessageComponent(Component):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"save\"\n    name = \"StoreMessage\"\n\n    inputs = [\n        MessageInput(name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\"),\n    ]\n\n    def store_message(self) -> Message:\n        message = self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            self.memory.add_messages([lc_message])\n            stored = self.memory.messages\n            stored = [Message.from_lc_message(m) for m in stored]\n            if message.sender:\n                stored = [m for m in stored if m.sender == message.sender]\n        else:\n            store_message(message, flow_id=self.graph.flow_id)\n            stored = get_messages(session_id=message.session_id, sender_name=message.sender_name, sender=message.sender)\n        self.status = stored\n        return stored\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The chat message to be stored.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "",
                "display_name": "Sender",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Stores a chat message or text into Langflow tables or an external memory.",
            "icon": "save",
            "base_classes": [
              "Message"
            ],
            "display_name": "Store Message",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "stored_messages",
                "display_name": "Stored Messages",
                "method": "store_message",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message",
              "memory",
              "sender",
              "sender_name",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "helpers",
            "key": "StoreMessage",
            "lf_version": "1.1.0"
          },
          "type": "StoreMessage",
          "id": "StoreMessage-kS9bC"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 618.0262867769094,
          "y": 900.1558502214912
        },
        "dragging": false
      },
      {
        "id": "StoreMessage-zCev3",
        "type": "genericNode",
        "position": {
          "x": 1711.3506887118897,
          "y": 973.8834672876201
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "The external memory to store the message. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import HandleInput, MessageInput\nfrom axiestudio.inputs.inputs import MessageTextInput\nfrom axiestudio.memory import get_messages, store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template import Output\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n\nclass StoreMessageComponent(Component):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"save\"\n    name = \"StoreMessage\"\n\n    inputs = [\n        MessageInput(name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\"),\n    ]\n\n    def store_message(self) -> Message:\n        message = self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            self.memory.add_messages([lc_message])\n            stored = self.memory.messages\n            stored = [Message.from_lc_message(m) for m in stored]\n            if message.sender:\n                stored = [m for m in stored if m.sender == message.sender]\n        else:\n            store_message(message, flow_id=self.graph.flow_id)\n            stored = get_messages(session_id=message.session_id, sender_name=message.sender_name, sender=message.sender)\n        self.status = stored\n        return stored\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The chat message to be stored.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "",
                "display_name": "Sender",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Stores a chat message or text into Langflow tables or an external memory.",
            "icon": "save",
            "base_classes": [
              "Message"
            ],
            "display_name": "Store Message",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "stored_messages",
                "display_name": "Stored Messages",
                "method": "store_message",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message",
              "memory",
              "sender",
              "sender_name",
              "session_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "helpers",
            "key": "StoreMessage",
            "lf_version": "1.1.0"
          },
          "type": "StoreMessage",
          "id": "StoreMessage-zCev3"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 1711.3506887118897,
          "y": 973.8834672876201
        },
        "dragging": false
      },
      {
        "id": "TavilyAISearch-9oILC",
        "type": "genericNode",
        "position": {
          "x": 1178.4377198024292,
          "y": -145.09571133121335
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Tavily API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Tavily API Key.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from enum import Enum\n\nimport httpx\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom loguru import logger\nfrom pydantic import BaseModel, Field\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom axiestudio.schema import Data\n\n\nclass TavilySearchDepth(Enum):\n    BASIC = \"basic\"\n    ADVANCED = \"advanced\"\n\n\nclass TavilySearchTopic(Enum):\n    GENERAL = \"general\"\n    NEWS = \"news\"\n\n\nclass TavilySearchSchema(BaseModel):\n    query: str = Field(..., description=\"The search query you want to execute with Tavily.\")\n    search_depth: TavilySearchDepth = Field(TavilySearchDepth.BASIC, description=\"The depth of the search.\")\n    topic: TavilySearchTopic = Field(TavilySearchTopic.GENERAL, description=\"The category of the search.\")\n    max_results: int = Field(5, description=\"The maximum number of search results to return.\")\n    include_images: bool = Field(default=False, description=\"Include a list of query-related images in the response.\")\n    include_answer: bool = Field(default=False, description=\"Include a short answer to original query.\")\n\n\nclass TavilySearchToolComponent(LCToolComponent):\n    display_name = \"Tavily AI Search\"\n    description = \"\"\"**Tavily AI** is a search engine optimized for LLMs and RAG, \\\n        aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n\"\"\"\n    icon = \"TavilyIcon\"\n    name = \"TavilyAISearch\"\n    documentation = \"https://docs.tavily.com/\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Tavily API Key\",\n            required=True,\n            info=\"Your Tavily API Key.\",\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The search query you want to execute with Tavily.\",\n        ),\n        DropdownInput(\n            name=\"search_depth\",\n            display_name=\"Search Depth\",\n            info=\"The depth of the search.\",\n            options=list(TavilySearchDepth),\n            value=TavilySearchDepth.ADVANCED,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"topic\",\n            display_name=\"Search Topic\",\n            info=\"The category of the search.\",\n            options=list(TavilySearchTopic),\n            value=TavilySearchTopic.GENERAL,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"The maximum number of search results to return.\",\n            value=5,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_images\",\n            display_name=\"Include Images\",\n            info=\"Include a list of query-related images in the response.\",\n            value=True,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_answer\",\n            display_name=\"Include Answer\",\n            info=\"Include a short answer to original query.\",\n            value=True,\n            advanced=True,\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        # Convert string values to enum instances with validation\n        try:\n            search_depth_enum = (\n                self.search_depth\n                if isinstance(self.search_depth, TavilySearchDepth)\n                else TavilySearchDepth(str(self.search_depth).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid search depth value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        try:\n            topic_enum = (\n                self.topic if isinstance(self.topic, TavilySearchTopic) else TavilySearchTopic(str(self.topic).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid topic value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        return self._tavily_search(\n            self.query,\n            search_depth=search_depth_enum,\n            topic=topic_enum,\n            max_results=self.max_results,\n            include_images=self.include_images,\n            include_answer=self.include_answer,\n        )\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"tavily_search\",\n            description=\"Perform a web search using the Tavily API.\",\n            func=self._tavily_search,\n            args_schema=TavilySearchSchema,\n        )\n\n    def _tavily_search(\n        self,\n        query: str,\n        *,\n        search_depth: TavilySearchDepth = TavilySearchDepth.BASIC,\n        topic: TavilySearchTopic = TavilySearchTopic.GENERAL,\n        max_results: int = 5,\n        include_images: bool = False,\n        include_answer: bool = False,\n    ) -> list[Data]:\n        # Validate enum values\n        if not isinstance(search_depth, TavilySearchDepth):\n            msg = f\"Invalid search_depth value: {search_depth}\"\n            raise TypeError(msg)\n        if not isinstance(topic, TavilySearchTopic):\n            msg = f\"Invalid topic value: {topic}\"\n            raise TypeError(msg)\n\n        try:\n            url = \"https://api.tavily.com/search\"\n            headers = {\n                \"content-type\": \"application/json\",\n                \"accept\": \"application/json\",\n            }\n            payload = {\n                \"api_key\": self.api_key,\n                \"query\": query,\n                \"search_depth\": search_depth.value,\n                \"topic\": topic.value,\n                \"max_results\": max_results,\n                \"include_images\": include_images,\n                \"include_answer\": include_answer,\n            }\n\n            with httpx.Client() as client:\n                response = client.post(url, json=payload, headers=headers)\n\n            response.raise_for_status()\n            search_results = response.json()\n\n            data_results = [\n                Data(\n                    data={\n                        \"title\": result.get(\"title\"),\n                        \"url\": result.get(\"url\"),\n                        \"content\": result.get(\"content\"),\n                        \"score\": result.get(\"score\"),\n                    }\n                )\n                for result in search_results.get(\"results\", [])\n            ]\n\n            if include_answer and search_results.get(\"answer\"):\n                data_results.insert(0, Data(data={\"answer\": search_results[\"answer\"]}))\n\n            if include_images and search_results.get(\"images\"):\n                data_results.append(Data(data={\"images\": search_results[\"images\"]}))\n\n            self.status = data_results  # type: ignore[assignment]\n\n        except httpx.HTTPStatusError as e:\n            error_message = f\"HTTP error: {e.response.status_code} - {e.response.text}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n        except Exception as e:\n            error_message = f\"Unexpected error: {e}\"\n            logger.opt(exception=True).debug(\"Error running Tavily Search\")\n            self.status = error_message\n            raise ToolException(error_message) from e\n        return data_results\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "include_answer": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "include_answer",
                "value": true,
                "display_name": "Include Answer",
                "advanced": true,
                "dynamic": false,
                "info": "Include a short answer to original query.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "include_images": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "include_images",
                "value": true,
                "display_name": "Include Images",
                "advanced": true,
                "dynamic": false,
                "info": "Include a list of query-related images in the response.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_results",
                "value": 5,
                "display_name": "Max Results",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of search results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The search query you want to execute with Tavily.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "search_depth": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "basic",
                  "advanced"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_depth",
                "value": "advanced",
                "display_name": "Search Depth",
                "advanced": true,
                "dynamic": false,
                "info": "The depth of the search.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "topic": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "general",
                  "news"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "topic",
                "value": "general",
                "display_name": "Search Topic",
                "advanced": true,
                "dynamic": false,
                "info": "The category of the search.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "**Tavily AI** is a search engine optimized for LLMs and RAG,         aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n",
            "icon": "TavilyIcon",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "Tavily AI Search",
            "documentation": "https://docs.tavily.com/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key"
                ]
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key"
                ]
              }
            ],
            "field_order": [
              "api_key",
              "query",
              "search_depth",
              "topic",
              "max_results",
              "include_images",
              "include_answer"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "tools",
            "key": "TavilyAISearch",
            "lf_version": "1.1.0"
          },
          "type": "TavilyAISearch",
          "id": "TavilyAISearch-9oILC"
        },
        "selected": false,
        "width": 320,
        "height": 482,
        "positionAbsolute": {
          "x": 1178.4377198024292,
          "y": -145.09571133121335
        },
        "dragging": false
      },
      {
        "id": "Prompt-pHoKD",
        "type": "genericNode",
        "position": {
          "x": 1717.1434941338093,
          "y": 241.15182519947098
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are a friendly and knowledgeable AI Travel Agent Assistant. You have a passion for travel and enjoy helping people plan their perfect trips. You're eficiente, adaptable, and always prioritize the traveler's needs and preferences.\n\n## Instructions\n\n1. Understand the user's travel needs:\n   - Ask about destinations, dates, budget, and preferences.\n   - Clarify any ambiguous information.\n\n2. Provide tailored travel advice:\n   - Suggest destinations based on user preferences.\n   - Offer tips on accommodations, attractions, and local customs.\n   - Help create balanced itineraries.\n\n3. Assist with budgeting:\n   - Provide estimated costs for various aspects of the trip.\n   - Suggest ways to optimize spending.\n\n4. Use your tools effectively:\n   - Search Tool: Find up-to-date travel information.\n   - Calculator Tool: Perform budget calculations and currency conversions.\n\n5. Ensure a positive interaction:\n   - Be concise but offer to elaborate when needed.\n   - Maintain an enthusiastic and helpful tone.\n   - Adapt your suggestions based on user feedback.\n\n6. Promote responsible travel:\n   - Offer tips on sustainable and respectful tourism when appropriate.\n\nRemember, your goal is to help users plan trips that match their desires while providing practical and valuable advice. Always prioritize the user's stated preferences and budget constraints in your recommendations.",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.1.0"
          },
          "id": "Prompt-pHoKD"
        },
        "selected": false,
        "width": 320,
        "height": 259,
        "positionAbsolute": {
          "x": 1717.1434941338093,
          "y": 241.15182519947098
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatInput-Tdj5J",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-VOGPG",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-VOGPG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Tdj5J",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-Tdj5J{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-VOGPG{œfieldNameœ:œinput_valueœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Agent-VOGPG",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-VOGPGœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-ASkuo",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ASkuoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-ASkuo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-VOGPG",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-VOGPG{œdataTypeœ:œAgentœ,œidœ:œAgent-VOGPGœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ASkuo{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ASkuoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "CalculatorTool-wBGpz",
        "sourceHandle": "{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-wBGpzœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-VOGPG",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-VOGPG",
            "inputTypes": [
              "Tool",
              "BaseTool",
              "StructuredTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CalculatorTool",
            "id": "CalculatorTool-wBGpz",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-CalculatorTool-wBGpz{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-wBGpzœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-VOGPG{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-Tdj5J",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StoreMessage-kS9bC",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "StoreMessage-kS9bC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-Tdj5J",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-Tdj5J{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-StoreMessage-kS9bC{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "AstraDBChatMemory-cgiAN",
        "sourceHandle": "{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}",
        "target": "StoreMessage-kS9bC",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "StoreMessage-kS9bC",
            "inputTypes": [
              "BaseChatMessageHistory"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraDBChatMemory",
            "id": "AstraDBChatMemory-cgiAN",
            "name": "memory",
            "output_types": [
              "BaseChatMessageHistory"
            ]
          }
        },
        "id": "reactflow__edge-AstraDBChatMemory-cgiAN{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}-StoreMessage-kS9bC{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatOutput-ASkuo",
        "sourceHandle": "{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-ASkuoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StoreMessage-zCev3",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "StoreMessage-zCev3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatOutput",
            "id": "ChatOutput-ASkuo",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatOutput-ASkuo{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-ASkuoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-StoreMessage-zCev3{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "AstraDBChatMemory-cgiAN",
        "sourceHandle": "{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}",
        "target": "StoreMessage-zCev3",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "StoreMessage-zCev3",
            "inputTypes": [
              "BaseChatMessageHistory"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "AstraDBChatMemory",
            "id": "AstraDBChatMemory-cgiAN",
            "name": "memory",
            "output_types": [
              "BaseChatMessageHistory"
            ]
          }
        },
        "id": "reactflow__edge-AstraDBChatMemory-cgiAN{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}-StoreMessage-zCev3{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "TavilyAISearch-9oILC",
        "sourceHandle": "{œdataTypeœ:œTavilyAISearchœ,œidœ:œTavilyAISearch-9oILCœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-VOGPG",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-VOGPG",
            "inputTypes": [
              "Tool",
              "BaseTool",
              "StructuredTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "TavilyAISearch",
            "id": "TavilyAISearch-9oILC",
            "name": "api_build_tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-TavilyAISearch-9oILC{œdataTypeœ:œTavilyAISearchœ,œidœ:œTavilyAISearch-9oILCœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-VOGPG{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-pHoKD",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-pHoKDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-VOGPG",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-VOGPG",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-pHoKD",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-pHoKD{œdataTypeœ:œPromptœ,œidœ:œPrompt-pHoKDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-VOGPG{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 284.6887795526418,
      "y": 99.04338394407398,
      "zoom": 0.42071115254901514
    }
  },
  "metadata": {
    "ChatInput": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "Agent": {
      "count": 1
    },
    "CalculatorTool": {
      "count": 1
    },
    "AstraDBChatMemory": {
      "count": 1
    },
    "StoreMessage": {
      "count": 2
    },
    "TavilyAISearch": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "total": 9
  },
  "original": {
    "id": "d7054d56-5010-4efe-a492-052eb375a270",
    "name": "Simple Travel Agent v.1.1",
    "description": "Here's a beginner-friendly example of a simple agent flow, perfect for anyone just getting started with agents. This walkthrough is designed to help you grasp the basics of how agents operate, providing a solid foundation for understanding the core steps and logic they use to complete tasks or solve problems.  ",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "28",
    "metadata": {
      "ChatInput": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "Agent": {
        "count": 1
      },
      "CalculatorTool": {
        "count": 1
      },
      "AstraDBChatMemory": {
        "count": 1
      },
      "StoreMessage": {
        "count": 2
      },
      "TavilyAISearch": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "total": 9
    },
    "last_tested_version": "1.1.0",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "ChatInput-Tdj5J",
          "type": "genericNode",
          "position": {
            "x": 609.4960180759202,
            "y": 577.3977387113978
          },
          "data": {
            "type": "ChatInput",
            "node": {
              "template": {
                "_type": "Component",
                "files": {
                  "trace_as_metadata": true,
                  "file_path": "",
                  "fileTypes": [
                    "txt",
                    "md",
                    "mdx",
                    "csv",
                    "json",
                    "yaml",
                    "yml",
                    "xml",
                    "html",
                    "htm",
                    "pdf",
                    "docx",
                    "py",
                    "sh",
                    "sql",
                    "js",
                    "ts",
                    "tsx",
                    "jpg",
                    "jpeg",
                    "png",
                    "bmp",
                    "image"
                  ],
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "files",
                  "value": "",
                  "display_name": "Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Files to be sent with the message.",
                  "title_case": false,
                  "type": "file",
                  "_input_type": "FileInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_NAME_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "what is my name?",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as input.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "User",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Get chat inputs from the Playground.",
              "icon": "ChatInput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Input",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "files"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.1.0"
            },
            "id": "ChatInput-Tdj5J"
          },
          "selected": false,
          "width": 320,
          "height": 233,
          "positionAbsolute": {
            "x": 609.4960180759202,
            "y": 577.3977387113978
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-ASkuo",
          "type": "genericNode",
          "position": {
            "x": 1705.9387678769672,
            "y": 633.4973168994502
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.1.0"
            },
            "id": "ChatOutput-ASkuo"
          },
          "selected": false,
          "width": 320,
          "height": 233,
          "positionAbsolute": {
            "x": 1705.9387678769672,
            "y": 633.4973168994502
          },
          "dragging": false
        },
        {
          "id": "Agent-VOGPG",
          "type": "genericNode",
          "position": {
            "x": 1177.2843447786609,
            "y": 425.0000000000001
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "output_parser": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_parser",
                  "value": "",
                  "display_name": "Output Parser",
                  "advanced": true,
                  "input_types": [
                    "OutputParser"
                  ],
                  "dynamic": false,
                  "info": "The parser to use to parse the output of the model",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "tools": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "tools",
                  "value": "",
                  "display_name": "Tools",
                  "advanced": false,
                  "input_types": [
                    "Tool",
                    "BaseTool",
                    "StructuredTool"
                  ],
                  "dynamic": false,
                  "info": "These are the tools that the agent can use to help with tasks.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "add_current_date_tool": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "add_current_date_tool",
                  "value": true,
                  "display_name": "Add tool Current Date",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, will add a tool to the agent that returns the current date.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "agent_description": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "agent_description",
                  "value": "A helpful assistant with access to the following tools:",
                  "display_name": "Agent Description",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "agent_llm": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Amazon Bedrock",
                    "Anthropic",
                    "Azure OpenAI",
                    "Groq",
                    "NVIDIA",
                    "OpenAI",
                    "Custom"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "agent_llm",
                  "value": "OpenAI",
                  "display_name": "Model Provider",
                  "advanced": false,
                  "input_types": [],
                  "dynamic": false,
                  "info": "The provider of the language model that the agent will use to generate responses.",
                  "real_time_refresh": true,
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "api_key": {
                  "load_from_db": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_core.tools import StructuredTool\n\nfrom axiestudio.base.agents.agent import LCToolsAgentComponent\nfrom axiestudio.base.models.model_input_constants import ALL_PROVIDER_FIELDS, MODEL_PROVIDERS_DICT\nfrom axiestudio.base.models.model_utils import get_model_name\nfrom axiestudio.components.helpers import CurrentDateComponent\nfrom axiestudio.components.helpers.memory import MemoryComponent\nfrom axiestudio.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom axiestudio.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom axiestudio.schema.dotdict import dotdict\nfrom axiestudio.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Add tool Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        llm_model, display_name = self.get_llm()\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n        if llm_model is None:\n            msg = \"No language model selected\"\n            raise ValueError(msg)\n        self.chat_history = self.get_memory_data()\n\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            # Convert CurrentDateComponent to a StructuredTool\n            current_date_tool = CurrentDateComponent().to_toolkit()[0]\n            if isinstance(current_date_tool, StructuredTool):\n                self.tools.append(current_date_tool)\n            else:\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise ValueError(msg)\n\n        if not self.tools:\n            msg = \"Tools are required to run the agent.\"\n            raise ValueError(msg)\n        self.set(\n            llm=llm_model,\n            tools=self.tools,\n            chat_history=self.chat_history,\n            input_value=self.input_value,\n            system_prompt=self.system_prompt,\n        )\n        agent = self.create_agent_runnable()\n        return await self.run_agent(agent)\n\n    def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n\n        return MemoryComponent().set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if isinstance(self.agent_llm, str):\n            try:\n                provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n                if provider_info:\n                    component_class = provider_info.get(\"component_class\")\n                    display_name = component_class.display_name\n                    inputs = provider_info.get(\"inputs\")\n                    prefix = provider_info.get(\"prefix\", \"\")\n                    return self._build_llm_model(component_class, inputs, prefix), display_name\n            except Exception as e:\n                msg = f\"Error building {self.agent_llm} language model\"\n                raise ValueError(msg) from e\n        return self.agent_llm, None\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: str, field_name: str | None = None) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name == \"agent_llm\":\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if isinstance(self.agent_llm, str) and self.agent_llm in MODEL_PROVIDERS_DICT:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n        return build_config\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "handle_parsing_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "handle_parsing_errors",
                  "value": true,
                  "display_name": "Handle Parse Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Should the Agent fix errors when reading user input for better processing?",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "input_value": {
                  "tool_mode": true,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The input provided by the user for the agent to process.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_iterations": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_iterations",
                  "value": 15,
                  "display_name": "Max Iterations",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Additional keyword arguments to pass to the model.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "n_messages": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "n_messages",
                  "value": 100,
                  "display_name": "Number of Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of messages to retrieve.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "order": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Ascending",
                    "Descending"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "order",
                  "value": "Ascending",
                  "display_name": "Order",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Order of the messages.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "sender": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User",
                    "Machine and User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine and User",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Filter by sender type.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Filter by sender name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "system_prompt": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_prompt",
                  "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                  "display_name": "Agent Instructions",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "template": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "{sender_name}: {text}",
                  "display_name": "Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "verbose": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "verbose",
                  "value": true,
                  "display_name": "Verbose",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Define the agent's instructions, then enter a task to complete using tools.",
              "icon": "bot",
              "base_classes": [
                "Message"
              ],
              "display_name": "Agent",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "response",
                  "display_name": "Response",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "agent_llm",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed",
                "output_parser",
                "system_prompt",
                "tools",
                "input_value",
                "handle_parsing_errors",
                "verbose",
                "max_iterations",
                "agent_description",
                "memory",
                "sender",
                "sender_name",
                "n_messages",
                "session_id",
                "order",
                "template",
                "add_current_date_tool"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "agents",
              "key": "Agent",
              "lf_version": "1.1.0"
            },
            "type": "Agent",
            "id": "Agent-VOGPG"
          },
          "selected": false,
          "width": 320,
          "height": 695,
          "dragging": false
        },
        {
          "id": "CalculatorTool-wBGpz",
          "type": "genericNode",
          "position": {
            "x": 602.9236617730055,
            "y": 222.94388312138466
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import ast\nimport operator\n\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom loguru import logger\nfrom pydantic import BaseModel, Field\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.inputs import MessageTextInput\nfrom axiestudio.schema import Data\n\n\nclass CalculatorToolComponent(LCToolComponent):\n    display_name = \"Calculator\"\n    description = \"Perform basic arithmetic operations on a given expression.\"\n    icon = \"calculator\"\n    name = \"CalculatorTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"expression\",\n            display_name=\"Expression\",\n            info=\"The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').\",\n            tool_mode=True,\n        ),\n    ]\n\n    class CalculatorToolSchema(BaseModel):\n        expression: str = Field(..., description=\"The arithmetic expression to evaluate.\")\n\n    def run_model(self) -> list[Data]:\n        return self._evaluate_expression(self.expression)\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"calculator\",\n            description=\"Evaluate basic arithmetic expressions. Input should be a string containing the expression.\",\n            func=self._eval_expr_with_error,\n            args_schema=self.CalculatorToolSchema,\n        )\n\n    def _eval_expr(self, node):\n        # Define the allowed operators\n        operators = {\n            ast.Add: operator.add,\n            ast.Sub: operator.sub,\n            ast.Mult: operator.mul,\n            ast.Div: operator.truediv,\n            ast.Pow: operator.pow,\n        }\n        if isinstance(node, ast.Num):\n            return node.n\n        if isinstance(node, ast.BinOp):\n            return operators[type(node.op)](self._eval_expr(node.left), self._eval_expr(node.right))\n        if isinstance(node, ast.UnaryOp):\n            return operators[type(node.op)](self._eval_expr(node.operand))\n        if isinstance(node, ast.Call):\n            msg = (\n                \"Function calls like sqrt(), sin(), cos() etc. are not supported. \"\n                \"Only basic arithmetic operations (+, -, *, /, **) are allowed.\"\n            )\n            raise TypeError(msg)\n        msg = f\"Unsupported operation or expression type: {type(node).__name__}\"\n        raise TypeError(msg)\n\n    def _eval_expr_with_error(self, expression: str) -> list[Data]:\n        try:\n            return self._evaluate_expression(expression)\n        except Exception as e:\n            raise ToolException(str(e)) from e\n\n    def _evaluate_expression(self, expression: str) -> list[Data]:\n        try:\n            # Parse the expression and evaluate it\n            tree = ast.parse(expression, mode=\"eval\")\n            result = self._eval_expr(tree.body)\n\n            # Format the result to a reasonable number of decimal places\n            formatted_result = f\"{result:.6f}\".rstrip(\"0\").rstrip(\".\")\n\n            self.status = formatted_result\n            return [Data(data={\"result\": formatted_result})]\n\n        except (SyntaxError, TypeError, KeyError) as e:\n            error_message = f\"Invalid expression: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except ZeroDivisionError:\n            error_message = \"Error: Division by zero\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n        except Exception as e:  # noqa: BLE001\n            logger.opt(exception=True).debug(\"Error evaluating expression\")\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message, \"input\": expression})]\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "expression": {
                  "tool_mode": true,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "expression",
                  "value": "",
                  "display_name": "Expression",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The arithmetic expression to evaluate (e.g., '4*4*(33/22)+12-20').",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Perform basic arithmetic operations on a given expression.",
              "icon": "calculator",
              "base_classes": [
                "Data",
                "Tool"
              ],
              "display_name": "Calculator",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                }
              ],
              "field_order": [
                "expression"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "tools",
              "key": "CalculatorTool",
              "lf_version": "1.1.0"
            },
            "type": "CalculatorTool",
            "id": "CalculatorTool-wBGpz"
          },
          "selected": false,
          "width": 320,
          "height": 301,
          "positionAbsolute": {
            "x": 602.9236617730055,
            "y": 222.94388312138466
          },
          "dragging": false
        },
        {
          "id": "AstraDBChatMemory-cgiAN",
          "type": "genericNode",
          "position": {
            "x": 1163.457295299928,
            "y": 1187.2077281198465
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "api_endpoint": {
                  "load_from_db": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_endpoint",
                  "value": "",
                  "display_name": "API Endpoint",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "API endpoint URL for the Astra DB service.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import os\n\nfrom astrapy.admin import parse_api_endpoint\n\nfrom axiestudio.base.memory.model import LCChatMemoryComponent\nfrom axiestudio.field_typing import BaseChatMessageHistory\nfrom axiestudio.inputs import MessageTextInput, SecretStrInput, StrInput\n\n\nclass AstraDBChatMemory(LCChatMemoryComponent):\n    display_name = \"Astra DB Chat Memory\"\n    description = \"Retrieves and store chat messages from Astra DB.\"\n    name = \"AstraDBChatMemory\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            advanced=os.getenv(\"ASTRA_ENHANCED\", \"false\").lower() == \"true\",\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_message_history(self) -> BaseChatMessageHistory:\n        try:\n            from langchain_astradb.chat_message_histories import AstraDBChatMessageHistory\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        return AstraDBChatMessageHistory(\n            session_id=self.session_id,\n            collection_name=self.collection_name,\n            token=self.token,\n            api_endpoint=self.api_endpoint,\n            namespace=self.namespace or None,\n            environment=parse_api_endpoint(self.api_endpoint).environment,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "collection_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "collection_name",
                  "value": "chathistory",
                  "display_name": "Collection Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The name of the collection within Astra DB where the vectors will be stored.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "namespace": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "namespace",
                  "value": "",
                  "display_name": "Namespace",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Optional namespace within Astra DB to use for the collection.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "session_id": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "token": {
                  "load_from_db": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "token",
                  "value": "",
                  "display_name": "Astra DB Application Token",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Authentication token for accessing Astra DB.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                }
              },
              "description": "Retrieves and store chat messages from Astra DB.",
              "icon": "AstraDB",
              "base_classes": [
                "BaseChatMessageHistory"
              ],
              "display_name": "Astra DB Chat Memory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "BaseChatMessageHistory"
                  ],
                  "selected": "BaseChatMessageHistory",
                  "name": "memory",
                  "display_name": "Memory",
                  "method": "build_message_history",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [
                    "api_endpoint",
                    "collection_name",
                    "token"
                  ]
                }
              ],
              "field_order": [
                "token",
                "api_endpoint",
                "collection_name",
                "namespace",
                "session_id"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "memories",
              "key": "AstraDBChatMemory",
              "lf_version": "1.1.0"
            },
            "type": "AstraDBChatMemory",
            "id": "AstraDBChatMemory-cgiAN"
          },
          "selected": false,
          "width": 320,
          "height": 429,
          "dragging": false,
          "positionAbsolute": {
            "x": 1163.457295299928,
            "y": 1187.2077281198465
          }
        },
        {
          "id": "StoreMessage-kS9bC",
          "type": "genericNode",
          "position": {
            "x": 618.0262867769094,
            "y": 900.1558502214912
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "The external memory to store the message. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import HandleInput, MessageInput\nfrom axiestudio.inputs.inputs import MessageTextInput\nfrom axiestudio.memory import get_messages, store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template import Output\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n\nclass StoreMessageComponent(Component):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"save\"\n    name = \"StoreMessage\"\n\n    inputs = [\n        MessageInput(name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\"),\n    ]\n\n    def store_message(self) -> Message:\n        message = self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            self.memory.add_messages([lc_message])\n            stored = self.memory.messages\n            stored = [Message.from_lc_message(m) for m in stored]\n            if message.sender:\n                stored = [m for m in stored if m.sender == message.sender]\n        else:\n            store_message(message, flow_id=self.graph.flow_id)\n            stored = get_messages(session_id=message.session_id, sender_name=message.sender_name, sender=message.sender)\n        self.status = stored\n        return stored\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "message",
                  "value": "",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The chat message to be stored.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "sender": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "",
                  "display_name": "Sender",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender_name": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Stores a chat message or text into Langflow tables or an external memory.",
              "icon": "save",
              "base_classes": [
                "Message"
              ],
              "display_name": "Store Message",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "stored_messages",
                  "display_name": "Stored Messages",
                  "method": "store_message",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "message",
                "memory",
                "sender",
                "sender_name",
                "session_id"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "helpers",
              "key": "StoreMessage",
              "lf_version": "1.1.0"
            },
            "type": "StoreMessage",
            "id": "StoreMessage-kS9bC"
          },
          "selected": false,
          "width": 320,
          "height": 301,
          "positionAbsolute": {
            "x": 618.0262867769094,
            "y": 900.1558502214912
          },
          "dragging": false
        },
        {
          "id": "StoreMessage-zCev3",
          "type": "genericNode",
          "position": {
            "x": 1711.3506887118897,
            "y": 973.8834672876201
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "memory": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "memory",
                  "value": "",
                  "display_name": "External Memory",
                  "advanced": false,
                  "input_types": [
                    "BaseChatMessageHistory"
                  ],
                  "dynamic": false,
                  "info": "The external memory to store the message. If empty, it will use the Langflow tables.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.inputs import HandleInput, MessageInput\nfrom axiestudio.inputs.inputs import MessageTextInput\nfrom axiestudio.memory import get_messages, store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template import Output\nfrom axiestudio.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI\n\n\nclass StoreMessageComponent(Component):\n    display_name = \"Store Message\"\n    description = \"Stores a chat message or text into Langflow tables or an external memory.\"\n    icon = \"save\"\n    name = \"StoreMessage\"\n\n    inputs = [\n        MessageInput(name=\"message\", display_name=\"Message\", info=\"The chat message to be stored.\", required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"The external memory to store the message. If empty, it will use the Langflow tables.\",\n        ),\n        MessageTextInput(\n            name=\"sender\",\n            display_name=\"Sender\",\n            info=\"The sender of the message. Might be Machine or User. \"\n            \"If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            value=\"\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Stored Messages\", name=\"stored_messages\", method=\"store_message\"),\n    ]\n\n    def store_message(self) -> Message:\n        message = self.message\n\n        message.session_id = self.session_id or message.session_id\n        message.sender = self.sender or message.sender or MESSAGE_SENDER_AI\n        message.sender_name = self.sender_name or message.sender_name or MESSAGE_SENDER_NAME_AI\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = message.session_id\n            lc_message = message.to_lc_message()\n            self.memory.add_messages([lc_message])\n            stored = self.memory.messages\n            stored = [Message.from_lc_message(m) for m in stored]\n            if message.sender:\n                stored = [m for m in stored if m.sender == message.sender]\n        else:\n            store_message(message, flow_id=self.graph.flow_id)\n            stored = get_messages(session_id=message.session_id, sender_name=message.sender_name, sender=message.sender)\n        self.status = stored\n        return stored\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "message",
                  "value": "",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The chat message to be stored.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "sender": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "",
                  "display_name": "Sender",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The sender of the message. Might be Machine or User. If empty, the current sender parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender_name": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The name of the sender. Might be AI or User. If empty, the current sender parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Stores a chat message or text into Langflow tables or an external memory.",
              "icon": "save",
              "base_classes": [
                "Message"
              ],
              "display_name": "Store Message",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "stored_messages",
                  "display_name": "Stored Messages",
                  "method": "store_message",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "message",
                "memory",
                "sender",
                "sender_name",
                "session_id"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "helpers",
              "key": "StoreMessage",
              "lf_version": "1.1.0"
            },
            "type": "StoreMessage",
            "id": "StoreMessage-zCev3"
          },
          "selected": false,
          "width": 320,
          "height": 301,
          "positionAbsolute": {
            "x": 1711.3506887118897,
            "y": 973.8834672876201
          },
          "dragging": false
        },
        {
          "id": "TavilyAISearch-9oILC",
          "type": "genericNode",
          "position": {
            "x": 1178.4377198024292,
            "y": -145.09571133121335
          },
          "data": {
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "Tavily API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Your Tavily API Key.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from enum import Enum\n\nimport httpx\nfrom langchain.tools import StructuredTool\nfrom langchain_core.tools import ToolException\nfrom loguru import logger\nfrom pydantic import BaseModel, Field\n\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\nfrom axiestudio.field_typing import Tool\nfrom axiestudio.inputs import BoolInput, DropdownInput, IntInput, MessageTextInput, SecretStrInput\nfrom axiestudio.schema import Data\n\n\nclass TavilySearchDepth(Enum):\n    BASIC = \"basic\"\n    ADVANCED = \"advanced\"\n\n\nclass TavilySearchTopic(Enum):\n    GENERAL = \"general\"\n    NEWS = \"news\"\n\n\nclass TavilySearchSchema(BaseModel):\n    query: str = Field(..., description=\"The search query you want to execute with Tavily.\")\n    search_depth: TavilySearchDepth = Field(TavilySearchDepth.BASIC, description=\"The depth of the search.\")\n    topic: TavilySearchTopic = Field(TavilySearchTopic.GENERAL, description=\"The category of the search.\")\n    max_results: int = Field(5, description=\"The maximum number of search results to return.\")\n    include_images: bool = Field(default=False, description=\"Include a list of query-related images in the response.\")\n    include_answer: bool = Field(default=False, description=\"Include a short answer to original query.\")\n\n\nclass TavilySearchToolComponent(LCToolComponent):\n    display_name = \"Tavily AI Search\"\n    description = \"\"\"**Tavily AI** is a search engine optimized for LLMs and RAG, \\\n        aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n\"\"\"\n    icon = \"TavilyIcon\"\n    name = \"TavilyAISearch\"\n    documentation = \"https://docs.tavily.com/\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Tavily API Key\",\n            required=True,\n            info=\"Your Tavily API Key.\",\n        ),\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Search Query\",\n            info=\"The search query you want to execute with Tavily.\",\n        ),\n        DropdownInput(\n            name=\"search_depth\",\n            display_name=\"Search Depth\",\n            info=\"The depth of the search.\",\n            options=list(TavilySearchDepth),\n            value=TavilySearchDepth.ADVANCED,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"topic\",\n            display_name=\"Search Topic\",\n            info=\"The category of the search.\",\n            options=list(TavilySearchTopic),\n            value=TavilySearchTopic.GENERAL,\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            info=\"The maximum number of search results to return.\",\n            value=5,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_images\",\n            display_name=\"Include Images\",\n            info=\"Include a list of query-related images in the response.\",\n            value=True,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_answer\",\n            display_name=\"Include Answer\",\n            info=\"Include a short answer to original query.\",\n            value=True,\n            advanced=True,\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        # Convert string values to enum instances with validation\n        try:\n            search_depth_enum = (\n                self.search_depth\n                if isinstance(self.search_depth, TavilySearchDepth)\n                else TavilySearchDepth(str(self.search_depth).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid search depth value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        try:\n            topic_enum = (\n                self.topic if isinstance(self.topic, TavilySearchTopic) else TavilySearchTopic(str(self.topic).lower())\n            )\n        except ValueError as e:\n            error_message = f\"Invalid topic value: {e!s}\"\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        return self._tavily_search(\n            self.query,\n            search_depth=search_depth_enum,\n            topic=topic_enum,\n            max_results=self.max_results,\n            include_images=self.include_images,\n            include_answer=self.include_answer,\n        )\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"tavily_search\",\n            description=\"Perform a web search using the Tavily API.\",\n            func=self._tavily_search,\n            args_schema=TavilySearchSchema,\n        )\n\n    def _tavily_search(\n        self,\n        query: str,\n        *,\n        search_depth: TavilySearchDepth = TavilySearchDepth.BASIC,\n        topic: TavilySearchTopic = TavilySearchTopic.GENERAL,\n        max_results: int = 5,\n        include_images: bool = False,\n        include_answer: bool = False,\n    ) -> list[Data]:\n        # Validate enum values\n        if not isinstance(search_depth, TavilySearchDepth):\n            msg = f\"Invalid search_depth value: {search_depth}\"\n            raise TypeError(msg)\n        if not isinstance(topic, TavilySearchTopic):\n            msg = f\"Invalid topic value: {topic}\"\n            raise TypeError(msg)\n\n        try:\n            url = \"https://api.tavily.com/search\"\n            headers = {\n                \"content-type\": \"application/json\",\n                \"accept\": \"application/json\",\n            }\n            payload = {\n                \"api_key\": self.api_key,\n                \"query\": query,\n                \"search_depth\": search_depth.value,\n                \"topic\": topic.value,\n                \"max_results\": max_results,\n                \"include_images\": include_images,\n                \"include_answer\": include_answer,\n            }\n\n            with httpx.Client() as client:\n                response = client.post(url, json=payload, headers=headers)\n\n            response.raise_for_status()\n            search_results = response.json()\n\n            data_results = [\n                Data(\n                    data={\n                        \"title\": result.get(\"title\"),\n                        \"url\": result.get(\"url\"),\n                        \"content\": result.get(\"content\"),\n                        \"score\": result.get(\"score\"),\n                    }\n                )\n                for result in search_results.get(\"results\", [])\n            ]\n\n            if include_answer and search_results.get(\"answer\"):\n                data_results.insert(0, Data(data={\"answer\": search_results[\"answer\"]}))\n\n            if include_images and search_results.get(\"images\"):\n                data_results.append(Data(data={\"images\": search_results[\"images\"]}))\n\n            self.status = data_results  # type: ignore[assignment]\n\n        except httpx.HTTPStatusError as e:\n            error_message = f\"HTTP error: {e.response.status_code} - {e.response.text}\"\n            logger.debug(error_message)\n            self.status = error_message\n            raise ToolException(error_message) from e\n        except Exception as e:\n            error_message = f\"Unexpected error: {e}\"\n            logger.opt(exception=True).debug(\"Error running Tavily Search\")\n            self.status = error_message\n            raise ToolException(error_message) from e\n        return data_results\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "include_answer": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "include_answer",
                  "value": true,
                  "display_name": "Include Answer",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Include a short answer to original query.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "include_images": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "include_images",
                  "value": true,
                  "display_name": "Include Images",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Include a list of query-related images in the response.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_results",
                  "value": 5,
                  "display_name": "Max Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of search results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "query": {
                  "tool_mode": false,
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The search query you want to execute with Tavily.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "search_depth": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "basic",
                    "advanced"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_depth",
                  "value": "advanced",
                  "display_name": "Search Depth",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The depth of the search.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "topic": {
                  "tool_mode": false,
                  "trace_as_metadata": true,
                  "options": [
                    "general",
                    "news"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "topic",
                  "value": "general",
                  "display_name": "Search Topic",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The category of the search.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                }
              },
              "description": "**Tavily AI** is a search engine optimized for LLMs and RAG,         aimed at efficient, quick, and persistent search results. It can be used independently or as an agent tool.\n\nNote: Check 'Advanced' for all options.\n",
              "icon": "TavilyIcon",
              "base_classes": [
                "Data",
                "Tool"
              ],
              "display_name": "Tavily AI Search",
              "documentation": "https://docs.tavily.com/",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [
                    "api_key"
                  ]
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [
                    "api_key"
                  ]
                }
              ],
              "field_order": [
                "api_key",
                "query",
                "search_depth",
                "topic",
                "max_results",
                "include_images",
                "include_answer"
              ],
              "beta": false,
              "legacy": false,
              "edited": false,
              "metadata": {},
              "tool_mode": false,
              "category": "tools",
              "key": "TavilyAISearch",
              "lf_version": "1.1.0"
            },
            "type": "TavilyAISearch",
            "id": "TavilyAISearch-9oILC"
          },
          "selected": false,
          "width": 320,
          "height": 482,
          "positionAbsolute": {
            "x": 1178.4377198024292,
            "y": -145.09571133121335
          },
          "dragging": false
        },
        {
          "id": "Prompt-pHoKD",
          "type": "genericNode",
          "position": {
            "x": 1717.1434941338093,
            "y": 241.15182519947098
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "You are a friendly and knowledgeable AI Travel Agent Assistant. You have a passion for travel and enjoy helping people plan their perfect trips. You're eficiente, adaptable, and always prioritize the traveler's needs and preferences.\n\n## Instructions\n\n1. Understand the user's travel needs:\n   - Ask about destinations, dates, budget, and preferences.\n   - Clarify any ambiguous information.\n\n2. Provide tailored travel advice:\n   - Suggest destinations based on user preferences.\n   - Offer tips on accommodations, attractions, and local customs.\n   - Help create balanced itineraries.\n\n3. Assist with budgeting:\n   - Provide estimated costs for various aspects of the trip.\n   - Suggest ways to optimize spending.\n\n4. Use your tools effectively:\n   - Search Tool: Find up-to-date travel information.\n   - Calculator Tool: Perform budget calculations and currency conversions.\n\n5. Ensure a positive interaction:\n   - Be concise but offer to elaborate when needed.\n   - Maintain an enthusiastic and helpful tone.\n   - Adapt your suggestions based on user feedback.\n\n6. Promote responsible travel:\n   - Offer tips on sustainable and respectful tourism when appropriate.\n\nRemember, your goal is to help users plan trips that match their desires while providing practical and valuable advice. Always prioritize the user's stated preferences and budget constraints in your recommendations.",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": []
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.1.0"
            },
            "id": "Prompt-pHoKD"
          },
          "selected": false,
          "width": 320,
          "height": 259,
          "positionAbsolute": {
            "x": 1717.1434941338093,
            "y": 241.15182519947098
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ChatInput-Tdj5J",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Agent-VOGPG",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "Agent-VOGPG",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-Tdj5J",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-Tdj5J{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-VOGPG{œfieldNameœ:œinput_valueœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "Agent-VOGPG",
          "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-VOGPGœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-ASkuo",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ASkuoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-ASkuo",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Agent",
              "id": "Agent-VOGPG",
              "name": "response",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Agent-VOGPG{œdataTypeœ:œAgentœ,œidœ:œAgent-VOGPGœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ASkuo{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ASkuoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "CalculatorTool-wBGpz",
          "sourceHandle": "{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-wBGpzœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "Agent-VOGPG",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "Agent-VOGPG",
              "inputTypes": [
                "Tool",
                "BaseTool",
                "StructuredTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CalculatorTool",
              "id": "CalculatorTool-wBGpz",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-CalculatorTool-wBGpz{œdataTypeœ:œCalculatorToolœ,œidœ:œCalculatorTool-wBGpzœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-VOGPG{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "ChatInput-Tdj5J",
          "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "StoreMessage-kS9bC",
          "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "message",
              "id": "StoreMessage-kS9bC",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatInput",
              "id": "ChatInput-Tdj5J",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatInput-Tdj5J{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Tdj5Jœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-StoreMessage-kS9bC{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "AstraDBChatMemory-cgiAN",
          "sourceHandle": "{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}",
          "target": "StoreMessage-kS9bC",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "StoreMessage-kS9bC",
              "inputTypes": [
                "BaseChatMessageHistory"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AstraDBChatMemory",
              "id": "AstraDBChatMemory-cgiAN",
              "name": "memory",
              "output_types": [
                "BaseChatMessageHistory"
              ]
            }
          },
          "id": "reactflow__edge-AstraDBChatMemory-cgiAN{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}-StoreMessage-kS9bC{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-kS9bCœ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "ChatOutput-ASkuo",
          "sourceHandle": "{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-ASkuoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
          "target": "StoreMessage-zCev3",
          "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "message",
              "id": "StoreMessage-zCev3",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ChatOutput",
              "id": "ChatOutput-ASkuo",
              "name": "message",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ChatOutput-ASkuo{œdataTypeœ:œChatOutputœ,œidœ:œChatOutput-ASkuoœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-StoreMessage-zCev3{œfieldNameœ:œmessageœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "AstraDBChatMemory-cgiAN",
          "sourceHandle": "{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}",
          "target": "StoreMessage-zCev3",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "StoreMessage-zCev3",
              "inputTypes": [
                "BaseChatMessageHistory"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "AstraDBChatMemory",
              "id": "AstraDBChatMemory-cgiAN",
              "name": "memory",
              "output_types": [
                "BaseChatMessageHistory"
              ]
            }
          },
          "id": "reactflow__edge-AstraDBChatMemory-cgiAN{œdataTypeœ:œAstraDBChatMemoryœ,œidœ:œAstraDBChatMemory-cgiANœ,œnameœ:œmemoryœ,œoutput_typesœ:[œBaseChatMessageHistoryœ]}-StoreMessage-zCev3{œfieldNameœ:œmemoryœ,œidœ:œStoreMessage-zCev3œ,œinputTypesœ:[œBaseChatMessageHistoryœ],œtypeœ:œotherœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "TavilyAISearch-9oILC",
          "sourceHandle": "{œdataTypeœ:œTavilyAISearchœ,œidœ:œTavilyAISearch-9oILCœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
          "target": "Agent-VOGPG",
          "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "tools",
              "id": "Agent-VOGPG",
              "inputTypes": [
                "Tool",
                "BaseTool",
                "StructuredTool"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "TavilyAISearch",
              "id": "TavilyAISearch-9oILC",
              "name": "api_build_tool",
              "output_types": [
                "Tool"
              ]
            }
          },
          "id": "reactflow__edge-TavilyAISearch-9oILC{œdataTypeœ:œTavilyAISearchœ,œidœ:œTavilyAISearch-9oILCœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-Agent-VOGPG{œfieldNameœ:œtoolsœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
          "animated": false,
          "className": ""
        },
        {
          "source": "Prompt-pHoKD",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-pHoKDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Agent-VOGPG",
          "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "system_prompt",
              "id": "Agent-VOGPG",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-pHoKD",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-pHoKD{œdataTypeœ:œPromptœ,œidœ:œPrompt-pHoKDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-VOGPG{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-VOGPGœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "animated": false,
          "className": ""
        }
      ],
      "viewport": {
        "x": 284.6887795526418,
        "y": 99.04338394407398,
        "zoom": 0.42071115254901514
      }
    },
    "date_created": "2024-11-18T10:49:55.878Z",
    "date_updated": "2024-11-18T10:49:55.939Z",
    "status": "Public",
    "sort": null,
    "user_updated": "76f05705-dfce-454b-8d27-4f5f02d94090",
    "user_created": {
      "username": "boreilly",
      "first_name": "Betul",
      "last_name": "O'Reilly",
      "id": "76f05705-dfce-454b-8d27-4f5f02d94090"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.262Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 106,
    "converter_version": "1.0.0"
  }
}