{
  "id": "68863f61-7f80-4864-8ef6-0d7717d46bc7",
  "name": "Local CV reviewer",
  "description": "Perform SWOT Analysis on your resume (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "MarcusPeters",
    "first_name": "Marcus",
    "last_name": "Peters",
    "id": "e7cdf003-4c76-4d08-a532-39be02ad5986",
    "full_name": "Marcus Peters"
  },
  "store_url": "https://www.langflow.store/store/component/68863f61-7f80-4864-8ef6-0d7717d46bc7",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-06-11T08:41:36.179Z",
    "updated": "2024-06-11T08:41:36.232Z",
    "downloaded": "2025-08-19T17:50:05.572Z"
  },
  "tags": [
    {
      "tags_id": {
        "name": "Chain",
        "id": "d442c88b-f8d0-4010-8752-16a644c7ac8e"
      }
    },
    {
      "tags_id": {
        "name": "Prompt",
        "id": "57f5c681-a1f5-4053-be33-e9525e7eb00a"
      }
    },
    {
      "tags_id": {
        "name": "Agent",
        "id": "ccabb590-c9e8-4e56-9d6c-309955936c6c"
      }
    }
  ],
  "technical": {
    "last_tested_version": "0.6.19",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "LLMChain-tAA2L",
        "type": "genericNode",
        "position": {
          "x": -2644.6620523187803,
          "y": -929.4386519276255
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable",
              "LLMChain",
              "Chain"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "prompt": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable",
              "LLMChain"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "LLMChain-tAA2L"
        },
        "selected": false,
        "width": 384,
        "height": 424,
        "dragging": false,
        "positionAbsolute": {
          "x": -2644.6620523187803,
          "y": -929.4386519276255
        }
      },
      {
        "id": "DirectoryLoader-TMeZb",
        "type": "genericNode",
        "position": {
          "x": -3655.081812714044,
          "y": -861.651548588108
        },
        "data": {
          "type": "DirectoryLoader",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any, Dict, List\n\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders.directory import DirectoryLoader\nfrom axiestudio import CustomComponent\n\n\nclass DirectoryLoaderComponent(CustomComponent):\n    display_name = \"DirectoryLoader\"\n    description = \"Load from a directory.\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"glob\": {\"display_name\": \"Glob Pattern\", \"value\": \"**/*.txt\"},\n            \"load_hidden\": {\"display_name\": \"Load Hidden Files\", \"value\": False, \"advanced\": True},\n            \"max_concurrency\": {\"display_name\": \"Max Concurrency\", \"value\": 10, \"advanced\": True},\n            \"metadata\": {\"display_name\": \"Metadata\", \"value\": {}},\n            \"path\": {\"display_name\": \"Local Directory\"},\n            \"recursive\": {\"display_name\": \"Recursive\", \"value\": True, \"advanced\": True},\n            \"silent_errors\": {\"display_name\": \"Silent Errors\", \"value\": False, \"advanced\": True},\n            \"use_multithreading\": {\"display_name\": \"Use Multithreading\", \"value\": True, \"advanced\": True},\n        }\n\n    def build(\n        self,\n        glob: str,\n        path: str,\n        max_concurrency: int = 2,\n        load_hidden: bool = False,\n        recursive: bool = True,\n        silent_errors: bool = False,\n        use_multithreading: bool = True,\n    ) -> List[Document]:\n        return DirectoryLoader(\n            glob=glob,\n            path=path,\n            load_hidden=load_hidden,\n            max_concurrency=max_concurrency,\n            recursive=recursive,\n            silent_errors=silent_errors,\n            use_multithreading=use_multithreading,\n        ).load()\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "glob": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "**/*.pdf",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "glob",
                "display_name": "Glob Pattern",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "load_hidden": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "load_hidden",
                "display_name": "Load Hidden Files",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "max_concurrency": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 10,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_concurrency",
                "display_name": "Max Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "path": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "path",
                "display_name": "Local Directory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": "C:\\Users\\jerem\\Documents\\Notes\\copies"
              },
              "recursive": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "recursive",
                "display_name": "Recursive",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "silent_errors": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "silent_errors",
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "use_multithreading": {
                "type": "bool",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "use_multithreading",
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Load from a directory.",
            "base_classes": [
              "Document"
            ],
            "display_name": "DirectoryLoader",
            "documentation": "",
            "custom_fields": {
              "glob": null,
              "path": null,
              "max_concurrency": null,
              "load_hidden": null,
              "recursive": null,
              "silent_errors": null,
              "use_multithreading": null
            },
            "output_types": [
              "Document"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "DirectoryLoader-TMeZb"
        },
        "selected": false,
        "width": 384,
        "height": 468,
        "positionAbsolute": {
          "x": -3655.081812714044,
          "y": -861.651548588108
        },
        "dragging": false
      },
      {
        "id": "PromptTemplate-u5EO7",
        "type": "genericNode",
        "position": {
          "x": -3165.7180435727273,
          "y": -398.0299742980356
        },
        "data": {
          "type": "PromptTemplate",
          "node": {
            "template": {
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true,
                "value": [
                  "directory"
                ]
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "template": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "password": false,
                "name": "template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true,
                "value": "\nYou are a very talented machine learning professor, your role is to evaluate the group exams made by the students.\nYou will find them stored at {directory}.\nEvaluate these works regarding the following aspects : \n\n1 . Problematic selection\n2. Data exploration and data cleaning\n3. Model training process\n4. Performance evaluation\n5. Metric selection and what they are telling us\n6.Benchmark of several machine learning models\n\nRate between 0 and 10 each of these items, and give me a recap answer with the ratings and reasons\n\nNever invent answers, say you don't know if the given information is not enough to give an enlightened answer."
              },
              "template_format": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": "f-string",
                "fileTypes": [],
                "password": false,
                "name": "template_format",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "PromptTemplate",
              "directory": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "directory",
                "display_name": "directory",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "Prompt template for a language model.",
            "icon": null,
            "base_classes": [
              "PromptTemplate",
              "StringPromptTemplate",
              "BasePromptTemplate"
            ],
            "name": "",
            "display_name": "PromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
            "custom_fields": {
              "": [
                "directory"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "PromptTemplate-u5EO7",
          "description": "Prompt template for a language model.",
          "display_name": "PromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 374,
        "positionAbsolute": {
          "x": -3165.7180435727273,
          "y": -398.0299742980356
        },
        "dragging": false
      },
      {
        "id": "OllamaLLM-RZUP8",
        "type": "genericNode",
        "position": {
          "x": -3190.649363457083,
          "y": -1375.8007698183264
        },
        "data": {
          "type": "OllamaLLM",
          "node": {
            "template": {
              "base_url": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "base_url",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                "title_case": true,
                "value": "http://localhost:11434"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Optional\n\nfrom langchain.llms.base import BaseLLM\nfrom langchain_community.llms.ollama import Ollama\n\nfrom axiestudio import CustomComponent\n\n\nclass OllamaLLM(CustomComponent):\n    display_name = \"Ollama\"\n    description = \"Local LLM with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate influencing the algorithm's response to feedback.\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls balance between coherence and diversity.\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating the next token.\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation.\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation.\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"Sets how far back the model looks to prevent repetition.\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling to reduce impact of less probable tokens.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K for reducing nonsense generation.\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"int\",\n                \"info\": \"Works with top-k to control diversity of generated text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        temperature: Optional[float],\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        num_thread: Optional[int] = None,\n        repeat_last_n: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        tfs_z: Optional[float] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseLLM:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        try:\n            llm = Ollama(\n                base_url=base_url,\n                model=model,\n                mirostat=mirostat_value,\n                mirostat_eta=mirostat_eta,\n                mirostat_tau=mirostat_tau,\n                num_ctx=num_ctx,\n                num_gpu=num_gpu,\n                num_thread=num_thread,\n                repeat_last_n=repeat_last_n,\n                repeat_penalty=repeat_penalty,\n                temperature=temperature,\n                stop=stop,\n                tfs_z=tfs_z,\n                top_k=top_k,\n                top_p=top_p,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama.\") from e\n\n        return llm\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "mirostat": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Disabled",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Disabled",
                  "Mirostat",
                  "Mirostat 2.0"
                ],
                "name": "mirostat",
                "display_name": "Mirostat",
                "advanced": true,
                "dynamic": false,
                "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                "title_case": true
              },
              "mirostat_eta": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_eta",
                "display_name": "Mirostat Eta",
                "advanced": true,
                "dynamic": false,
                "info": "Learning rate influencing the algorithm's response to feedback.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "mirostat_tau": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "mirostat_tau",
                "display_name": "Mirostat Tau",
                "advanced": true,
                "dynamic": false,
                "info": "Controls balance between coherence and diversity.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "model": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "llama3",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "Refer to https://ollama.ai/library for more models.",
                "title_case": true
              },
              "num_ctx": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_ctx",
                "display_name": "Context Window Size",
                "advanced": true,
                "dynamic": false,
                "info": "Size of the context window for generating the next token.",
                "title_case": true
              },
              "num_gpu": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_gpu",
                "display_name": "Number of GPUs",
                "advanced": true,
                "dynamic": false,
                "info": "Number of GPUs to use for computation.",
                "title_case": true
              },
              "num_thread": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "num_thread",
                "display_name": "Number of Threads",
                "advanced": true,
                "dynamic": false,
                "info": "Number of threads to use during computation.",
                "title_case": true
              },
              "repeat_last_n": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_last_n",
                "display_name": "Repeat Last N",
                "advanced": true,
                "dynamic": false,
                "info": "Sets how far back the model looks to prevent repetition.",
                "title_case": true
              },
              "repeat_penalty": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repeat_penalty",
                "display_name": "Repeat Penalty",
                "advanced": true,
                "dynamic": false,
                "info": "Penalty for repetitions in generated text.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "stop": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "stop",
                "display_name": "Stop Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "List of tokens to signal the model to stop generating text.",
                "title_case": true
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.8,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Controls the creativity of model responses.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "tfs_z": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "tfs_z",
                "display_name": "TFS Z",
                "advanced": true,
                "dynamic": false,
                "info": "Tail free sampling to reduce impact of less probable tokens.",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "top_k": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_k",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Limits token selection to top K for reducing nonsense generation.",
                "title_case": true
              },
              "top_p": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_p",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "Works with top-k to control diversity of generated text.",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Local LLM with Ollama.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "display_name": "Ollama",
            "documentation": "",
            "custom_fields": {
              "base_url": null,
              "model": null,
              "temperature": null,
              "mirostat": null,
              "mirostat_eta": null,
              "mirostat_tau": null,
              "num_ctx": null,
              "num_gpu": null,
              "num_thread": null,
              "repeat_last_n": null,
              "repeat_penalty": null,
              "stop": null,
              "tfs_z": null,
              "top_k": null,
              "top_p": null
            },
            "output_types": [
              "BaseLLM"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "OllamaLLM-RZUP8"
        },
        "selected": false,
        "width": 384,
        "height": 553,
        "positionAbsolute": {
          "x": -3190.649363457083,
          "y": -1375.8007698183264
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "DirectoryLoader-TMeZb",
        "sourceHandle": "{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œDirectoryLoaderœ,œidœ:œDirectoryLoader-TMeZbœ}",
        "target": "PromptTemplate-u5EO7",
        "targetHandle": "{œfieldNameœ:œdirectoryœ,œidœ:œPromptTemplate-u5EO7œ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "directory",
            "id": "PromptTemplate-u5EO7",
            "inputTypes": [
              "Document",
              "BaseOutputParser"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "Document"
            ],
            "dataType": "DirectoryLoader",
            "id": "DirectoryLoader-TMeZb"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-DirectoryLoader-TMeZb{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œDirectoryLoaderœ,œidœ:œDirectoryLoader-TMeZbœ}-PromptTemplate-u5EO7{œfieldNameœ:œdirectoryœ,œidœ:œPromptTemplate-u5EO7œ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
      },
      {
        "source": "PromptTemplate-u5EO7",
        "sourceHandle": "{œbaseClassesœ:[œPromptTemplateœ,œStringPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-u5EO7œ}",
        "target": "LLMChain-tAA2L",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-tAA2L",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "PromptTemplate",
              "StringPromptTemplate",
              "BasePromptTemplate"
            ],
            "dataType": "PromptTemplate",
            "id": "PromptTemplate-u5EO7"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-PromptTemplate-u5EO7{œbaseClassesœ:[œPromptTemplateœ,œStringPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-u5EO7œ}-LLMChain-tAA2L{œfieldNameœ:œpromptœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
      },
      {
        "source": "OllamaLLM-RZUP8",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-RZUP8œ}",
        "target": "LLMChain-tAA2L",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-tAA2L",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "dataType": "OllamaLLM",
            "id": "OllamaLLM-RZUP8"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-OllamaLLM-RZUP8{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-RZUP8œ}-LLMChain-tAA2L{œfieldNameœ:œllmœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      }
    ],
    "viewport": {
      "x": 2082.6922598244364,
      "y": 710.0530996535786,
      "zoom": 0.5149667852941726
    }
  },
  "metadata": {
    "LLMChain": {
      "count": 1
    },
    "DirectoryLoader": {
      "count": 1
    },
    "PromptTemplate": {
      "count": 1
    },
    "OllamaLLM": {
      "count": 1
    },
    "total": 4
  },
  "original": {
    "id": "68863f61-7f80-4864-8ef6-0d7717d46bc7",
    "name": "Local CV reviewer",
    "description": "Perform SWOT Analysis on your resume",
    "is_component": false,
    "liked_by_count": "27",
    "downloads_count": "358",
    "metadata": {
      "LLMChain": {
        "count": 1
      },
      "DirectoryLoader": {
        "count": 1
      },
      "PromptTemplate": {
        "count": 1
      },
      "OllamaLLM": {
        "count": 1
      },
      "total": 4
    },
    "last_tested_version": "0.6.19",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "LLMChain-tAA2L",
          "type": "genericNode",
          "position": {
            "x": -2644.6620523187803,
            "y": -929.4386519276255
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "BasePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt",
                  "display_name": "Prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "Chain",
                "Callable",
                "LLMChain",
                "Chain"
              ],
              "display_name": "LLMChain",
              "documentation": "",
              "custom_fields": {
                "prompt": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable",
                "LLMChain"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "LLMChain-tAA2L"
          },
          "selected": false,
          "width": 384,
          "height": 424,
          "dragging": false,
          "positionAbsolute": {
            "x": -2644.6620523187803,
            "y": -929.4386519276255
          }
        },
        {
          "id": "DirectoryLoader-TMeZb",
          "type": "genericNode",
          "position": {
            "x": -3655.081812714044,
            "y": -861.651548588108
          },
          "data": {
            "type": "DirectoryLoader",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Any, Dict, List\n\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders.directory import DirectoryLoader\nfrom axiestudio import CustomComponent\n\n\nclass DirectoryLoaderComponent(CustomComponent):\n    display_name = \"DirectoryLoader\"\n    description = \"Load from a directory.\"\n\n    def build_config(self) -> Dict[str, Any]:\n        return {\n            \"glob\": {\"display_name\": \"Glob Pattern\", \"value\": \"**/*.txt\"},\n            \"load_hidden\": {\"display_name\": \"Load Hidden Files\", \"value\": False, \"advanced\": True},\n            \"max_concurrency\": {\"display_name\": \"Max Concurrency\", \"value\": 10, \"advanced\": True},\n            \"metadata\": {\"display_name\": \"Metadata\", \"value\": {}},\n            \"path\": {\"display_name\": \"Local Directory\"},\n            \"recursive\": {\"display_name\": \"Recursive\", \"value\": True, \"advanced\": True},\n            \"silent_errors\": {\"display_name\": \"Silent Errors\", \"value\": False, \"advanced\": True},\n            \"use_multithreading\": {\"display_name\": \"Use Multithreading\", \"value\": True, \"advanced\": True},\n        }\n\n    def build(\n        self,\n        glob: str,\n        path: str,\n        max_concurrency: int = 2,\n        load_hidden: bool = False,\n        recursive: bool = True,\n        silent_errors: bool = False,\n        use_multithreading: bool = True,\n    ) -> List[Document]:\n        return DirectoryLoader(\n            glob=glob,\n            path=path,\n            load_hidden=load_hidden,\n            max_concurrency=max_concurrency,\n            recursive=recursive,\n            silent_errors=silent_errors,\n            use_multithreading=use_multithreading,\n        ).load()\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "glob": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "**/*.pdf",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "glob",
                  "display_name": "Glob Pattern",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "load_hidden": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "load_hidden",
                  "display_name": "Load Hidden Files",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "max_concurrency": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 10,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_concurrency",
                  "display_name": "Max Concurrency",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "path": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "path",
                  "display_name": "Local Directory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": "C:\\Users\\jerem\\Documents\\Notes\\copies"
                },
                "recursive": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "recursive",
                  "display_name": "Recursive",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "silent_errors": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "silent_errors",
                  "display_name": "Silent Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "use_multithreading": {
                  "type": "bool",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "use_multithreading",
                  "display_name": "Use Multithreading",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Load from a directory.",
              "base_classes": [
                "Document"
              ],
              "display_name": "DirectoryLoader",
              "documentation": "",
              "custom_fields": {
                "glob": null,
                "path": null,
                "max_concurrency": null,
                "load_hidden": null,
                "recursive": null,
                "silent_errors": null,
                "use_multithreading": null
              },
              "output_types": [
                "Document"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "DirectoryLoader-TMeZb"
          },
          "selected": false,
          "width": 384,
          "height": 468,
          "positionAbsolute": {
            "x": -3655.081812714044,
            "y": -861.651548588108
          },
          "dragging": false
        },
        {
          "id": "PromptTemplate-u5EO7",
          "type": "genericNode",
          "position": {
            "x": -3165.7180435727273,
            "y": -398.0299742980356
          },
          "data": {
            "type": "PromptTemplate",
            "node": {
              "template": {
                "output_parser": {
                  "type": "BaseOutputParser",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_types": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_types",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_variables": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true,
                  "value": [
                    "directory"
                  ]
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "name",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "partial_variables": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "tags": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "template": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "fileTypes": [],
                  "password": false,
                  "name": "template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true,
                  "value": "\nYou are a very talented machine learning professor, your role is to evaluate the group exams made by the students.\nYou will find them stored at {directory}.\nEvaluate these works regarding the following aspects : \n\n1 . Problematic selection\n2. Data exploration and data cleaning\n3. Model training process\n4. Performance evaluation\n5. Metric selection and what they are telling us\n6.Benchmark of several machine learning models\n\nRate between 0 and 10 each of these items, and give me a recap answer with the ratings and reasons\n\nNever invent answers, say you don't know if the given information is not enough to give an enlightened answer."
                },
                "template_format": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": "f-string",
                  "fileTypes": [],
                  "password": false,
                  "name": "template_format",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "validate_template": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "PromptTemplate",
                "directory": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "directory",
                  "display_name": "directory",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                }
              },
              "description": "Prompt template for a language model.",
              "icon": null,
              "base_classes": [
                "PromptTemplate",
                "StringPromptTemplate",
                "BasePromptTemplate"
              ],
              "name": "",
              "display_name": "PromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
              "custom_fields": {
                "": [
                  "directory"
                ]
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "PromptTemplate-u5EO7",
            "description": "Prompt template for a language model.",
            "display_name": "PromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 374,
          "positionAbsolute": {
            "x": -3165.7180435727273,
            "y": -398.0299742980356
          },
          "dragging": false
        },
        {
          "id": "OllamaLLM-RZUP8",
          "type": "genericNode",
          "position": {
            "x": -3190.649363457083,
            "y": -1375.8007698183264
          },
          "data": {
            "type": "OllamaLLM",
            "node": {
              "template": {
                "base_url": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "base_url",
                  "display_name": "Base URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.",
                  "title_case": true,
                  "value": "http://localhost:11434"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import List, Optional\n\nfrom langchain.llms.base import BaseLLM\nfrom langchain_community.llms.ollama import Ollama\n\nfrom axiestudio import CustomComponent\n\n\nclass OllamaLLM(CustomComponent):\n    display_name = \"Ollama\"\n    description = \"Local LLM with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate influencing the algorithm's response to feedback.\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls balance between coherence and diversity.\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating the next token.\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation.\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation.\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"Sets how far back the model looks to prevent repetition.\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling to reduce impact of less probable tokens.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K for reducing nonsense generation.\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"int\",\n                \"info\": \"Works with top-k to control diversity of generated text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        temperature: Optional[float],\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        num_thread: Optional[int] = None,\n        repeat_last_n: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        tfs_z: Optional[float] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseLLM:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        try:\n            llm = Ollama(\n                base_url=base_url,\n                model=model,\n                mirostat=mirostat_value,\n                mirostat_eta=mirostat_eta,\n                mirostat_tau=mirostat_tau,\n                num_ctx=num_ctx,\n                num_gpu=num_gpu,\n                num_thread=num_thread,\n                repeat_last_n=repeat_last_n,\n                repeat_penalty=repeat_penalty,\n                temperature=temperature,\n                stop=stop,\n                tfs_z=tfs_z,\n                top_k=top_k,\n                top_p=top_p,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama.\") from e\n\n        return llm\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "mirostat": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Disabled",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Disabled",
                    "Mirostat",
                    "Mirostat 2.0"
                  ],
                  "name": "mirostat",
                  "display_name": "Mirostat",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Enable/disable Mirostat sampling for controlling perplexity.",
                  "title_case": true
                },
                "mirostat_eta": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_eta",
                  "display_name": "Mirostat Eta",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Learning rate influencing the algorithm's response to feedback.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "mirostat_tau": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "mirostat_tau",
                  "display_name": "Mirostat Tau",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Controls balance between coherence and diversity.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "model": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "llama3",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Refer to https://ollama.ai/library for more models.",
                  "title_case": true
                },
                "num_ctx": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_ctx",
                  "display_name": "Context Window Size",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Size of the context window for generating the next token.",
                  "title_case": true
                },
                "num_gpu": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_gpu",
                  "display_name": "Number of GPUs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of GPUs to use for computation.",
                  "title_case": true
                },
                "num_thread": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "num_thread",
                  "display_name": "Number of Threads",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of threads to use during computation.",
                  "title_case": true
                },
                "repeat_last_n": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_last_n",
                  "display_name": "Repeat Last N",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Sets how far back the model looks to prevent repetition.",
                  "title_case": true
                },
                "repeat_penalty": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repeat_penalty",
                  "display_name": "Repeat Penalty",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Penalty for repetitions in generated text.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "stop": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "stop",
                  "display_name": "Stop Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "List of tokens to signal the model to stop generating text.",
                  "title_case": true
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.8,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Controls the creativity of model responses.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "tfs_z": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "tfs_z",
                  "display_name": "TFS Z",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Tail free sampling to reduce impact of less probable tokens.",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "top_k": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_k",
                  "display_name": "Top K",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Limits token selection to top K for reducing nonsense generation.",
                  "title_case": true
                },
                "top_p": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_p",
                  "display_name": "Top P",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Works with top-k to control diversity of generated text.",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Local LLM with Ollama.",
              "base_classes": [
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "display_name": "Ollama",
              "documentation": "",
              "custom_fields": {
                "base_url": null,
                "model": null,
                "temperature": null,
                "mirostat": null,
                "mirostat_eta": null,
                "mirostat_tau": null,
                "num_ctx": null,
                "num_gpu": null,
                "num_thread": null,
                "repeat_last_n": null,
                "repeat_penalty": null,
                "stop": null,
                "tfs_z": null,
                "top_k": null,
                "top_p": null
              },
              "output_types": [
                "BaseLLM"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "OllamaLLM-RZUP8"
          },
          "selected": false,
          "width": 384,
          "height": 553,
          "positionAbsolute": {
            "x": -3190.649363457083,
            "y": -1375.8007698183264
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "DirectoryLoader-TMeZb",
          "sourceHandle": "{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œDirectoryLoaderœ,œidœ:œDirectoryLoader-TMeZbœ}",
          "target": "PromptTemplate-u5EO7",
          "targetHandle": "{œfieldNameœ:œdirectoryœ,œidœ:œPromptTemplate-u5EO7œ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "directory",
              "id": "PromptTemplate-u5EO7",
              "inputTypes": [
                "Document",
                "BaseOutputParser"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "Document"
              ],
              "dataType": "DirectoryLoader",
              "id": "DirectoryLoader-TMeZb"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-DirectoryLoader-TMeZb{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œDirectoryLoaderœ,œidœ:œDirectoryLoader-TMeZbœ}-PromptTemplate-u5EO7{œfieldNameœ:œdirectoryœ,œidœ:œPromptTemplate-u5EO7œ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
        },
        {
          "source": "PromptTemplate-u5EO7",
          "sourceHandle": "{œbaseClassesœ:[œPromptTemplateœ,œStringPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-u5EO7œ}",
          "target": "LLMChain-tAA2L",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "LLMChain-tAA2L",
              "inputTypes": null,
              "type": "BasePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "PromptTemplate",
                "StringPromptTemplate",
                "BasePromptTemplate"
              ],
              "dataType": "PromptTemplate",
              "id": "PromptTemplate-u5EO7"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-PromptTemplate-u5EO7{œbaseClassesœ:[œPromptTemplateœ,œStringPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-u5EO7œ}-LLMChain-tAA2L{œfieldNameœ:œpromptœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
        },
        {
          "source": "OllamaLLM-RZUP8",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-RZUP8œ}",
          "target": "LLMChain-tAA2L",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-tAA2L",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "dataType": "OllamaLLM",
              "id": "OllamaLLM-RZUP8"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-OllamaLLM-RZUP8{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œOllamaLLMœ,œidœ:œOllamaLLM-RZUP8œ}-LLMChain-tAA2L{œfieldNameœ:œllmœ,œidœ:œLLMChain-tAA2Lœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        }
      ],
      "viewport": {
        "x": 2082.6922598244364,
        "y": 710.0530996535786,
        "zoom": 0.5149667852941726
      }
    },
    "date_created": "2024-06-11T08:41:36.179Z",
    "date_updated": "2024-06-11T08:41:36.232Z",
    "status": "Public",
    "sort": null,
    "user_updated": "e7cdf003-4c76-4d08-a532-39be02ad5986",
    "user_created": {
      "username": "MarcusPeters",
      "first_name": "Marcus",
      "last_name": "Peters",
      "id": "e7cdf003-4c76-4d08-a532-39be02ad5986"
    },
    "tags": [
      {
        "tags_id": {
          "name": "Chain",
          "id": "d442c88b-f8d0-4010-8752-16a644c7ac8e"
        }
      },
      {
        "tags_id": {
          "name": "Prompt",
          "id": "57f5c681-a1f5-4053-be33-e9525e7eb00a"
        }
      },
      {
        "tags_id": {
          "name": "Agent",
          "id": "ccabb590-c9e8-4e56-9d6c-309955936c6c"
        }
      }
    ]
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:59.397Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 8,
    "converter_version": "1.0.0"
  }
}