{
  "id": "ae02f2c7-aee5-4f2c-91f2-a95d5c166dce",
  "name": "NeoHydraGen",
  "description": "",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "Mimr_0",
    "first_name": "Milan",
    "last_name": "Mrdenovic",
    "id": "4d6acd51-154b-427e-af47-512b44b0c1ba",
    "full_name": "Milan Mrdenovic"
  },
  "store_url": "https://www.langflow.store/store/component/ae02f2c7-aee5-4f2c-91f2-a95d5c166dce",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-06-18T10:37:34.229Z",
    "updated": "2024-06-18T10:37:34.262Z",
    "downloaded": "2025-08-19T17:50:05.748Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.0a49",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "CustomComponent-ZSMAm",
        "type": "genericNode",
        "position": {
          "x": 1694.5922895533595,
          "y": -619.6827398771425
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "apikey": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "apikey",
                "display_name": "API Key",
                "advanced": false,
                "dynamic": false,
                "info": "API uses API keys for authentication.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Record\n#from axiestudio import CustomComponent\nfrom axiestudio import custom\nfrom langchain.schema import Document\nfrom typing import Optional\nfrom langchain.llms.base import BaseLLM\nfrom langchain_ibm import WatsonxLLM\n\n\nclass Watsonx(CustomComponent):\n    display_name = \"Watsonx\"\n    description = \"Watsonx foundation models\"\n    \n    def build_config(self) -> dict:\n        model_options = [\n            # Part of the officially supported foundation models in watsonx.ai\n            'mistralai/mixtral-8x7b-instruct-v01',\n            'meta-llama/llama-3-8b-instruct',\n            'meta-llama/llama-3-70b-instruct',\n            'meta-llama/llama-2-13b-chat',\n            'meta-llama/llama-2-70b-chat',\n            'ibm-mistralai/merlinite-7b',\n            'codellama/codellama-34b-instruct-hf',\n            'google/flan-t5-xl',\n            'google/flan-t5-xxl',\n            'google/flan-ul2',\n            'ibm/granite-13b-chat-v2',\n            'ibm/granite-13b-instruct-v2',\n            'ibm/granite-20b-code-instruct',\n            'ibm/granite-20b-multilingual',\n            'ibm/granite-34b-code-instruct',\n            'ibm/granite-7b-lab',\n            'ibm/granite-8b-code-instruct',\n            'bigscience/mt0-xxl',\n        ]\n\n        decoding_options = [\n            \"greedy\",\n            \"sample\"\n        ]\n        \n        url_options = [      \n            \"https://us-south.ml.cloud.ibm.com\",\n            \"https://eu-gb.ml.cloud.ibm.com\",\n            \"https://eu-de.ml.cloud.ibm.com\",\n            \"https://jp-tok.ml.cloud.ibm.com\"\n        ]\n\n        stp_sequences = [  \n            \"</s>\",\n            \"<|end_of_text|>\"\n        ]\n \n\n        return {\n            \"model_id\": {\n                \"display_name\": \"Model Name\",\n                \"options\": model_options,\n                \"value\": model_options[2],\n                \"info\": \"The ID of the model or tune to be used for this request.\",\n            },\n            \"url\": {\n                \"display_name\": \"Url Endpoint\",\n                \"info\": \"Url endpoint for watsonx\",\n                \"options\": url_options,\n                \"value\": url_options[2],\n            },\n            \"apikey\": {\n                \"display_name\": \"API Key\",\n                \"password\": True,\n                \"info\": \"API uses API keys for authentication.\",\n                \"value\": \"HPsQWoh12PnzXwOdPYWZl8q6GusQX9T4vxsvhS-vcdIs\",  ###placeholder\n                \"required\": True\n            },\n            \"project_id\": {\n                \"display_name\": \"Project_id\",\n                \"info\": \"Project Id necessary to run inference.\",\n                \"value\": \"f275d991-68a4-47d9-b6e8-c8c052f63b33\",  ###placeholder\n                \"required\": True\n            },\n            # \"api_endpoint\": { \"display_name\": \"API Endpoint\", \"value\": \"https://bam-api.res.ibm.com/v1/\" },\n            \"decoding_method\": {\n                \"display_name\": \"Decoding Method\",\n                \"options\": decoding_options,\n                \"value\": decoding_options[0],\n                \"info\": \"Represents the strategy used for picking the tokens during generation of the output text.\"\n            },\n            \"stop_sequences\": {\n                \"display_name\": \"Stopping Sequences\",\n                \"options\": stp_sequences,\n                \"value\": stp_sequences[0],\n                \"info\": \"Encountering these strings will cause the model to stop generation.\",\n            },\n            \"min_new_tokens\": {\n                \"display_name\": \"Minimum New Tokens\",\n                \"value\": 5,\n                \"info\": \"The minimum number of new tokens to be generated.\"\n            },\n            \"max_new_tokens\": {\n                \"display_name\": \"Max New Tokens\",\n                \"value\": 4000,\n                \"info\": \"The maximum number of new tokens to be generated.\"\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n                \"info\": \"A value used to modify the next-token probabilities in sampling mode.\"\n            },\n            \"repetition_penalty\": {\n                \"display_name\": \"Repetition Penalty\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1\"\n            },\n            \"random_seed\": {\n                \"display_name\": \"Random Seed\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1.\"\n            },\n            \"top_p\": {\n                \"display_name\": \"Top_P\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1.\"\n            },\n            \"top_k\": {\n                \"display_name\": \"Top_K\",\n                \"value\": 50,\n                \"info\": \"Defaults to 50.\"\n            },\n            \"code\": {\"show\": False}\n        }\n\n    def build(\n            self,\n            model_id: str,\n            apikey: str,\n            url: str,\n            project_id: str,\n            decoding_method: str,\n            stop_sequences: str,\n            repetition_penalty: float,\n            max_new_tokens: int,\n            min_new_tokens: int,\n            temperature: float,\n            random_seed: int,\n            top_p: float,\n            top_k: int,\n        ) -> BaseLLM:\n            from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n            #creds = APIClient(apikey, url)\n            stop_seq = [seq.strip() for seq in stop_sequences.splitlines()]\n            params = {\n                GenParams.TEMPERATURE: temperature,\n                GenParams.MAX_NEW_TOKENS: max_new_tokens,\n                GenParams.MIN_NEW_TOKENS: min_new_tokens,\n                GenParams.DECODING_METHOD: decoding_method,\n                GenParams.REPETITION_PENALTY: repetition_penalty,\n                GenParams.TOP_K: top_k,\n                GenParams.TOP_P: top_p,\n                GenParams.STOP_SEQUENCES: stop_seq,\n                GenParams.RANDOM_SEED: random_seed,\n            }\n            print(params)\n            model = WatsonxLLM(model_id=model_id, params=params, apikey=apikey, url=url, project_id=project_id)\n            return model\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "decoding_method": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "greedy",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "greedy",
                  "sample"
                ],
                "name": "decoding_method",
                "display_name": "Decoding Method",
                "advanced": false,
                "dynamic": false,
                "info": "Represents the strategy used for picking the tokens during generation of the output text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "max_new_tokens": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 4000,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_new_tokens",
                "display_name": "Max New Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of new tokens to be generated.",
                "load_from_db": false,
                "title_case": false
              },
              "min_new_tokens": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 5,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "min_new_tokens",
                "display_name": "Minimum New Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The minimum number of new tokens to be generated.",
                "load_from_db": false,
                "title_case": false
              },
              "model_id": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "mistralai/mixtral-8x7b-instruct-v01",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "mistralai/mixtral-8x7b-instruct-v01",
                  "meta-llama/llama-3-8b-instruct",
                  "meta-llama/llama-3-70b-instruct",
                  "meta-llama/llama-2-13b-chat",
                  "meta-llama/llama-2-70b-chat",
                  "ibm-mistralai/merlinite-7b",
                  "codellama/codellama-34b-instruct-hf",
                  "google/flan-t5-xl",
                  "google/flan-t5-xxl",
                  "google/flan-ul2",
                  "ibm/granite-13b-chat-v2",
                  "ibm/granite-13b-instruct-v2",
                  "ibm/granite-20b-code-instruct",
                  "ibm/granite-20b-multilingual",
                  "ibm/granite-34b-code-instruct",
                  "ibm/granite-7b-lab",
                  "ibm/granite-8b-code-instruct",
                  "bigscience/mt0-xxl"
                ],
                "name": "model_id",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "The ID of the model or tune to be used for this request.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "project_id": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "f275d991-68a4-47d9-b6e8-c8c052f63b33",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "project_id",
                "display_name": "Project_id",
                "advanced": false,
                "dynamic": false,
                "info": "Project Id necessary to run inference.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "random_seed": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 1,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "random_seed",
                "display_name": "Random Seed",
                "advanced": false,
                "dynamic": false,
                "info": "Defaults to 1.",
                "load_from_db": false,
                "title_case": false
              },
              "repetition_penalty": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 1,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "repetition_penalty",
                "display_name": "Repetition Penalty",
                "advanced": false,
                "dynamic": false,
                "info": "Defaults to 1",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "stop_sequences": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "</s>",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "</s>",
                  "<|end_of_text|>"
                ],
                "name": "stop_sequences",
                "display_name": "Stopping Sequences",
                "advanced": false,
                "dynamic": false,
                "info": "Encountering these strings will cause the model to stop generation.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "temperature": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.7,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "A value used to modify the next-token probabilities in sampling mode.",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "top_k": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 50,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_k",
                "display_name": "Top_K",
                "advanced": false,
                "dynamic": false,
                "info": "Defaults to 50.",
                "load_from_db": false,
                "title_case": false
              },
              "top_p": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 1,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "top_p",
                "display_name": "Top_P",
                "advanced": false,
                "dynamic": false,
                "info": "Defaults to 1.",
                "rangeSpec": {
                  "step_type": "float",
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "load_from_db": false,
                "title_case": false
              },
              "url": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "https://eu-de.ml.cloud.ibm.com",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "https://us-south.ml.cloud.ibm.com",
                  "https://eu-gb.ml.cloud.ibm.com",
                  "https://eu-de.ml.cloud.ibm.com",
                  "https://jp-tok.ml.cloud.ibm.com"
                ],
                "name": "url",
                "display_name": "Url Endpoint",
                "advanced": false,
                "dynamic": false,
                "info": "Url endpoint for watsonx",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Watsonx foundation models",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLLM",
              "Generic",
              "object",
              "Runnable",
              "RunnableSerializable",
              "Serializable"
            ],
            "display_name": "watsonx.ai - mixtral-8x7b",
            "documentation": "",
            "custom_fields": {
              "model_id": null,
              "apikey": null,
              "url": null,
              "project_id": null,
              "decoding_method": null,
              "stop_sequences": null,
              "repetition_penalty": null,
              "max_new_tokens": null,
              "min_new_tokens": null,
              "temperature": null,
              "random_seed": null,
              "top_p": null,
              "top_k": null
            },
            "output_types": [
              "BaseLLM"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "official": false
          },
          "id": "CustomComponent-ZSMAm"
        },
        "selected": false,
        "width": 384,
        "height": 1348,
        "positionAbsolute": {
          "x": 1694.5922895533595,
          "y": -619.6827398771425
        },
        "dragging": false
      },
      {
        "id": "Prompt-2HeG1",
        "type": "genericNode",
        "position": {
          "x": 1753.3030961524453,
          "y": 902.0076526884102
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "<s>[INST] Using the text between [INPUT] and [END_OF_INPUT] extract the different elements into a cohesive list with their relationships and {instruction_context} characteristics.\nReturn the output as JSON.\nDifferent steps should be grouped into the following larger scale groupings chronologically (unless otherwise specified): {groupings}\nAlso assign emotional intensity scores from 1 (horrible), 2 (unsatisfied), 3 (neutral), 4 (happy) to 5 (fantastic) to each step based on the text with a very slight emphasis for a stronger effect. [/INST]\n\n[INST] Using the text between [INPUT] and [END_OF_INPUT] extract the different elements into a cohesive list with their relationships and {instruction_context} characteristics. Return the output as JSON.\nDifferent steps should be grouped into the following larger scale groupings chronologically (unless otherwise specified): {groupings}\nAlso assign emotional intensity scores from 1 (horrible), 2 (unsatisfied), 3 (neutral), 4 (happy) to 5 (fantastic) to each step based on the text with a very slight emphasis for a stronger effect.\n[INPUT] {input_text} [END_OF_INPUT] [/INST]\n\n\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "instruction_context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "instruction_context",
                "display_name": "instruction_context",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "groupings": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "groupings",
                "display_name": "groupings",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "input_text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_text",
                "display_name": "input_text",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "name": "",
            "display_name": "element_extractor_PT",
            "documentation": "",
            "custom_fields": {
              "template": [
                "instruction_context",
                "groupings",
                "input_text"
              ]
            },
            "output_types": [
              "Text"
            ],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-2HeG1",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "element_extractor_PT"
        },
        "selected": false,
        "width": 384,
        "height": 566,
        "dragging": false,
        "positionAbsolute": {
          "x": 1753.3030961524453,
          "y": 902.0076526884102
        }
      },
      {
        "id": "TextInput-Rc4fR",
        "type": "genericNode",
        "position": {
          "x": 676.0998391156161,
          "y": 1608.8362666707594
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "User Journey",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": [
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "Text or Record to be passed as input.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "instruction_context",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextInput-Rc4fR"
        },
        "selected": false,
        "width": 384,
        "height": 287,
        "positionAbsolute": {
          "x": 676.0998391156161,
          "y": 1608.8362666707594
        },
        "dragging": false
      },
      {
        "id": "TextInput-UtN4a",
        "type": "genericNode",
        "position": {
          "x": 742.0169480176012,
          "y": 880.2478435068135
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Goal, Start of Journey, Painpoints, End of Journey AS-IS",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": [
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "Text or Record to be passed as input.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "groupings",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextInput-UtN4a"
        },
        "selected": false,
        "width": 384,
        "height": 287,
        "dragging": false,
        "positionAbsolute": {
          "x": 742.0169480176012,
          "y": 880.2478435068135
        }
      },
      {
        "id": "LLMChain-ui78J",
        "type": "genericNode",
        "position": {
          "x": 2772.0293238862037,
          "y": 787.6196353789855
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langchain.chains.llm import LLMChain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Text\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n        }\n\n    def build(\n        self,\n        template: Text,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        prompt = PromptTemplate.from_template(template)\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\n        result_dict = runnable.invoke({})\n        output_key = runnable.output_key\n        result = result_dict[output_key]\n        self.status = result\n        return result\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "extract",
            "documentation": "",
            "custom_fields": {
              "template": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "LLMChain-ui78J"
        },
        "selected": false,
        "width": 384,
        "height": 383,
        "dragging": false,
        "positionAbsolute": {
          "x": 2772.0293238862037,
          "y": 787.6196353789855
        }
      },
      {
        "id": "ChatOutput-ehQgZ",
        "type": "genericNode",
        "position": {
          "x": 4924.29592860122,
          "y": -120.42653355286228
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{text}",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "In case of Message being a Record, this template will be used to convert it to text.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "return_record": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_record",
                "display_name": "Return Record",
                "advanced": true,
                "dynamic": false,
                "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                "load_from_db": false,
                "title_case": false
              },
              "sender": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "Machine",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "Machine",
                  "User"
                ],
                "name": "sender",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "sender_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "AI",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "sender_name",
                "display_name": "Sender Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "session_id": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "If provided, the message will be stored in the memory.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "object",
              "Record",
              "str",
              "Text"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {
              "sender": null,
              "sender_name": null,
              "input_value": null,
              "session_id": null,
              "return_record": null,
              "record_template": null
            },
            "output_types": [
              "Text",
              "Record"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "ChatOutput-ehQgZ"
        },
        "selected": false,
        "width": 384,
        "height": 380,
        "positionAbsolute": {
          "x": 4924.29592860122,
          "y": -120.42653355286228
        },
        "dragging": false
      },
      {
        "id": "Prompt-hClEA",
        "type": "genericNode",
        "position": {
          "x": 3528.6802519902367,
          "y": 576.5451206978421
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "prompt",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": " <s> [INST] Create a Mermaid User Journey graph in markdown output connecting the elements that are related to each other in the JSON data.\nThe data to be processed will be in between [Data] and [End of data].\n\nSection each part of the user journey that falls under a separate overall category and add emotional intensity scores to all values under the same section, use shortened names for the section names.\n\n[Diagram Documentation]\n{diagram_context}\n[End of Documentation]\n\n[Example]\n{example}\n[End of Example]\n[/INST]\n\n[INST] Create a Mermaid User Journey graph in markdown output connecting the elements that are related to each other in the JSON data.\nThe data to be processed will be in between [Data] and [End of data].\n\nSection each part of the user journey that falls under a separate overall category and add emotional intensity scores to all values under the same section, use shortened names for the section names.\n\n[Diagram Documentation]\n{diagram_context}\n[End of Documentation]\n\n[Example]\n{example}\n[End of Example]\n\n[Data]{text}[End of data]\n\nOutput the return as:\n\"[```mermaid]\n<result>\n[```]\"\n[/INST]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent",
              "diagram_context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "User Journey Diagram\n\nUser journeys describe at a high level of detail exactly what steps different users take to complete a specific task within a system, application or website. This technique shows the current (as-is) user workflow, and reveals areas of improvement for the to-be workflow. (Wikipedia)\n\nMermaid can render user journey diagrams:\n\n```mermaid-example\njourney\n    title My working day\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    section Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me\n```\n\nEach user journey is split into sections, these describe the part of the task\nthe user is trying to complete.\n\nTasks syntax is `Task name: <score>: <comma separated list of actors>`",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "diagram_context",
                "display_name": "diagram_context",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "example": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "journey\n      title My working day\n      section Go to work\n        Make tea: 5: Me\n        Go upstairs: 3: Me\n        Do work: 1: Me, Cat\n      section Go home\n        Go downstairs: 5: Me\n        Sit down: 5: Me",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "example",
                "display_name": "example",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "text": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "text",
                "display_name": "text",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "name": "",
            "display_name": "user_journey_generator_PT",
            "documentation": "",
            "custom_fields": {
              "template": [
                "diagram_context",
                "example",
                "text"
              ]
            },
            "output_types": [
              "Text"
            ],
            "full_path": null,
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false,
            "error": null
          },
          "id": "Prompt-hClEA",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "user_journey_generator_PT"
        },
        "selected": false,
        "width": 384,
        "height": 566,
        "positionAbsolute": {
          "x": 3528.6802519902367,
          "y": 576.5451206978421
        },
        "dragging": false
      },
      {
        "id": "LLMChain-S3BR5",
        "type": "genericNode",
        "position": {
          "x": 4244.546546830011,
          "y": 258.6613524493296
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom langchain.chains.llm import LLMChain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Text\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n        }\n\n    def build(\n        self,\n        template: Text,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        prompt = PromptTemplate.from_template(template)\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\n        result_dict = runnable.invoke({})\n        output_key = runnable.output_key\n        result = result_dict[output_key]\n        self.status = result\n        return result\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "template": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "LLMChain-S3BR5"
        },
        "selected": false,
        "width": 384,
        "height": 382,
        "positionAbsolute": {
          "x": 4244.546546830011,
          "y": 258.6613524493296
        },
        "dragging": false
      },
      {
        "id": "TextInput-k42fF",
        "type": "genericNode",
        "position": {
          "x": 705.2733487471658,
          "y": 1229.437558602747
        },
        "data": {
          "type": "TextInput",
          "node": {
            "template": {
              "input_value": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "Emma reached for her phone on the nightstand, preparing for a busy day ahead. She needed to quickly review her account balance before heading out the door. However, upon opening her mobile banking app, she was met with an unexpected error message: \"We're experiencing technical difficulties. Please try again later.\"  Emma's concern grew as she realized she had important financial tasks to attend to, including a pending bill payment and a transfer to her sister for their shared rent. She attempted to log in again, but the same error message persisted. To troubleshoot, she verified her internet connection, ensuring it was stable and functional.  Seeking assistance, Emma decided to utilize the app's built-in chat support feature. She composed a detailed message describing the issue and awaited a response from the support team. As the minutes ticked by, Emma's sense of urgency increased, knowing she had to leave for work soon.  Finally, a response from the support team arrived: \"We apologize for the inconvenience, Emma. Our team is currently addressing a technical issue. As a troubleshooting step, could you please try deleting and reinstalling the app?\" Emma was slightly disappointed, having already attempted this solution without success. She crafted a polite response, explaining that she had already tried reinstalling the app, and kindly requested further assistance to resolve the matter.  As she waited for a follow-up response, Emma couldn't help but feel a sense of frustration, hoping that the issue would be resolved promptly to avoid any further delays in her day.",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_value",
                "display_name": "Value",
                "advanced": false,
                "input_types": [
                  "Record",
                  "Text"
                ],
                "dynamic": false,
                "info": "Text or Record to be passed as input.",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "record_template": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "record_template",
                "display_name": "Record Template",
                "advanced": true,
                "dynamic": false,
                "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                "load_from_db": false,
                "title_case": false,
                "input_types": [
                  "Text"
                ]
              },
              "_type": "CustomComponent"
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "object",
              "str",
              "Text"
            ],
            "display_name": "input_text",
            "documentation": "",
            "custom_fields": {
              "input_value": null,
              "record_template": null
            },
            "output_types": [
              "Text"
            ],
            "field_formatters": {},
            "frozen": false,
            "field_order": [],
            "beta": false
          },
          "id": "TextInput-k42fF"
        },
        "selected": true,
        "width": 384,
        "height": 287,
        "positionAbsolute": {
          "x": 705.2733487471658,
          "y": 1229.437558602747
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "TextInput-Rc4fR",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Rc4fRœ}",
        "target": "Prompt-2HeG1",
        "targetHandle": "{œfieldNameœ:œinstruction_contextœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "instruction_context",
            "id": "Prompt-2HeG1",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "TextInput",
            "id": "TextInput-Rc4fR"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-TextInput-Rc4fR{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Rc4fRœ}-Prompt-2HeG1{œfieldNameœ:œinstruction_contextœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "TextInput-UtN4a",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UtN4aœ}",
        "target": "Prompt-2HeG1",
        "targetHandle": "{œfieldNameœ:œgroupingsœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "groupings",
            "id": "Prompt-2HeG1",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "TextInput",
            "id": "TextInput-UtN4a"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-TextInput-UtN4a{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UtN4aœ}-Prompt-2HeG1{œfieldNameœ:œgroupingsœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "CustomComponent-ZSMAm",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}",
        "target": "LLMChain-ui78J",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-ui78J",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLLM",
              "Generic",
              "object",
              "Runnable",
              "RunnableSerializable",
              "Serializable"
            ],
            "dataType": "CustomComponent",
            "id": "CustomComponent-ZSMAm"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-CustomComponent-ZSMAm{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}-LLMChain-ui78J{œfieldNameœ:œllmœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "Prompt-2HeG1",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-2HeG1œ}",
        "target": "LLMChain-ui78J",
        "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "template",
            "id": "LLMChain-ui78J",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "Prompt",
            "id": "Prompt-2HeG1"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-Prompt-2HeG1{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-2HeG1œ}-LLMChain-ui78J{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "LLMChain-ui78J",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-ui78Jœ}",
        "target": "Prompt-hClEA",
        "targetHandle": "{œfieldNameœ:œtextœ,œidœ:œPrompt-hClEAœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "text",
            "id": "Prompt-hClEA",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "LLMChain",
            "id": "LLMChain-ui78J"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-LLMChain-ui78J{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-ui78Jœ}-Prompt-hClEA{œfieldNameœ:œtextœ,œidœ:œPrompt-hClEAœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "LLMChain-S3BR5",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-S3BR5œ}",
        "target": "ChatOutput-ehQgZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ehQgZœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-ehQgZ",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "LLMChain",
            "id": "LLMChain-S3BR5"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-LLMChain-S3BR5{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-S3BR5œ}-ChatOutput-ehQgZ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ehQgZœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "Prompt-hClEA",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-hClEAœ}",
        "target": "LLMChain-S3BR5",
        "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "template",
            "id": "LLMChain-S3BR5",
            "inputTypes": [
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "Prompt",
            "id": "Prompt-hClEA"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-Prompt-hClEA{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-hClEAœ}-LLMChain-S3BR5{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
      },
      {
        "source": "CustomComponent-ZSMAm",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}",
        "target": "LLMChain-S3BR5",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-S3BR5",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLLM",
              "Generic",
              "object",
              "Runnable",
              "RunnableSerializable",
              "Serializable"
            ],
            "dataType": "CustomComponent",
            "id": "CustomComponent-ZSMAm"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-CustomComponent-ZSMAm{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}-LLMChain-S3BR5{œfieldNameœ:œllmœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "TextInput-k42fF",
        "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-k42fFœ}",
        "target": "Prompt-2HeG1",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_text",
            "id": "Prompt-2HeG1",
            "inputTypes": [
              "Document",
              "Record",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "object",
              "str",
              "Text"
            ],
            "dataType": "TextInput",
            "id": "TextInput-k42fF"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground stroke-connection",
        "id": "reactflow__edge-TextInput-k42fF{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-k42fFœ}-Prompt-2HeG1{œfieldNameœ:œinput_textœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": -95.57652960163136,
      "y": 246.2401551465146,
      "zoom": 0.2952584202113449
    }
  },
  "metadata": {
    "CustomComponent": {
      "count": 1
    },
    "Prompt": {
      "count": 2
    },
    "TextInput": {
      "count": 3
    },
    "LLMChain": {
      "count": 2
    },
    "ChatOutput": {
      "count": 1
    },
    "total": 9
  },
  "original": {
    "id": "ae02f2c7-aee5-4f2c-91f2-a95d5c166dce",
    "name": "NeoHydraGen",
    "description": "",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "0",
    "metadata": {
      "CustomComponent": {
        "count": 1
      },
      "Prompt": {
        "count": 2
      },
      "TextInput": {
        "count": 3
      },
      "LLMChain": {
        "count": 2
      },
      "ChatOutput": {
        "count": 1
      },
      "total": 9
    },
    "last_tested_version": "1.0.0a49",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "CustomComponent-ZSMAm",
          "type": "genericNode",
          "position": {
            "x": 1694.5922895533595,
            "y": -619.6827398771425
          },
          "data": {
            "type": "CustomComponent",
            "node": {
              "template": {
                "apikey": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "apikey",
                  "display_name": "API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "API uses API keys for authentication.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.schema import Record\n#from axiestudio import CustomComponent\nfrom axiestudio import custom\nfrom langchain.schema import Document\nfrom typing import Optional\nfrom langchain.llms.base import BaseLLM\nfrom langchain_ibm import WatsonxLLM\n\n\nclass Watsonx(CustomComponent):\n    display_name = \"Watsonx\"\n    description = \"Watsonx foundation models\"\n    \n    def build_config(self) -> dict:\n        model_options = [\n            # Part of the officially supported foundation models in watsonx.ai\n            'mistralai/mixtral-8x7b-instruct-v01',\n            'meta-llama/llama-3-8b-instruct',\n            'meta-llama/llama-3-70b-instruct',\n            'meta-llama/llama-2-13b-chat',\n            'meta-llama/llama-2-70b-chat',\n            'ibm-mistralai/merlinite-7b',\n            'codellama/codellama-34b-instruct-hf',\n            'google/flan-t5-xl',\n            'google/flan-t5-xxl',\n            'google/flan-ul2',\n            'ibm/granite-13b-chat-v2',\n            'ibm/granite-13b-instruct-v2',\n            'ibm/granite-20b-code-instruct',\n            'ibm/granite-20b-multilingual',\n            'ibm/granite-34b-code-instruct',\n            'ibm/granite-7b-lab',\n            'ibm/granite-8b-code-instruct',\n            'bigscience/mt0-xxl',\n        ]\n\n        decoding_options = [\n            \"greedy\",\n            \"sample\"\n        ]\n        \n        url_options = [      \n            \"https://us-south.ml.cloud.ibm.com\",\n            \"https://eu-gb.ml.cloud.ibm.com\",\n            \"https://eu-de.ml.cloud.ibm.com\",\n            \"https://jp-tok.ml.cloud.ibm.com\"\n        ]\n\n        stp_sequences = [  \n            \"</s>\",\n            \"<|end_of_text|>\"\n        ]\n \n\n        return {\n            \"model_id\": {\n                \"display_name\": \"Model Name\",\n                \"options\": model_options,\n                \"value\": model_options[2],\n                \"info\": \"The ID of the model or tune to be used for this request.\",\n            },\n            \"url\": {\n                \"display_name\": \"Url Endpoint\",\n                \"info\": \"Url endpoint for watsonx\",\n                \"options\": url_options,\n                \"value\": url_options[2],\n            },\n            \"apikey\": {\n                \"display_name\": \"API Key\",\n                \"password\": True,\n                \"info\": \"API uses API keys for authentication.\",\n                \"value\": \"HPsQWoh12PnzXwOdPYWZl8q6GusQX9T4vxsvhS-vcdIs\",  ###placeholder\n                \"required\": True\n            },\n            \"project_id\": {\n                \"display_name\": \"Project_id\",\n                \"info\": \"Project Id necessary to run inference.\",\n                \"value\": \"f275d991-68a4-47d9-b6e8-c8c052f63b33\",  ###placeholder\n                \"required\": True\n            },\n            # \"api_endpoint\": { \"display_name\": \"API Endpoint\", \"value\": \"https://bam-api.res.ibm.com/v1/\" },\n            \"decoding_method\": {\n                \"display_name\": \"Decoding Method\",\n                \"options\": decoding_options,\n                \"value\": decoding_options[0],\n                \"info\": \"Represents the strategy used for picking the tokens during generation of the output text.\"\n            },\n            \"stop_sequences\": {\n                \"display_name\": \"Stopping Sequences\",\n                \"options\": stp_sequences,\n                \"value\": stp_sequences[0],\n                \"info\": \"Encountering these strings will cause the model to stop generation.\",\n            },\n            \"min_new_tokens\": {\n                \"display_name\": \"Minimum New Tokens\",\n                \"value\": 5,\n                \"info\": \"The minimum number of new tokens to be generated.\"\n            },\n            \"max_new_tokens\": {\n                \"display_name\": \"Max New Tokens\",\n                \"value\": 4000,\n                \"info\": \"The maximum number of new tokens to be generated.\"\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n                \"info\": \"A value used to modify the next-token probabilities in sampling mode.\"\n            },\n            \"repetition_penalty\": {\n                \"display_name\": \"Repetition Penalty\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1\"\n            },\n            \"random_seed\": {\n                \"display_name\": \"Random Seed\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1.\"\n            },\n            \"top_p\": {\n                \"display_name\": \"Top_P\",\n                \"value\": 1,\n                \"info\": \"Defaults to 1.\"\n            },\n            \"top_k\": {\n                \"display_name\": \"Top_K\",\n                \"value\": 50,\n                \"info\": \"Defaults to 50.\"\n            },\n            \"code\": {\"show\": False}\n        }\n\n    def build(\n            self,\n            model_id: str,\n            apikey: str,\n            url: str,\n            project_id: str,\n            decoding_method: str,\n            stop_sequences: str,\n            repetition_penalty: float,\n            max_new_tokens: int,\n            min_new_tokens: int,\n            temperature: float,\n            random_seed: int,\n            top_p: float,\n            top_k: int,\n        ) -> BaseLLM:\n            from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n            #creds = APIClient(apikey, url)\n            stop_seq = [seq.strip() for seq in stop_sequences.splitlines()]\n            params = {\n                GenParams.TEMPERATURE: temperature,\n                GenParams.MAX_NEW_TOKENS: max_new_tokens,\n                GenParams.MIN_NEW_TOKENS: min_new_tokens,\n                GenParams.DECODING_METHOD: decoding_method,\n                GenParams.REPETITION_PENALTY: repetition_penalty,\n                GenParams.TOP_K: top_k,\n                GenParams.TOP_P: top_p,\n                GenParams.STOP_SEQUENCES: stop_seq,\n                GenParams.RANDOM_SEED: random_seed,\n            }\n            print(params)\n            model = WatsonxLLM(model_id=model_id, params=params, apikey=apikey, url=url, project_id=project_id)\n            return model\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "decoding_method": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "greedy",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "greedy",
                    "sample"
                  ],
                  "name": "decoding_method",
                  "display_name": "Decoding Method",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Represents the strategy used for picking the tokens during generation of the output text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "max_new_tokens": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 4000,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_new_tokens",
                  "display_name": "Max New Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of new tokens to be generated.",
                  "load_from_db": false,
                  "title_case": false
                },
                "min_new_tokens": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 5,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "min_new_tokens",
                  "display_name": "Minimum New Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The minimum number of new tokens to be generated.",
                  "load_from_db": false,
                  "title_case": false
                },
                "model_id": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "mistralai/mixtral-8x7b-instruct-v01",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "mistralai/mixtral-8x7b-instruct-v01",
                    "meta-llama/llama-3-8b-instruct",
                    "meta-llama/llama-3-70b-instruct",
                    "meta-llama/llama-2-13b-chat",
                    "meta-llama/llama-2-70b-chat",
                    "ibm-mistralai/merlinite-7b",
                    "codellama/codellama-34b-instruct-hf",
                    "google/flan-t5-xl",
                    "google/flan-t5-xxl",
                    "google/flan-ul2",
                    "ibm/granite-13b-chat-v2",
                    "ibm/granite-13b-instruct-v2",
                    "ibm/granite-20b-code-instruct",
                    "ibm/granite-20b-multilingual",
                    "ibm/granite-34b-code-instruct",
                    "ibm/granite-7b-lab",
                    "ibm/granite-8b-code-instruct",
                    "bigscience/mt0-xxl"
                  ],
                  "name": "model_id",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The ID of the model or tune to be used for this request.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "project_id": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "f275d991-68a4-47d9-b6e8-c8c052f63b33",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "project_id",
                  "display_name": "Project_id",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Project Id necessary to run inference.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "random_seed": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 1,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "random_seed",
                  "display_name": "Random Seed",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Defaults to 1.",
                  "load_from_db": false,
                  "title_case": false
                },
                "repetition_penalty": {
                  "type": "float",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 1,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "repetition_penalty",
                  "display_name": "Repetition Penalty",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Defaults to 1",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "stop_sequences": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "</s>",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "</s>",
                    "<|end_of_text|>"
                  ],
                  "name": "stop_sequences",
                  "display_name": "Stopping Sequences",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Encountering these strings will cause the model to stop generation.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "temperature": {
                  "type": "float",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.7,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "A value used to modify the next-token probabilities in sampling mode.",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "top_k": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 50,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_k",
                  "display_name": "Top_K",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Defaults to 50.",
                  "load_from_db": false,
                  "title_case": false
                },
                "top_p": {
                  "type": "float",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 1,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "top_p",
                  "display_name": "Top_P",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Defaults to 1.",
                  "rangeSpec": {
                    "step_type": "float",
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "load_from_db": false,
                  "title_case": false
                },
                "url": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "https://eu-de.ml.cloud.ibm.com",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "https://us-south.ml.cloud.ibm.com",
                    "https://eu-gb.ml.cloud.ibm.com",
                    "https://eu-de.ml.cloud.ibm.com",
                    "https://jp-tok.ml.cloud.ibm.com"
                  ],
                  "name": "url",
                  "display_name": "Url Endpoint",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Url endpoint for watsonx",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Watsonx foundation models",
              "base_classes": [
                "BaseLanguageModel",
                "BaseLLM",
                "Generic",
                "object",
                "Runnable",
                "RunnableSerializable",
                "Serializable"
              ],
              "display_name": "watsonx.ai - mixtral-8x7b",
              "documentation": "",
              "custom_fields": {
                "model_id": null,
                "apikey": null,
                "url": null,
                "project_id": null,
                "decoding_method": null,
                "stop_sequences": null,
                "repetition_penalty": null,
                "max_new_tokens": null,
                "min_new_tokens": null,
                "temperature": null,
                "random_seed": null,
                "top_p": null,
                "top_k": null
              },
              "output_types": [
                "BaseLLM"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false,
              "official": false
            },
            "id": "CustomComponent-ZSMAm"
          },
          "selected": false,
          "width": 384,
          "height": 1348,
          "positionAbsolute": {
            "x": 1694.5922895533595,
            "y": -619.6827398771425
          },
          "dragging": false
        },
        {
          "id": "Prompt-2HeG1",
          "type": "genericNode",
          "position": {
            "x": 1753.3030961524453,
            "y": 902.0076526884102
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "prompt",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "<s>[INST] Using the text between [INPUT] and [END_OF_INPUT] extract the different elements into a cohesive list with their relationships and {instruction_context} characteristics.\nReturn the output as JSON.\nDifferent steps should be grouped into the following larger scale groupings chronologically (unless otherwise specified): {groupings}\nAlso assign emotional intensity scores from 1 (horrible), 2 (unsatisfied), 3 (neutral), 4 (happy) to 5 (fantastic) to each step based on the text with a very slight emphasis for a stronger effect. [/INST]\n\n[INST] Using the text between [INPUT] and [END_OF_INPUT] extract the different elements into a cohesive list with their relationships and {instruction_context} characteristics. Return the output as JSON.\nDifferent steps should be grouped into the following larger scale groupings chronologically (unless otherwise specified): {groupings}\nAlso assign emotional intensity scores from 1 (horrible), 2 (unsatisfied), 3 (neutral), 4 (happy) to 5 (fantastic) to each step based on the text with a very slight emphasis for a stronger effect.\n[INPUT] {input_text} [END_OF_INPUT] [/INST]\n\n\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent",
                "instruction_context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "instruction_context",
                  "display_name": "instruction_context",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "groupings": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "groupings",
                  "display_name": "groupings",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "input_text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_text",
                  "display_name": "input_text",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "name": "",
              "display_name": "element_extractor_PT",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "instruction_context",
                  "groupings",
                  "input_text"
                ]
              },
              "output_types": [
                "Text"
              ],
              "full_path": null,
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false,
              "error": null
            },
            "id": "Prompt-2HeG1",
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "element_extractor_PT"
          },
          "selected": false,
          "width": 384,
          "height": 566,
          "dragging": false,
          "positionAbsolute": {
            "x": 1753.3030961524453,
            "y": 902.0076526884102
          }
        },
        {
          "id": "TextInput-Rc4fR",
          "type": "genericNode",
          "position": {
            "x": 676.0998391156161,
            "y": 1608.8362666707594
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "User Journey",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Value",
                  "advanced": false,
                  "input_types": [
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "Text or Record to be passed as input.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "instruction_context",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "record_template": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "TextInput-Rc4fR"
          },
          "selected": false,
          "width": 384,
          "height": 287,
          "positionAbsolute": {
            "x": 676.0998391156161,
            "y": 1608.8362666707594
          },
          "dragging": false
        },
        {
          "id": "TextInput-UtN4a",
          "type": "genericNode",
          "position": {
            "x": 742.0169480176012,
            "y": 880.2478435068135
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "Goal, Start of Journey, Painpoints, End of Journey AS-IS",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Value",
                  "advanced": false,
                  "input_types": [
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "Text or Record to be passed as input.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "groupings",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "record_template": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "TextInput-UtN4a"
          },
          "selected": false,
          "width": 384,
          "height": 287,
          "dragging": false,
          "positionAbsolute": {
            "x": 742.0169480176012,
            "y": 880.2478435068135
          }
        },
        {
          "id": "LLMChain-ui78J",
          "type": "genericNode",
          "position": {
            "x": 2772.0293238862037,
            "y": 787.6196353789855
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom langchain.chains.llm import LLMChain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Text\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n        }\n\n    def build(\n        self,\n        template: Text,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        prompt = PromptTemplate.from_template(template)\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\n        result_dict = runnable.invoke({})\n        output_key = runnable.output_key\n        result = result_dict[output_key]\n        self.status = result\n        return result\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "extract",
              "documentation": "",
              "custom_fields": {
                "template": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "LLMChain-ui78J"
          },
          "selected": false,
          "width": 384,
          "height": 383,
          "dragging": false,
          "positionAbsolute": {
            "x": 2772.0293238862037,
            "y": 787.6196353789855
          }
        },
        {
          "id": "ChatOutput-ehQgZ",
          "type": "genericNode",
          "position": {
            "x": 4924.29592860122,
            "y": -120.42653355286228
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, Union\n\nfrom axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.field_typing import Text\nfrom axiestudio.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Message",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "{text}",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "In case of Message being a Record, this template will be used to convert it to text.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "return_record": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_record",
                  "display_name": "Return Record",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Return the message as a record containing the sender, sender_name, and session_id.",
                  "load_from_db": false,
                  "title_case": false
                },
                "sender": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "Machine",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "name": "sender",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "sender_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "AI",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "sender_name",
                  "display_name": "Sender Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "session_id": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "session_id",
                  "display_name": "Session ID",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If provided, the message will be stored in the memory.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "object",
                "Record",
                "str",
                "Text"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {
                "sender": null,
                "sender_name": null,
                "input_value": null,
                "session_id": null,
                "return_record": null,
                "record_template": null
              },
              "output_types": [
                "Text",
                "Record"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "ChatOutput-ehQgZ"
          },
          "selected": false,
          "width": 384,
          "height": 380,
          "positionAbsolute": {
            "x": 4924.29592860122,
            "y": -120.42653355286228
          },
          "dragging": false
        },
        {
          "id": "Prompt-hClEA",
          "type": "genericNode",
          "position": {
            "x": 3528.6802519902367,
            "y": 576.5451206978421
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from axiestudio.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "prompt",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": " <s> [INST] Create a Mermaid User Journey graph in markdown output connecting the elements that are related to each other in the JSON data.\nThe data to be processed will be in between [Data] and [End of data].\n\nSection each part of the user journey that falls under a separate overall category and add emotional intensity scores to all values under the same section, use shortened names for the section names.\n\n[Diagram Documentation]\n{diagram_context}\n[End of Documentation]\n\n[Example]\n{example}\n[End of Example]\n[/INST]\n\n[INST] Create a Mermaid User Journey graph in markdown output connecting the elements that are related to each other in the JSON data.\nThe data to be processed will be in between [Data] and [End of data].\n\nSection each part of the user journey that falls under a separate overall category and add emotional intensity scores to all values under the same section, use shortened names for the section names.\n\n[Diagram Documentation]\n{diagram_context}\n[End of Documentation]\n\n[Example]\n{example}\n[End of Example]\n\n[Data]{text}[End of data]\n\nOutput the return as:\n\"[```mermaid]\n<result>\n[```]\"\n[/INST]",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "display_name": "Template",
                  "advanced": false,
                  "input_types": [
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent",
                "diagram_context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "User Journey Diagram\n\nUser journeys describe at a high level of detail exactly what steps different users take to complete a specific task within a system, application or website. This technique shows the current (as-is) user workflow, and reveals areas of improvement for the to-be workflow. (Wikipedia)\n\nMermaid can render user journey diagrams:\n\n```mermaid-example\njourney\n    title My working day\n    section Go to work\n      Make tea: 5: Me\n      Go upstairs: 3: Me\n      Do work: 1: Me, Cat\n    section Go home\n      Go downstairs: 5: Me\n      Sit down: 5: Me\n```\n\nEach user journey is split into sections, these describe the part of the task\nthe user is trying to complete.\n\nTasks syntax is `Task name: <score>: <comma separated list of actors>`",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "diagram_context",
                  "display_name": "diagram_context",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "example": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "journey\n      title My working day\n      section Go to work\n        Make tea: 5: Me\n        Go upstairs: 3: Me\n        Do work: 1: Me, Cat\n      section Go home\n        Go downstairs: 5: Me\n        Sit down: 5: Me",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "example",
                  "display_name": "example",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "text": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "text",
                  "display_name": "text",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Create a prompt template with dynamic variables.",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "name": "",
              "display_name": "user_journey_generator_PT",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "diagram_context",
                  "example",
                  "text"
                ]
              },
              "output_types": [
                "Text"
              ],
              "full_path": null,
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false,
              "error": null
            },
            "id": "Prompt-hClEA",
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "user_journey_generator_PT"
          },
          "selected": false,
          "width": 384,
          "height": 566,
          "positionAbsolute": {
            "x": 3528.6802519902367,
            "y": 576.5451206978421
          },
          "dragging": false
        },
        {
          "id": "LLMChain-S3BR5",
          "type": "genericNode",
          "position": {
            "x": 4244.546546830011,
            "y": 258.6613524493296
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom langchain.chains.llm import LLMChain\nfrom langchain_core.prompts import PromptTemplate\n\nfrom axiestudio.custom import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Text\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n        }\n\n    def build(\n        self,\n        template: Text,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Text:\n        prompt = PromptTemplate.from_template(template)\n        runnable = LLMChain(prompt=prompt, llm=llm, memory=memory)\n        result_dict = runnable.invoke({})\n        output_key = runnable.output_key\n        result = result_dict[output_key]\n        self.status = result\n        return result\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "LLMChain",
              "documentation": "",
              "custom_fields": {
                "template": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "LLMChain-S3BR5"
          },
          "selected": false,
          "width": 384,
          "height": 382,
          "positionAbsolute": {
            "x": 4244.546546830011,
            "y": 258.6613524493296
          },
          "dragging": false
        },
        {
          "id": "TextInput-k42fF",
          "type": "genericNode",
          "position": {
            "x": 705.2733487471658,
            "y": 1229.437558602747
          },
          "data": {
            "type": "TextInput",
            "node": {
              "template": {
                "input_value": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "Emma reached for her phone on the nightstand, preparing for a busy day ahead. She needed to quickly review her account balance before heading out the door. However, upon opening her mobile banking app, she was met with an unexpected error message: \"We're experiencing technical difficulties. Please try again later.\"  Emma's concern grew as she realized she had important financial tasks to attend to, including a pending bill payment and a transfer to her sister for their shared rent. She attempted to log in again, but the same error message persisted. To troubleshoot, she verified her internet connection, ensuring it was stable and functional.  Seeking assistance, Emma decided to utilize the app's built-in chat support feature. She composed a detailed message describing the issue and awaited a response from the support team. As the minutes ticked by, Emma's sense of urgency increased, knowing she had to leave for work soon.  Finally, a response from the support team arrived: \"We apologize for the inconvenience, Emma. Our team is currently addressing a technical issue. As a troubleshooting step, could you please try deleting and reinstalling the app?\" Emma was slightly disappointed, having already attempted this solution without success. She crafted a polite response, explaining that she had already tried reinstalling the app, and kindly requested further assistance to resolve the matter.  As she waited for a follow-up response, Emma couldn't help but feel a sense of frustration, hoping that the issue would be resolved promptly to avoid any further delays in her day.",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_value",
                  "display_name": "Value",
                  "advanced": false,
                  "input_types": [
                    "Record",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "Text or Record to be passed as input.",
                  "load_from_db": false,
                  "title_case": false
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\n\nfrom axiestudio.base.io.text import TextComponent\nfrom axiestudio.field_typing import Text\n\n\nclass TextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as input.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Optional[Text] = \"\",\n        record_template: Optional[str] = \"\",\n    ) -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "record_template": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "record_template",
                  "display_name": "Record Template",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.",
                  "load_from_db": false,
                  "title_case": false,
                  "input_types": [
                    "Text"
                  ]
                },
                "_type": "CustomComponent"
              },
              "description": "Get text inputs from the Playground.",
              "icon": "type",
              "base_classes": [
                "object",
                "str",
                "Text"
              ],
              "display_name": "input_text",
              "documentation": "",
              "custom_fields": {
                "input_value": null,
                "record_template": null
              },
              "output_types": [
                "Text"
              ],
              "field_formatters": {},
              "frozen": false,
              "field_order": [],
              "beta": false
            },
            "id": "TextInput-k42fF"
          },
          "selected": true,
          "width": 384,
          "height": 287,
          "positionAbsolute": {
            "x": 705.2733487471658,
            "y": 1229.437558602747
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "TextInput-Rc4fR",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Rc4fRœ}",
          "target": "Prompt-2HeG1",
          "targetHandle": "{œfieldNameœ:œinstruction_contextœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "instruction_context",
              "id": "Prompt-2HeG1",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "TextInput",
              "id": "TextInput-Rc4fR"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-TextInput-Rc4fR{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-Rc4fRœ}-Prompt-2HeG1{œfieldNameœ:œinstruction_contextœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "TextInput-UtN4a",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UtN4aœ}",
          "target": "Prompt-2HeG1",
          "targetHandle": "{œfieldNameœ:œgroupingsœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "groupings",
              "id": "Prompt-2HeG1",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "TextInput",
              "id": "TextInput-UtN4a"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-TextInput-UtN4a{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-UtN4aœ}-Prompt-2HeG1{œfieldNameœ:œgroupingsœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "CustomComponent-ZSMAm",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}",
          "target": "LLMChain-ui78J",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-ui78J",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseLLM",
                "Generic",
                "object",
                "Runnable",
                "RunnableSerializable",
                "Serializable"
              ],
              "dataType": "CustomComponent",
              "id": "CustomComponent-ZSMAm"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-CustomComponent-ZSMAm{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}-LLMChain-ui78J{œfieldNameœ:œllmœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "Prompt-2HeG1",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-2HeG1œ}",
          "target": "LLMChain-ui78J",
          "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "template",
              "id": "LLMChain-ui78J",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "Prompt",
              "id": "Prompt-2HeG1"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-Prompt-2HeG1{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-2HeG1œ}-LLMChain-ui78J{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-ui78Jœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "LLMChain-ui78J",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-ui78Jœ}",
          "target": "Prompt-hClEA",
          "targetHandle": "{œfieldNameœ:œtextœ,œidœ:œPrompt-hClEAœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "text",
              "id": "Prompt-hClEA",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "LLMChain",
              "id": "LLMChain-ui78J"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-LLMChain-ui78J{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-ui78Jœ}-Prompt-hClEA{œfieldNameœ:œtextœ,œidœ:œPrompt-hClEAœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "LLMChain-S3BR5",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-S3BR5œ}",
          "target": "ChatOutput-ehQgZ",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ehQgZœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-ehQgZ",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "LLMChain",
              "id": "LLMChain-S3BR5"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-LLMChain-S3BR5{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œLLMChainœ,œidœ:œLLMChain-S3BR5œ}-ChatOutput-ehQgZ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ehQgZœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "Prompt-hClEA",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-hClEAœ}",
          "target": "LLMChain-S3BR5",
          "targetHandle": "{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "template",
              "id": "LLMChain-S3BR5",
              "inputTypes": [
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "Prompt",
              "id": "Prompt-hClEA"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-Prompt-hClEA{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-hClEAœ}-LLMChain-S3BR5{œfieldNameœ:œtemplateœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"
        },
        {
          "source": "CustomComponent-ZSMAm",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}",
          "target": "LLMChain-S3BR5",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-S3BR5",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseLLM",
                "Generic",
                "object",
                "Runnable",
                "RunnableSerializable",
                "Serializable"
              ],
              "dataType": "CustomComponent",
              "id": "CustomComponent-ZSMAm"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-CustomComponent-ZSMAm{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-ZSMAmœ}-LLMChain-S3BR5{œfieldNameœ:œllmœ,œidœ:œLLMChain-S3BR5œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "TextInput-k42fF",
          "sourceHandle": "{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-k42fFœ}",
          "target": "Prompt-2HeG1",
          "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_text",
              "id": "Prompt-2HeG1",
              "inputTypes": [
                "Document",
                "Record",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "object",
                "str",
                "Text"
              ],
              "dataType": "TextInput",
              "id": "TextInput-k42fF"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground stroke-connection",
          "id": "reactflow__edge-TextInput-k42fF{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œTextInputœ,œidœ:œTextInput-k42fFœ}-Prompt-2HeG1{œfieldNameœ:œinput_textœ,œidœ:œPrompt-2HeG1œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": -95.57652960163136,
        "y": 246.2401551465146,
        "zoom": 0.2952584202113449
      }
    },
    "date_created": "2024-06-18T10:37:34.229Z",
    "date_updated": "2024-06-18T10:37:34.262Z",
    "status": "Public",
    "sort": null,
    "user_updated": "4d6acd51-154b-427e-af47-512b44b0c1ba",
    "user_created": {
      "username": "Mimr_0",
      "first_name": "Milan",
      "last_name": "Mrdenovic",
      "id": "4d6acd51-154b-427e-af47-512b44b0c1ba"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:03.802Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 48,
    "converter_version": "1.0.0"
  }
}