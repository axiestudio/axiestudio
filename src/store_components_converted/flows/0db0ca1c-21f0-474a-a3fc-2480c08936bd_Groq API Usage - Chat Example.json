{
  "id": "0db0ca1c-21f0-474a-a3fc-2480c08936bd",
  "name": "Groq API Usage - Chat Example",
  "description": "This flow is an example of the Groq API Usage, where you can try models running in LPUs through Groq API. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "NickF2K",
    "first_name": "Nicholas",
    "last_name": "Ferrara",
    "id": "4dffcb59-11fb-48b4-8696-2ab1fba6e6ca",
    "full_name": "Nicholas Ferrara"
  },
  "store_url": "https://www.langflow.store/store/component/0db0ca1c-21f0-474a-a3fc-2480c08936bd",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-05-20T23:19:10.701Z",
    "updated": "2024-05-20T23:19:10.739Z",
    "downloaded": "2025-08-19T17:50:05.691Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.6.19",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ConversationChain-DcFfh",
        "type": "genericNode",
        "position": {
          "x": -1428.860170682643,
          "y": 807.6802377191115
        },
        "data": {
          "type": "ConversationChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "Memory to load context from. If none is provided, a ConversationBufferMemory will be used.",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio import CustomComponent\nfrom langchain.chains import ConversationChain\nfrom typing import Optional, Union, Callable\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Chain\n\n\nclass ConversationChainComponent(CustomComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\n                \"display_name\": \"Memory\",\n                \"info\": \"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        if memory is None:\n            return ConversationChain(llm=llm)\n        return ConversationChain(llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to have a conversation and load context from memory.",
            "base_classes": [
              "Chain",
              "Callable"
            ],
            "display_name": "ConversationChain",
            "documentation": "",
            "custom_fields": {
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "ConversationChain-DcFfh"
        },
        "selected": false,
        "width": 384,
        "height": 397,
        "positionAbsolute": {
          "x": -1428.860170682643,
          "y": 807.6802377191115
        },
        "dragging": false
      },
      {
        "id": "Cohere-UMlIe",
        "type": "genericNode",
        "position": {
          "x": -1877.0562558955917,
          "y": 860.9107124139372
        },
        "data": {
          "type": "Cohere",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.llms.cohere import Cohere\nfrom langchain_core.language_models.base import BaseLanguageModel\nfrom axiestudio import CustomComponent\n\n\nclass CohereComponent(CustomComponent):\n    display_name = \"Cohere\"\n    description = \"Cohere large language models.\"\n    documentation = \"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\"\n\n    def build_config(self):\n        return {\n            \"cohere_api_key\": {\"display_name\": \"Cohere API Key\", \"type\": \"password\", \"password\": True},\n            \"max_tokens\": {\"display_name\": \"Max Tokens\", \"default\": 256, \"type\": \"int\", \"show\": True},\n            \"temperature\": {\"display_name\": \"Temperature\", \"default\": 0.75, \"type\": \"float\", \"show\": True},\n        }\n\n    def build(\n        self,\n        cohere_api_key: str,\n        max_tokens: int = 256,\n        temperature: float = 0.75,\n    ) -> BaseLanguageModel:\n        return Cohere(cohere_api_key=cohere_api_key, max_tokens=max_tokens, temperature=temperature)  # type: ignore\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "cohere_api_key": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "cohere_api_key",
                "display_name": "Cohere API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "max_tokens": {
                "type": "int",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "500",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "temperature": {
                "type": "float",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.75,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Cohere large language models.",
            "base_classes": [
              "BaseLanguageModel"
            ],
            "display_name": "Cohere",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere",
            "custom_fields": {
              "cohere_api_key": null,
              "max_tokens": null,
              "temperature": null
            },
            "output_types": [
              "BaseLanguageModel"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "Cohere-UMlIe"
        },
        "selected": false,
        "width": 384,
        "height": 547,
        "positionAbsolute": {
          "x": -1877.0562558955917,
          "y": 860.9107124139372
        },
        "dragging": false
      },
      {
        "id": "ChatPromptTemplate-w8Q58",
        "type": "genericNode",
        "position": {
          "x": -1894.4483035392395,
          "y": 595.7789183966333
        },
        "data": {
          "type": "ChatPromptTemplate",
          "node": {
            "template": {
              "messages": {
                "type": "BaseMessagePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "messages",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "ChatPromptTemplate"
            },
            "description": "Prompt template for chat models.",
            "base_classes": [
              "BasePromptTemplate",
              "ChatPromptTemplate",
              "BaseChatPromptTemplate"
            ],
            "display_name": "ChatPromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "ChatPromptTemplate-w8Q58"
        },
        "selected": false,
        "width": 384,
        "height": 243,
        "positionAbsolute": {
          "x": -1894.4483035392395,
          "y": 595.7789183966333
        },
        "dragging": false
      },
      {
        "id": "LLMChain-HKNkj",
        "type": "genericNode",
        "position": {
          "x": -2296.1443404155616,
          "y": 937.9744439268809
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable",
              "Chain",
              "LLMChain"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "prompt": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable",
              "LLMChain"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "LLMChain-HKNkj"
        },
        "selected": false,
        "width": 384,
        "height": 425,
        "dragging": false,
        "positionAbsolute": {
          "x": -2296.1443404155616,
          "y": 937.9744439268809
        }
      },
      {
        "id": "HumanMessagePromptTemplate-RhRDX",
        "type": "genericNode",
        "position": {
          "x": -2305.324332566608,
          "y": 595.9622014173954
        },
        "data": {
          "type": "HumanMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": true,
                "value": "You are a helpful assistant.",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "HumanMessagePromptTemplate"
            },
            "description": "Human message prompt template. This is a message sent from the user.",
            "icon": null,
            "base_classes": [
              "_StringImageMessagePromptTemplate",
              "BaseMessagePromptTemplate",
              "HumanMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "HumanMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {
              "": []
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "HumanMessagePromptTemplate-RhRDX",
          "description": "Human message prompt template. This is a message sent from the user.",
          "display_name": "HumanMessagePromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 301,
        "positionAbsolute": {
          "x": -2305.324332566608,
          "y": 595.9622014173954
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Cohere-UMlIe",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}",
        "target": "ConversationChain-DcFfh",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-DcFfhœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationChain-DcFfh",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel"
            ],
            "dataType": "Cohere",
            "id": "Cohere-UMlIe"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-Cohere-UMlIe{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}-ConversationChain-DcFfh{œfieldNameœ:œllmœ,œidœ:œConversationChain-DcFfhœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "ChatPromptTemplate-w8Q58",
        "sourceHandle": "{œbaseClassesœ:[œBasePromptTemplateœ,œChatPromptTemplateœ,œBaseChatPromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-w8Q58œ}",
        "target": "LLMChain-HKNkj",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-HKNkj",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "BasePromptTemplate",
              "ChatPromptTemplate",
              "BaseChatPromptTemplate"
            ],
            "dataType": "ChatPromptTemplate",
            "id": "ChatPromptTemplate-w8Q58"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatPromptTemplate-w8Q58{œbaseClassesœ:[œBasePromptTemplateœ,œChatPromptTemplateœ,œBaseChatPromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-w8Q58œ}-LLMChain-HKNkj{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
      },
      {
        "source": "Cohere-UMlIe",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}",
        "target": "LLMChain-HKNkj",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-HKNkj",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel"
            ],
            "dataType": "Cohere",
            "id": "Cohere-UMlIe"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-Cohere-UMlIe{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}-LLMChain-HKNkj{œfieldNameœ:œllmœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "HumanMessagePromptTemplate-RhRDX",
        "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-RhRDXœ}",
        "target": "ChatPromptTemplate-w8Q58",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-w8Q58œ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-w8Q58",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "_StringImageMessagePromptTemplate",
              "BaseMessagePromptTemplate",
              "HumanMessagePromptTemplate"
            ],
            "dataType": "HumanMessagePromptTemplate",
            "id": "HumanMessagePromptTemplate-RhRDX"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-HumanMessagePromptTemplate-RhRDX{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-RhRDXœ}-ChatPromptTemplate-w8Q58{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-w8Q58œ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      }
    ],
    "viewport": {
      "x": 1580.6778457460805,
      "y": -237.28443307791713,
      "zoom": 0.612355418195931
    }
  },
  "metadata": {
    "ConversationChain": {
      "count": 1
    },
    "Cohere": {
      "count": 1
    },
    "ChatPromptTemplate": {
      "count": 1
    },
    "LLMChain": {
      "count": 1
    },
    "HumanMessagePromptTemplate": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "0db0ca1c-21f0-474a-a3fc-2480c08936bd",
    "name": "Groq API Usage - Chat Example",
    "description": "This flow is an example of the Groq API Usage, where you can try models running in LPUs through Groq API.",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "2",
    "metadata": {
      "ConversationChain": {
        "count": 1
      },
      "Cohere": {
        "count": 1
      },
      "ChatPromptTemplate": {
        "count": 1
      },
      "LLMChain": {
        "count": 1
      },
      "HumanMessagePromptTemplate": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "0.6.19",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "ConversationChain-DcFfh",
          "type": "genericNode",
          "position": {
            "x": -1428.860170682643,
            "y": 807.6802377191115
          },
          "data": {
            "type": "ConversationChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Memory to load context from. If none is provided, a ConversationBufferMemory will be used.",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio import CustomComponent\nfrom langchain.chains import ConversationChain\nfrom typing import Optional, Union, Callable\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Chain\n\n\nclass ConversationChainComponent(CustomComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\n                \"display_name\": \"Memory\",\n                \"info\": \"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        if memory is None:\n            return ConversationChain(llm=llm)\n        return ConversationChain(llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to have a conversation and load context from memory.",
              "base_classes": [
                "Chain",
                "Callable"
              ],
              "display_name": "ConversationChain",
              "documentation": "",
              "custom_fields": {
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "ConversationChain-DcFfh"
          },
          "selected": false,
          "width": 384,
          "height": 397,
          "positionAbsolute": {
            "x": -1428.860170682643,
            "y": 807.6802377191115
          },
          "dragging": false
        },
        {
          "id": "Cohere-UMlIe",
          "type": "genericNode",
          "position": {
            "x": -1877.0562558955917,
            "y": 860.9107124139372
          },
          "data": {
            "type": "Cohere",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.llms.cohere import Cohere\nfrom langchain_core.language_models.base import BaseLanguageModel\nfrom axiestudio import CustomComponent\n\n\nclass CohereComponent(CustomComponent):\n    display_name = \"Cohere\"\n    description = \"Cohere large language models.\"\n    documentation = \"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\"\n\n    def build_config(self):\n        return {\n            \"cohere_api_key\": {\"display_name\": \"Cohere API Key\", \"type\": \"password\", \"password\": True},\n            \"max_tokens\": {\"display_name\": \"Max Tokens\", \"default\": 256, \"type\": \"int\", \"show\": True},\n            \"temperature\": {\"display_name\": \"Temperature\", \"default\": 0.75, \"type\": \"float\", \"show\": True},\n        }\n\n    def build(\n        self,\n        cohere_api_key: str,\n        max_tokens: int = 256,\n        temperature: float = 0.75,\n    ) -> BaseLanguageModel:\n        return Cohere(cohere_api_key=cohere_api_key, max_tokens=max_tokens, temperature=temperature)  # type: ignore\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "cohere_api_key": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "cohere_api_key",
                  "display_name": "Cohere API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": ""
                },
                "max_tokens": {
                  "type": "int",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "500",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "temperature": {
                  "type": "float",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.75,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Cohere large language models.",
              "base_classes": [
                "BaseLanguageModel"
              ],
              "display_name": "Cohere",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere",
              "custom_fields": {
                "cohere_api_key": null,
                "max_tokens": null,
                "temperature": null
              },
              "output_types": [
                "BaseLanguageModel"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "Cohere-UMlIe"
          },
          "selected": false,
          "width": 384,
          "height": 547,
          "positionAbsolute": {
            "x": -1877.0562558955917,
            "y": 860.9107124139372
          },
          "dragging": false
        },
        {
          "id": "ChatPromptTemplate-w8Q58",
          "type": "genericNode",
          "position": {
            "x": -1894.4483035392395,
            "y": 595.7789183966333
          },
          "data": {
            "type": "ChatPromptTemplate",
            "node": {
              "template": {
                "messages": {
                  "type": "BaseMessagePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "messages",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "output_parser": {
                  "type": "BaseOutputParser",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_types": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_types",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_variables": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "name",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "partial_variables": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "tags": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "validate_template": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "ChatPromptTemplate"
              },
              "description": "Prompt template for chat models.",
              "base_classes": [
                "BasePromptTemplate",
                "ChatPromptTemplate",
                "BaseChatPromptTemplate"
              ],
              "display_name": "ChatPromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "ChatPromptTemplate-w8Q58"
          },
          "selected": false,
          "width": 384,
          "height": 243,
          "positionAbsolute": {
            "x": -1894.4483035392395,
            "y": 595.7789183966333
          },
          "dragging": false
        },
        {
          "id": "LLMChain-HKNkj",
          "type": "genericNode",
          "position": {
            "x": -2296.1443404155616,
            "y": 937.9744439268809
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "BasePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt",
                  "display_name": "Prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "Chain",
                "Callable",
                "Chain",
                "LLMChain"
              ],
              "display_name": "LLMChain",
              "documentation": "",
              "custom_fields": {
                "prompt": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable",
                "LLMChain"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "LLMChain-HKNkj"
          },
          "selected": false,
          "width": 384,
          "height": 425,
          "dragging": false,
          "positionAbsolute": {
            "x": -2296.1443404155616,
            "y": 937.9744439268809
          }
        },
        {
          "id": "HumanMessagePromptTemplate-RhRDX",
          "type": "genericNode",
          "position": {
            "x": -2305.324332566608,
            "y": 595.9622014173954
          },
          "data": {
            "type": "HumanMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": true,
                  "value": "You are a helpful assistant.",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "HumanMessagePromptTemplate"
              },
              "description": "Human message prompt template. This is a message sent from the user.",
              "icon": null,
              "base_classes": [
                "_StringImageMessagePromptTemplate",
                "BaseMessagePromptTemplate",
                "HumanMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "HumanMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {
                "": []
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "HumanMessagePromptTemplate-RhRDX",
            "description": "Human message prompt template. This is a message sent from the user.",
            "display_name": "HumanMessagePromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 301,
          "positionAbsolute": {
            "x": -2305.324332566608,
            "y": 595.9622014173954
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Cohere-UMlIe",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}",
          "target": "ConversationChain-DcFfh",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-DcFfhœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ConversationChain-DcFfh",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel"
              ],
              "dataType": "Cohere",
              "id": "Cohere-UMlIe"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-Cohere-UMlIe{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}-ConversationChain-DcFfh{œfieldNameœ:œllmœ,œidœ:œConversationChain-DcFfhœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "ChatPromptTemplate-w8Q58",
          "sourceHandle": "{œbaseClassesœ:[œBasePromptTemplateœ,œChatPromptTemplateœ,œBaseChatPromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-w8Q58œ}",
          "target": "LLMChain-HKNkj",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "LLMChain-HKNkj",
              "inputTypes": null,
              "type": "BasePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "BasePromptTemplate",
                "ChatPromptTemplate",
                "BaseChatPromptTemplate"
              ],
              "dataType": "ChatPromptTemplate",
              "id": "ChatPromptTemplate-w8Q58"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatPromptTemplate-w8Q58{œbaseClassesœ:[œBasePromptTemplateœ,œChatPromptTemplateœ,œBaseChatPromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-w8Q58œ}-LLMChain-HKNkj{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
        },
        {
          "source": "Cohere-UMlIe",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}",
          "target": "LLMChain-HKNkj",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-HKNkj",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel"
              ],
              "dataType": "Cohere",
              "id": "Cohere-UMlIe"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-Cohere-UMlIe{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œCohereœ,œidœ:œCohere-UMlIeœ}-LLMChain-HKNkj{œfieldNameœ:œllmœ,œidœ:œLLMChain-HKNkjœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "HumanMessagePromptTemplate-RhRDX",
          "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-RhRDXœ}",
          "target": "ChatPromptTemplate-w8Q58",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-w8Q58œ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-w8Q58",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "_StringImageMessagePromptTemplate",
                "BaseMessagePromptTemplate",
                "HumanMessagePromptTemplate"
              ],
              "dataType": "HumanMessagePromptTemplate",
              "id": "HumanMessagePromptTemplate-RhRDX"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-HumanMessagePromptTemplate-RhRDX{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œBaseMessagePromptTemplateœ,œHumanMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-RhRDXœ}-ChatPromptTemplate-w8Q58{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-w8Q58œ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        }
      ],
      "viewport": {
        "x": 1580.6778457460805,
        "y": -237.28443307791713,
        "zoom": 0.612355418195931
      }
    },
    "date_created": "2024-05-20T23:19:10.701Z",
    "date_updated": "2024-05-20T23:19:10.739Z",
    "status": "Public",
    "sort": null,
    "user_updated": "4dffcb59-11fb-48b4-8696-2ab1fba6e6ca",
    "user_created": {
      "username": "NickF2K",
      "first_name": "Nicholas",
      "last_name": "Ferrara",
      "id": "4dffcb59-11fb-48b4-8696-2ab1fba6e6ca"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:53.912Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 10,
    "converter_version": "1.0.0"
  }
}