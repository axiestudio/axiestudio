{
  "id": "704cde09-7335-47cf-98a4-cff924dd71f4",
  "name": "Weaviate Document Reader + Keywords",
  "description": "Weaviate Document Reader (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "omid",
    "first_name": "Omid",
    "last_name": "Ha",
    "id": "8256fbbf-aacf-416a-b01f-ff4ec4b038be",
    "full_name": "Omid Ha"
  },
  "store_url": "https://www.langflow.store/store/component/704cde09-7335-47cf-98a4-cff924dd71f4",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-10-16T09:10:07.780Z",
    "updated": "2024-10-16T09:10:07.893Z",
    "downloaded": "2025-08-19T17:50:06.932Z"
  },
  "tags": [
    {
      "tags_id": {
        "name": "Vector Store",
        "id": "cd614b49-dd57-4c8b-a5eb-f8bb5f957b9a"
      }
    },
    {
      "tags_id": {
        "name": "Chain",
        "id": "d442c88b-f8d0-4010-8752-16a644c7ac8e"
      }
    }
  ],
  "technical": {
    "last_tested_version": "1.0.19",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "SplitText-AYSbJ",
        "type": "genericNode",
        "position": {
          "x": 979.8505261780281,
          "y": 471.10725283542536
        },
        "data": {
          "description": "Split text into chunks based on specified criteria.",
          "display_name": "Split Text",
          "id": "SplitText-AYSbJ",
          "node": {
            "template": {
              "_type": "Component",
              "data_inputs": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_inputs",
                "value": "",
                "display_name": "Data Inputs",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "chunk_overlap": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "Number of characters to overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of characters in each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        \n        print(data)\n        \n        self.status = data\n        return data\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The character to split on. Defaults to newline.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text into chunks based on specified criteria.",
            "icon": "scissors-line-dashed",
            "base_classes": [
              "Data"
            ],
            "display_name": "Split Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "chunks",
                "display_name": "Chunks",
                "method": "split_text",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data_inputs",
              "chunk_overlap",
              "chunk_size",
              "separator"
            ],
            "beta": false,
            "edited": true,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "type": "SplitText"
        },
        "selected": false,
        "width": 384,
        "height": 525,
        "positionAbsolute": {
          "x": 979.8505261780281,
          "y": 471.10725283542536
        },
        "dragging": false
      },
      {
        "id": "CohereEmbeddings-ixXbu",
        "type": "genericNode",
        "position": {
          "x": 2181.359451495761,
          "y": 1932.6282631325369
        },
        "data": {
          "type": "CohereEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"cohere_api_key\", \n            display_name=\"Cohere API Key\", \n            advanced=False,\n            value=\"COHERE_API_KEY\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-multilingual-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        c_api_key = self.cohere_api_key\n            \n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=c_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "display_name": "code"
              },
              "cohere_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cohere_api_key",
                "value": "",
                "display_name": "Cohere API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "trace_as_metadata": true,
                "options": [
                  "embed-english-v2.0",
                  "embed-multilingual-v2.0",
                  "embed-english-light-v2.0",
                  "embed-multilingual-light-v2.0"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "embed-multilingual-v2.0",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "truncate": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "truncate",
                "value": "",
                "display_name": "Truncate",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_agent": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_agent",
                "value": "langchain",
                "display_name": "User Agent",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using Cohere models.",
            "icon": "Cohere",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "Cohere Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cohere_api_key",
              "model",
              "truncate",
              "max_retries",
              "user_agent",
              "request_timeout"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.19"
          },
          "id": "CohereEmbeddings-ixXbu"
        },
        "selected": false,
        "width": 384,
        "height": 375,
        "positionAbsolute": {
          "x": 2181.359451495761,
          "y": 1932.6282631325369
        },
        "dragging": false
      },
      {
        "id": "Directory-I7RPA",
        "type": "genericNode",
        "position": {
          "x": 231.9564828558806,
          "y": 847.84460750427
        },
        "data": {
          "type": "Directory",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, IntInput, MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all default supported types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = (\n            self.types if self.types and self.types != [\"\"] else TEXT_FILE_TYPES\n        )  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(resolved_path, load_hidden, recursive, depth, types)\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors, max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore[return-value]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "depth": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "depth",
                "value": 1,
                "display_name": "Depth",
                "advanced": false,
                "dynamic": false,
                "info": "Depth to search for files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              },
              "load_hidden": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "load_hidden",
                "value": false,
                "display_name": "Load Hidden",
                "advanced": true,
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_concurrency",
                "value": 2,
                "display_name": "Max Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "/app/data_folder/test1",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "recursive": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "recursive",
                "value": false,
                "display_name": "Recursive",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "types": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "types",
                "value": "",
                "display_name": "Types",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "File types to load. Leave empty to load all default supported types.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "use_multithreading": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": false,
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Recursively load files from a directory.",
            "icon": "folder",
            "base_classes": [
              "Data"
            ],
            "display_name": "Directory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_directory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "Directory-I7RPA",
          "description": "Recursively load files from a directory.",
          "display_name": "Directory"
        },
        "selected": false,
        "width": 384,
        "height": 461,
        "positionAbsolute": {
          "x": 231.9564828558806,
          "y": 847.84460750427
        },
        "dragging": false
      },
      {
        "id": "Weaviate-r9U57",
        "type": "genericNode",
        "position": {
          "x": 2784.6538761705447,
          "y": 1118.462368847748
        },
        "data": {
          "type": "Weaviate",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import weaviate\nfrom langchain_community.vectorstores import Weaviate\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, SecretStrInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass WeaviateVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Weaviate\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate\"\n    name = \"Weaviate\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://localhost:8080\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=False),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"Requires capitalized index name.\",\n        ),\n        StrInput(name=\"text_key\", display_name=\"Text Key\", value=\"text\", advanced=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Weaviate:\n        if self.api_key:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n\n        if self.index_name != self.index_name.capitalize():\n            msg = f\"Weaviate requires the index name to be capitalized. Use: {self.index_name.capitalize()}\"\n            raise ValueError(msg)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents and self.embedding:\n            return Weaviate.from_documents(\n                client=client,\n                index_name=self.index_name,\n                documents=documents,\n                embedding=self.embedding,\n                by_text=self.search_by_text,\n            )\n\n        return Weaviate(\n            client=client,\n            index_name=self.index_name,\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "index_name",
                "value": "Test5",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "Requires capitalized index name.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_by_text": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_by_text",
                "value": false,
                "display_name": "Search By Text",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "search_query": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "text_key": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "text",
                "display_name": "Text Key",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": " http://weaviate:8080",
                "display_name": "Weaviate URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Weaviate Vector Store with search capabilities",
            "icon": "Weaviate",
            "base_classes": [
              "Data",
              "Retriever",
              "VectorStore"
            ],
            "display_name": "Weaviate",
            "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key",
                  "embedding",
                  "index_name",
                  "ingest_data",
                  "number_of_results",
                  "search_by_text",
                  "search_query",
                  "text_key",
                  "url"
                ]
              },
              {
                "types": [
                  "VectorStore"
                ],
                "selected": "VectorStore",
                "name": "vector_store",
                "display_name": "Vector Store",
                "method": "cast_vector_store",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "url",
              "api_key",
              "index_name",
              "text_key",
              "search_query",
              "ingest_data",
              "embedding",
              "number_of_results",
              "search_by_text"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "Weaviate-r9U57",
          "description": "Weaviate Vector Store with search capabilities",
          "display_name": "Weaviate"
        },
        "selected": false,
        "width": 384,
        "height": 723,
        "dragging": false,
        "positionAbsolute": {
          "x": 2784.6538761705447,
          "y": 1118.462368847748
        }
      },
      {
        "id": "CustomComponent-rD4hM",
        "type": "genericNode",
        "position": {
          "x": 1603.1748302361966,
          "y": 1153.6624813557771
        },
        "data": {
          "type": "KeywordExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "ingest_data": {
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\nimport operator\nimport warnings\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.schema.message import Message\nfrom axiestudio.schema import Data\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n    MessageInput,\n    MessageTextInput,\n    DataInput\n)\nfrom axiestudio.inputs.inputs import HandleInput\nfrom axiestudio.template.field.base import Output\n\n\nclass KeywordExtractorComponent(Component):\n    display_name = \"Keyword Extractor\"\n    description = \"Extracts Keywords using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"KeywordExtractorComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\",\n                  info=STREAM_INFO_TEXT, advanced=True),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\",\n                  display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Language Model\",\n               name=\"model_output\", method=\"build_model\"),\n        Output(display_name=\"Data Output\",\n               name=\"output\", method=\"build_output\"),\n    ]\n\n    def _validate_outputs(self):\n        # At least these two outputs must be defined\n        required_output_methods = [\n            \"build_model\", \"build_output\"]\n        output_names = [output.name for output in self.outputs]\n        for method_name in required_output_methods:\n            if method_name not in output_names:\n                msg = f\"Output with name '{method_name}' must be defined.\"\n                raise ValueError(msg)\n            if not hasattr(self, method_name):\n                msg = f\"Method '{method_name}' must be defined.\"\n                raise ValueError(msg)\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n\n        output_schema_dict: dict[str, str] = reduce(\n            operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key) if openai_api_key else None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(\n                    schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def build_output(self) -> list[Data]:\n        data = self.ingest_data\n\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n\n        results = []\n        index = 0\n\n        # Iteriere durch jedes Objekt in data\n        for value_dict in data:\n            if isinstance(value_dict, Data):\n                text = value_dict.data.get('text', '')\n                result = self.get_chat_result(\n                    output, stream, text, system_message)\n\n                keywords_raw = json.loads(result.get(\n                    \"tokens\", {}).get(\"response\", {}))\n                keywords = keywords_raw[\"keywords\"]\n\n                updated_data = value_dict.data.copy()\n                updated_data['keywords'] = keywords\n                updated_data['keywords'].append(f\"index_{index}\")\n                index += 1  # Erhöhe den Index für das nächste Element\n\n                # Erstelle ein neues Data-Objekt und füge es zur results-Liste hinzu\n                processed_value_dict = {\n                    key: value.get_text() if isinstance(value, Data) else value\n                    for key, value in updated_data.items()\n                }\n                results.append(\n                    Data(data=processed_value_dict, text_key='text'))\n\n        self.status = results\n        return results\n\n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: str | None = None,\n    ):\n        messages: list[BaseMessage] = []\n        if not input_value and not system_message:\n            msg = \"The message you want to send to the model is empty.\"\n            raise ValueError(msg)\n        system_message_added = False\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        if system_message:\n                            prompt.messages = [\n                                SystemMessage(content=system_message),\n                                *prompt.messages,  # type: ignore[has-type]\n                            ]\n                            system_message_added = True\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n            else:\n                messages.append(HumanMessage(content=input_value))\n\n        if system_message and not system_message_added:\n            messages.insert(0, SystemMessage(content=system_message))\n        inputs: list | dict = messages or {}\n        try:\n            if self.output_parser is not None:\n                runnable = runnable | self.output_parser\n\n            runnable = runnable.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            if stream:\n                return runnable.stream(inputs)\n            message = runnable.invoke(inputs)\n\n            result = message.content if hasattr(\n                message, \"content\") else message\n            if isinstance(message, AIMessage):\n                status_message = self.build_status_message(message)\n                return status_message\n                # self.status = status_message\n            elif isinstance(result, dict):\n                result = json.dumps(message, indent=4)\n                # self.status = result\n            # else:\n                # self.status = result\n            return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise\n\n    def build_status_message(self, message: AIMessage):\n        \"\"\"\n        Builds a status message from an AIMessage object.\n\n        Args:\n            message (AIMessage): The AIMessage object to build the status message from.\n\n        Returns:\n            The status message.\n        \"\"\"\n        if message.response_metadata:\n            # Build a well formatted status message\n            content = message.content\n            response_metadata = message.response_metadata\n            openai_keys = [\"token_usage\", \"model_name\", \"finish_reason\"]\n            inner_openai_keys = [\"completion_tokens\",\n                                 \"prompt_tokens\", \"total_tokens\"]\n            if all(key in response_metadata for key in openai_keys) and all(\n                key in response_metadata[\"token_usage\"] for key in inner_openai_keys\n            ):\n                token_usage = response_metadata[\"token_usage\"]\n                status_message = {\n                    \"tokens\": {\n                        \"input\": token_usage[\"prompt_tokens\"],\n                        \"output\": token_usage[\"completion_tokens\"],\n                        \"total\": token_usage[\"total_tokens\"],\n                        \"stop_reason\": response_metadata[\"finish_reason\"],\n                        \"response\": content,\n                    }\n                }\n\n            else:\n                status_message = f\"Response: {\n                    content}\"  # type: ignore[assignment]\n        else:\n            status_message = f\"Response: {\n                message.content}\"  # type: ignore[assignment]\n        return status_message\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": true,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": 150,
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "Gibt die 5 Wichtigsten Schlagworte zurück, deine Rückgabe sollte eine valide JSON sein",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Extracts Keywords using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "Data",
              "LanguageModel"
            ],
            "display_name": "Custom Component",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Data Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "system_message",
              "ingest_data",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "edited": true,
            "metadata": {},
            "lf_version": "1.0.19"
          },
          "id": "CustomComponent-rD4hM"
        },
        "selected": false,
        "width": 384,
        "height": 549,
        "positionAbsolute": {
          "x": 1603.1748302361966,
          "y": 1153.6624813557771
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Directory-I7RPA",
        "target": "SplitText-AYSbJ",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-I7RPAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-AYSbJœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-Directory-I7RPA{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-I7RPAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-AYSbJ{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-AYSbJœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_inputs",
            "id": "SplitText-AYSbJ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-I7RPA",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "CohereEmbeddings-ixXbu",
        "target": "Weaviate-r9U57",
        "sourceHandle": "{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-ixXbuœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CohereEmbeddings-ixXbu{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-ixXbuœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-Weaviate-r9U57{œfieldNameœ:œembeddingœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Weaviate-r9U57",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CohereEmbeddings",
            "id": "CohereEmbeddings-ixXbu",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "SplitText-AYSbJ",
        "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-AYSbJœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-rD4hM",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-rD4hMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "CustomComponent-rD4hM",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "SplitText",
            "id": "SplitText-AYSbJ",
            "name": "chunks",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-SplitText-AYSbJ{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-AYSbJœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-CustomComponent-rD4hM{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-rD4hMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "CustomComponent-rD4hM",
        "sourceHandle": "{œdataTypeœ:œKeywordExtractorComponentœ,œidœ:œCustomComponent-rD4hMœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "Weaviate-r9U57",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "Weaviate-r9U57",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KeywordExtractorComponent",
            "id": "CustomComponent-rD4hM",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-rD4hM{œdataTypeœ:œKeywordExtractorComponentœ,œidœ:œCustomComponent-rD4hMœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-Weaviate-r9U57{œfieldNameœ:œingest_dataœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": -372.68146934089646,
      "y": -240.0803971886836,
      "zoom": 0.48423220405845735
    }
  },
  "metadata": {
    "SplitText": {
      "count": 1
    },
    "CohereEmbeddings": {
      "count": 1
    },
    "Directory": {
      "count": 1
    },
    "Weaviate": {
      "count": 1
    },
    "CustomComponent": {
      "count": 1
    },
    "total": 5
  },
  "original": {
    "id": "704cde09-7335-47cf-98a4-cff924dd71f4",
    "name": "Weaviate Document Reader + Keywords",
    "description": "Weaviate Document Reader",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "1",
    "metadata": {
      "SplitText": {
        "count": 1
      },
      "CohereEmbeddings": {
        "count": 1
      },
      "Directory": {
        "count": 1
      },
      "Weaviate": {
        "count": 1
      },
      "CustomComponent": {
        "count": 1
      },
      "total": 5
    },
    "last_tested_version": "1.0.19",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "SplitText-AYSbJ",
          "type": "genericNode",
          "position": {
            "x": 979.8505261780281,
            "y": 471.10725283542536
          },
          "data": {
            "description": "Split text into chunks based on specified criteria.",
            "display_name": "Split Text",
            "id": "SplitText-AYSbJ",
            "node": {
              "template": {
                "_type": "Component",
                "data_inputs": {
                  "trace_as_metadata": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_inputs",
                  "value": "",
                  "display_name": "Data Inputs",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to split.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "chunk_overlap": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_overlap",
                  "value": 200,
                  "display_name": "Chunk Overlap",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Number of characters to overlap between chunks.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "chunk_size": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "chunk_size",
                  "value": 1000,
                  "display_name": "Chunk Size",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The maximum number of characters in each chunk.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_text_splitters import CharacterTextSplitter\n\nfrom axiestudio.custom import Component\nfrom axiestudio.io import HandleInput, IntInput, MessageTextInput, Output\nfrom axiestudio.schema import Data\nfrom axiestudio.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        return [Data(text=doc.page_content, data=doc.metadata) for doc in docs]\n\n    def split_text(self) -> list[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = [_input.to_lc_document() for _input in self.data_inputs if isinstance(_input, Data)]\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        \n        print(data)\n        \n        self.status = data\n        return data\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "separator": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "separator",
                  "value": "\n",
                  "display_name": "Separator",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The character to split on. Defaults to newline.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Split text into chunks based on specified criteria.",
              "icon": "scissors-line-dashed",
              "base_classes": [
                "Data"
              ],
              "display_name": "Split Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "chunks",
                  "display_name": "Chunks",
                  "method": "split_text",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data_inputs",
                "chunk_overlap",
                "chunk_size",
                "separator"
              ],
              "beta": false,
              "edited": true,
              "metadata": {},
              "lf_version": "1.0.19"
            },
            "type": "SplitText"
          },
          "selected": false,
          "width": 384,
          "height": 525,
          "positionAbsolute": {
            "x": 979.8505261780281,
            "y": 471.10725283542536
          },
          "dragging": false
        },
        {
          "id": "CohereEmbeddings-ixXbu",
          "type": "genericNode",
          "position": {
            "x": 2181.359451495761,
            "y": 1932.6282631325369
          },
          "data": {
            "type": "CohereEmbeddings",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from langchain_community.embeddings.cohere import CohereEmbeddings\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.field_typing import Embeddings\nfrom axiestudio.io import DropdownInput, FloatInput, IntInput, MessageTextInput, Output, SecretStrInput\n\n\nclass CohereEmbeddingsComponent(LCModelComponent):\n    display_name = \"Cohere Embeddings\"\n    description = \"Generate embeddings using Cohere models.\"\n    icon = \"Cohere\"\n    name = \"CohereEmbeddings\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"cohere_api_key\", \n            display_name=\"Cohere API Key\", \n            advanced=False,\n            value=\"COHERE_API_KEY\"),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=True,\n            options=[\n                \"embed-english-v2.0\",\n                \"embed-multilingual-v2.0\",\n                \"embed-english-light-v2.0\",\n                \"embed-multilingual-light-v2.0\",\n            ],\n            value=\"embed-multilingual-v2.0\",\n        ),\n        MessageTextInput(name=\"truncate\", display_name=\"Truncate\", advanced=True),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        MessageTextInput(name=\"user_agent\", display_name=\"User Agent\", advanced=True, value=\"langchain\"),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n    ]\n\n    outputs = [\n        Output(display_name=\"Embeddings\", name=\"embeddings\", method=\"build_embeddings\"),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        c_api_key = self.cohere_api_key\n            \n        return CohereEmbeddings(  # type: ignore\n            cohere_api_key=c_api_key,\n            model=self.model,\n            truncate=self.truncate,\n            max_retries=self.max_retries,\n            user_agent=self.user_agent,\n            request_timeout=self.request_timeout or None,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "display_name": "code"
                },
                "cohere_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cohere_api_key",
                  "value": "",
                  "display_name": "Cohere API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "max_retries": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_retries",
                  "value": 3,
                  "display_name": "Max Retries",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model": {
                  "trace_as_metadata": true,
                  "options": [
                    "embed-english-v2.0",
                    "embed-multilingual-v2.0",
                    "embed-english-light-v2.0",
                    "embed-multilingual-light-v2.0"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model",
                  "value": "embed-multilingual-v2.0",
                  "display_name": "Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "request_timeout": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "request_timeout",
                  "value": "",
                  "display_name": "Request Timeout",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                },
                "truncate": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "truncate",
                  "value": "",
                  "display_name": "Truncate",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_agent": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_agent",
                  "value": "langchain",
                  "display_name": "User Agent",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Generate embeddings using Cohere models.",
              "icon": "Cohere",
              "base_classes": [
                "Embeddings"
              ],
              "display_name": "Cohere Embeddings",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Embeddings"
                  ],
                  "selected": "Embeddings",
                  "name": "embeddings",
                  "display_name": "Embeddings",
                  "method": "build_embeddings",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cohere_api_key",
                "model",
                "truncate",
                "max_retries",
                "user_agent",
                "request_timeout"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.19"
            },
            "id": "CohereEmbeddings-ixXbu"
          },
          "selected": false,
          "width": 384,
          "height": 375,
          "positionAbsolute": {
            "x": 2181.359451495761,
            "y": 1932.6282631325369
          },
          "dragging": false
        },
        {
          "id": "Directory-I7RPA",
          "type": "genericNode",
          "position": {
            "x": 231.9564828558806,
            "y": 847.84460750427
          },
          "data": {
            "type": "Directory",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom axiestudio.custom import Component\nfrom axiestudio.io import BoolInput, IntInput, MessageTextInput\nfrom axiestudio.schema import Data\nfrom axiestudio.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all default supported types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = (\n            self.types if self.types and self.types != [\"\"] else TEXT_FILE_TYPES\n        )  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(resolved_path, load_hidden, recursive, depth, types)\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors, max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore[return-value]\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "depth": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "depth",
                  "value": 1,
                  "display_name": "Depth",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Depth to search for files.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput",
                  "load_from_db": false
                },
                "load_hidden": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "load_hidden",
                  "value": false,
                  "display_name": "Load Hidden",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, hidden files will be loaded.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_concurrency": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_concurrency",
                  "value": 2,
                  "display_name": "Max Concurrency",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Maximum concurrency for loading files.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "path": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "path",
                  "value": "/app/data_folder/test1",
                  "display_name": "Path",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Path to the directory to load files from.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "recursive": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "recursive",
                  "value": false,
                  "display_name": "Recursive",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, the search will be recursive.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "silent_errors": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "silent_errors",
                  "value": false,
                  "display_name": "Silent Errors",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, errors will not raise an exception.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "types": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "types",
                  "value": "",
                  "display_name": "Types",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "File types to load. Leave empty to load all default supported types.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "use_multithreading": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "use_multithreading",
                  "value": false,
                  "display_name": "Use Multithreading",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If true, multithreading will be used.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Recursively load files from a directory.",
              "icon": "folder",
              "base_classes": [
                "Data"
              ],
              "display_name": "Directory",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "data",
                  "display_name": "Data",
                  "method": "load_directory",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "path",
                "types",
                "depth",
                "max_concurrency",
                "load_hidden",
                "recursive",
                "silent_errors",
                "use_multithreading"
              ],
              "beta": false,
              "edited": false,
              "metadata": {},
              "lf_version": "1.0.19"
            },
            "id": "Directory-I7RPA",
            "description": "Recursively load files from a directory.",
            "display_name": "Directory"
          },
          "selected": false,
          "width": 384,
          "height": 461,
          "positionAbsolute": {
            "x": 231.9564828558806,
            "y": 847.84460750427
          },
          "dragging": false
        },
        {
          "id": "Weaviate-r9U57",
          "type": "genericNode",
          "position": {
            "x": 2784.6538761705447,
            "y": 1118.462368847748
          },
          "data": {
            "type": "Weaviate",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "embedding",
                  "value": "",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import weaviate\nfrom langchain_community.vectorstores import Weaviate\n\nfrom axiestudio.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom axiestudio.helpers.data import docs_to_data\nfrom axiestudio.io import BoolInput, DataInput, HandleInput, IntInput, MultilineInput, SecretStrInput, StrInput\nfrom axiestudio.schema import Data\n\n\nclass WeaviateVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Weaviate\"\n    description = \"Weaviate Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate\"\n    name = \"Weaviate\"\n    icon = \"Weaviate\"\n\n    inputs = [\n        StrInput(name=\"url\", display_name=\"Weaviate URL\", value=\"http://localhost:8080\", required=True),\n        SecretStrInput(name=\"api_key\", display_name=\"API Key\", required=False),\n        StrInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"Requires capitalized index name.\",\n        ),\n        StrInput(name=\"text_key\", display_name=\"Text Key\", value=\"text\", advanced=True),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n        BoolInput(name=\"search_by_text\", display_name=\"Search By Text\", advanced=True),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Weaviate:\n        if self.api_key:\n            auth_config = weaviate.AuthApiKey(api_key=self.api_key)\n            client = weaviate.Client(url=self.url, auth_client_secret=auth_config)\n        else:\n            client = weaviate.Client(url=self.url)\n\n        if self.index_name != self.index_name.capitalize():\n            msg = f\"Weaviate requires the index name to be capitalized. Use: {self.index_name.capitalize()}\"\n            raise ValueError(msg)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents and self.embedding:\n            return Weaviate.from_documents(\n                client=client,\n                index_name=self.index_name,\n                documents=documents,\n                embedding=self.embedding,\n                by_text=self.search_by_text,\n            )\n\n        return Weaviate(\n            client=client,\n            index_name=self.index_name,\n            text_key=self.text_key,\n            embedding=self.embedding,\n            by_text=self.search_by_text,\n        )\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        return []\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "index_name": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "index_name",
                  "value": "Test5",
                  "display_name": "Index Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Requires capitalized index name.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "number_of_results": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "number_of_results",
                  "value": 4,
                  "display_name": "Number of Results",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Number of results to return.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "search_by_text": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_by_text",
                  "value": false,
                  "display_name": "Search By Text",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "search_query": {
                  "trace_as_input": true,
                  "multiline": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "search_query",
                  "value": "",
                  "display_name": "Search Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MultilineInput"
                },
                "text_key": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text_key",
                  "value": "text",
                  "display_name": "Text Key",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "name": "url",
                  "value": " http://weaviate:8080",
                  "display_name": "Weaviate URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "Weaviate Vector Store with search capabilities",
              "icon": "Weaviate",
              "base_classes": [
                "Data",
                "Retriever",
                "VectorStore"
              ],
              "display_name": "Weaviate",
              "documentation": "https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/weaviate",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Retriever"
                  ],
                  "selected": "Retriever",
                  "name": "base_retriever",
                  "display_name": "Retriever",
                  "method": "build_base_retriever",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "search_results",
                  "display_name": "Search Results",
                  "method": "search_documents",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": [
                    "api_key",
                    "embedding",
                    "index_name",
                    "ingest_data",
                    "number_of_results",
                    "search_by_text",
                    "search_query",
                    "text_key",
                    "url"
                  ]
                },
                {
                  "types": [
                    "VectorStore"
                  ],
                  "selected": "VectorStore",
                  "name": "vector_store",
                  "display_name": "Vector Store",
                  "method": "cast_vector_store",
                  "value": "__UNDEFINED__",
                  "cache": true,
                  "required_inputs": []
                }
              ],
              "field_order": [
                "url",
                "api_key",
                "index_name",
                "text_key",
                "search_query",
                "ingest_data",
                "embedding",
                "number_of_results",
                "search_by_text"
              ],
              "beta": false,
              "edited": false,
              "metadata": {},
              "lf_version": "1.0.19"
            },
            "id": "Weaviate-r9U57",
            "description": "Weaviate Vector Store with search capabilities",
            "display_name": "Weaviate"
          },
          "selected": false,
          "width": 384,
          "height": 723,
          "dragging": false,
          "positionAbsolute": {
            "x": 2784.6538761705447,
            "y": 1118.462368847748
          }
        },
        {
          "id": "CustomComponent-rD4hM",
          "type": "genericNode",
          "position": {
            "x": 1603.1748302361966,
            "y": 1153.6624813557771
          },
          "data": {
            "type": "KeywordExtractorComponent",
            "node": {
              "template": {
                "_type": "Component",
                "ingest_data": {
                  "trace_as_metadata": true,
                  "list": true,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "ingest_data",
                  "value": "",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "output_parser": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_parser",
                  "value": "",
                  "display_name": "Output Parser",
                  "advanced": true,
                  "input_types": [
                    "OutputParser"
                  ],
                  "dynamic": false,
                  "info": "The parser to use to parse the output of the model",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "HandleInput"
                },
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import json\nimport operator\nimport warnings\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.base.constants import STREAM_INFO_TEXT\nfrom axiestudio.custom import Component\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom axiestudio.schema.message import Message\nfrom axiestudio.schema import Data\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n    MessageInput,\n    MessageTextInput,\n    DataInput\n)\nfrom axiestudio.inputs.inputs import HandleInput\nfrom axiestudio.template.field.base import Output\n\n\nclass KeywordExtractorComponent(Component):\n    display_name = \"Keyword Extractor\"\n    description = \"Extracts Keywords using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"KeywordExtractorComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\",\n                  info=STREAM_INFO_TEXT, advanced=True),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\",\n                  display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Language Model\",\n               name=\"model_output\", method=\"build_model\"),\n        Output(display_name=\"Data Output\",\n               name=\"output\", method=\"build_output\"),\n    ]\n\n    def _validate_outputs(self):\n        # At least these two outputs must be defined\n        required_output_methods = [\n            \"build_model\", \"build_output\"]\n        output_names = [output.name for output in self.outputs]\n        for method_name in required_output_methods:\n            if method_name not in output_names:\n                msg = f\"Output with name '{method_name}' must be defined.\"\n                raise ValueError(msg)\n            if not hasattr(self, method_name):\n                msg = f\"Method '{method_name}' must be defined.\"\n                raise ValueError(msg)\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n\n        output_schema_dict: dict[str, str] = reduce(\n            operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key) if openai_api_key else None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(\n                    schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def build_output(self) -> list[Data]:\n        data = self.ingest_data\n\n        stream = self.stream\n        system_message = self.system_message\n        output = self.build_model()\n\n        results = []\n        index = 0\n\n        # Iteriere durch jedes Objekt in data\n        for value_dict in data:\n            if isinstance(value_dict, Data):\n                text = value_dict.data.get('text', '')\n                result = self.get_chat_result(\n                    output, stream, text, system_message)\n\n                keywords_raw = json.loads(result.get(\n                    \"tokens\", {}).get(\"response\", {}))\n                keywords = keywords_raw[\"keywords\"]\n\n                updated_data = value_dict.data.copy()\n                updated_data['keywords'] = keywords\n                updated_data['keywords'].append(f\"index_{index}\")\n                index += 1  # Erhöhe den Index für das nächste Element\n\n                # Erstelle ein neues Data-Objekt und füge es zur results-Liste hinzu\n                processed_value_dict = {\n                    key: value.get_text() if isinstance(value, Data) else value\n                    for key, value in updated_data.items()\n                }\n                results.append(\n                    Data(data=processed_value_dict, text_key='text'))\n\n        self.status = results\n        return results\n\n    def get_chat_result(\n        self,\n        runnable: LanguageModel,\n        stream: bool,\n        input_value: str | Message,\n        system_message: str | None = None,\n    ):\n        messages: list[BaseMessage] = []\n        if not input_value and not system_message:\n            msg = \"The message you want to send to the model is empty.\"\n            raise ValueError(msg)\n        system_message_added = False\n        if input_value:\n            if isinstance(input_value, Message):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\"ignore\")\n                    if \"prompt\" in input_value:\n                        prompt = input_value.load_lc_prompt()\n                        if system_message:\n                            prompt.messages = [\n                                SystemMessage(content=system_message),\n                                *prompt.messages,  # type: ignore[has-type]\n                            ]\n                            system_message_added = True\n                        runnable = prompt | runnable\n                    else:\n                        messages.append(input_value.to_lc_message())\n            else:\n                messages.append(HumanMessage(content=input_value))\n\n        if system_message and not system_message_added:\n            messages.insert(0, SystemMessage(content=system_message))\n        inputs: list | dict = messages or {}\n        try:\n            if self.output_parser is not None:\n                runnable = runnable | self.output_parser\n\n            runnable = runnable.with_config(\n                {\n                    \"run_name\": self.display_name,\n                    \"project_name\": self.get_project_name(),\n                    \"callbacks\": self.get_langchain_callbacks(),\n                }\n            )\n            if stream:\n                return runnable.stream(inputs)\n            message = runnable.invoke(inputs)\n\n            result = message.content if hasattr(\n                message, \"content\") else message\n            if isinstance(message, AIMessage):\n                status_message = self.build_status_message(message)\n                return status_message\n                # self.status = status_message\n            elif isinstance(result, dict):\n                result = json.dumps(message, indent=4)\n                # self.status = result\n            # else:\n                # self.status = result\n            return result\n        except Exception as e:\n            if message := self._get_exception_message(e):\n                raise ValueError(message) from e\n            raise\n\n    def build_status_message(self, message: AIMessage):\n        \"\"\"\n        Builds a status message from an AIMessage object.\n\n        Args:\n            message (AIMessage): The AIMessage object to build the status message from.\n\n        Returns:\n            The status message.\n        \"\"\"\n        if message.response_metadata:\n            # Build a well formatted status message\n            content = message.content\n            response_metadata = message.response_metadata\n            openai_keys = [\"token_usage\", \"model_name\", \"finish_reason\"]\n            inner_openai_keys = [\"completion_tokens\",\n                                 \"prompt_tokens\", \"total_tokens\"]\n            if all(key in response_metadata for key in openai_keys) and all(\n                key in response_metadata[\"token_usage\"] for key in inner_openai_keys\n            ):\n                token_usage = response_metadata[\"token_usage\"]\n                status_message = {\n                    \"tokens\": {\n                        \"input\": token_usage[\"prompt_tokens\"],\n                        \"output\": token_usage[\"completion_tokens\"],\n                        \"total\": token_usage[\"total_tokens\"],\n                        \"stop_reason\": response_metadata[\"finish_reason\"],\n                        \"response\": content,\n                    }\n                }\n\n            else:\n                status_message = f\"Response: {\n                    content}\"  # type: ignore[assignment]\n        else:\n            status_message = f\"Response: {\n                message.content}\"  # type: ignore[assignment]\n        return status_message\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": true,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput",
                  "load_from_db": false
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": 150,
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput",
                  "load_from_db": false
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "Gibt die 5 Wichtigsten Schlagworte zurück, deine Rückgabe sollte eine valide JSON sein",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Extracts Keywords using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "Data",
                "LanguageModel"
              ],
              "display_name": "Custom Component",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Data Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "system_message",
                "ingest_data",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed",
                "output_parser"
              ],
              "beta": false,
              "edited": true,
              "metadata": {},
              "lf_version": "1.0.19"
            },
            "id": "CustomComponent-rD4hM"
          },
          "selected": false,
          "width": 384,
          "height": 549,
          "positionAbsolute": {
            "x": 1603.1748302361966,
            "y": 1153.6624813557771
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Directory-I7RPA",
          "target": "SplitText-AYSbJ",
          "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-I7RPAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
          "targetHandle": "{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-AYSbJœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "id": "reactflow__edge-Directory-I7RPA{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-I7RPAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SplitText-AYSbJ{œfieldNameœ:œdata_inputsœ,œidœ:œSplitText-AYSbJœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data_inputs",
              "id": "SplitText-AYSbJ",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "Directory",
              "id": "Directory-I7RPA",
              "name": "data",
              "output_types": [
                "Data"
              ]
            }
          },
          "selected": false,
          "className": "",
          "animated": false
        },
        {
          "source": "CohereEmbeddings-ixXbu",
          "target": "Weaviate-r9U57",
          "sourceHandle": "{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-ixXbuœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
          "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "id": "reactflow__edge-CohereEmbeddings-ixXbu{œdataTypeœ:œCohereEmbeddingsœ,œidœ:œCohereEmbeddings-ixXbuœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-Weaviate-r9U57{œfieldNameœ:œembeddingœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "embedding",
              "id": "Weaviate-r9U57",
              "inputTypes": [
                "Embeddings"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "CohereEmbeddings",
              "id": "CohereEmbeddings-ixXbu",
              "name": "embeddings",
              "output_types": [
                "Embeddings"
              ]
            }
          },
          "selected": false,
          "className": "",
          "animated": false
        },
        {
          "source": "SplitText-AYSbJ",
          "sourceHandle": "{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-AYSbJœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}",
          "target": "CustomComponent-rD4hM",
          "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-rD4hMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "CustomComponent-rD4hM",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "SplitText",
              "id": "SplitText-AYSbJ",
              "name": "chunks",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-SplitText-AYSbJ{œdataTypeœ:œSplitTextœ,œidœ:œSplitText-AYSbJœ,œnameœ:œchunksœ,œoutput_typesœ:[œDataœ]}-CustomComponent-rD4hM{œfieldNameœ:œingest_dataœ,œidœ:œCustomComponent-rD4hMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": "",
          "animated": false
        },
        {
          "source": "CustomComponent-rD4hM",
          "sourceHandle": "{œdataTypeœ:œKeywordExtractorComponentœ,œidœ:œCustomComponent-rD4hMœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
          "target": "Weaviate-r9U57",
          "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "ingest_data",
              "id": "Weaviate-r9U57",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KeywordExtractorComponent",
              "id": "CustomComponent-rD4hM",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-CustomComponent-rD4hM{œdataTypeœ:œKeywordExtractorComponentœ,œidœ:œCustomComponent-rD4hMœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-Weaviate-r9U57{œfieldNameœ:œingest_dataœ,œidœ:œWeaviate-r9U57œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "animated": false,
          "className": ""
        }
      ],
      "viewport": {
        "x": -372.68146934089646,
        "y": -240.0803971886836,
        "zoom": 0.48423220405845735
      }
    },
    "date_created": "2024-10-16T09:10:07.780Z",
    "date_updated": "2024-10-16T09:10:07.893Z",
    "status": "Public",
    "sort": null,
    "user_updated": "8256fbbf-aacf-416a-b01f-ff4ec4b038be",
    "user_created": {
      "username": "omid",
      "first_name": "Omid",
      "last_name": "Ha",
      "id": "8256fbbf-aacf-416a-b01f-ff4ec4b038be"
    },
    "tags": [
      {
        "tags_id": {
          "name": "Vector Store",
          "id": "cd614b49-dd57-4c8b-a5eb-f8bb5f957b9a"
        }
      },
      {
        "tags_id": {
          "name": "Chain",
          "id": "d442c88b-f8d0-4010-8752-16a644c7ac8e"
        }
      }
    ]
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:59.861Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 52,
    "converter_version": "1.0.0"
  }
}