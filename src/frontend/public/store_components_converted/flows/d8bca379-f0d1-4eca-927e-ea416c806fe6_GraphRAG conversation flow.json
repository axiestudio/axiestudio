{
  "id": "d8bca379-f0d1-4eca-927e-ea416c806fe6",
  "name": "GraphRAG conversation flow",
  "description": "Conversation flow of GraphRAG (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "jingconsult",
    "first_name": "Jing",
    "last_name": "Consulting",
    "id": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "full_name": "Jing Consulting"
  },
  "store_url": "https://www.langflow.store/store/component/d8bca379-f0d1-4eca-927e-ea416c806fe6",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-09-26T03:45:12.556Z",
    "updated": "2024-10-01T08:45:09.883Z",
    "downloaded": "2025-08-19T17:50:07.247Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.17",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
        "type": "genericNode",
        "position": {
          "x": -1179.4591011367195,
          "y": 83.23755043873282
        },
        "data": {
          "type": "KnowledgeGraphIndexKRetrieverComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n        if self.neo4j_credentials:\r\n            self.populate_node_type_options()\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n        DropdownInput(\r\n            name=\"node_type\",\r\n            display_name=\"Nodes to be returned\",\r\n            options=[\r\n            ],\r\n            value=\"\"\r\n        ),\r\n        \r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=self.node_type,\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "k",
                "value": 4,
                "display_name": "Number of results to return",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "node_type": {
                "trace_as_metadata": true,
                "options": [],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "node_type",
                "value": "Document",
                "display_name": "Nodes to be returned",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_embedding_model": {
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_embedding_model",
                "value": "text-embedding-3-small",
                "display_name": "Embedding Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "user_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "User query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Neo4J K Retriever (Vector Search)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "user_query",
              "k",
              "node_type",
              "openai_embedding_model",
              "openai_api_key",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt"
        },
        "selected": false,
        "width": 384,
        "height": 768,
        "positionAbsolute": {
          "x": -1179.4591011367195,
          "y": 83.23755043873282
        },
        "dragging": false
      },
      {
        "id": "Prompt-uir6X",
        "type": "genericNode",
        "position": {
          "x": 529.4599977883669,
          "y": 724.4927039333264
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Answer the question shortly. Analyse the question based on conversation memory if given. Find answer in the context and if the answer is not in the context, generate the answer.\nConversation Memory: {memory}\nContext: {context}\nQuestion: {question}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "memory": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "memory",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Generate a prompt for LLM to process query",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "memory",
                "context",
                "question"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "error": null,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "Prompt-uir6X"
        },
        "selected": false,
        "width": 384,
        "height": 554,
        "positionAbsolute": {
          "x": 529.4599977883669,
          "y": 724.4927039333264
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-R02xB",
        "type": "genericNode",
        "position": {
          "x": 998.0026271897107,
          "y": 1346.4512284874122
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "OpenAIModel-R02xB"
        },
        "selected": false,
        "width": 384,
        "height": 599,
        "positionAbsolute": {
          "x": 998.0026271897107,
          "y": 1346.4512284874122
        },
        "dragging": false
      },
      {
        "id": "IfElseComponent-rcfCg",
        "type": "genericNode",
        "position": {
          "x": -5631.81437595536,
          "y": -1466.6582277720001
        },
        "data": {
          "type": "IfElseComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, Output\r\nfrom axiestudio.schema import Data\r\nq\r\n\r\nclass IfElseComponent(Component):\r\n    display_name = \"If Else Component\"\r\n    description = \"Capture a boolean value, trigger a workflow based on the input.\\n2 outputs will return True or None based on the input.\\nUse case: Next component should have a input check header for triggering.\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"IfElseComponent\"\r\n\r\n    inputs = [\r\n        BoolInput(name=\"input_value\", display_name=\"Input Value\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"build_true_output\"),\r\n        Output(display_name=\"False Output\", name=\"false_output\", method=\"build_false_output\")\r\n    ]\r\n\r\n    def build_true_output(self) -> Data:\r\n        if self.input_value:\r\n            data = Data(value=True)\r\n            self.status = data\r\n            return data\r\n        else:\r\n            data = Data(value=None)\r\n            self.status = data\r\n            return None\r\n    def build_false_output(self) -> Data:\r\n        if not self.input_value:\r\n            data = Data(value=True)\r\n            self.status = data\r\n            return data\r\n        else:\r\n            data = Data(value=None)\r\n            self.status = data\r\n            return None\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": true,
                "display_name": "Input Value",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Capture a boolean value, trigger a workflow based on the input.\n2 outputs will return True or None based on the input.\nUse case: Next component should have a input check header for triggering.",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "If Else Component (obsolete)",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "true_output",
                "display_name": "True Output",
                "method": "build_true_output",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "false_output",
                "display_name": "False Output",
                "method": "build_false_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "IfElseComponent-rcfCg"
        },
        "selected": false,
        "width": 384,
        "height": 440,
        "dragging": false,
        "positionAbsolute": {
          "x": -5631.81437595536,
          "y": -1466.6582277720001
        }
      },
      {
        "id": "Neo4jCredentialLoader-NuezZ",
        "type": "genericNode",
        "position": {
          "x": -2069.8490306603435,
          "y": 152.06299156043423
        },
        "data": {
          "type": "Neo4jCredentialLoader",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "neo4j_password": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_password",
                "value": "Jingconsult",
                "display_name": "Neo4j Password",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_url": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_url",
                "value": "neo4j://jingconsult.tech:7687",
                "display_name": "Neo4j URL",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "neo4j_username": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_username",
                "value": "neo4j",
                "display_name": "Neo4j Username",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "A handy component to load neo4j credentials",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Neo4j Credential Loader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "credentials",
                "display_name": "Credentials",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "neo4j_url",
              "neo4j_username",
              "neo4j_password"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "Neo4jCredentialLoader-NuezZ"
        },
        "selected": false,
        "width": 384,
        "height": 469,
        "positionAbsolute": {
          "x": -2069.8490306603435,
          "y": 152.06299156043423
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-4hTcP",
        "type": "genericNode",
        "position": {
          "x": 1493.329312159434,
          "y": 1071.2747611720902
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "ChatOutput",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "ChatOutput-4hTcP"
        },
        "selected": false,
        "width": 384,
        "height": 297,
        "positionAbsolute": {
          "x": 1493.329312159434,
          "y": 1071.2747611720902
        },
        "dragging": false
      },
      {
        "id": "GraphRAGChatAPIComponent-d0zgt",
        "type": "genericNode",
        "position": {
          "x": -2502.0623555732836,
          "y": 664.1980394995265
        },
        "data": {
          "type": "GraphRAGChatAPIComponent",
          "node": {
            "template": {
              "_type": "Component",
              "api_request": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_request",
                "value": "/jingconsult.consult/api/?query=How+much+initial+financial+investment+will+it+be+for+setting+up+a+hydrogen+plant&session_id=session_abc123",
                "display_name": "User's API request",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport urllib.parse as urlparse\r\n\r\nclass GraphRAGChatAPIComponent(Component):\r\n    display_name = \"GraphRAG Chat API Component\"\r\n    description = \"Handle API requests\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRAGChatAPIComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"api_request\", display_name=\"User's API request\", value=\"/jingconsult.consult/api/?query=What+is+Graph&session_id=session_abc123\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"User query\", name=\"query\", method=\"build_output_user_query\"),\r\n        Output(display_name=\"User session\", name=\"session_id\", method=\"build_output_user_session\")\r\n    ]\r\n    \r\n    def extract_param_from_request(self, param_name: str) -> str:\r\n        # Parse the input URL\r\n        parsed_url = urlparse.urlparse(self.api_request)\r\n        query_params = urlparse.parse_qs(parsed_url.query)\r\n        return query_params.get(param_name, [\"\"])[0]  # Return the first value of the parameter\r\n        \r\n\r\n    def build_output_user_query(self) -> Message:\r\n        query = self.extract_param_from_request('query')\r\n        return Message(text=query)\r\n\r\n    def build_output_user_session(self) -> Message:\r\n        session_id = self.extract_param_from_request('session_id')\r\n        return Message(text=session_id)\r\n\r\n    \r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Handle API requests",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "GraphRAG Chat API",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "query",
                "display_name": "User query",
                "method": "build_output_user_query",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "session_id",
                "display_name": "User session",
                "method": "build_output_user_session",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "api_request"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "GraphRAGChatAPIComponent-d0zgt"
        },
        "selected": false,
        "width": 384,
        "height": 342,
        "dragging": false,
        "positionAbsolute": {
          "x": -2502.0623555732836,
          "y": 664.1980394995265
        }
      },
      {
        "id": "VectorRetrieverParserComponent-3mPsc",
        "type": "genericNode",
        "position": {
          "x": -636.2086082501868,
          "y": 655.1407064554317
        },
        "data": {
          "type": "VectorRetrieverParserComponent",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Parse retrieved Documents",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Vector Retriever Parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parsed_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "VectorRetrieverParserComponent-3mPsc"
        },
        "selected": false,
        "width": 384,
        "height": 259,
        "positionAbsolute": {
          "x": -636.2086082501868,
          "y": 655.1407064554317
        },
        "dragging": false
      },
      {
        "id": "converstaion_history_retriever-EwxtO",
        "type": "genericNode",
        "position": {
          "x": -1699.76070200596,
          "y": 1770.844549058779
        },
        "data": {
          "type": "converstaion_history_retriever",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional\r\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\r\nfrom axiestudio.inputs import MessageTextInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\nimport psycopg2  # PostgreSQL connect lib\r\nimport json\r\nimport datetime\r\nclass ConversationHistoryRetrieverComponent(LCToolComponent):\r\n    display_name: str = \"Conversation History Retriever\"\r\n    description: str = \"Retrieve a conversation history of a chat session.\"\r\n    name = \"converstaion_history_retriever\"\r\n    icon = \"custom_components\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"host\",\r\n            display_name=\"Host\",\r\n            info=\"PostgreSQL server address\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user\",\r\n            display_name=\"User\",\r\n            info=\"Username for authentication\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"password\",\r\n            display_name=\"Password\",\r\n            info=\"Password for authentication\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"database\",\r\n            display_name=\"Database\",\r\n            info=\"Database name\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_id\",\r\n            display_name=\"Chat User ID\",\r\n            info=\"Chat user\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session_id\",\r\n            display_name=\"Conversation Session ID\",\r\n            info=\"Chat session\",\r\n        ),\r\n    ]\r\n\r\n    class PostgreSQLQuerySchema(BaseModel):\r\n        host: str = Field(..., description=\"PostgreSQL server address\")\r\n        user: str = Field(..., description=\"Username for authentication\")\r\n        password: str = Field(..., description=\"Password for authentication\")\r\n        database: str = Field(..., description=\"Database name\")\r\n        query: str = Field(..., description=\"The SQL query to execute\")\r\n\r\n    def run_model(self) -> Text:\r\n        # Coletando os inputs\r\n        input_dict = {input_obj.name: input_obj.value for input_obj in self.inputs}\r\n\r\n        host = input_dict.get(\"host\")\r\n        user = input_dict.get(\"user\")\r\n        password = input_dict.get(\"password\")\r\n        database = input_dict.get(\"database\")\r\n        session_id = input_dict.get(\"session_id\")\r\n        query = f\"\"\"\r\n        SELECT * FROM chat_history\r\n        WHERE session_id = '{session_id}'\r\n        ORDER BY time_stamp ASC;\r\n        \"\"\"\r\n\r\n        # Conectando ao banco de dados PostgreSQL\r\n        try:\r\n            connection = psycopg2.connect(\r\n                host=host,\r\n                user=user,\r\n                password=password,\r\n                database=database\r\n            )\r\n            cursor = connection.cursor()\r\n            cursor.execute(query)\r\n            result = cursor.fetchall()\r\n            cursor.close()\r\n            connection.close()\r\n            \r\n            # Parse row\r\n            results = [\r\n                {\r\n                    'message_id': row[0],\r\n                    'user_id': row[1],\r\n                    'session_id': row[2],\r\n                    'time_stamp': row[3].isoformat(),\r\n                    'content': row[4],\r\n                    'sender': 'user' if row[5] == 0 else 'assistent',\r\n                    'additional_kwargs': row[6]\r\n                }\r\n                for row in result\r\n            ]\r\n            self.status = results\r\n            return results\r\n\r\n        except Exception as e:\r\n            if connection:\r\n                connection.close()  # Garantir que a conex?o seja fechada em caso de erro\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return f\"Error executing query: {str(e)}\"\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "database": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "database",
                "value": "userchat",
                "display_name": "Database",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Database name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "host": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "host",
                "value": "localhost",
                "display_name": "Host",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "PostgreSQL server address",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "password": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "password",
                "value": "",
                "display_name": "Password",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Password for authentication",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "session_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Conversation Session ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Chat session",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user",
                "value": "userchat",
                "display_name": "User",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Username for authentication",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_id": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_id",
                "value": "1",
                "display_name": "Chat User ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Chat user",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Retrieve a conversation history of a chat session.",
            "icon": "custom_components",
            "base_classes": [
              "Data",
              "Message",
              "Text",
              "Tool"
            ],
            "display_name": "Conversation History Retriever",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data",
                  "Text",
                  "Message"
                ],
                "selected": "Data",
                "name": "api_run_model",
                "display_name": "Data",
                "method": "run_model",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "api_build_tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "host",
              "user",
              "password",
              "database",
              "user_id",
              "session_id"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "converstaion_history_retriever-EwxtO"
        },
        "selected": false,
        "width": 384,
        "height": 771,
        "positionAbsolute": {
          "x": -1699.76070200596,
          "y": 1770.844549058779
        },
        "dragging": false
      },
      {
        "id": "ConversationHistoryParser-RZtMc",
        "type": "genericNode",
        "position": {
          "x": -553.0492586890932,
          "y": 1751.0583807189107
        },
        "data": {
          "type": "ConversationHistoryParser",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The conversation history to parse",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\r\n\r\nfrom axiestudio.io import DataInput, Output, StrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.schema import Data\r\nimport json\r\nclass ConversationHistoryParserComponent(Component):\r\n\r\n    display_name = \"Conversation History Parser\"\r\n    description = \"Merge and convert retrieved conversation history to text.\"\r\n    icon = \"braces\"\r\n    name = \"ConversationHistoryParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The conversation history to parse\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"Parsed Conversation\", method=\"parse_data\"),\r\n    ]\r\n\r\n    def parse_data(self) -> Message:\r\n        parsed_output = \"\"\r\n        for message in self.data:\r\n            timestamp, content, sender = message['time_stamp'], message['content'], message['sender']\r\n            parsed_output += f\"[{timestamp}] {sender}: {content}\\n\"\r\n        self.status = parsed_output\r\n        return Message(text=parsed_output)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Merge and convert retrieved conversation history to text.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Conversation History Parser",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "Parsed Conversation",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "ConversationHistoryParser-RZtMc"
        },
        "selected": false,
        "width": 384,
        "height": 287,
        "dragging": false,
        "positionAbsolute": {
          "x": -553.0492586890932,
          "y": 1751.0583807189107
        }
      },
      {
        "id": "GraphTransformer-bCo9N",
        "type": "genericNode",
        "position": {
          "x": -1785.9780419973927,
          "y": 1078.0412251422817
        },
        "data": {
          "type": "GraphTransformer",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output, DropdownInput\r\nfrom axiestudio.schema import Data\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_experimental.graph_transformers import LLMGraphTransformer\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom langchain_core.documents import Document\r\nimport json\r\nclass GraphTransformer(Component):\r\n    display_name = \"Graph Transformer\"\r\n    description = \"Transform any text input into graph. Input: text, schema in JSON to control\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphTransformer\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_text\", display_name=\"Input Text\", value=\"Hello, World!\"),\r\n        MessageTextInput(name=\"schema_text\", display_name=\"Schema Text\", value=\"\"\"{\r\n    \"allowed_nodes\": [],\r\n    \"allowed_relationships\": [],\r\n    \"prompt\": null,\r\n    \"strict_mode\": true,\r\n    \"node_properties\": true,\r\n    \"relationship_properties\": true\r\n}\"\"\"),\r\n        DropdownInput(\r\n            name=\"openai_model\",\r\n            display_name=\"Graph Transformation Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"gpt-4o-mini\",\r\n                \"gpt-4o\",\r\n                \"gpt-4-turbo\",\r\n                \"gpt-3.5-turbo\",\r\n            ],\r\n            value=\"gpt-4o-mini\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    def process_text(self,text: str, transformer: LLMGraphTransformer) -> List[GraphDocument]:\r\n        doc = Document(page_content=text)\r\n        return transformer.convert_to_graph_documents([doc])\r\n    def build_output(self) -> Data:\r\n        schema = json.loads(self.schema_text)\r\n        llm = ChatOpenAI(\r\n            temperature=0,\r\n            model_name=self.openai_model,\r\n            api_key=self.openai_api_key\r\n        )\r\n        llm_transformer = LLMGraphTransformer(\r\n            llm = llm,\r\n            allowed_nodes=schema.get(\"allowed_nodes\", []),  \r\n            allowed_relationships=schema.get(\"allowed_relationships\", []),  \r\n            prompt=schema.get(\"prompt\", None),  \r\n            strict_mode=schema.get(\"strict_mode\", True),  \r\n            node_properties=schema.get(\"node_properties\", True),  \r\n            relationship_properties=schema.get(\"relationship_properties\", True) \r\n        )\r\n        result = self.process_text(self.input_text, llm_transformer)\r\n        self.status = result\r\n        return result\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Input Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_model": {
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-3.5-turbo"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_model",
                "value": "gpt-4o-mini",
                "display_name": "Graph Transformation Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "schema_text": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "schema_text",
                "value": "{\n    \"allowed_nodes\": [],\n    \"allowed_relationships\": [],\n    \"prompt\": null,\n    \"strict_mode\": true,\n    \"node_properties\": true,\n    \"relationship_properties\": true\n}",
                "display_name": "Schema Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Transform any text input into graph. Input: text, schema in JSON to control",
            "icon": "custom_components",
            "base_classes": [
              "Data"
            ],
            "display_name": "Graph Transfomrer",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_text",
              "schema_text",
              "openai_model",
              "openai_api_key"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17",
            "official": false
          },
          "id": "GraphTransformer-bCo9N"
        },
        "selected": false,
        "width": 384,
        "height": 582,
        "positionAbsolute": {
          "x": -1785.9780419973927,
          "y": 1078.0412251422817
        },
        "dragging": false
      },
      {
        "id": "GraphSearchCypher-VxMoO",
        "type": "genericNode",
        "position": {
          "x": -1247.2169451753498,
          "y": 1511.5292175554393
        },
        "data": {
          "type": "GraphSearchCypher",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "User's query graph data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nclass GraphSearchCypherComponent(Component):\r\n    display_name = \"Graph Search Cypher\"\r\n    description = \"Generate cypher to search nodes in the graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphSearchCypher\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"User's query graph data\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Cypher Query\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # only generate queries for nodes search\r\n        output_str = \"\"\r\n        documents = self.data\r\n        node_ids =[]\r\n        for document in documents:\r\n            for node in document.nodes:\r\n                node_ids.append(node.id)\r\n        query = f\"\"\"\r\n        UNWIND {node_ids} as node_id\r\n        MATCH (n {{id: node_id}})\r\n        OPTIONAL MATCH (n)-[]-(doc:Document)\r\n        WITH doc, [key IN keys(doc) WHERE NOT key IN ['elementId', 'id', 'embedding']] AS filteredKeys\r\n        RETURN collect(apoc.map.submap(doc, filteredKeys)) AS docAttributes\r\n        \"\"\"\r\n        self.status = query\r\n        return query\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Generate cypher to search nodes in the graph",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Search Cypher",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Cypher Query",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "GraphSearchCypher-VxMoO"
        },
        "selected": false,
        "width": 384,
        "height": 259,
        "dragging": false,
        "positionAbsolute": {
          "x": -1247.2169451753498,
          "y": 1511.5292175554393
        }
      },
      {
        "id": "GraphRetriever-mH1bD",
        "type": "genericNode",
        "position": {
          "x": -612.93405763902,
          "y": 1202.9916700342628
        },
        "data": {
          "type": "GraphRetriever",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom neo4j import GraphDatabase\r\n\r\nimport json\r\nclass GraphRetriever(Component):\r\n\r\n    \r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"cypher_query\", \r\n                         display_name=\"Cypher Query\",\r\n                         info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n       \r\n                \r\n    def build_output(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        with driver.session() as session:\r\n            results = session.run(self.cypher_query)\r\n            data = json.dumps([doc[\"docAttributes\"] for doc in results.data()])\r\n\r\n        driver.close()\r\n        self.status = data  # Update status with extracted data\r\n        return Message(text=data)\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "cypher_query": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "cypher_query",
                "value": "",
                "display_name": "Cypher Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Cypher query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "neo4j_credentials": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "neo4j_credentials",
                "value": "",
                "display_name": "Neo4j Credentials",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Execute cypher query to retrieve from knowledge graph",
            "icon": "custom_components",
            "base_classes": [
              "Message"
            ],
            "display_name": "Graph Retriever",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cypher_query",
              "neo4j_credentials"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.17"
          },
          "id": "GraphRetriever-mH1bD"
        },
        "selected": false,
        "width": 384,
        "height": 411,
        "positionAbsolute": {
          "x": -612.93405763902,
          "y": 1202.9916700342628
        },
        "dragging": false
      },
      {
        "id": "CombineText-dS7aS",
        "type": "genericNode",
        "position": {
          "x": -9.447721501909768,
          "y": 545.0194787654442
        },
        "data": {
          "type": "CombineText",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "delimiter": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "delimiter",
                "value": " \\n",
                "display_name": "Delimiter",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text1": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text1",
                "value": "",
                "display_name": "First Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The first text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text2": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text2",
                "value": "",
                "display_name": "Second Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The second text input to concatenate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
            "icon": "merge",
            "base_classes": [
              "Message"
            ],
            "display_name": "Combine Text",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "combined_text",
                "display_name": "Combined Text",
                "method": "combine_texts",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "text1",
              "text2",
              "delimiter"
            ],
            "beta": false,
            "edited": false,
            "lf_version": "1.0.17"
          },
          "id": "CombineText-dS7aS"
        },
        "selected": false,
        "width": 384,
        "height": 497,
        "positionAbsolute": {
          "x": -9.447721501909768,
          "y": 545.0194787654442
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "Prompt-uir6X",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-uir6Xœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-R02xB",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-R02xBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-R02xB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-uir6X",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-uir6X{œdataTypeœ:œPromptœ,œidœ:œPrompt-uir6Xœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-R02xB{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-R02xBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "OpenAIModel-R02xB",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-R02xBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-4hTcP",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4hTcPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-4hTcP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-R02xB",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-R02xB{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-R02xBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-4hTcP{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4hTcPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphRAGChatAPIComponent-d0zgt",
        "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-uir6X",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt-uir6X",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRAGChatAPIComponent",
            "id": "GraphRAGChatAPIComponent-d0zgt",
            "name": "query",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œquestionœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-NuezZ",
        "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
        "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-NuezZ",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-NuezZ{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphRAGChatAPIComponent-d0zgt",
        "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
        "target": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRAGChatAPIComponent",
            "id": "GraphRAGChatAPIComponent-d0zgt",
            "name": "query",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false
      },
      {
        "source": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
        "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "VectorRetrieverParserComponent-3mPsc",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "VectorRetrieverParserComponent-3mPsc",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "KnowledgeGraphIndexKRetrieverComponent",
            "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-VectorRetrieverParserComponent-3mPsc{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "GraphRAGChatAPIComponent-d0zgt",
        "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œsession_idœ,œoutput_typesœ:[œMessageœ]}",
        "target": "converstaion_history_retriever-EwxtO",
        "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "session_id",
            "id": "converstaion_history_retriever-EwxtO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRAGChatAPIComponent",
            "id": "GraphRAGChatAPIComponent-d0zgt",
            "name": "session_id",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œsession_idœ,œoutput_typesœ:[œMessageœ]}-converstaion_history_retriever-EwxtO{œfieldNameœ:œsession_idœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "converstaion_history_retriever-EwxtO",
        "sourceHandle": "{œdataTypeœ:œconverstaion_history_retrieverœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}",
        "target": "ConversationHistoryParser-RZtMc",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œConversationHistoryParser-RZtMcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ConversationHistoryParser-RZtMc",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "converstaion_history_retriever",
            "id": "converstaion_history_retriever-EwxtO",
            "name": "api_run_model",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-converstaion_history_retriever-EwxtO{œdataTypeœ:œconverstaion_history_retrieverœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}-ConversationHistoryParser-RZtMc{œfieldNameœ:œdataœ,œidœ:œConversationHistoryParser-RZtMcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "ConversationHistoryParser-RZtMc",
        "sourceHandle": "{œdataTypeœ:œConversationHistoryParserœ,œidœ:œConversationHistoryParser-RZtMcœ,œnameœ:œParsed Conversationœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-uir6X",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "Prompt-uir6X",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConversationHistoryParser",
            "id": "ConversationHistoryParser-RZtMc",
            "name": "Parsed Conversation",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConversationHistoryParser-RZtMc{œdataTypeœ:œConversationHistoryParserœ,œidœ:œConversationHistoryParser-RZtMcœ,œnameœ:œParsed Conversationœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œmemoryœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphTransformer-bCo9N",
        "sourceHandle": "{œdataTypeœ:œGraphTransformerœ,œidœ:œGraphTransformer-bCo9Nœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "GraphSearchCypher-VxMoO",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œGraphSearchCypher-VxMoOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "GraphSearchCypher-VxMoO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "GraphTransformer",
            "id": "GraphTransformer-bCo9N",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-GraphTransformer-bCo9N{œdataTypeœ:œGraphTransformerœ,œidœ:œGraphTransformer-bCo9Nœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-GraphSearchCypher-VxMoO{œfieldNameœ:œdataœ,œidœ:œGraphSearchCypher-VxMoOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": ""
      },
      {
        "source": "GraphSearchCypher-VxMoO",
        "sourceHandle": "{œdataTypeœ:œGraphSearchCypherœ,œidœ:œGraphSearchCypher-VxMoOœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GraphRetriever-mH1bD",
        "targetHandle": "{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "cypher_query",
            "id": "GraphRetriever-mH1bD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphSearchCypher",
            "id": "GraphSearchCypher-VxMoO",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphSearchCypher-VxMoO{œdataTypeœ:œGraphSearchCypherœ,œidœ:œGraphSearchCypher-VxMoOœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-mH1bD{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "Neo4jCredentialLoader-NuezZ",
        "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GraphRetriever-mH1bD",
        "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "neo4j_credentials",
            "id": "GraphRetriever-mH1bD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Neo4jCredentialLoader",
            "id": "Neo4jCredentialLoader-NuezZ",
            "name": "credentials",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Neo4jCredentialLoader-NuezZ{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-mH1bD{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphRAGChatAPIComponent-d0zgt",
        "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GraphTransformer-bCo9N",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œGraphTransformer-bCo9Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_text",
            "id": "GraphTransformer-bCo9N",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRAGChatAPIComponent",
            "id": "GraphRAGChatAPIComponent-d0zgt",
            "name": "query",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-GraphTransformer-bCo9N{œfieldNameœ:œinput_textœ,œidœ:œGraphTransformer-bCo9Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "VectorRetrieverParserComponent-3mPsc",
        "sourceHandle": "{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-dS7aS",
        "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "text1",
            "id": "CombineText-dS7aS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "VectorRetrieverParserComponent",
            "id": "VectorRetrieverParserComponent-3mPsc",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-VectorRetrieverParserComponent-3mPsc{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-dS7aS{œfieldNameœ:œtext1œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "GraphRetriever-mH1bD",
        "sourceHandle": "{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-mH1bDœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CombineText-dS7aS",
        "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "text2",
            "id": "CombineText-dS7aS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GraphRetriever",
            "id": "GraphRetriever-mH1bD",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GraphRetriever-mH1bD{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-mH1bDœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-CombineText-dS7aS{œfieldNameœ:œtext2œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": ""
      },
      {
        "source": "CombineText-dS7aS",
        "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-dS7aSœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-uir6X",
        "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "context",
            "id": "Prompt-uir6X",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CombineText",
            "id": "CombineText-dS7aS",
            "name": "combined_text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CombineText-dS7aS{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-dS7aSœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œcontextœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 1443.039268658152,
      "y": -59.111418878404265,
      "zoom": 0.5113339656472234
    }
  },
  "metadata": {
    "KnowledgeGraphIndexKRetrieverComponent": {
      "count": 1
    },
    "Prompt": {
      "count": 1
    },
    "OpenAIModel": {
      "count": 1
    },
    "IfElseComponent": {
      "count": 1
    },
    "Neo4jCredentialLoader": {
      "count": 1
    },
    "ChatOutput": {
      "count": 1
    },
    "GraphRAGChatAPIComponent": {
      "count": 1
    },
    "VectorRetrieverParserComponent": {
      "count": 1
    },
    "converstaion_history_retriever": {
      "count": 1
    },
    "ConversationHistoryParser": {
      "count": 1
    },
    "GraphTransformer": {
      "count": 1
    },
    "GraphSearchCypher": {
      "count": 1
    },
    "GraphRetriever": {
      "count": 1
    },
    "CombineText": {
      "count": 1
    },
    "total": 14
  },
  "original": {
    "id": "d8bca379-f0d1-4eca-927e-ea416c806fe6",
    "name": "GraphRAG conversation flow",
    "description": "Conversation flow of GraphRAG",
    "is_component": false,
    "liked_by_count": "1",
    "downloads_count": "14",
    "metadata": {
      "KnowledgeGraphIndexKRetrieverComponent": {
        "count": 1
      },
      "Prompt": {
        "count": 1
      },
      "OpenAIModel": {
        "count": 1
      },
      "IfElseComponent": {
        "count": 1
      },
      "Neo4jCredentialLoader": {
        "count": 1
      },
      "ChatOutput": {
        "count": 1
      },
      "GraphRAGChatAPIComponent": {
        "count": 1
      },
      "VectorRetrieverParserComponent": {
        "count": 1
      },
      "converstaion_history_retriever": {
        "count": 1
      },
      "ConversationHistoryParser": {
        "count": 1
      },
      "GraphTransformer": {
        "count": 1
      },
      "GraphSearchCypher": {
        "count": 1
      },
      "GraphRetriever": {
        "count": 1
      },
      "CombineText": {
        "count": 1
      },
      "total": 14
    },
    "last_tested_version": "1.0.17",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
          "type": "genericNode",
          "position": {
            "x": -1179.4591011367195,
            "y": 83.23755043873282
          },
          "data": {
            "type": "KnowledgeGraphIndexKRetrieverComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.vectorstores import Neo4jVector\r\nfrom langchain_openai import OpenAIEmbeddings\r\nimport json\r\nclass KnowledgeGraphIndexKRetrieverComponent(Component):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        # Populate the node_type dropdown after credentials are set\r\n        if self.neo4j_credentials:\r\n            self.populate_node_type_options()\r\n    \r\n    display_name = \"KnowledgeGraphIndexKRetriever\"\r\n    description = \"Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.\"\r\n    icon = \"custom_components\"\r\n    name = \"KnowledgeGraphIndexKRetrieverComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"user_query\", \r\n                         display_name=\"Query\",\r\n                         info=\"User query\"),\r\n        IntInput(name=\"k\", display_name=\"Number of results to return\", value=4),\r\n        DropdownInput(\r\n            name=\"node_type\",\r\n            display_name=\"Nodes to be returned\",\r\n            options=[\r\n            ],\r\n            value=\"\"\r\n        ),\r\n        \r\n        DropdownInput(\r\n            name=\"openai_embedding_model\",\r\n            display_name=\"Embedding Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"text-embedding-3-small\",\r\n                \"text-embedding-3-large\",\r\n                \"text-embedding-ada-002\",\r\n            ],\r\n            value=\"text-embedding-3-small\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n        \r\n    def populate_node_type_options(self):\r\n        # Fetch node types from Neo4j and populate the options\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        node_types = set()\r\n        with driver.session() as session:\r\n            result = session.run(\"MATCH (n) RETURN DISTINCT labels(n) AS labels\")\r\n            for record in result:\r\n                node_types.update(record[\"labels\"])\r\n\r\n        driver.close()\r\n        \r\n        # Update the dropdown options\r\n        node_type_input = self._get_input_by_name(\"node_type\")\r\n        if node_type_input:\r\n            node_type_input.options = list(node_types)\r\n            if node_types:\r\n                node_type_input.value = list(node_types)[0]  # Set a default value if needed\r\n                \r\n    def build_output(self) -> Data:\r\n        embeddings = OpenAIEmbeddings(\r\n            api_key=self.openai_api_key,\r\n            model=self.openai_embedding_model\r\n        )\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        vector_index = Neo4jVector.from_existing_graph(\r\n            embeddings,\r\n            search_type=\"hybrid\",\r\n            node_label=self.node_type,\r\n            text_node_properties=[\"text\"],\r\n            embedding_node_property=\"embedding\",\r\n            url=credentials[\"url\"],\r\n            username=credentials[\"username\"],\r\n            password=credentials[\"password\"],\r\n        )\r\n        results = vector_index.similarity_search(self.user_query, k=self.k)\r\n        # data = Data(data=results)\r\n        self.status = results\r\n        return results\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "k": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "k",
                  "value": 4,
                  "display_name": "Number of results to return",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "node_type": {
                  "trace_as_metadata": true,
                  "options": [],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "node_type",
                  "value": "Document",
                  "display_name": "Nodes to be returned",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput",
                  "load_from_db": false
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_embedding_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "text-embedding-3-small",
                    "text-embedding-3-large",
                    "text-embedding-ada-002"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_embedding_model",
                  "value": "text-embedding-3-small",
                  "display_name": "Embedding Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "user_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_query",
                  "value": "",
                  "display_name": "Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "User query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Neo4j knowledge graph retriever implemented using vector similarity search. Return top k results.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Neo4J K Retriever (Vector Search)",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "user_query",
                "k",
                "node_type",
                "openai_embedding_model",
                "openai_api_key",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt"
          },
          "selected": false,
          "width": 384,
          "height": 768,
          "positionAbsolute": {
            "x": -1179.4591011367195,
            "y": 83.23755043873282
          },
          "dragging": false
        },
        {
          "id": "Prompt-uir6X",
          "type": "genericNode",
          "position": {
            "x": 529.4599977883669,
            "y": 724.4927039333264
          },
          "data": {
            "type": "Prompt",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.prompts.api_utils import process_prompt_template\nfrom axiestudio.custom import Component\nfrom axiestudio.inputs.inputs import DefaultPromptField\nfrom axiestudio.io import Output, PromptInput\nfrom axiestudio.schema.message import Message\nfrom axiestudio.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "template": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "template",
                  "value": "Answer the question shortly. Analyse the question based on conversation memory if given. Find answer in the context and if the answer is not in the context, generate the answer.\nConversation Memory: {memory}\nContext: {context}\nQuestion: {question}",
                  "display_name": "Template",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "prompt",
                  "_input_type": "PromptInput"
                },
                "context": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "context",
                  "display_name": "context",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "question": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "question",
                  "display_name": "question",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                },
                "memory": {
                  "field_type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "memory",
                  "advanced": false,
                  "input_types": [
                    "Message",
                    "Text"
                  ],
                  "dynamic": false,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "Generate a prompt for LLM to process query",
              "icon": "prompts",
              "is_input": null,
              "is_output": null,
              "is_composition": null,
              "base_classes": [
                "Message"
              ],
              "name": "",
              "display_name": "Prompt",
              "documentation": "",
              "custom_fields": {
                "template": [
                  "memory",
                  "context",
                  "question"
                ]
              },
              "output_types": [],
              "full_path": null,
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "prompt",
                  "hidden": null,
                  "display_name": "Prompt Message",
                  "method": "build_prompt",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "template"
              ],
              "beta": false,
              "error": null,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "Prompt-uir6X"
          },
          "selected": false,
          "width": 384,
          "height": 554,
          "positionAbsolute": {
            "x": 529.4599977883669,
            "y": 724.4927039333264
          },
          "dragging": false
        },
        {
          "id": "OpenAIModel-R02xB",
          "type": "genericNode",
          "position": {
            "x": 998.0026271897107,
            "y": 1346.4512284874122
          },
          "data": {
            "type": "OpenAIModel",
            "node": {
              "template": {
                "_type": "Component",
                "api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The OpenAI API Key to use for the OpenAI model.",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import operator\nfrom functools import reduce\n\nfrom axiestudio.field_typing.range_spec import RangeSpec\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom axiestudio.base.models.model import LCModelComponent\nfrom axiestudio.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom axiestudio.field_typing import LanguageModel\nfrom axiestudio.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = LCModelComponent._base_inputs + [\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Input",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageInput"
                },
                "json_mode": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "json_mode",
                  "value": false,
                  "display_name": "JSON Mode",
                  "advanced": true,
                  "dynamic": false,
                  "info": "If True, it will output JSON regardless of passing a schema.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "max_tokens": {
                  "trace_as_metadata": true,
                  "range_spec": {
                    "step_type": "float",
                    "min": 0,
                    "max": 128000,
                    "step": 0.1
                  },
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "max_tokens",
                  "value": "",
                  "display_name": "Max Tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "model_kwargs": {
                  "trace_as_input": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_kwargs",
                  "value": {},
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "model_name": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-4-turbo-preview",
                    "gpt-4",
                    "gpt-3.5-turbo",
                    "gpt-3.5-turbo-0125"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "model_name",
                  "value": "gpt-4o-mini",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "openai_api_base": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_base",
                  "value": "",
                  "display_name": "OpenAI API Base",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "output_schema": {
                  "trace_as_input": true,
                  "list": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "output_schema",
                  "value": {},
                  "display_name": "Schema",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.",
                  "title_case": false,
                  "type": "dict",
                  "_input_type": "DictInput"
                },
                "seed": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "seed",
                  "value": 1,
                  "display_name": "Seed",
                  "advanced": true,
                  "dynamic": false,
                  "info": "The seed controls the reproducibility of the job.",
                  "title_case": false,
                  "type": "int",
                  "_input_type": "IntInput"
                },
                "stream": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "stream",
                  "value": false,
                  "display_name": "Stream",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Stream the response from the model. Streaming works only in Chat.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                },
                "system_message": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "system_message",
                  "value": "",
                  "display_name": "System Message",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "System message to pass to the model.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "temperature": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "temperature",
                  "value": 0.1,
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "float",
                  "_input_type": "FloatInput"
                }
              },
              "description": "Generates text using OpenAI LLMs.",
              "icon": "OpenAI",
              "base_classes": [
                "LanguageModel",
                "Message"
              ],
              "display_name": "OpenAI",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text_output",
                  "display_name": "Text",
                  "method": "text_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "LanguageModel"
                  ],
                  "selected": "LanguageModel",
                  "name": "model_output",
                  "display_name": "Language Model",
                  "method": "build_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "system_message",
                "stream",
                "max_tokens",
                "model_kwargs",
                "json_mode",
                "output_schema",
                "model_name",
                "openai_api_base",
                "api_key",
                "temperature",
                "seed"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "OpenAIModel-R02xB"
          },
          "selected": false,
          "width": 384,
          "height": 599,
          "positionAbsolute": {
            "x": 998.0026271897107,
            "y": 1346.4512284874122
          },
          "dragging": false
        },
        {
          "id": "IfElseComponent-rcfCg",
          "type": "genericNode",
          "position": {
            "x": -5631.81437595536,
            "y": -1466.6582277720001
          },
          "data": {
            "type": "IfElseComponent",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import BoolInput, Output\r\nfrom axiestudio.schema import Data\r\nq\r\n\r\nclass IfElseComponent(Component):\r\n    display_name = \"If Else Component\"\r\n    description = \"Capture a boolean value, trigger a workflow based on the input.\\n2 outputs will return True or None based on the input.\\nUse case: Next component should have a input check header for triggering.\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"IfElseComponent\"\r\n\r\n    inputs = [\r\n        BoolInput(name=\"input_value\", display_name=\"Input Value\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"True Output\", name=\"true_output\", method=\"build_true_output\"),\r\n        Output(display_name=\"False Output\", name=\"false_output\", method=\"build_false_output\")\r\n    ]\r\n\r\n    def build_true_output(self) -> Data:\r\n        if self.input_value:\r\n            data = Data(value=True)\r\n            self.status = data\r\n            return data\r\n        else:\r\n            data = Data(value=None)\r\n            self.status = data\r\n            return None\r\n    def build_false_output(self) -> Data:\r\n        if not self.input_value:\r\n            data = Data(value=True)\r\n            self.status = data\r\n            return data\r\n        else:\r\n            data = Data(value=None)\r\n            self.status = data\r\n            return None\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_value": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": true,
                  "display_name": "Input Value",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Capture a boolean value, trigger a workflow based on the input.\n2 outputs will return True or None based on the input.\nUse case: Next component should have a input check header for triggering.",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "If Else Component (obsolete)",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "true_output",
                  "display_name": "True Output",
                  "method": "build_true_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "false_output",
                  "display_name": "False Output",
                  "method": "build_false_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "IfElseComponent-rcfCg"
          },
          "selected": false,
          "width": 384,
          "height": 440,
          "dragging": false,
          "positionAbsolute": {
            "x": -5631.81437595536,
            "y": -1466.6582277720001
          }
        },
        {
          "id": "Neo4jCredentialLoader-NuezZ",
          "type": "genericNode",
          "position": {
            "x": -2069.8490306603435,
            "y": 152.06299156043423
          },
          "data": {
            "type": "Neo4jCredentialLoader",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\n\r\nclass Neo4jCredentialLoader(Component):\r\n    display_name = \"Neo4j Credential Loader\"\r\n    description = \"A handy component to load neo4j credentials\"\r\n    icon = \"custom_components\"\r\n    name = \"Neo4jCredentialLoader\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"neo4j_url\", display_name=\"Neo4j URL\"),\r\n        StrInput(name=\"neo4j_username\", display_name=\"Neo4j Username\"),\r\n        StrInput(name=\"neo4j_password\", display_name=\"Neo4j Password\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Credentials\", name=\"credentials\", method=\"build_output\")\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        message = Message(text=json.dumps(\r\n            {\r\n                'url': self.neo4j_url,\r\n                'username': self.neo4j_username,\r\n                'password': self.neo4j_password\r\n            }\r\n        ))\r\n        self.status=message\r\n        return message\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "neo4j_password": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_password",
                  "value": "Jingconsult",
                  "display_name": "Neo4j Password",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_url": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_url",
                  "value": "neo4j://jingconsult.tech:7687",
                  "display_name": "Neo4j URL",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                },
                "neo4j_username": {
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_username",
                  "value": "neo4j",
                  "display_name": "Neo4j Username",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "StrInput"
                }
              },
              "description": "A handy component to load neo4j credentials",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Neo4j Credential Loader",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "credentials",
                  "display_name": "Credentials",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "neo4j_url",
                "neo4j_username",
                "neo4j_password"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "Neo4jCredentialLoader-NuezZ"
          },
          "selected": false,
          "width": 384,
          "height": 469,
          "positionAbsolute": {
            "x": -2069.8490306603435,
            "y": 152.06299156043423
          },
          "dragging": false
        },
        {
          "id": "ChatOutput-4hTcP",
          "type": "genericNode",
          "position": {
            "x": 1493.329312159434,
            "y": 1071.2747611720902
          },
          "data": {
            "type": "ChatOutput",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.base.io.chat import ChatComponent\nfrom axiestudio.inputs import BoolInput\nfrom axiestudio.io import DropdownInput, MessageTextInput, Output\nfrom axiestudio.memory import store_message\nfrom axiestudio.schema.message import Message\nfrom axiestudio.utils.constants import MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER, MESSAGE_SENDER_AI\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if (\n            self.session_id\n            and isinstance(message, Message)\n            and isinstance(message.text, str)\n            and self.should_store_message\n        ):\n            store_message(\n                message,\n                flow_id=self.graph.flow_id,\n            )\n            self.message.value = message\n\n        self.status = message\n        return message\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "data_template": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data_template",
                  "value": "{text}",
                  "display_name": "Data Template",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "input_value": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_value",
                  "value": "",
                  "display_name": "Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Message to be passed as output.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "sender": {
                  "trace_as_metadata": true,
                  "options": [
                    "Machine",
                    "User"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender",
                  "value": "Machine",
                  "display_name": "Sender Type",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Type of sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "sender_name": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "sender_name",
                  "value": "AI",
                  "display_name": "Sender Name",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Name of the sender.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Session ID",
                  "advanced": true,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "should_store_message": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "should_store_message",
                  "value": true,
                  "display_name": "Store Messages",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Store the message in the history.",
                  "title_case": false,
                  "type": "bool",
                  "_input_type": "BoolInput"
                }
              },
              "description": "Display a chat message in the Playground.",
              "icon": "ChatOutput",
              "base_classes": [
                "Message"
              ],
              "display_name": "Chat Output",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "message",
                  "display_name": "Message",
                  "method": "message_response",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_value",
                "should_store_message",
                "sender",
                "sender_name",
                "session_id",
                "data_template"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "ChatOutput-4hTcP"
          },
          "selected": false,
          "width": 384,
          "height": 297,
          "positionAbsolute": {
            "x": 1493.329312159434,
            "y": 1071.2747611720902
          },
          "dragging": false
        },
        {
          "id": "GraphRAGChatAPIComponent-d0zgt",
          "type": "genericNode",
          "position": {
            "x": -2502.0623555732836,
            "y": 664.1980394995265
          },
          "data": {
            "type": "GraphRAGChatAPIComponent",
            "node": {
              "template": {
                "_type": "Component",
                "api_request": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "api_request",
                  "value": "/jingconsult.consult/api/?query=How+much+initial+financial+investment+will+it+be+for+setting+up+a+hydrogen+plant&session_id=session_abc123",
                  "display_name": "User's API request",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport urllib.parse as urlparse\r\n\r\nclass GraphRAGChatAPIComponent(Component):\r\n    display_name = \"GraphRAG Chat API Component\"\r\n    description = \"Handle API requests\"\r\n    documentation: str = \"http://docs.axiestudio.org/components/custom\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRAGChatAPIComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"api_request\", display_name=\"User's API request\", value=\"/jingconsult.consult/api/?query=What+is+Graph&session_id=session_abc123\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"User query\", name=\"query\", method=\"build_output_user_query\"),\r\n        Output(display_name=\"User session\", name=\"session_id\", method=\"build_output_user_session\")\r\n    ]\r\n    \r\n    def extract_param_from_request(self, param_name: str) -> str:\r\n        # Parse the input URL\r\n        parsed_url = urlparse.urlparse(self.api_request)\r\n        query_params = urlparse.parse_qs(parsed_url.query)\r\n        return query_params.get(param_name, [\"\"])[0]  # Return the first value of the parameter\r\n        \r\n\r\n    def build_output_user_query(self) -> Message:\r\n        query = self.extract_param_from_request('query')\r\n        return Message(text=query)\r\n\r\n    def build_output_user_session(self) -> Message:\r\n        session_id = self.extract_param_from_request('session_id')\r\n        return Message(text=session_id)\r\n\r\n    \r\n\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Handle API requests",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "GraphRAG Chat API",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "query",
                  "display_name": "User query",
                  "method": "build_output_user_query",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "session_id",
                  "display_name": "User session",
                  "method": "build_output_user_session",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "api_request"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "GraphRAGChatAPIComponent-d0zgt"
          },
          "selected": false,
          "width": 384,
          "height": 342,
          "dragging": false,
          "positionAbsolute": {
            "x": -2502.0623555732836,
            "y": 664.1980394995265
          }
        },
        {
          "id": "VectorRetrieverParserComponent-3mPsc",
          "type": "genericNode",
          "position": {
            "x": -636.2086082501868,
            "y": 655.1407064554317
          },
          "data": {
            "type": "VectorRetrieverParserComponent",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The data to convert to text.",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DataInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nimport json\r\nclass VectorRetrieverParserComponent(Component):\r\n    display_name = \"Vector Retriever Parser\"\r\n    description = \"Parse retrieved Documents\"\r\n    icon = \"custom_components\"\r\n    name = \"VectorRetrieverParserComponent\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"parsed_data\"),\r\n    ]\r\n\r\n    def parsed_data(self) -> Message:\r\n        documents = []\r\n        if self.data:\r\n            for document in self.data:\r\n                documents.append(\r\n                    {\r\n                        \"metadata\": document.metadata,\r\n                        \"page_content\": document.page_content\r\n                    }\r\n                )\r\n        \r\n            return json.dumps(documents)\r\n        else:\r\n            return None\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Parse retrieved Documents",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Vector Retriever Parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "text",
                  "display_name": "Text",
                  "method": "parsed_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "VectorRetrieverParserComponent-3mPsc"
          },
          "selected": false,
          "width": 384,
          "height": 259,
          "positionAbsolute": {
            "x": -636.2086082501868,
            "y": 655.1407064554317
          },
          "dragging": false
        },
        {
          "id": "converstaion_history_retriever-EwxtO",
          "type": "genericNode",
          "position": {
            "x": -1699.76070200596,
            "y": 1770.844549058779
          },
          "data": {
            "type": "converstaion_history_retriever",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional\r\nfrom axiestudio.base.langchain_utilities.model import LCToolComponent\r\nfrom axiestudio.inputs import MessageTextInput, SecretStrInput\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\nimport psycopg2  # PostgreSQL connect lib\r\nimport json\r\nimport datetime\r\nclass ConversationHistoryRetrieverComponent(LCToolComponent):\r\n    display_name: str = \"Conversation History Retriever\"\r\n    description: str = \"Retrieve a conversation history of a chat session.\"\r\n    name = \"converstaion_history_retriever\"\r\n    icon = \"custom_components\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"host\",\r\n            display_name=\"Host\",\r\n            info=\"PostgreSQL server address\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user\",\r\n            display_name=\"User\",\r\n            info=\"Username for authentication\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"password\",\r\n            display_name=\"Password\",\r\n            info=\"Password for authentication\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"database\",\r\n            display_name=\"Database\",\r\n            info=\"Database name\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_id\",\r\n            display_name=\"Chat User ID\",\r\n            info=\"Chat user\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session_id\",\r\n            display_name=\"Conversation Session ID\",\r\n            info=\"Chat session\",\r\n        ),\r\n    ]\r\n\r\n    class PostgreSQLQuerySchema(BaseModel):\r\n        host: str = Field(..., description=\"PostgreSQL server address\")\r\n        user: str = Field(..., description=\"Username for authentication\")\r\n        password: str = Field(..., description=\"Password for authentication\")\r\n        database: str = Field(..., description=\"Database name\")\r\n        query: str = Field(..., description=\"The SQL query to execute\")\r\n\r\n    def run_model(self) -> Text:\r\n        # Coletando os inputs\r\n        input_dict = {input_obj.name: input_obj.value for input_obj in self.inputs}\r\n\r\n        host = input_dict.get(\"host\")\r\n        user = input_dict.get(\"user\")\r\n        password = input_dict.get(\"password\")\r\n        database = input_dict.get(\"database\")\r\n        session_id = input_dict.get(\"session_id\")\r\n        query = f\"\"\"\r\n        SELECT * FROM chat_history\r\n        WHERE session_id = '{session_id}'\r\n        ORDER BY time_stamp ASC;\r\n        \"\"\"\r\n\r\n        # Conectando ao banco de dados PostgreSQL\r\n        try:\r\n            connection = psycopg2.connect(\r\n                host=host,\r\n                user=user,\r\n                password=password,\r\n                database=database\r\n            )\r\n            cursor = connection.cursor()\r\n            cursor.execute(query)\r\n            result = cursor.fetchall()\r\n            cursor.close()\r\n            connection.close()\r\n            \r\n            # Parse row\r\n            results = [\r\n                {\r\n                    'message_id': row[0],\r\n                    'user_id': row[1],\r\n                    'session_id': row[2],\r\n                    'time_stamp': row[3].isoformat(),\r\n                    'content': row[4],\r\n                    'sender': 'user' if row[5] == 0 else 'assistent',\r\n                    'additional_kwargs': row[6]\r\n                }\r\n                for row in result\r\n            ]\r\n            self.status = results\r\n            return results\r\n\r\n        except Exception as e:\r\n            if connection:\r\n                connection.close()  # Garantir que a conex?o seja fechada em caso de erro\r\n            self.status = f\"Error executing query: {str(e)}\"\r\n            return f\"Error executing query: {str(e)}\"\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "database": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "database",
                  "value": "userchat",
                  "display_name": "Database",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Database name",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "host": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "host",
                  "value": "localhost",
                  "display_name": "Host",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "PostgreSQL server address",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "password": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "password",
                  "value": "",
                  "display_name": "Password",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Password for authentication",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "session_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "session_id",
                  "value": "",
                  "display_name": "Conversation Session ID",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Chat session",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user",
                  "value": "userchat",
                  "display_name": "User",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Username for authentication",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "user_id": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "user_id",
                  "value": "1",
                  "display_name": "Chat User ID",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Chat user",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Retrieve a conversation history of a chat session.",
              "icon": "custom_components",
              "base_classes": [
                "Data",
                "Message",
                "Text",
                "Tool"
              ],
              "display_name": "Conversation History Retriever",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data",
                    "Text",
                    "Message"
                  ],
                  "selected": "Data",
                  "name": "api_run_model",
                  "display_name": "Data",
                  "method": "run_model",
                  "value": "__UNDEFINED__",
                  "cache": true
                },
                {
                  "types": [
                    "Tool"
                  ],
                  "selected": "Tool",
                  "name": "api_build_tool",
                  "display_name": "Tool",
                  "method": "build_tool",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "host",
                "user",
                "password",
                "database",
                "user_id",
                "session_id"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "converstaion_history_retriever-EwxtO"
          },
          "selected": false,
          "width": 384,
          "height": 771,
          "positionAbsolute": {
            "x": -1699.76070200596,
            "y": 1770.844549058779
          },
          "dragging": false
        },
        {
          "id": "ConversationHistoryParser-RZtMc",
          "type": "genericNode",
          "position": {
            "x": -553.0492586890932,
            "y": 1751.0583807189107
          },
          "data": {
            "type": "ConversationHistoryParser",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "The conversation history to parse",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\r\n\r\nfrom axiestudio.io import DataInput, Output, StrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.schema import Data\r\nimport json\r\nclass ConversationHistoryParserComponent(Component):\r\n\r\n    display_name = \"Conversation History Parser\"\r\n    description = \"Merge and convert retrieved conversation history to text.\"\r\n    icon = \"braces\"\r\n    name = \"ConversationHistoryParser\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The conversation history to parse\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"Parsed Conversation\", method=\"parse_data\"),\r\n    ]\r\n\r\n    def parse_data(self) -> Message:\r\n        parsed_output = \"\"\r\n        for message in self.data:\r\n            timestamp, content, sender = message['time_stamp'], message['content'], message['sender']\r\n            parsed_output += f\"[{timestamp}] {sender}: {content}\\n\"\r\n        self.status = parsed_output\r\n        return Message(text=parsed_output)\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Merge and convert retrieved conversation history to text.",
              "icon": "braces",
              "base_classes": [
                "Message"
              ],
              "display_name": "Conversation History Parser",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "Parsed Conversation",
                  "display_name": "Text",
                  "method": "parse_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "ConversationHistoryParser-RZtMc"
          },
          "selected": false,
          "width": 384,
          "height": 287,
          "dragging": false,
          "positionAbsolute": {
            "x": -553.0492586890932,
            "y": 1751.0583807189107
          }
        },
        {
          "id": "GraphTransformer-bCo9N",
          "type": "genericNode",
          "position": {
            "x": -1785.9780419973927,
            "y": 1078.0412251422817
          },
          "data": {
            "type": "GraphTransformer",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output, DropdownInput\r\nfrom axiestudio.schema import Data\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_experimental.graph_transformers import LLMGraphTransformer\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom langchain_core.documents import Document\r\nimport json\r\nclass GraphTransformer(Component):\r\n    display_name = \"Graph Transformer\"\r\n    description = \"Transform any text input into graph. Input: text, schema in JSON to control\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphTransformer\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"input_text\", display_name=\"Input Text\", value=\"Hello, World!\"),\r\n        MessageTextInput(name=\"schema_text\", display_name=\"Schema Text\", value=\"\"\"{\r\n    \"allowed_nodes\": [],\r\n    \"allowed_relationships\": [],\r\n    \"prompt\": null,\r\n    \"strict_mode\": true,\r\n    \"node_properties\": true,\r\n    \"relationship_properties\": true\r\n}\"\"\"),\r\n        DropdownInput(\r\n            name=\"openai_model\",\r\n            display_name=\"Graph Transformation Model\",\r\n            advanced=False,\r\n            options=[\r\n                \"gpt-4o-mini\",\r\n                \"gpt-4o\",\r\n                \"gpt-4-turbo\",\r\n                \"gpt-3.5-turbo\",\r\n            ],\r\n            value=\"gpt-4o-mini\",\r\n        ),\r\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n    def process_text(self,text: str, transformer: LLMGraphTransformer) -> List[GraphDocument]:\r\n        doc = Document(page_content=text)\r\n        return transformer.convert_to_graph_documents([doc])\r\n    def build_output(self) -> Data:\r\n        schema = json.loads(self.schema_text)\r\n        llm = ChatOpenAI(\r\n            temperature=0,\r\n            model_name=self.openai_model,\r\n            api_key=self.openai_api_key\r\n        )\r\n        llm_transformer = LLMGraphTransformer(\r\n            llm = llm,\r\n            allowed_nodes=schema.get(\"allowed_nodes\", []),  \r\n            allowed_relationships=schema.get(\"allowed_relationships\", []),  \r\n            prompt=schema.get(\"prompt\", None),  \r\n            strict_mode=schema.get(\"strict_mode\", True),  \r\n            node_properties=schema.get(\"node_properties\", True),  \r\n            relationship_properties=schema.get(\"relationship_properties\", True) \r\n        )\r\n        result = self.process_text(self.input_text, llm_transformer)\r\n        self.status = result\r\n        return result\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "input_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "input_text",
                  "value": "",
                  "display_name": "Input Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "openai_api_key": {
                  "load_from_db": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_api_key",
                  "value": "",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "password": true,
                  "type": "str",
                  "_input_type": "SecretStrInput"
                },
                "openai_model": {
                  "trace_as_metadata": true,
                  "options": [
                    "gpt-4o-mini",
                    "gpt-4o",
                    "gpt-4-turbo",
                    "gpt-3.5-turbo"
                  ],
                  "combobox": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "openai_model",
                  "value": "gpt-4o-mini",
                  "display_name": "Graph Transformation Model",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "DropdownInput"
                },
                "schema_text": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "schema_text",
                  "value": "{\n    \"allowed_nodes\": [],\n    \"allowed_relationships\": [],\n    \"prompt\": null,\n    \"strict_mode\": true,\n    \"node_properties\": true,\n    \"relationship_properties\": true\n}",
                  "display_name": "Schema Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Transform any text input into graph. Input: text, schema in JSON to control",
              "icon": "custom_components",
              "base_classes": [
                "Data"
              ],
              "display_name": "Graph Transfomrer",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Data"
                  ],
                  "selected": "Data",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "input_text",
                "schema_text",
                "openai_model",
                "openai_api_key"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17",
              "official": false
            },
            "id": "GraphTransformer-bCo9N"
          },
          "selected": false,
          "width": 384,
          "height": 582,
          "positionAbsolute": {
            "x": -1785.9780419973927,
            "y": 1078.0412251422817
          },
          "dragging": false
        },
        {
          "id": "GraphSearchCypher-VxMoO",
          "type": "genericNode",
          "position": {
            "x": -1247.2169451753498,
            "y": 1511.5292175554393
          },
          "data": {
            "type": "GraphSearchCypher",
            "node": {
              "template": {
                "_type": "Component",
                "data": {
                  "trace_as_metadata": true,
                  "list": false,
                  "trace_as_input": true,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "data",
                  "value": "",
                  "display_name": "User's query graph data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other",
                  "_input_type": "DataInput"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import MessageTextInput, Output\r\nfrom axiestudio.schema import Data\r\nfrom axiestudio.schema.message import Message\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nclass GraphSearchCypherComponent(Component):\r\n    display_name = \"Graph Search Cypher\"\r\n    description = \"Generate cypher to search nodes in the graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphSearchCypher\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"data\", display_name=\"User's query graph data\"),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Cypher Query\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Message:\r\n        # only generate queries for nodes search\r\n        output_str = \"\"\r\n        documents = self.data\r\n        node_ids =[]\r\n        for document in documents:\r\n            for node in document.nodes:\r\n                node_ids.append(node.id)\r\n        query = f\"\"\"\r\n        UNWIND {node_ids} as node_id\r\n        MATCH (n {{id: node_id}})\r\n        OPTIONAL MATCH (n)-[]-(doc:Document)\r\n        WITH doc, [key IN keys(doc) WHERE NOT key IN ['elementId', 'id', 'embedding']] AS filteredKeys\r\n        RETURN collect(apoc.map.submap(doc, filteredKeys)) AS docAttributes\r\n        \"\"\"\r\n        self.status = query\r\n        return query\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                }
              },
              "description": "Generate cypher to search nodes in the graph",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Search Cypher",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Cypher Query",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "data"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "GraphSearchCypher-VxMoO"
          },
          "selected": false,
          "width": 384,
          "height": 259,
          "dragging": false,
          "positionAbsolute": {
            "x": -1247.2169451753498,
            "y": 1511.5292175554393
          }
        },
        {
          "id": "GraphRetriever-mH1bD",
          "type": "genericNode",
          "position": {
            "x": -612.93405763902,
            "y": 1202.9916700342628
          },
          "data": {
            "type": "GraphRetriever",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "# from axiestudio.field_typing import Data\r\nfrom axiestudio.io import Output, DataInput, IntInput, MessageTextInput, DropdownInput, SecretStrInput\r\nfrom axiestudio.schema.message import Message\r\nfrom axiestudio.custom import Component\r\nfrom langchain_community.graphs.graph_document import GraphDocument\r\nfrom neo4j import GraphDatabase\r\n\r\nimport json\r\nclass GraphRetriever(Component):\r\n\r\n    \r\n    display_name = \"Graph Retriever\"\r\n    description = \"Execute cypher query to retrieve from knowledge graph\"\r\n    icon = \"custom_components\"\r\n    name = \"GraphRetriever\"\r\n\r\n    inputs = [\r\n        MessageTextInput(name=\"cypher_query\", \r\n                         display_name=\"Cypher Query\",\r\n                         info=\"Cypher query\"),\r\n        MessageTextInput(name=\"neo4j_credentials\", display_name=\"Neo4j Credentials\")\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n       \r\n                \r\n    def build_output(self) -> Message:\r\n        credentials = json.loads(self.neo4j_credentials)\r\n        driver = GraphDatabase.driver(credentials[\"url\"], auth=(credentials[\"username\"], credentials[\"password\"]))\r\n        \r\n        results = None\r\n        with driver.session() as session:\r\n            results = session.run(self.cypher_query)\r\n            data = json.dumps([doc[\"docAttributes\"] for doc in results.data()])\r\n\r\n        driver.close()\r\n        self.status = data  # Update status with extracted data\r\n        return Message(text=data)\r\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "cypher_query": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "cypher_query",
                  "value": "",
                  "display_name": "Cypher Query",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "Cypher query",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "neo4j_credentials": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "neo4j_credentials",
                  "value": "",
                  "display_name": "Neo4j Credentials",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Execute cypher query to retrieve from knowledge graph",
              "icon": "custom_components",
              "base_classes": [
                "Message"
              ],
              "display_name": "Graph Retriever",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "output",
                  "display_name": "Output",
                  "method": "build_output",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "cypher_query",
                "neo4j_credentials"
              ],
              "beta": false,
              "edited": true,
              "lf_version": "1.0.17"
            },
            "id": "GraphRetriever-mH1bD"
          },
          "selected": false,
          "width": 384,
          "height": 411,
          "positionAbsolute": {
            "x": -612.93405763902,
            "y": 1202.9916700342628
          },
          "dragging": false
        },
        {
          "id": "CombineText-dS7aS",
          "type": "genericNode",
          "position": {
            "x": -9.447721501909768,
            "y": 545.0194787654442
          },
          "data": {
            "type": "CombineText",
            "node": {
              "template": {
                "_type": "Component",
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio.custom import Component\nfrom axiestudio.io import MessageTextInput, Output\nfrom axiestudio.schema.message import Message\n\n\nclass CombineTextComponent(Component):\n    display_name = \"Combine Text\"\n    description = \"Concatenate two text sources into a single text chunk using a specified delimiter.\"\n    icon = \"merge\"\n    name = \"CombineText\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"text1\",\n            display_name=\"First Text\",\n            info=\"The first text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"text2\",\n            display_name=\"Second Text\",\n            info=\"The second text input to concatenate.\",\n        ),\n        MessageTextInput(\n            name=\"delimiter\",\n            display_name=\"Delimiter\",\n            info=\"A string used to separate the two text inputs. Defaults to a whitespace.\",\n            value=\" \",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Combined Text\", name=\"combined_text\", method=\"combine_texts\"),\n    ]\n\n    def combine_texts(self) -> Message:\n        combined = self.delimiter.join([self.text1, self.text2])\n        self.status = combined\n        return Message(text=combined)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "delimiter": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "delimiter",
                  "value": " \\n",
                  "display_name": "Delimiter",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "A string used to separate the two text inputs. Defaults to a whitespace.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text1": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text1",
                  "value": "",
                  "display_name": "First Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The first text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                },
                "text2": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "name": "text2",
                  "value": "",
                  "display_name": "Second Text",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "The second text input to concatenate.",
                  "title_case": false,
                  "type": "str",
                  "_input_type": "MessageTextInput"
                }
              },
              "description": "Concatenate two text sources into a single text chunk using a specified delimiter.",
              "icon": "merge",
              "base_classes": [
                "Message"
              ],
              "display_name": "Combine Text",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "combined_text",
                  "display_name": "Combined Text",
                  "method": "combine_texts",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "text1",
                "text2",
                "delimiter"
              ],
              "beta": false,
              "edited": false,
              "lf_version": "1.0.17"
            },
            "id": "CombineText-dS7aS"
          },
          "selected": false,
          "width": 384,
          "height": 497,
          "positionAbsolute": {
            "x": -9.447721501909768,
            "y": 545.0194787654442
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "Prompt-uir6X",
          "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-uir6Xœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
          "target": "OpenAIModel-R02xB",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-R02xBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "OpenAIModel-R02xB",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Prompt",
              "id": "Prompt-uir6X",
              "name": "prompt",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Prompt-uir6X{œdataTypeœ:œPromptœ,œidœ:œPrompt-uir6Xœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-R02xB{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-R02xBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "OpenAIModel-R02xB",
          "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-R02xBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "ChatOutput-4hTcP",
          "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4hTcPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_value",
              "id": "ChatOutput-4hTcP",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "OpenAIModel",
              "id": "OpenAIModel-R02xB",
              "name": "text_output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-OpenAIModel-R02xB{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-R02xBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-4hTcP{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4hTcPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphRAGChatAPIComponent-d0zgt",
          "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-uir6X",
          "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "question",
              "id": "Prompt-uir6X",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRAGChatAPIComponent",
              "id": "GraphRAGChatAPIComponent-d0zgt",
              "name": "query",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œquestionœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-NuezZ",
          "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
          "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-NuezZ",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-NuezZ{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œfieldNameœ:œneo4j_credentialsœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphRAGChatAPIComponent-d0zgt",
          "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
          "target": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
          "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "user_query",
              "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRAGChatAPIComponent",
              "id": "GraphRAGChatAPIComponent-d0zgt",
              "name": "query",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œfieldNameœ:œuser_queryœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": "",
          "selected": false
        },
        {
          "source": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
          "sourceHandle": "{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
          "target": "VectorRetrieverParserComponent-3mPsc",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "VectorRetrieverParserComponent-3mPsc",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "KnowledgeGraphIndexKRetrieverComponent",
              "id": "KnowledgeGraphIndexKRetrieverComponent-KXmCt",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-KnowledgeGraphIndexKRetrieverComponent-KXmCt{œdataTypeœ:œKnowledgeGraphIndexKRetrieverComponentœ,œidœ:œKnowledgeGraphIndexKRetrieverComponent-KXmCtœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-VectorRetrieverParserComponent-3mPsc{œfieldNameœ:œdataœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "GraphRAGChatAPIComponent-d0zgt",
          "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œsession_idœ,œoutput_typesœ:[œMessageœ]}",
          "target": "converstaion_history_retriever-EwxtO",
          "targetHandle": "{œfieldNameœ:œsession_idœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "session_id",
              "id": "converstaion_history_retriever-EwxtO",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRAGChatAPIComponent",
              "id": "GraphRAGChatAPIComponent-d0zgt",
              "name": "session_id",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œsession_idœ,œoutput_typesœ:[œMessageœ]}-converstaion_history_retriever-EwxtO{œfieldNameœ:œsession_idœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "converstaion_history_retriever-EwxtO",
          "sourceHandle": "{œdataTypeœ:œconverstaion_history_retrieverœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}",
          "target": "ConversationHistoryParser-RZtMc",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œConversationHistoryParser-RZtMcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "ConversationHistoryParser-RZtMc",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "converstaion_history_retriever",
              "id": "converstaion_history_retriever-EwxtO",
              "name": "api_run_model",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-converstaion_history_retriever-EwxtO{œdataTypeœ:œconverstaion_history_retrieverœ,œidœ:œconverstaion_history_retriever-EwxtOœ,œnameœ:œapi_run_modelœ,œoutput_typesœ:[œDataœ]}-ConversationHistoryParser-RZtMc{œfieldNameœ:œdataœ,œidœ:œConversationHistoryParser-RZtMcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "ConversationHistoryParser-RZtMc",
          "sourceHandle": "{œdataTypeœ:œConversationHistoryParserœ,œidœ:œConversationHistoryParser-RZtMcœ,œnameœ:œParsed Conversationœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-uir6X",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "Prompt-uir6X",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "ConversationHistoryParser",
              "id": "ConversationHistoryParser-RZtMc",
              "name": "Parsed Conversation",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-ConversationHistoryParser-RZtMc{œdataTypeœ:œConversationHistoryParserœ,œidœ:œConversationHistoryParser-RZtMcœ,œnameœ:œParsed Conversationœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œmemoryœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphTransformer-bCo9N",
          "sourceHandle": "{œdataTypeœ:œGraphTransformerœ,œidœ:œGraphTransformer-bCo9Nœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
          "target": "GraphSearchCypher-VxMoO",
          "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œGraphSearchCypher-VxMoOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "data": {
            "targetHandle": {
              "fieldName": "data",
              "id": "GraphSearchCypher-VxMoO",
              "inputTypes": [
                "Data"
              ],
              "type": "other"
            },
            "sourceHandle": {
              "dataType": "GraphTransformer",
              "id": "GraphTransformer-bCo9N",
              "name": "output",
              "output_types": [
                "Data"
              ]
            }
          },
          "id": "reactflow__edge-GraphTransformer-bCo9N{œdataTypeœ:œGraphTransformerœ,œidœ:œGraphTransformer-bCo9Nœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-GraphSearchCypher-VxMoO{œfieldNameœ:œdataœ,œidœ:œGraphSearchCypher-VxMoOœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
          "className": ""
        },
        {
          "source": "GraphSearchCypher-VxMoO",
          "sourceHandle": "{œdataTypeœ:œGraphSearchCypherœ,œidœ:œGraphSearchCypher-VxMoOœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "GraphRetriever-mH1bD",
          "targetHandle": "{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "cypher_query",
              "id": "GraphRetriever-mH1bD",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphSearchCypher",
              "id": "GraphSearchCypher-VxMoO",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphSearchCypher-VxMoO{œdataTypeœ:œGraphSearchCypherœ,œidœ:œGraphSearchCypher-VxMoOœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-mH1bD{œfieldNameœ:œcypher_queryœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "Neo4jCredentialLoader-NuezZ",
          "sourceHandle": "{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}",
          "target": "GraphRetriever-mH1bD",
          "targetHandle": "{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "neo4j_credentials",
              "id": "GraphRetriever-mH1bD",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "Neo4jCredentialLoader",
              "id": "Neo4jCredentialLoader-NuezZ",
              "name": "credentials",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-Neo4jCredentialLoader-NuezZ{œdataTypeœ:œNeo4jCredentialLoaderœ,œidœ:œNeo4jCredentialLoader-NuezZœ,œnameœ:œcredentialsœ,œoutput_typesœ:[œMessageœ]}-GraphRetriever-mH1bD{œfieldNameœ:œneo4j_credentialsœ,œidœ:œGraphRetriever-mH1bDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphRAGChatAPIComponent-d0zgt",
          "sourceHandle": "{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}",
          "target": "GraphTransformer-bCo9N",
          "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œGraphTransformer-bCo9Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "input_text",
              "id": "GraphTransformer-bCo9N",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRAGChatAPIComponent",
              "id": "GraphRAGChatAPIComponent-d0zgt",
              "name": "query",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRAGChatAPIComponent-d0zgt{œdataTypeœ:œGraphRAGChatAPIComponentœ,œidœ:œGraphRAGChatAPIComponent-d0zgtœ,œnameœ:œqueryœ,œoutput_typesœ:[œMessageœ]}-GraphTransformer-bCo9N{œfieldNameœ:œinput_textœ,œidœ:œGraphTransformer-bCo9Nœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "VectorRetrieverParserComponent-3mPsc",
          "sourceHandle": "{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CombineText-dS7aS",
          "targetHandle": "{œfieldNameœ:œtext1œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "text1",
              "id": "CombineText-dS7aS",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "VectorRetrieverParserComponent",
              "id": "VectorRetrieverParserComponent-3mPsc",
              "name": "text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-VectorRetrieverParserComponent-3mPsc{œdataTypeœ:œVectorRetrieverParserComponentœ,œidœ:œVectorRetrieverParserComponent-3mPscœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CombineText-dS7aS{œfieldNameœ:œtext1œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "GraphRetriever-mH1bD",
          "sourceHandle": "{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-mH1bDœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
          "target": "CombineText-dS7aS",
          "targetHandle": "{œfieldNameœ:œtext2œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "text2",
              "id": "CombineText-dS7aS",
              "inputTypes": [
                "Message"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "GraphRetriever",
              "id": "GraphRetriever-mH1bD",
              "name": "output",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-GraphRetriever-mH1bD{œdataTypeœ:œGraphRetrieverœ,œidœ:œGraphRetriever-mH1bDœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-CombineText-dS7aS{œfieldNameœ:œtext2œ,œidœ:œCombineText-dS7aSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
          "className": ""
        },
        {
          "source": "CombineText-dS7aS",
          "sourceHandle": "{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-dS7aSœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}",
          "target": "Prompt-uir6X",
          "targetHandle": "{œfieldNameœ:œcontextœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "context",
              "id": "Prompt-uir6X",
              "inputTypes": [
                "Message",
                "Text"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "dataType": "CombineText",
              "id": "CombineText-dS7aS",
              "name": "combined_text",
              "output_types": [
                "Message"
              ]
            }
          },
          "id": "reactflow__edge-CombineText-dS7aS{œdataTypeœ:œCombineTextœ,œidœ:œCombineText-dS7aSœ,œnameœ:œcombined_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-uir6X{œfieldNameœ:œcontextœ,œidœ:œPrompt-uir6Xœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
          "className": ""
        }
      ],
      "viewport": {
        "x": 1443.039268658152,
        "y": -59.111418878404265,
        "zoom": 0.5113339656472234
      }
    },
    "date_created": "2024-09-26T03:45:12.556Z",
    "date_updated": "2024-10-01T08:45:09.883Z",
    "status": "Public",
    "sort": null,
    "user_updated": "6decf44a-a4d8-438a-92d3-df07d49ad213",
    "user_created": {
      "username": "jingconsult",
      "first_name": "Jing",
      "last_name": "Consulting",
      "id": "6decf44a-a4d8-438a-92d3-df07d49ad213"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:06.371Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 134,
    "converter_version": "1.0.0"
  }
}