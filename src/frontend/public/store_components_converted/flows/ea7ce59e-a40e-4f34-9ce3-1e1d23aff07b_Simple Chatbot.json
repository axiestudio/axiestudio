{
  "id": "ea7ce59e-a40e-4f34-9ce3-1e1d23aff07b",
  "name": "Simple Chatbot",
  "description": "Conversational Cartography Unlocked. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "langflow-store-user",
    "first_name": "Kok Sheng",
    "last_name": "Ang",
    "id": "f825e672-2255-4825-96b9-51fb9830c984",
    "full_name": "Kok Sheng Ang"
  },
  "store_url": "https://www.langflow.store/store/component/ea7ce59e-a40e-4f34-9ce3-1e1d23aff07b",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-05-13T06:07:49.726Z",
    "updated": "2024-05-13T06:07:49.945Z",
    "downloaded": "2025-08-19T17:50:05.268Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.6.19",
    "private": false,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "ConversationChain-5K138",
        "type": "genericNode",
        "position": {
          "x": 431.6497803216697,
          "y": -1.370753771282807
        },
        "data": {
          "type": "ConversationChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "Memory to load context from. If none is provided, a ConversationBufferMemory will be used.",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio import CustomComponent\nfrom langchain.chains import ConversationChain\nfrom typing import Optional, Union, Callable\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Chain\n\n\nclass ConversationChainComponent(CustomComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\n                \"display_name\": \"Memory\",\n                \"info\": \"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        if memory is None:\n            return ConversationChain(llm=llm)\n        return ConversationChain(llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to have a conversation and load context from memory.",
            "base_classes": [
              "Chain",
              "Callable"
            ],
            "display_name": "ConversationChain",
            "documentation": "",
            "custom_fields": {
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "ConversationChain-5K138"
        },
        "selected": false,
        "width": 384,
        "height": 397
      },
      {
        "id": "ConversationBufferMemory-Gg3jH",
        "type": "genericNode",
        "position": {
          "x": -222,
          "y": 544.3908331831402
        },
        "data": {
          "type": "ConversationBufferMemory",
          "node": {
            "template": {
              "chat_memory": {
                "type": "BaseChatMessageHistory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "chat_memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "ai_prefix": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": "AI",
                "fileTypes": [],
                "password": false,
                "name": "ai_prefix",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "human_prefix": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": "Human",
                "fileTypes": [],
                "password": false,
                "name": "human_prefix",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "input_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Input when more than one variable is available.",
                "title_case": true
              },
              "memory_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "history",
                "fileTypes": [],
                "password": false,
                "name": "memory_key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "output_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "output_key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)",
                "title_case": true
              },
              "return_messages": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "return_messages",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "_type": "ConversationBufferMemory"
            },
            "description": "Buffer for storing conversation memory.",
            "base_classes": [
              "ConversationBufferMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "display_name": "ConversationBufferMemory",
            "documentation": "https://python.langchain.com/docs/modules/memory/how_to/buffer",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "ConversationBufferMemory-Gg3jH"
        },
        "selected": false,
        "width": 384,
        "height": 602
      },
      {
        "id": "AzureChatOpenAIDemoComponent-NMTSm",
        "type": "genericNode",
        "position": {
          "x": -236.91973572933327,
          "y": -40.87036833826655
        },
        "data": {
          "type": "AzureChatOpenAIDemoComponent",
          "node": {
            "template": {
              "azure_endpoint": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "https://btazureopenaipoc.openai.azure.com",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "azure_endpoint",
                "display_name": "Azure endpoint",
                "advanced": true,
                "dynamic": false,
                "info": "Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "\"\"\"\nAzure Chat Open AI with default settings preloaded. \nFor more informatation, visit https://docs.axiestudio.org/guidelines/custom-component\n\"\"\"\n\n# Standard library imports\nimport os\nfrom typing import Dict\n\n# Third-party library imports\nfrom langchain.llms.base import BaseLanguageModel\nfrom langchain_openai import AzureChatOpenAI\nfrom axiestudio import CustomComponent\n\n\nclass AzureChatOpenAIDemoComponent(CustomComponent):\n    \"\"\"\n    Azure ChatOpenAI Components that are preloaded with credentials.\n    Source code taken from: https://github.com/logspace-ai/axiestudio/discussions/1221\n\n    Returns:\n        A dictionary with the configuration fields for the component.\n        The dictionary will be passed as a parameter in the build() method.\n    \"\"\"\n\n    display_name: str = \"Azure Chat OpenAI Demo Component\"\n    description: str = \"LLM model from Azure ChatOpenAI.\"\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-35-turbo\",\n        \"gpt-35-turbo-16k\",\n        \"gpt-35-turbo-instruct\",\n    ]\n\n    def build_config(self) -> Dict:\n        \"\"\"\n        The build config defines configuration fields for the component\n\n        Returns:\n            A dictionary with the configuration fields for the AzureChatOpenAI.\n            The azure_endpoint , deployment_name, & openai_api_key is prefilled automatically and hidden from the user\n            The dictionary will be passed as a parameter in the build() method.\n        \"\"\"\n\n        return {\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"value\": self.AZURE_OPENAI_MODELS[0],\n                \"options\": self.AZURE_OPENAI_MODELS,\n                \"required\": True,\n            },\n            \"azure_endpoint\": {\n                \"display_name\": \"Azure endpoint\",\n                \"required\": False,\n                \"advanced\": True,\n                \"info\": \"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\n                \"value\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n            },\n            \"deployment_name\": {\n                \"display_name\": \"Deployment Name\",\n                \"required\": True,\n                \"value\": os.getenv(\"DEPLOYMENT_NAME\"),\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"value\": \"2023-05-15\",\n                \"required\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"API Key\",\n                \"required\": False,\n                \"password\": True,\n                \"advanced\": True,\n                \"value\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n                \"field_type\": \"float\",\n                \"required\": False,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max tokens\",\n                \"value\": 1000,\n                \"required\": False,\n                \"field_type\": \"int\",\n                \"advanced\": True,\n            },\n            \"streaming\": {\n                \"display_name\": \"Streaming\",\n                \"field_type\": \"bool\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model_name: str,\n        azure_endpoint: str,\n        deployment_name: str,\n        openai_api_key: str,\n        openai_api_version: str = \"2023-05-15\",\n        temperature: float = 0.7,\n        max_tokens: int = 1000,\n        streaming: bool = False,\n    ) -> BaseLanguageModel:\n        \"\"\"\n        The build method is where the component's logic is implemented.\n\n        Args:\n            model_name: The name of the model to use.\n            azure_endpoint: Your Azure endpoint, including the resource. Automatically inferred from env var AZURE_OPENAI_ENDPOINT if not provided.\n            deployment_name: The name of the deployment to use.\n            openai_api_key: Your OpenAI API key. Automatically inferred from env var OPENAI_API_KEY if not provided.\n            openai_api_version: The OpenAI API version to use.\n            temperature: The temperature to use.\n            max_tokens: The maximum number of tokens to generate.\n            streaming: Whether to stream the response.\n\n        Returns:\n            A BaseLanguageModel object.\n            For more information, visit https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n        \"\"\"\n\n        return AzureChatOpenAI(\n            model_name=model_name,\n            azure_endpoint=azure_endpoint,\n            deployment_name=deployment_name,\n            openai_api_key=openai_api_key,\n            openai_api_version=openai_api_version,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            streaming=streaming,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "deployment_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "gpt-35-turbo",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "deployment_name",
                "display_name": "Deployment Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 1000,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max tokens",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "gpt-35-turbo",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-35-turbo",
                  "gpt-35-turbo-16k",
                  "gpt-35-turbo-instruct"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "openai_api_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "API Key",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "openai_api_version": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "2023-05-15",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_version",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "streaming": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "streaming",
                "display_name": "Streaming",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": 0.7,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "LLM model from Azure ChatOpenAI.",
            "base_classes": [
              "BaseLanguageModel"
            ],
            "display_name": "Azure Chat OpenAI Demo Component",
            "documentation": "",
            "custom_fields": {
              "model_name": null,
              "azure_endpoint": null,
              "deployment_name": null,
              "openai_api_key": null,
              "openai_api_version": null,
              "temperature": null,
              "max_tokens": null,
              "streaming": null
            },
            "output_types": [
              "BaseLanguageModel"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "AzureChatOpenAIDemoComponent-NMTSm"
        },
        "selected": false,
        "width": 384,
        "height": 552
      }
    ],
    "edges": [
      {
        "source": "ConversationBufferMemory-Gg3jH",
        "target": "ConversationChain-5K138",
        "sourceHandle": "{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Gg3jHœ}",
        "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
        "id": "reactflow__edge-ConversationBufferMemory-Gg3jH{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Gg3jHœ}-ConversationChain-5K138{œfieldNameœ:œmemoryœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "ConversationChain-5K138",
            "inputTypes": null,
            "type": "BaseMemory"
          },
          "sourceHandle": {
            "baseClasses": [
              "ConversationBufferMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "dataType": "ConversationBufferMemory",
            "id": "ConversationBufferMemory-Gg3jH"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "selected": false
      },
      {
        "source": "AzureChatOpenAIDemoComponent-NMTSm",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œAzureChatOpenAIDemoComponentœ,œidœ:œAzureChatOpenAIDemoComponent-NMTSmœ}",
        "target": "ConversationChain-5K138",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationChain-5K138",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel"
            ],
            "dataType": "AzureChatOpenAIDemoComponent",
            "id": "AzureChatOpenAIDemoComponent-NMTSm"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-AzureChatOpenAIDemoComponent-NMTSm{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œAzureChatOpenAIDemoComponentœ,œidœ:œAzureChatOpenAIDemoComponent-NMTSmœ}-ConversationChain-5K138{œfieldNameœ:œllmœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      }
    ],
    "viewport": {
      "x": 517.2120717598397,
      "y": 176.32261399800421,
      "zoom": 0.7901773460890451
    }
  },
  "metadata": {
    "ConversationChain": {
      "count": 1
    },
    "ConversationBufferMemory": {
      "count": 1
    },
    "AzureChatOpenAIDemoComponent": {
      "count": 1
    },
    "total": 3
  },
  "original": {
    "id": "ea7ce59e-a40e-4f34-9ce3-1e1d23aff07b",
    "name": "Simple Chatbot",
    "description": "Conversational Cartography Unlocked.",
    "is_component": false,
    "liked_by_count": "13",
    "downloads_count": "229",
    "metadata": {
      "ConversationChain": {
        "count": 1
      },
      "ConversationBufferMemory": {
        "count": 1
      },
      "AzureChatOpenAIDemoComponent": {
        "count": 1
      },
      "total": 3
    },
    "last_tested_version": "0.6.19",
    "private": false,
    "data": {
      "nodes": [
        {
          "id": "ConversationChain-5K138",
          "type": "genericNode",
          "position": {
            "x": 431.6497803216697,
            "y": -1.370753771282807
          },
          "data": {
            "type": "ConversationChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "Memory to load context from. If none is provided, a ConversationBufferMemory will be used.",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio import CustomComponent\nfrom langchain.chains import ConversationChain\nfrom typing import Optional, Union, Callable\nfrom axiestudio.field_typing import BaseLanguageModel, BaseMemory, Chain\n\n\nclass ConversationChainComponent(CustomComponent):\n    display_name = \"ConversationChain\"\n    description = \"Chain to have a conversation and load context from memory.\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\n                \"display_name\": \"Memory\",\n                \"info\": \"Memory to load context from. If none is provided, a ConversationBufferMemory will be used.\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable]:\n        if memory is None:\n            return ConversationChain(llm=llm)\n        return ConversationChain(llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to have a conversation and load context from memory.",
              "base_classes": [
                "Chain",
                "Callable"
              ],
              "display_name": "ConversationChain",
              "documentation": "",
              "custom_fields": {
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "ConversationChain-5K138"
          },
          "selected": false,
          "width": 384,
          "height": 397
        },
        {
          "id": "ConversationBufferMemory-Gg3jH",
          "type": "genericNode",
          "position": {
            "x": -222,
            "y": 544.3908331831402
          },
          "data": {
            "type": "ConversationBufferMemory",
            "node": {
              "template": {
                "chat_memory": {
                  "type": "BaseChatMessageHistory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "chat_memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "ai_prefix": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": "AI",
                  "fileTypes": [],
                  "password": false,
                  "name": "ai_prefix",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "human_prefix": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": "Human",
                  "fileTypes": [],
                  "password": false,
                  "name": "human_prefix",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "input_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The variable to be used as Chat Input when more than one variable is available.",
                  "title_case": true
                },
                "memory_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "history",
                  "fileTypes": [],
                  "password": false,
                  "name": "memory_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "output_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "output_key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)",
                  "title_case": true
                },
                "return_messages": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "return_messages",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "_type": "ConversationBufferMemory"
              },
              "description": "Buffer for storing conversation memory.",
              "base_classes": [
                "ConversationBufferMemory",
                "BaseChatMemory",
                "BaseMemory"
              ],
              "display_name": "ConversationBufferMemory",
              "documentation": "https://python.langchain.com/docs/modules/memory/how_to/buffer",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "ConversationBufferMemory-Gg3jH"
          },
          "selected": false,
          "width": 384,
          "height": 602
        },
        {
          "id": "AzureChatOpenAIDemoComponent-NMTSm",
          "type": "genericNode",
          "position": {
            "x": -236.91973572933327,
            "y": -40.87036833826655
          },
          "data": {
            "type": "AzureChatOpenAIDemoComponent",
            "node": {
              "template": {
                "azure_endpoint": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "https://btazureopenaipoc.openai.azure.com",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "azure_endpoint",
                  "display_name": "Azure endpoint",
                  "advanced": true,
                  "dynamic": false,
                  "info": "Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "\"\"\"\nAzure Chat Open AI with default settings preloaded. \nFor more informatation, visit https://docs.axiestudio.org/guidelines/custom-component\n\"\"\"\n\n# Standard library imports\nimport os\nfrom typing import Dict\n\n# Third-party library imports\nfrom langchain.llms.base import BaseLanguageModel\nfrom langchain_openai import AzureChatOpenAI\nfrom axiestudio import CustomComponent\n\n\nclass AzureChatOpenAIDemoComponent(CustomComponent):\n    \"\"\"\n    Azure ChatOpenAI Components that are preloaded with credentials.\n    Source code taken from: https://github.com/logspace-ai/axiestudio/discussions/1221\n\n    Returns:\n        A dictionary with the configuration fields for the component.\n        The dictionary will be passed as a parameter in the build() method.\n    \"\"\"\n\n    display_name: str = \"Azure Chat OpenAI Demo Component\"\n    description: str = \"LLM model from Azure ChatOpenAI.\"\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-35-turbo\",\n        \"gpt-35-turbo-16k\",\n        \"gpt-35-turbo-instruct\",\n    ]\n\n    def build_config(self) -> Dict:\n        \"\"\"\n        The build config defines configuration fields for the component\n\n        Returns:\n            A dictionary with the configuration fields for the AzureChatOpenAI.\n            The azure_endpoint , deployment_name, & openai_api_key is prefilled automatically and hidden from the user\n            The dictionary will be passed as a parameter in the build() method.\n        \"\"\"\n\n        return {\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"value\": self.AZURE_OPENAI_MODELS[0],\n                \"options\": self.AZURE_OPENAI_MODELS,\n                \"required\": True,\n            },\n            \"azure_endpoint\": {\n                \"display_name\": \"Azure endpoint\",\n                \"required\": False,\n                \"advanced\": True,\n                \"info\": \"Your Azure endpoint, including the resource.. Example: `https://example-resource.azure.openai.com/`\",\n                \"value\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n            },\n            \"deployment_name\": {\n                \"display_name\": \"Deployment Name\",\n                \"required\": True,\n                \"value\": os.getenv(\"DEPLOYMENT_NAME\"),\n            },\n            \"openai_api_version\": {\n                \"display_name\": \"OpenAI API Version\",\n                \"value\": \"2023-05-15\",\n                \"required\": True,\n                \"advanced\": True,\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"API Key\",\n                \"required\": False,\n                \"password\": True,\n                \"advanced\": True,\n                \"value\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.7,\n                \"field_type\": \"float\",\n                \"required\": False,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max tokens\",\n                \"value\": 1000,\n                \"required\": False,\n                \"field_type\": \"int\",\n                \"advanced\": True,\n            },\n            \"streaming\": {\n                \"display_name\": \"Streaming\",\n                \"field_type\": \"bool\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model_name: str,\n        azure_endpoint: str,\n        deployment_name: str,\n        openai_api_key: str,\n        openai_api_version: str = \"2023-05-15\",\n        temperature: float = 0.7,\n        max_tokens: int = 1000,\n        streaming: bool = False,\n    ) -> BaseLanguageModel:\n        \"\"\"\n        The build method is where the component's logic is implemented.\n\n        Args:\n            model_name: The name of the model to use.\n            azure_endpoint: Your Azure endpoint, including the resource. Automatically inferred from env var AZURE_OPENAI_ENDPOINT if not provided.\n            deployment_name: The name of the deployment to use.\n            openai_api_key: Your OpenAI API key. Automatically inferred from env var OPENAI_API_KEY if not provided.\n            openai_api_version: The OpenAI API version to use.\n            temperature: The temperature to use.\n            max_tokens: The maximum number of tokens to generate.\n            streaming: Whether to stream the response.\n\n        Returns:\n            A BaseLanguageModel object.\n            For more information, visit https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n        \"\"\"\n\n        return AzureChatOpenAI(\n            model_name=model_name,\n            azure_endpoint=azure_endpoint,\n            deployment_name=deployment_name,\n            openai_api_key=openai_api_key,\n            openai_api_version=openai_api_version,\n            temperature=temperature,\n            max_tokens=max_tokens,\n            streaming=streaming,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "deployment_name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "gpt-35-turbo",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "deployment_name",
                  "display_name": "Deployment Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "max_tokens": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 1000,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_tokens",
                  "display_name": "Max tokens",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "model_name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "gpt-35-turbo",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "gpt-35-turbo",
                    "gpt-35-turbo-16k",
                    "gpt-35-turbo-instruct"
                  ],
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "openai_api_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "openai_api_key",
                  "display_name": "API Key",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "openai_api_version": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "2023-05-15",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "openai_api_version",
                  "display_name": "OpenAI API Version",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "streaming": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "streaming",
                  "display_name": "Streaming",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": 0.7,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "LLM model from Azure ChatOpenAI.",
              "base_classes": [
                "BaseLanguageModel"
              ],
              "display_name": "Azure Chat OpenAI Demo Component",
              "documentation": "",
              "custom_fields": {
                "model_name": null,
                "azure_endpoint": null,
                "deployment_name": null,
                "openai_api_key": null,
                "openai_api_version": null,
                "temperature": null,
                "max_tokens": null,
                "streaming": null
              },
              "output_types": [
                "BaseLanguageModel"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "AzureChatOpenAIDemoComponent-NMTSm"
          },
          "selected": false,
          "width": 384,
          "height": 552
        }
      ],
      "edges": [
        {
          "source": "ConversationBufferMemory-Gg3jH",
          "target": "ConversationChain-5K138",
          "sourceHandle": "{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Gg3jHœ}",
          "targetHandle": "{œfieldNameœ:œmemoryœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
          "id": "reactflow__edge-ConversationBufferMemory-Gg3jH{œbaseClassesœ:[œConversationBufferMemoryœ,œBaseChatMemoryœ,œBaseMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Gg3jHœ}-ConversationChain-5K138{œfieldNameœ:œmemoryœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}",
          "data": {
            "targetHandle": {
              "fieldName": "memory",
              "id": "ConversationChain-5K138",
              "inputTypes": null,
              "type": "BaseMemory"
            },
            "sourceHandle": {
              "baseClasses": [
                "ConversationBufferMemory",
                "BaseChatMemory",
                "BaseMemory"
              ],
              "dataType": "ConversationBufferMemory",
              "id": "ConversationBufferMemory-Gg3jH"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "selected": false
        },
        {
          "source": "AzureChatOpenAIDemoComponent-NMTSm",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œAzureChatOpenAIDemoComponentœ,œidœ:œAzureChatOpenAIDemoComponent-NMTSmœ}",
          "target": "ConversationChain-5K138",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "ConversationChain-5K138",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel"
              ],
              "dataType": "AzureChatOpenAIDemoComponent",
              "id": "AzureChatOpenAIDemoComponent-NMTSm"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-AzureChatOpenAIDemoComponent-NMTSm{œbaseClassesœ:[œBaseLanguageModelœ],œdataTypeœ:œAzureChatOpenAIDemoComponentœ,œidœ:œAzureChatOpenAIDemoComponent-NMTSmœ}-ConversationChain-5K138{œfieldNameœ:œllmœ,œidœ:œConversationChain-5K138œ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        }
      ],
      "viewport": {
        "x": 517.2120717598397,
        "y": 176.32261399800421,
        "zoom": 0.7901773460890451
      }
    },
    "date_created": "2024-05-13T06:07:49.726Z",
    "date_updated": "2024-05-13T06:07:49.945Z",
    "status": "Public",
    "sort": null,
    "user_updated": "f825e672-2255-4825-96b9-51fb9830c984",
    "user_created": {
      "username": "langflow-store-user",
      "first_name": "Kok Sheng",
      "last_name": "Ang",
      "id": "f825e672-2255-4825-96b9-51fb9830c984"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:07.589Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 10,
    "converter_version": "1.0.0"
  }
}