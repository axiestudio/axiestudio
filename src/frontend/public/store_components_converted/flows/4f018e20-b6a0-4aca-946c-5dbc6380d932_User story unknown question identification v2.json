{
  "id": "4f018e20-b6a0-4aca-946c-5dbc6380d932",
  "name": "User story unknown question identification [v2]",
  "description": "Identify an unknowns / outstanding questions that can be detected from the supplied user story  (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "FLOW",
  "is_component": false,
  "author": {
    "username": "wiresky",
    "first_name": "Nguyen",
    "last_name": "Nam",
    "id": "dc599610-3065-4b5b-94ed-de108ec210dd",
    "full_name": "Nguyen Nam"
  },
  "store_url": "https://www.langflow.store/store/component/4f018e20-b6a0-4aca-946c-5dbc6380d932",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-05-06T14:18:14.789Z",
    "updated": "2024-05-07T02:22:15.432Z",
    "downloaded": "2025-08-19T17:50:04.914Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "0.6.18",
    "private": true,
    "status": "Public"
  },
  "data": {
    "nodes": [
      {
        "id": "LLMChain-RxurM",
        "type": "genericNode",
        "position": {
          "x": 843,
          "y": 152.328125
        },
        "data": {
          "type": "LLMChain",
          "node": {
            "template": {
              "llm": {
                "type": "BaseLanguageModel",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "memory": {
                "type": "BaseMemory",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "BasePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "Chain to run queries against LLMs",
            "base_classes": [
              "Chain",
              "Callable",
              "LLMChain",
              "Chain"
            ],
            "display_name": "LLMChain",
            "documentation": "",
            "custom_fields": {
              "prompt": null,
              "llm": null,
              "memory": null
            },
            "output_types": [
              "Chain",
              "Callable",
              "LLMChain"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "LLMChain-RxurM"
        },
        "selected": false,
        "width": 384,
        "height": 424
      },
      {
        "id": "ChatOpenAI-QVz5L",
        "type": "genericNode",
        "position": {
          "x": 114.35117376684252,
          "y": -648.2826353660611
        },
        "data": {
          "type": "ChatOpenAI",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Optional, Union\n\nfrom langchain.llms import BaseLLM\nfrom langchain_community.chat_models.openai import ChatOpenAI\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"field_type\": \"int\",\n                \"advanced\": False,\n                \"required\": False,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"field_type\": \"NestedDict\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"options\": [\n                    \"gpt-4-turbo-preview\",\n                    \"gpt-4-0125-preview\",\n                    \"gpt-4-1106-preview\",\n                    \"gpt-4-vision-preview\",\n                    \"gpt-3.5-turbo-0125\",\n                    \"gpt-3.5-turbo-1106\",\n                ],\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"gpt-4-1106-preview\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> Union[BaseLanguageModel, BaseLLM]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        return ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=openai_api_key,\n            temperature=temperature,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "max_tokens": {
                "type": "int",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "1024",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_kwargs": {
                "type": "NestedDict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": {},
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "model_kwargs",
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "model_name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "value": "gpt-3.5-turbo-0125",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "options": [
                  "gpt-4-turbo-preview",
                  "gpt-4-0125-preview",
                  "gpt-4-1106-preview",
                  "gpt-4-vision-preview",
                  "gpt-3.5-turbo-0125",
                  "gpt-3.5-turbo-1106"
                ],
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "openai_api_base": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "openai_api_base",
                "display_name": "OpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": true
              },
              "openai_api_key": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": true,
                "name": "openai_api_key",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": ""
              },
              "temperature": {
                "type": "float",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "value": "0.2",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "rangeSpec": {
                  "min": -1,
                  "max": 1,
                  "step": 0.1
                },
                "title_case": true
              },
              "_type": "CustomComponent"
            },
            "description": "`OpenAI` Chat large language models API.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "display_name": "ChatOpenAI",
            "documentation": "",
            "custom_fields": {
              "max_tokens": null,
              "model_kwargs": null,
              "model_name": null,
              "openai_api_base": null,
              "openai_api_key": null,
              "temperature": null
            },
            "output_types": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "field_formatters": {},
            "beta": true
          },
          "id": "ChatOpenAI-QVz5L"
        },
        "selected": false,
        "width": 384,
        "height": 727,
        "dragging": false,
        "positionAbsolute": {
          "x": 114.35117376684252,
          "y": -648.2826353660611
        }
      },
      {
        "id": "ChatPromptTemplate-yFyBU",
        "type": "genericNode",
        "position": {
          "x": 278.3771975962494,
          "y": 370.60084381245076
        },
        "data": {
          "type": "ChatPromptTemplate",
          "node": {
            "template": {
              "messages": {
                "type": "BaseMessagePromptTemplate",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "messages",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "output_parser": {
                "type": "BaseOutputParser",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "output_parser",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_types": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_types",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "input_variables": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "input_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "metadata": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "metadata",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "name": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "name",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "partial_variables": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "partial_variables",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "tags": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": true,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "tags",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "validate_template": {
                "type": "bool",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "value": false,
                "fileTypes": [],
                "password": false,
                "name": "validate_template",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "ChatPromptTemplate"
            },
            "description": "Prompt template for chat models.",
            "base_classes": [
              "ChatPromptTemplate",
              "BaseChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "display_name": "ChatPromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {},
            "output_types": [],
            "field_formatters": {},
            "beta": false
          },
          "id": "ChatPromptTemplate-yFyBU"
        },
        "selected": false,
        "width": 384,
        "height": 242,
        "positionAbsolute": {
          "x": 278.3771975962494,
          "y": 370.60084381245076
        },
        "dragging": false
      },
      {
        "id": "SystemMessagePromptTemplate-36J1c",
        "type": "genericNode",
        "position": {
          "x": -311.23654677629554,
          "y": 85.64612930849594
        },
        "data": {
          "type": "SystemMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": true,
                "value": "## Instructions\n{Instructions}\n\n## EXAMPLES:\n\n{Examples}",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "SystemMessagePromptTemplate",
              "Instructions": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "Instructions",
                "display_name": "Instructions",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "Examples": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "Examples",
                "display_name": "Examples",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "System message prompt template.",
            "icon": null,
            "base_classes": [
              "_StringImageMessagePromptTemplate",
              "SystemMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "SystemMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {
              "": [
                "Instructions",
                "Examples"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "SystemMessagePromptTemplate-36J1c",
          "description": "System message prompt template.",
          "display_name": "SystemMessagePromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 467,
        "positionAbsolute": {
          "x": -311.23654677629554,
          "y": 85.64612930849594
        },
        "dragging": false
      },
      {
        "id": "HumanMessagePromptTemplate-OLdnC",
        "type": "genericNode",
        "position": {
          "x": -276.37506574655634,
          "y": 687.3856062131241
        },
        "data": {
          "type": "HumanMessagePromptTemplate",
          "node": {
            "template": {
              "additional_kwargs": {
                "type": "dict",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": false,
                "multiline": false,
                "fileTypes": [],
                "password": false,
                "name": "additional_kwargs",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt": {
                "type": "prompt",
                "required": true,
                "placeholder": "",
                "list": true,
                "show": true,
                "multiline": true,
                "value": "#### CONTEXT\n{input_context}\n\n#### INPUT\n{input_title}",
                "fileTypes": [],
                "password": false,
                "name": "prompt",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "_type": "HumanMessagePromptTemplate",
              "input_context": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "The Preferences Manager must support role based access\nThe Preferences Manager must only support authenticated access\nThe Preferences Manager must log all authentication events\nThe Preferences Manager must ensure that all authentication credentials are stored securely\nThe Preferences Manager must be resistent to replay attacks\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PMS Provider Application\"\nThe Preferences Manager must allow PEXA to configure a given notification type as either mandatory or optional within each jurisdiction\n\"The Preferences Manager must support the following jurisdictions:\n- Australia\n- UK\"\nThe Preferences Manager must support creating additional national and/or state level jurisdictions\nThe Preferences Manager must allow PEXA to configure individual notifications as unavailable in a given jurisdiction\nThe Preferences Manager must provide a confirmation response (success or fail) for all attempts to update subscription preferences.\nThe Preferences Manager must allow PMS providers to subscribe their applications to one or more notifications\nThe Preferences Manager must allow notification preference users to subscribe to one or more notifications\nThe Preferences Manager must allow registered notification parties to unsubscribe from notifications\nThe Preferences Manager must ensure that (within a preference profile) each notification deemed mandatory is configured to be delivered at least one channel\nThe Preferences Manager must allow PEXA subscribers to use more than one PMS within a single jurisdiction\nThe Preferences Manager must allow notification service users to set individual notification preferences per jurisdiction\nThe Notification Manager will only send notifications that the recipient has enabled via their notification preferences\nThe Preferences Manager must allow notification preferences users to retrieve their current notification preferences via API\nThe Notification Manager must perform processing compliant with General Data Protection Regulation (GDPR)\nThe Notification Manager must be capable of sending more than 100+ notifications per hour (peak processing)\nThe Notification Manager must ensure that UK notifications are sent in chronological sequence for each subscriber\nThe Notification Manager must include criticality level within notifications\nThe Email Push Notification Solution must confirm a notification is enabled under notification preferences before sending\nThe Email Push Notification Solution must not send a notification unless the recipient has previously enabled the notification for the email channel\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PEXA subscriber\"\nThe Preferences Manager must allow enable a single PEXA subscriber to define preferences against multiple integrators (e.g. PMS applications)\nThe Preferences Manager must allow PEXA to set preferences via API for notification services\nThe Notification Manager must support versioning of business events\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- Individual user (e.g. a Practitoner)\"\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PMS Provider\n- Corporate level (e.g. a Legal Practice)\n- Role level\n- Individual user\"\nThe Preferences Manager must allow PMS providers to update their notification subscription preferences via GUI.\nThe Preferences Manager must support sending the notification set details to authorised external parties\nThe Preferences Manager must support sending the notification set details to internal PEXA services\nThe Preferences Manager must create a new notifications set version each time there is a change to the contained notifications\nThe Preferences Manager must support sending the list of notifications available under the currently active notifications set \nThe Notification Manager must allow notifications to be pushed out to PEXA customer-facing applications",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_context",
                "display_name": "input_context",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              },
              "input_title": {
                "type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "{ \"Title\": \"Implement role-based access control for Preferences Manager\", \"Description\": \"Define user roles and permissions to control access to the Preferences Manager based on roles.\" }",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "input_title",
                "display_name": "input_title",
                "advanced": false,
                "input_types": [
                  "Document",
                  "BaseOutputParser"
                ],
                "dynamic": false,
                "info": "",
                "title_case": true
              }
            },
            "description": "Human message prompt template. This is a message sent from the user.",
            "icon": null,
            "base_classes": [
              "_StringImageMessagePromptTemplate",
              "HumanMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "name": "",
            "display_name": "HumanMessagePromptTemplate",
            "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
            "custom_fields": {
              "": [
                "input_context",
                "input_title"
              ]
            },
            "output_types": [],
            "full_path": null,
            "field_formatters": {},
            "beta": false,
            "error": null
          },
          "id": "HumanMessagePromptTemplate-OLdnC",
          "description": "Human message prompt template. This is a message sent from the user.",
          "display_name": "HumanMessagePromptTemplate"
        },
        "selected": false,
        "width": 384,
        "height": 487,
        "positionAbsolute": {
          "x": -276.37506574655634,
          "y": 687.3856062131241
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-bpnrm",
        "type": "genericNode",
        "position": {
          "x": -1080.5483895795674,
          "y": -105.92883593905408
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio import CustomComponent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langfuse import Langfuse\nimport os\n\nclass PromptRetrieverToString(CustomComponent):\n    display_name = \"PromptRetrieverToString\"\n    documentation = \"http://docs.axiestudio.org/components/custom\"\n    description = \"Get prompt from Langfuse and return the prompt string\"\n\n    def build_config(self):\n        return {\"prompt_name\": {\"display_name\": \"Prompt name\"}}\n\n    def build(self, prompt_name: str) -> str:\n        \n        langfuse = Langfuse(\n            secret_key=os.environ.get('LANGFLOW_LANGFUSE_SECRET_KEY', ''),\n            public_key=os.environ.get('LANGFLOW_LANGFUSE_PUBLIC_KEY', ''),\n            host=os.environ.get('LANGFLOW_LANGFUSE_HOST', ''),\n        )\n        langfuse_prompt = langfuse.get_prompt(prompt_name)\n        langchain_prompt = langfuse_prompt.get_langchain_prompt()\n    \n        return langchain_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt_name",
                "display_name": "Prompt name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": "generate-user-story_generate-unknowns_examples"
              },
              "_type": "CustomComponent"
            },
            "description": "Get prompt from Langfuse and return the prompt string",
            "base_classes": [
              "str"
            ],
            "display_name": "PromptRetrieverToString",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {
              "prompt_name": null
            },
            "output_types": [
              "str"
            ],
            "field_formatters": {},
            "beta": true,
            "official": false
          },
          "id": "CustomComponent-bpnrm"
        },
        "selected": false,
        "width": 384,
        "height": 394,
        "positionAbsolute": {
          "x": -1080.5483895795674,
          "y": -105.92883593905408
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-Jru9n",
        "type": "genericNode",
        "position": {
          "x": -1059.9800312150273,
          "y": 350.94420902975764
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from axiestudio import CustomComponent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langfuse import Langfuse\nimport os\n\nclass PromptRetrieverToString(CustomComponent):\n    display_name = \"PromptRetrieverToString\"\n    documentation = \"http://docs.axiestudio.org/components/custom\"\n    description = \"Get prompt from Langfuse and return the prompt string\"\n\n    def build_config(self):\n        return {\"prompt_name\": {\"display_name\": \"Prompt name\"}}\n\n    def build(self, prompt_name: str) -> str:\n        \n        langfuse = Langfuse(\n            secret_key=os.environ.get('LANGFLOW_LANGFUSE_SECRET_KEY', ''),\n            public_key=os.environ.get('LANGFLOW_LANGFUSE_PUBLIC_KEY', ''),\n            host=os.environ.get('LANGFLOW_LANGFUSE_HOST', ''),\n        )\n        langfuse_prompt = langfuse.get_prompt(prompt_name)\n        langchain_prompt = langfuse_prompt.get_langchain_prompt()\n    \n        return langchain_prompt\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": false,
                "dynamic": true,
                "info": "",
                "title_case": true
              },
              "prompt_name": {
                "type": "str",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "prompt_name",
                "display_name": "Prompt name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": true,
                "value": "generate-user-story_generate-unknowns_system-prompt"
              },
              "_type": "CustomComponent"
            },
            "description": "Get prompt from Langfuse and return the prompt string",
            "base_classes": [
              "str"
            ],
            "display_name": "PromptRetrieverToString",
            "documentation": "http://docs.axiestudio.org/components/custom",
            "custom_fields": {
              "prompt_name": null
            },
            "output_types": [
              "str"
            ],
            "field_formatters": {},
            "beta": true,
            "official": false
          },
          "id": "CustomComponent-Jru9n"
        },
        "selected": false,
        "width": 384,
        "height": 394,
        "positionAbsolute": {
          "x": -1059.9800312150273,
          "y": 350.94420902975764
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "ChatOpenAI-QVz5L",
        "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-QVz5Lœ}",
        "target": "LLMChain-RxurM",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "LLMChain-RxurM",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "dataType": "ChatOpenAI",
            "id": "ChatOpenAI-QVz5L"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatOpenAI-QVz5L{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-QVz5Lœ}-LLMChain-RxurM{œfieldNameœ:œllmœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
      },
      {
        "source": "ChatPromptTemplate-yFyBU",
        "sourceHandle": "{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-yFyBUœ}",
        "target": "LLMChain-RxurM",
        "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "prompt",
            "id": "LLMChain-RxurM",
            "inputTypes": null,
            "type": "BasePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "ChatPromptTemplate",
              "BaseChatPromptTemplate",
              "BasePromptTemplate"
            ],
            "dataType": "ChatPromptTemplate",
            "id": "ChatPromptTemplate-yFyBU"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ChatPromptTemplate-yFyBU{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-yFyBUœ}-LLMChain-RxurM{œfieldNameœ:œpromptœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
      },
      {
        "source": "SystemMessagePromptTemplate-36J1c",
        "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-36J1cœ}",
        "target": "ChatPromptTemplate-yFyBU",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-yFyBU",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "_StringImageMessagePromptTemplate",
              "SystemMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "dataType": "SystemMessagePromptTemplate",
            "id": "SystemMessagePromptTemplate-36J1c"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-SystemMessagePromptTemplate-36J1c{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-36J1cœ}-ChatPromptTemplate-yFyBU{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      },
      {
        "source": "HumanMessagePromptTemplate-OLdnC",
        "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-OLdnCœ}",
        "target": "ChatPromptTemplate-yFyBU",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "ChatPromptTemplate-yFyBU",
            "inputTypes": null,
            "type": "BaseMessagePromptTemplate"
          },
          "sourceHandle": {
            "baseClasses": [
              "_StringImageMessagePromptTemplate",
              "HumanMessagePromptTemplate",
              "BaseMessagePromptTemplate"
            ],
            "dataType": "HumanMessagePromptTemplate",
            "id": "HumanMessagePromptTemplate-OLdnC"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-HumanMessagePromptTemplate-OLdnC{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-OLdnCœ}-ChatPromptTemplate-yFyBU{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
      },
      {
        "source": "CustomComponent-bpnrm",
        "sourceHandle": "{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-bpnrmœ}",
        "target": "SystemMessagePromptTemplate-36J1c",
        "targetHandle": "{œfieldNameœ:œExamplesœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Examples",
            "id": "SystemMessagePromptTemplate-36J1c",
            "inputTypes": [
              "Document",
              "BaseOutputParser"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "str"
            ],
            "dataType": "CustomComponent",
            "id": "CustomComponent-bpnrm"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-CustomComponent-bpnrm{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-bpnrmœ}-SystemMessagePromptTemplate-36J1c{œfieldNameœ:œExamplesœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
      },
      {
        "source": "CustomComponent-Jru9n",
        "sourceHandle": "{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Jru9nœ}",
        "target": "SystemMessagePromptTemplate-36J1c",
        "targetHandle": "{œfieldNameœ:œInstructionsœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Instructions",
            "id": "SystemMessagePromptTemplate-36J1c",
            "inputTypes": [
              "Document",
              "BaseOutputParser"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "baseClasses": [
              "str"
            ],
            "dataType": "CustomComponent",
            "id": "CustomComponent-Jru9n"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-CustomComponent-Jru9n{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Jru9nœ}-SystemMessagePromptTemplate-36J1c{œfieldNameœ:œInstructionsœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
      }
    ],
    "viewport": {
      "x": 735.7742890713404,
      "y": 256.92468484883216,
      "zoom": 0.5547847360339239
    }
  },
  "metadata": {
    "LLMChain": {
      "count": 1
    },
    "ChatOpenAI": {
      "count": 1
    },
    "ChatPromptTemplate": {
      "count": 1
    },
    "SystemMessagePromptTemplate": {
      "count": 1
    },
    "HumanMessagePromptTemplate": {
      "count": 1
    },
    "CustomComponent": {
      "count": 2
    },
    "total": 7
  },
  "original": {
    "id": "4f018e20-b6a0-4aca-946c-5dbc6380d932",
    "name": "User story unknown question identification [v2]",
    "description": "Identify an unknowns / outstanding questions that can be detected from the supplied user story ",
    "is_component": false,
    "liked_by_count": "0",
    "downloads_count": "3",
    "metadata": {
      "LLMChain": {
        "count": 1
      },
      "ChatOpenAI": {
        "count": 1
      },
      "ChatPromptTemplate": {
        "count": 1
      },
      "SystemMessagePromptTemplate": {
        "count": 1
      },
      "HumanMessagePromptTemplate": {
        "count": 1
      },
      "CustomComponent": {
        "count": 2
      },
      "total": 7
    },
    "last_tested_version": "0.6.18",
    "private": true,
    "data": {
      "nodes": [
        {
          "id": "LLMChain-RxurM",
          "type": "genericNode",
          "position": {
            "x": 843,
            "y": 152.328125
          },
          "data": {
            "type": "LLMChain",
            "node": {
              "template": {
                "llm": {
                  "type": "BaseLanguageModel",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "llm",
                  "display_name": "LLM",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "memory": {
                  "type": "BaseMemory",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "memory",
                  "display_name": "Memory",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "BasePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt",
                  "display_name": "Prompt",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "Chain to run queries against LLMs",
              "base_classes": [
                "Chain",
                "Callable",
                "LLMChain",
                "Chain"
              ],
              "display_name": "LLMChain",
              "documentation": "",
              "custom_fields": {
                "prompt": null,
                "llm": null,
                "memory": null
              },
              "output_types": [
                "Chain",
                "Callable",
                "LLMChain"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "LLMChain-RxurM"
          },
          "selected": false,
          "width": 384,
          "height": 424
        },
        {
          "id": "ChatOpenAI-QVz5L",
          "type": "genericNode",
          "position": {
            "x": 114.35117376684252,
            "y": -648.2826353660611
          },
          "data": {
            "type": "ChatOpenAI",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from typing import Optional, Union\n\nfrom langchain.llms import BaseLLM\nfrom langchain_community.chat_models.openai import ChatOpenAI\n\nfrom axiestudio import CustomComponent\nfrom axiestudio.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"field_type\": \"int\",\n                \"advanced\": False,\n                \"required\": False,\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"field_type\": \"NestedDict\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"options\": [\n                    \"gpt-4-turbo-preview\",\n                    \"gpt-4-0125-preview\",\n                    \"gpt-4-1106-preview\",\n                    \"gpt-4-vision-preview\",\n                    \"gpt-3.5-turbo-0125\",\n                    \"gpt-3.5-turbo-1106\",\n                ],\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"field_type\": \"str\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"gpt-4-1106-preview\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> Union[BaseLanguageModel, BaseLLM]:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        return ChatOpenAI(\n            max_tokens=max_tokens,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=openai_api_key,\n            temperature=temperature,\n        )\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "max_tokens": {
                  "type": "int",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "1024",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "max_tokens",
                  "display_name": "Max Tokens",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "model_kwargs": {
                  "type": "NestedDict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": {},
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "model_kwargs",
                  "display_name": "Model Kwargs",
                  "advanced": true,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "model_name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "value": "gpt-3.5-turbo-0125",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "options": [
                    "gpt-4-turbo-preview",
                    "gpt-4-0125-preview",
                    "gpt-4-1106-preview",
                    "gpt-4-vision-preview",
                    "gpt-3.5-turbo-0125",
                    "gpt-3.5-turbo-1106"
                  ],
                  "name": "model_name",
                  "display_name": "Model Name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "openai_api_base": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "openai_api_base",
                  "display_name": "OpenAI API Base",
                  "advanced": false,
                  "dynamic": false,
                  "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.",
                  "title_case": true
                },
                "openai_api_key": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": true,
                  "name": "openai_api_key",
                  "display_name": "OpenAI API Key",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": ""
                },
                "temperature": {
                  "type": "float",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "value": "0.2",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "temperature",
                  "display_name": "Temperature",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "rangeSpec": {
                    "min": -1,
                    "max": 1,
                    "step": 0.1
                  },
                  "title_case": true
                },
                "_type": "CustomComponent"
              },
              "description": "`OpenAI` Chat large language models API.",
              "base_classes": [
                "BaseLanguageModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "display_name": "ChatOpenAI",
              "documentation": "",
              "custom_fields": {
                "max_tokens": null,
                "model_kwargs": null,
                "model_name": null,
                "openai_api_base": null,
                "openai_api_key": null,
                "temperature": null
              },
              "output_types": [
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "field_formatters": {},
              "beta": true
            },
            "id": "ChatOpenAI-QVz5L"
          },
          "selected": false,
          "width": 384,
          "height": 727,
          "dragging": false,
          "positionAbsolute": {
            "x": 114.35117376684252,
            "y": -648.2826353660611
          }
        },
        {
          "id": "ChatPromptTemplate-yFyBU",
          "type": "genericNode",
          "position": {
            "x": 278.3771975962494,
            "y": 370.60084381245076
          },
          "data": {
            "type": "ChatPromptTemplate",
            "node": {
              "template": {
                "messages": {
                  "type": "BaseMessagePromptTemplate",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "messages",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "output_parser": {
                  "type": "BaseOutputParser",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "output_parser",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_types": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_types",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "input_variables": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "input_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "metadata": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "metadata",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "name": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "name",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "partial_variables": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "partial_variables",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "tags": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": true,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "tags",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "validate_template": {
                  "type": "bool",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "value": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "validate_template",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "ChatPromptTemplate"
              },
              "description": "Prompt template for chat models.",
              "base_classes": [
                "ChatPromptTemplate",
                "BaseChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "display_name": "ChatPromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {},
              "output_types": [],
              "field_formatters": {},
              "beta": false
            },
            "id": "ChatPromptTemplate-yFyBU"
          },
          "selected": false,
          "width": 384,
          "height": 242,
          "positionAbsolute": {
            "x": 278.3771975962494,
            "y": 370.60084381245076
          },
          "dragging": false
        },
        {
          "id": "SystemMessagePromptTemplate-36J1c",
          "type": "genericNode",
          "position": {
            "x": -311.23654677629554,
            "y": 85.64612930849594
          },
          "data": {
            "type": "SystemMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": true,
                  "value": "## Instructions\n{Instructions}\n\n## EXAMPLES:\n\n{Examples}",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "SystemMessagePromptTemplate",
                "Instructions": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "Instructions",
                  "display_name": "Instructions",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "Examples": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "Examples",
                  "display_name": "Examples",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                }
              },
              "description": "System message prompt template.",
              "icon": null,
              "base_classes": [
                "_StringImageMessagePromptTemplate",
                "SystemMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "SystemMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {
                "": [
                  "Instructions",
                  "Examples"
                ]
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "SystemMessagePromptTemplate-36J1c",
            "description": "System message prompt template.",
            "display_name": "SystemMessagePromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 467,
          "positionAbsolute": {
            "x": -311.23654677629554,
            "y": 85.64612930849594
          },
          "dragging": false
        },
        {
          "id": "HumanMessagePromptTemplate-OLdnC",
          "type": "genericNode",
          "position": {
            "x": -276.37506574655634,
            "y": 687.3856062131241
          },
          "data": {
            "type": "HumanMessagePromptTemplate",
            "node": {
              "template": {
                "additional_kwargs": {
                  "type": "dict",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": false,
                  "multiline": false,
                  "fileTypes": [],
                  "password": false,
                  "name": "additional_kwargs",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt": {
                  "type": "prompt",
                  "required": true,
                  "placeholder": "",
                  "list": true,
                  "show": true,
                  "multiline": true,
                  "value": "#### CONTEXT\n{input_context}\n\n#### INPUT\n{input_title}",
                  "fileTypes": [],
                  "password": false,
                  "name": "prompt",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "_type": "HumanMessagePromptTemplate",
                "input_context": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "The Preferences Manager must support role based access\nThe Preferences Manager must only support authenticated access\nThe Preferences Manager must log all authentication events\nThe Preferences Manager must ensure that all authentication credentials are stored securely\nThe Preferences Manager must be resistent to replay attacks\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PMS Provider Application\"\nThe Preferences Manager must allow PEXA to configure a given notification type as either mandatory or optional within each jurisdiction\n\"The Preferences Manager must support the following jurisdictions:\n- Australia\n- UK\"\nThe Preferences Manager must support creating additional national and/or state level jurisdictions\nThe Preferences Manager must allow PEXA to configure individual notifications as unavailable in a given jurisdiction\nThe Preferences Manager must provide a confirmation response (success or fail) for all attempts to update subscription preferences.\nThe Preferences Manager must allow PMS providers to subscribe their applications to one or more notifications\nThe Preferences Manager must allow notification preference users to subscribe to one or more notifications\nThe Preferences Manager must allow registered notification parties to unsubscribe from notifications\nThe Preferences Manager must ensure that (within a preference profile) each notification deemed mandatory is configured to be delivered at least one channel\nThe Preferences Manager must allow PEXA subscribers to use more than one PMS within a single jurisdiction\nThe Preferences Manager must allow notification service users to set individual notification preferences per jurisdiction\nThe Notification Manager will only send notifications that the recipient has enabled via their notification preferences\nThe Preferences Manager must allow notification preferences users to retrieve their current notification preferences via API\nThe Notification Manager must perform processing compliant with General Data Protection Regulation (GDPR)\nThe Notification Manager must be capable of sending more than 100+ notifications per hour (peak processing)\nThe Notification Manager must ensure that UK notifications are sent in chronological sequence for each subscriber\nThe Notification Manager must include criticality level within notifications\nThe Email Push Notification Solution must confirm a notification is enabled under notification preferences before sending\nThe Email Push Notification Solution must not send a notification unless the recipient has previously enabled the notification for the email channel\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PEXA subscriber\"\nThe Preferences Manager must allow enable a single PEXA subscriber to define preferences against multiple integrators (e.g. PMS applications)\nThe Preferences Manager must allow PEXA to set preferences via API for notification services\nThe Notification Manager must support versioning of business events\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- Individual user (e.g. a Practitoner)\"\n\"The Preferences Manager must allow notification preferences to be set at the following entity levels:\n- PMS Provider\n- Corporate level (e.g. a Legal Practice)\n- Role level\n- Individual user\"\nThe Preferences Manager must allow PMS providers to update their notification subscription preferences via GUI.\nThe Preferences Manager must support sending the notification set details to authorised external parties\nThe Preferences Manager must support sending the notification set details to internal PEXA services\nThe Preferences Manager must create a new notifications set version each time there is a change to the contained notifications\nThe Preferences Manager must support sending the list of notifications available under the currently active notifications set \nThe Notification Manager must allow notifications to be pushed out to PEXA customer-facing applications",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_context",
                  "display_name": "input_context",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                },
                "input_title": {
                  "type": "str",
                  "required": false,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "{ \"Title\": \"Implement role-based access control for Preferences Manager\", \"Description\": \"Define user roles and permissions to control access to the Preferences Manager based on roles.\" }",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "input_title",
                  "display_name": "input_title",
                  "advanced": false,
                  "input_types": [
                    "Document",
                    "BaseOutputParser"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": true
                }
              },
              "description": "Human message prompt template. This is a message sent from the user.",
              "icon": null,
              "base_classes": [
                "_StringImageMessagePromptTemplate",
                "HumanMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "name": "",
              "display_name": "HumanMessagePromptTemplate",
              "documentation": "https://python.langchain.com/docs/modules/model_io/models/chat/how_to/prompts",
              "custom_fields": {
                "": [
                  "input_context",
                  "input_title"
                ]
              },
              "output_types": [],
              "full_path": null,
              "field_formatters": {},
              "beta": false,
              "error": null
            },
            "id": "HumanMessagePromptTemplate-OLdnC",
            "description": "Human message prompt template. This is a message sent from the user.",
            "display_name": "HumanMessagePromptTemplate"
          },
          "selected": false,
          "width": 384,
          "height": 487,
          "positionAbsolute": {
            "x": -276.37506574655634,
            "y": 687.3856062131241
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-bpnrm",
          "type": "genericNode",
          "position": {
            "x": -1080.5483895795674,
            "y": -105.92883593905408
          },
          "data": {
            "type": "CustomComponent",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio import CustomComponent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langfuse import Langfuse\nimport os\n\nclass PromptRetrieverToString(CustomComponent):\n    display_name = \"PromptRetrieverToString\"\n    documentation = \"http://docs.axiestudio.org/components/custom\"\n    description = \"Get prompt from Langfuse and return the prompt string\"\n\n    def build_config(self):\n        return {\"prompt_name\": {\"display_name\": \"Prompt name\"}}\n\n    def build(self, prompt_name: str) -> str:\n        \n        langfuse = Langfuse(\n            secret_key=os.environ.get('LANGFLOW_LANGFUSE_SECRET_KEY', ''),\n            public_key=os.environ.get('LANGFLOW_LANGFUSE_PUBLIC_KEY', ''),\n            host=os.environ.get('LANGFLOW_LANGFUSE_HOST', ''),\n        )\n        langfuse_prompt = langfuse.get_prompt(prompt_name)\n        langchain_prompt = langfuse_prompt.get_langchain_prompt()\n    \n        return langchain_prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt_name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt_name",
                  "display_name": "Prompt name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": "generate-user-story_generate-unknowns_examples"
                },
                "_type": "CustomComponent"
              },
              "description": "Get prompt from Langfuse and return the prompt string",
              "base_classes": [
                "str"
              ],
              "display_name": "PromptRetrieverToString",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {
                "prompt_name": null
              },
              "output_types": [
                "str"
              ],
              "field_formatters": {},
              "beta": true,
              "official": false
            },
            "id": "CustomComponent-bpnrm"
          },
          "selected": false,
          "width": 384,
          "height": 394,
          "positionAbsolute": {
            "x": -1080.5483895795674,
            "y": -105.92883593905408
          },
          "dragging": false
        },
        {
          "id": "CustomComponent-Jru9n",
          "type": "genericNode",
          "position": {
            "x": -1059.9800312150273,
            "y": 350.94420902975764
          },
          "data": {
            "type": "CustomComponent",
            "node": {
              "template": {
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "from axiestudio import CustomComponent\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langfuse import Langfuse\nimport os\n\nclass PromptRetrieverToString(CustomComponent):\n    display_name = \"PromptRetrieverToString\"\n    documentation = \"http://docs.axiestudio.org/components/custom\"\n    description = \"Get prompt from Langfuse and return the prompt string\"\n\n    def build_config(self):\n        return {\"prompt_name\": {\"display_name\": \"Prompt name\"}}\n\n    def build(self, prompt_name: str) -> str:\n        \n        langfuse = Langfuse(\n            secret_key=os.environ.get('LANGFLOW_LANGFUSE_SECRET_KEY', ''),\n            public_key=os.environ.get('LANGFLOW_LANGFUSE_PUBLIC_KEY', ''),\n            host=os.environ.get('LANGFLOW_LANGFUSE_HOST', ''),\n        )\n        langfuse_prompt = langfuse.get_prompt(prompt_name)\n        langchain_prompt = langfuse_prompt.get_langchain_prompt()\n    \n        return langchain_prompt\n",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": false,
                  "dynamic": true,
                  "info": "",
                  "title_case": true
                },
                "prompt_name": {
                  "type": "str",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": false,
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "prompt_name",
                  "display_name": "Prompt name",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": true,
                  "value": "generate-user-story_generate-unknowns_system-prompt"
                },
                "_type": "CustomComponent"
              },
              "description": "Get prompt from Langfuse and return the prompt string",
              "base_classes": [
                "str"
              ],
              "display_name": "PromptRetrieverToString",
              "documentation": "http://docs.axiestudio.org/components/custom",
              "custom_fields": {
                "prompt_name": null
              },
              "output_types": [
                "str"
              ],
              "field_formatters": {},
              "beta": true,
              "official": false
            },
            "id": "CustomComponent-Jru9n"
          },
          "selected": false,
          "width": 384,
          "height": 394,
          "positionAbsolute": {
            "x": -1059.9800312150273,
            "y": 350.94420902975764
          },
          "dragging": false
        }
      ],
      "edges": [
        {
          "source": "ChatOpenAI-QVz5L",
          "sourceHandle": "{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-QVz5Lœ}",
          "target": "LLMChain-RxurM",
          "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}",
          "data": {
            "targetHandle": {
              "fieldName": "llm",
              "id": "LLMChain-RxurM",
              "inputTypes": null,
              "type": "BaseLanguageModel"
            },
            "sourceHandle": {
              "baseClasses": [
                "BaseLanguageModel",
                "BaseLanguageModel",
                "BaseLLM"
              ],
              "dataType": "ChatOpenAI",
              "id": "ChatOpenAI-QVz5L"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatOpenAI-QVz5L{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œChatOpenAIœ,œidœ:œChatOpenAI-QVz5Lœ}-LLMChain-RxurM{œfieldNameœ:œllmœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"
        },
        {
          "source": "ChatPromptTemplate-yFyBU",
          "sourceHandle": "{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-yFyBUœ}",
          "target": "LLMChain-RxurM",
          "targetHandle": "{œfieldNameœ:œpromptœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "prompt",
              "id": "LLMChain-RxurM",
              "inputTypes": null,
              "type": "BasePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "ChatPromptTemplate",
                "BaseChatPromptTemplate",
                "BasePromptTemplate"
              ],
              "dataType": "ChatPromptTemplate",
              "id": "ChatPromptTemplate-yFyBU"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-ChatPromptTemplate-yFyBU{œbaseClassesœ:[œChatPromptTemplateœ,œBaseChatPromptTemplateœ,œBasePromptTemplateœ],œdataTypeœ:œChatPromptTemplateœ,œidœ:œChatPromptTemplate-yFyBUœ}-LLMChain-RxurM{œfieldNameœ:œpromptœ,œidœ:œLLMChain-RxurMœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"
        },
        {
          "source": "SystemMessagePromptTemplate-36J1c",
          "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-36J1cœ}",
          "target": "ChatPromptTemplate-yFyBU",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-yFyBU",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "_StringImageMessagePromptTemplate",
                "SystemMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "dataType": "SystemMessagePromptTemplate",
              "id": "SystemMessagePromptTemplate-36J1c"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-SystemMessagePromptTemplate-36J1c{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œSystemMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œSystemMessagePromptTemplateœ,œidœ:œSystemMessagePromptTemplate-36J1cœ}-ChatPromptTemplate-yFyBU{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        },
        {
          "source": "HumanMessagePromptTemplate-OLdnC",
          "sourceHandle": "{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-OLdnCœ}",
          "target": "ChatPromptTemplate-yFyBU",
          "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}",
          "data": {
            "targetHandle": {
              "fieldName": "messages",
              "id": "ChatPromptTemplate-yFyBU",
              "inputTypes": null,
              "type": "BaseMessagePromptTemplate"
            },
            "sourceHandle": {
              "baseClasses": [
                "_StringImageMessagePromptTemplate",
                "HumanMessagePromptTemplate",
                "BaseMessagePromptTemplate"
              ],
              "dataType": "HumanMessagePromptTemplate",
              "id": "HumanMessagePromptTemplate-OLdnC"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-gray-900  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-HumanMessagePromptTemplate-OLdnC{œbaseClassesœ:[œ_StringImageMessagePromptTemplateœ,œHumanMessagePromptTemplateœ,œBaseMessagePromptTemplateœ],œdataTypeœ:œHumanMessagePromptTemplateœ,œidœ:œHumanMessagePromptTemplate-OLdnCœ}-ChatPromptTemplate-yFyBU{œfieldNameœ:œmessagesœ,œidœ:œChatPromptTemplate-yFyBUœ,œinputTypesœ:null,œtypeœ:œBaseMessagePromptTemplateœ}"
        },
        {
          "source": "CustomComponent-bpnrm",
          "sourceHandle": "{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-bpnrmœ}",
          "target": "SystemMessagePromptTemplate-36J1c",
          "targetHandle": "{œfieldNameœ:œExamplesœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Examples",
              "id": "SystemMessagePromptTemplate-36J1c",
              "inputTypes": [
                "Document",
                "BaseOutputParser"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "str"
              ],
              "dataType": "CustomComponent",
              "id": "CustomComponent-bpnrm"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-CustomComponent-bpnrm{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-bpnrmœ}-SystemMessagePromptTemplate-36J1c{œfieldNameœ:œExamplesœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
        },
        {
          "source": "CustomComponent-Jru9n",
          "sourceHandle": "{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Jru9nœ}",
          "target": "SystemMessagePromptTemplate-36J1c",
          "targetHandle": "{œfieldNameœ:œInstructionsœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}",
          "data": {
            "targetHandle": {
              "fieldName": "Instructions",
              "id": "SystemMessagePromptTemplate-36J1c",
              "inputTypes": [
                "Document",
                "BaseOutputParser"
              ],
              "type": "str"
            },
            "sourceHandle": {
              "baseClasses": [
                "str"
              ],
              "dataType": "CustomComponent",
              "id": "CustomComponent-Jru9n"
            }
          },
          "style": {
            "stroke": "#555"
          },
          "className": "stroke-foreground  stroke-connection",
          "animated": false,
          "id": "reactflow__edge-CustomComponent-Jru9n{œbaseClassesœ:[œstrœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Jru9nœ}-SystemMessagePromptTemplate-36J1c{œfieldNameœ:œInstructionsœ,œidœ:œSystemMessagePromptTemplate-36J1cœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}"
        }
      ],
      "viewport": {
        "x": 735.7742890713404,
        "y": 256.92468484883216,
        "zoom": 0.5547847360339239
      }
    },
    "date_created": "2024-05-06T14:18:14.789Z",
    "date_updated": "2024-05-07T02:22:15.432Z",
    "status": "Public",
    "sort": null,
    "user_updated": "dc599610-3065-4b5b-94ed-de108ec210dd",
    "user_created": {
      "username": "wiresky",
      "first_name": "Nguyen",
      "last_name": "Nam",
      "id": "dc599610-3065-4b5b-94ed-de108ec210dd"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:08:57.731Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 20,
    "converter_version": "1.0.0"
  }
}