{
  "id": "7d8c0b76-99e7-4ee7-a925-9f2affc117a5",
  "name": "Microsoft GraphRAG Store",
  "description": "A component that uses GraphRag to index data. (Converted from Langflow Store for AxieStudio compatibility)",
  "type": "COMPONENT",
  "is_component": true,
  "author": {
    "username": "yamon",
    "first_name": "YamonCompany",
    "last_name": "kim",
    "id": "23c5d1e9-66fe-4789-85da-d07be25ec3cc",
    "full_name": "YamonCompany kim"
  },
  "store_url": "https://www.langflow.store/store/component/7d8c0b76-99e7-4ee7-a925-9f2affc117a5",
  "stats": {
    "downloads": 0,
    "likes": 0
  },
  "dates": {
    "created": "2024-07-23T08:46:03.042Z",
    "updated": "2024-07-23T08:46:03.110Z",
    "downloaded": "2025-08-19T17:50:06.354Z"
  },
  "tags": [],
  "technical": {
    "last_tested_version": "1.0.12",
    "private": false,
    "status": "Public"
  },
  "data": {
    "edges": [],
    "nodes": [
      {
        "data": {
          "type": "GraphRagStore",
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "ingest_data": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "ingest_data",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "llm",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\r\nimport shutil\r\nimport yaml\r\nfrom pathlib import Path\r\nimport subprocess\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DropdownInput, DataInput, Output, HandleInput, MessageTextInput\r\nfrom axiestudio.schema.message import Message\r\n\r\nfrom graphrag.index.cli import index_cli\r\nfrom graphrag.index.graph.extractors.claims.prompts import CLAIM_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.community_reports.prompts import COMMUNITY_REPORT_PROMPT\r\nfrom graphrag.index.graph.extractors.graph.prompts import GRAPH_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.summarize.prompts import SUMMARIZE_PROMPT\r\nfrom graphrag.index.init_content import INIT_DOTENV, INIT_YAML\r\nfrom graphrag.index.progress import ProgressReporter, NullProgressReporter\r\nfrom graphrag.index.progress.rich import RichProgressReporter\r\nfrom graphrag.config import StorageType\r\nimport graphrag.config.defaults as defs\r\n\r\nclass GraphRagStore(Component):\r\n    display_name = \"Microsoft GraphRAG Store\"\r\n    description = \"A component that uses GraphRag to index data.\"\r\n    STORAGE_TYPES = [StorageType.memory.value, StorageType.blob.value, StorageType.file.value]\r\n    ACCEPTED_LLM = [\"ollama-chat\", \"openai-chat\"]\r\n    \r\n    inputs = [\r\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\r\n        HandleInput(\r\n            name=\"embedding\",\r\n            display_name=\"Embedding\",\r\n            input_types=[\"Embeddings\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"persist_directory\",\r\n            display_name=\"Persist Directory\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"storage_type\",\r\n            display_name=\"Storage Type\",\r\n            advanced=False,\r\n            options=STORAGE_TYPES,\r\n            value='file',\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"ingest_data\",\r\n            display_name=\"Ingest Data\",\r\n            required=True,\r\n            is_list=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"result_text\", method=\"save_data\")\r\n    ]\r\n    \r\n    def save_data(self) -> Message:\r\n        if not self.llm._llm_type or (self.llm._llm_type != \"ollama-chat\" and self.llm._llm_type != \"openai-chat\"):\r\n            raise ValueError(\"LLM must be Ollama or OpenAI model.\")\r\n        \r\n        if not self.embedding.model:\r\n            raise ValueError(\"Embedding must be Ollama or OpenAI embbedding.\")\r\n\r\n        is_saved = False\r\n        try:\r\n            progress_reporter = RichProgressReporter(\"GraphRAG Indexer \")\r\n            self.try_initialize_project_at(progress_reporter)\r\n            \r\n            self.set_settings()\r\n            \r\n            with open('/link_volumes/graphrag/test.txt', 'w') as f:\r\n                subprocess.call(['python', \"-m\", \"graphrag.index\", \"--root\", self.persist_directory], stdout=f)\r\n            \r\n            # index_cli(\r\n            #     root=self.persist_directory,\r\n            #     init=False,\r\n            #     verbose=False,\r\n            #     resume=None,\r\n            #     memprofile=True,\r\n            #     nocache=False,\r\n            #     reporter='none',\r\n            #     config=None,\r\n            #     emit=None,\r\n            #     dryrun=False,\r\n            #     cli=False,\r\n            # )\r\n            is_saved = True\r\n        except Exception as e:\r\n            is_saved = False\r\n            raise ValueError(f\"An error occurred: {str(e.with_traceback(None))}\")\r\n\r\n        if is_saved:\r\n            result = Message(text=\"Data saved successfully.\")\r\n        else:\r\n            result = Message(text=\"Data not saved.\")\r\n\r\n        self.status = result\r\n        return result\r\n\r\n    def try_initialize_project_at(self, reporter: ProgressReporter):\r\n        \"\"\"Initialize the project at the given path.\"\"\"\r\n        reporter.info(f\"Initializing project at {self.persist_directory}\")\r\n        root = Path(self.persist_directory)\r\n        if not root.exists():\r\n            root.mkdir(parents=True, exist_ok=True)\r\n\r\n        input_path = os.path.join(self.persist_directory, defs.INPUT_BASE_DIR)\r\n        if not os.path.exists(input_path):\r\n            os.makedirs(input_path)\r\n        for filename in os.listdir(input_path):\r\n            file_path = os.path.join(input_path, filename)\r\n            try:\r\n                if os.path.isfile(file_path) or os.path.islink(file_path):\r\n                    os.unlink(file_path)\r\n                elif os.path.isdir(file_path):\r\n                    shutil.rmtree(file_path)\r\n            except Exception as e:\r\n                print('Failed to delete %s. Reason: %s' % (file_path, e))\r\n        for i in range(len(self.ingest_data)):\r\n            f = open(os.path.join(input_path, f\"data{i}.txt\"), \"w\", encoding='utf-8')\r\n            f.write(self.ingest_data[i].get_text())\r\n            f.close()\r\n        \r\n        settings_yaml = root / \"settings.yaml\"\r\n        if settings_yaml.exists():\r\n            return\r\n\r\n        dotenv = root / \".env\"\r\n        if not dotenv.exists():\r\n            with settings_yaml.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(INIT_YAML)\r\n\r\n        with dotenv.open(\"w\", encoding=\"utf-8\") as file:\r\n            file.write(INIT_DOTENV)\r\n\r\n        prompts_dir = root / \"prompts\"\r\n        if not prompts_dir.exists():\r\n            prompts_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n        entity_extraction = prompts_dir / \"entity_extraction.txt\"\r\n        if not entity_extraction.exists():\r\n            with entity_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(GRAPH_EXTRACTION_PROMPT)\r\n\r\n        summarize_descriptions = prompts_dir / \"summarize_descriptions.txt\"\r\n        if not summarize_descriptions.exists():\r\n            with summarize_descriptions.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(SUMMARIZE_PROMPT)\r\n\r\n        claim_extraction = prompts_dir / \"claim_extraction.txt\"\r\n        if not claim_extraction.exists():\r\n            with claim_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(CLAIM_EXTRACTION_PROMPT)\r\n\r\n        community_report = prompts_dir / \"community_report.txt\"\r\n        if not community_report.exists():\r\n            with community_report.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(COMMUNITY_REPORT_PROMPT)\r\n                \r\n    def set_settings(self):\r\n        env_path = os.path.join(self.persist_directory, \".env\")\r\n        if os.path.isfile(env_path) or os.path.islink(env_path):\r\n            os.unlink(env_path)\r\n        f = open(env_path, \"w\", encoding='utf-8')\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            f.write(\"GRAPHRAG_API_KEY=ollama\\n\")\r\n        else:\r\n            f.write(f\"GRAPHRAG_API_KEY={self.llm.openai_api_key.get_secret_value()}\\n\")\r\n        f.close()\r\n\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"r\", encoding='utf-8') as f:\r\n            configs = yaml.safe_load(f)\r\n        configs['embeddings']['llm']['model'] = self.embedding.model\r\n        configs['storage']['type'] = self.storage_type\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            configs['llm']['model'] = self.llm.model\r\n            configs['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['llm']['api_base'] = f'{self.llm.base_url}/v1'\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['embeddings']['llm']['api_base'] = f'{self.llm.base_url}/api'\r\n        else:\r\n            configs['llm']['model'] = self.llm.model_name\r\n            if configs['llm'].get('api_base'):\r\n                del configs['llm']['api_base']\r\n            configs['llm']['lang_llm_type'] = \"openai\"\r\n            if configs['embeddings']['llm'].get('api_base'):\r\n                del configs['embeddings']['llm']['api_base']\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"openai\"\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"w\", encoding='utf-8') as f:\r\n            yaml.dump(configs, f)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "persist_directory": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "value": "",
                "name": "persist_directory",
                "display_name": "Persist Directory",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              },
              "storage_type": {
                "trace_as_metadata": true,
                "options": [
                  "memory",
                  "blob",
                  "file"
                ],
                "required": true,
                "placeholder": "",
                "show": true,
                "value": "file",
                "name": "storage_type",
                "display_name": "Storage Type",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str"
              }
            },
            "description": "A component that uses GraphRag to index data.",
            "base_classes": [
              "Message"
            ],
            "display_name": "Microsoft GraphRAG Store",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "result_text",
                "display_name": "Text",
                "method": "save_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "llm",
              "embedding",
              "persist_directory",
              "storage_type",
              "ingest_data"
            ],
            "beta": false,
            "edited": true,
            "official": false
          },
          "id": "GraphRagStore-9ItbB",
          "description": "A component that uses GraphRag to index data.",
          "display_name": "GraphRAG Vector Store"
        },
        "id": "GraphRagStore-9ItbB",
        "position": {
          "x": 0,
          "y": 0
        },
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 1,
      "y": 1,
      "zoom": 1
    }
  },
  "metadata": {
    "GraphRagStore": {
      "count": 1
    },
    "total": 1
  },
  "original": {
    "id": "7d8c0b76-99e7-4ee7-a925-9f2affc117a5",
    "name": "Microsoft GraphRAG Store",
    "description": "A component that uses GraphRag to index data.",
    "is_component": true,
    "liked_by_count": "25",
    "downloads_count": "204",
    "metadata": {
      "GraphRagStore": {
        "count": 1
      },
      "total": 1
    },
    "last_tested_version": "1.0.12",
    "private": false,
    "data": {
      "edges": [],
      "nodes": [
        {
          "data": {
            "type": "GraphRagStore",
            "node": {
              "template": {
                "_type": "Component",
                "embedding": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "embedding",
                  "display_name": "Embedding",
                  "advanced": false,
                  "input_types": [
                    "Embeddings"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "ingest_data": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "list": true,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "ingest_data",
                  "display_name": "Ingest Data",
                  "advanced": false,
                  "input_types": [
                    "Data"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "llm": {
                  "trace_as_metadata": true,
                  "list": false,
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "llm",
                  "display_name": "Language Model",
                  "advanced": false,
                  "input_types": [
                    "LanguageModel"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "other"
                },
                "code": {
                  "type": "code",
                  "required": true,
                  "placeholder": "",
                  "list": false,
                  "show": true,
                  "multiline": true,
                  "value": "import os\r\nimport shutil\r\nimport yaml\r\nfrom pathlib import Path\r\nimport subprocess\r\n\r\nfrom axiestudio.custom import Component\r\nfrom axiestudio.io import DropdownInput, DataInput, Output, HandleInput, MessageTextInput\r\nfrom axiestudio.schema.message import Message\r\n\r\nfrom graphrag.index.cli import index_cli\r\nfrom graphrag.index.graph.extractors.claims.prompts import CLAIM_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.community_reports.prompts import COMMUNITY_REPORT_PROMPT\r\nfrom graphrag.index.graph.extractors.graph.prompts import GRAPH_EXTRACTION_PROMPT\r\nfrom graphrag.index.graph.extractors.summarize.prompts import SUMMARIZE_PROMPT\r\nfrom graphrag.index.init_content import INIT_DOTENV, INIT_YAML\r\nfrom graphrag.index.progress import ProgressReporter, NullProgressReporter\r\nfrom graphrag.index.progress.rich import RichProgressReporter\r\nfrom graphrag.config import StorageType\r\nimport graphrag.config.defaults as defs\r\n\r\nclass GraphRagStore(Component):\r\n    display_name = \"Microsoft GraphRAG Store\"\r\n    description = \"A component that uses GraphRag to index data.\"\r\n    STORAGE_TYPES = [StorageType.memory.value, StorageType.blob.value, StorageType.file.value]\r\n    ACCEPTED_LLM = [\"ollama-chat\", \"openai-chat\"]\r\n    \r\n    inputs = [\r\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\r\n        HandleInput(\r\n            name=\"embedding\",\r\n            display_name=\"Embedding\",\r\n            input_types=[\"Embeddings\"],\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"persist_directory\",\r\n            display_name=\"Persist Directory\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"storage_type\",\r\n            display_name=\"Storage Type\",\r\n            advanced=False,\r\n            options=STORAGE_TYPES,\r\n            value='file',\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"ingest_data\",\r\n            display_name=\"Ingest Data\",\r\n            required=True,\r\n            is_list=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"result_text\", method=\"save_data\")\r\n    ]\r\n    \r\n    def save_data(self) -> Message:\r\n        if not self.llm._llm_type or (self.llm._llm_type != \"ollama-chat\" and self.llm._llm_type != \"openai-chat\"):\r\n            raise ValueError(\"LLM must be Ollama or OpenAI model.\")\r\n        \r\n        if not self.embedding.model:\r\n            raise ValueError(\"Embedding must be Ollama or OpenAI embbedding.\")\r\n\r\n        is_saved = False\r\n        try:\r\n            progress_reporter = RichProgressReporter(\"GraphRAG Indexer \")\r\n            self.try_initialize_project_at(progress_reporter)\r\n            \r\n            self.set_settings()\r\n            \r\n            with open('/link_volumes/graphrag/test.txt', 'w') as f:\r\n                subprocess.call(['python', \"-m\", \"graphrag.index\", \"--root\", self.persist_directory], stdout=f)\r\n            \r\n            # index_cli(\r\n            #     root=self.persist_directory,\r\n            #     init=False,\r\n            #     verbose=False,\r\n            #     resume=None,\r\n            #     memprofile=True,\r\n            #     nocache=False,\r\n            #     reporter='none',\r\n            #     config=None,\r\n            #     emit=None,\r\n            #     dryrun=False,\r\n            #     cli=False,\r\n            # )\r\n            is_saved = True\r\n        except Exception as e:\r\n            is_saved = False\r\n            raise ValueError(f\"An error occurred: {str(e.with_traceback(None))}\")\r\n\r\n        if is_saved:\r\n            result = Message(text=\"Data saved successfully.\")\r\n        else:\r\n            result = Message(text=\"Data not saved.\")\r\n\r\n        self.status = result\r\n        return result\r\n\r\n    def try_initialize_project_at(self, reporter: ProgressReporter):\r\n        \"\"\"Initialize the project at the given path.\"\"\"\r\n        reporter.info(f\"Initializing project at {self.persist_directory}\")\r\n        root = Path(self.persist_directory)\r\n        if not root.exists():\r\n            root.mkdir(parents=True, exist_ok=True)\r\n\r\n        input_path = os.path.join(self.persist_directory, defs.INPUT_BASE_DIR)\r\n        if not os.path.exists(input_path):\r\n            os.makedirs(input_path)\r\n        for filename in os.listdir(input_path):\r\n            file_path = os.path.join(input_path, filename)\r\n            try:\r\n                if os.path.isfile(file_path) or os.path.islink(file_path):\r\n                    os.unlink(file_path)\r\n                elif os.path.isdir(file_path):\r\n                    shutil.rmtree(file_path)\r\n            except Exception as e:\r\n                print('Failed to delete %s. Reason: %s' % (file_path, e))\r\n        for i in range(len(self.ingest_data)):\r\n            f = open(os.path.join(input_path, f\"data{i}.txt\"), \"w\", encoding='utf-8')\r\n            f.write(self.ingest_data[i].get_text())\r\n            f.close()\r\n        \r\n        settings_yaml = root / \"settings.yaml\"\r\n        if settings_yaml.exists():\r\n            return\r\n\r\n        dotenv = root / \".env\"\r\n        if not dotenv.exists():\r\n            with settings_yaml.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(INIT_YAML)\r\n\r\n        with dotenv.open(\"w\", encoding=\"utf-8\") as file:\r\n            file.write(INIT_DOTENV)\r\n\r\n        prompts_dir = root / \"prompts\"\r\n        if not prompts_dir.exists():\r\n            prompts_dir.mkdir(parents=True, exist_ok=True)\r\n\r\n        entity_extraction = prompts_dir / \"entity_extraction.txt\"\r\n        if not entity_extraction.exists():\r\n            with entity_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(GRAPH_EXTRACTION_PROMPT)\r\n\r\n        summarize_descriptions = prompts_dir / \"summarize_descriptions.txt\"\r\n        if not summarize_descriptions.exists():\r\n            with summarize_descriptions.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(SUMMARIZE_PROMPT)\r\n\r\n        claim_extraction = prompts_dir / \"claim_extraction.txt\"\r\n        if not claim_extraction.exists():\r\n            with claim_extraction.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(CLAIM_EXTRACTION_PROMPT)\r\n\r\n        community_report = prompts_dir / \"community_report.txt\"\r\n        if not community_report.exists():\r\n            with community_report.open(\"w\", encoding=\"utf-8\") as file:\r\n                file.write(COMMUNITY_REPORT_PROMPT)\r\n                \r\n    def set_settings(self):\r\n        env_path = os.path.join(self.persist_directory, \".env\")\r\n        if os.path.isfile(env_path) or os.path.islink(env_path):\r\n            os.unlink(env_path)\r\n        f = open(env_path, \"w\", encoding='utf-8')\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            f.write(\"GRAPHRAG_API_KEY=ollama\\n\")\r\n        else:\r\n            f.write(f\"GRAPHRAG_API_KEY={self.llm.openai_api_key.get_secret_value()}\\n\")\r\n        f.close()\r\n\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"r\", encoding='utf-8') as f:\r\n            configs = yaml.safe_load(f)\r\n        configs['embeddings']['llm']['model'] = self.embedding.model\r\n        configs['storage']['type'] = self.storage_type\r\n        if self.llm._llm_type == \"ollama-chat\":\r\n            configs['llm']['model'] = self.llm.model\r\n            configs['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['llm']['api_base'] = f'{self.llm.base_url}/v1'\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"ollama\"\r\n            configs['embeddings']['llm']['api_base'] = f'{self.llm.base_url}/api'\r\n        else:\r\n            configs['llm']['model'] = self.llm.model_name\r\n            if configs['llm'].get('api_base'):\r\n                del configs['llm']['api_base']\r\n            configs['llm']['lang_llm_type'] = \"openai\"\r\n            if configs['embeddings']['llm'].get('api_base'):\r\n                del configs['embeddings']['llm']['api_base']\r\n            configs['embeddings']['llm']['lang_llm_type'] = \"openai\"\r\n        with open(os.path.join(self.persist_directory, \"settings.yaml\"), \"w\", encoding='utf-8') as f:\r\n            yaml.dump(configs, f)",
                  "fileTypes": [],
                  "file_path": "",
                  "password": false,
                  "name": "code",
                  "advanced": true,
                  "dynamic": true,
                  "info": "",
                  "load_from_db": false,
                  "title_case": false
                },
                "persist_directory": {
                  "trace_as_input": true,
                  "trace_as_metadata": true,
                  "load_from_db": false,
                  "list": false,
                  "required": false,
                  "placeholder": "",
                  "show": true,
                  "value": "",
                  "name": "persist_directory",
                  "display_name": "Persist Directory",
                  "advanced": false,
                  "input_types": [
                    "Message"
                  ],
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                },
                "storage_type": {
                  "trace_as_metadata": true,
                  "options": [
                    "memory",
                    "blob",
                    "file"
                  ],
                  "required": true,
                  "placeholder": "",
                  "show": true,
                  "value": "file",
                  "name": "storage_type",
                  "display_name": "Storage Type",
                  "advanced": false,
                  "dynamic": false,
                  "info": "",
                  "title_case": false,
                  "type": "str"
                }
              },
              "description": "A component that uses GraphRag to index data.",
              "base_classes": [
                "Message"
              ],
              "display_name": "Microsoft GraphRAG Store",
              "documentation": "",
              "custom_fields": {},
              "output_types": [],
              "pinned": false,
              "conditional_paths": [],
              "frozen": false,
              "outputs": [
                {
                  "types": [
                    "Message"
                  ],
                  "selected": "Message",
                  "name": "result_text",
                  "display_name": "Text",
                  "method": "save_data",
                  "value": "__UNDEFINED__",
                  "cache": true
                }
              ],
              "field_order": [
                "llm",
                "embedding",
                "persist_directory",
                "storage_type",
                "ingest_data"
              ],
              "beta": false,
              "edited": true,
              "official": false
            },
            "id": "GraphRagStore-9ItbB",
            "description": "A component that uses GraphRag to index data.",
            "display_name": "GraphRAG Vector Store"
          },
          "id": "GraphRagStore-9ItbB",
          "position": {
            "x": 0,
            "y": 0
          },
          "type": "genericNode"
        }
      ],
      "viewport": {
        "x": 1,
        "y": 1,
        "zoom": 1
      }
    },
    "date_created": "2024-07-23T08:46:03.042Z",
    "date_updated": "2024-07-23T08:46:03.110Z",
    "status": "Public",
    "sort": null,
    "user_updated": "23c5d1e9-66fe-4789-85da-d07be25ec3cc",
    "user_created": {
      "username": "yamon",
      "first_name": "YamonCompany",
      "last_name": "kim",
      "id": "23c5d1e9-66fe-4789-85da-d07be25ec3cc"
    },
    "tags": []
  },
  "conversion": {
    "converted_at": "2025-08-19T18:09:10.758Z",
    "converted_from": "langflow",
    "converted_to": "axiestudio",
    "conversions_made": 6,
    "converter_version": "1.0.0"
  }
}